{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#documentation","title":"Documentation","text":"<p>CAREamics is a PyTorch library aimed at simplifying the use of Noise2Void and its many variants and cousins (CARE, Noise2Noise, N2V2, P(P)N2V, HDN, muSplit etc.).</p>"},{"location":"#why-careamics","title":"Why CAREamics?","text":"<p>Noise2Void is a widely used denoising algorithm, and is readily available from the <code>n2v</code> python package. However, n2v is based on TensorFlow and Keras and we found it  increasingly hard to maintain. In addition, more recent methods (PPN2V, DivNoising, HDN) are all implemented in PyTorch, but are lacking the extra features that would make them usable by the community.</p> <p>The aim of CAREamics is to provide a PyTorch library reuniting all the latest methods in one package, while providing a simple and consistent API. The library relies on  PyTorch Lightning as a back-end. In addition, we will provide extensive documentation and  tutorials on how to best apply these methods in a scientific context.</p> <p>Work in progress</p> <p>These pages are still under construction.</p>"},{"location":"#getting-started","title":"Getting Started","text":"Installation <p>                                     Get started with CAREamics installation.                                 </p> Current State <p>                                     Check out where we stand and where we want to go.                                 </p> Guides <p>                                     In-depth guides on CAREamics usage and features.                                 </p> Applications <p>                                     Examples of CAREamics in action on various datasets.                                 </p> Algorithms <p>                                     Dive into the various CAREamics algorithms.                                 </p> Code Reference <p>                                     Code documentation for all CAREamics libraries.                                 </p>"},{"location":"#feedback","title":"Feedback","text":"<p>We are always welcoming feedback on what to improve of what features could be useful, therefore do not hesitate to open an issue on the Github repository!</p>"},{"location":"current_state/","title":"Current state","text":"<p>CAREamics is an on-going project and will include new algorithms in the next releases.  We are currently reaching Milestone 1. Here is a list of the current features:</p>"},{"location":"current_state/#algorithms","title":"Algorithms","text":"<ul> <li> Noise2Void 2D/3D/Channels</li> <li> structN2V 2D/3D/Channels</li> <li> N2V2 2D/3D/Channels</li> <li> CARE 2D/3D/Channels</li> <li> Noise2Noise 2D/3D/Channels</li> <li> CryoCARE 2D/3D</li> <li> PN2V 2D/3D/Channels</li> <li> PPN2V 2D/3D/Channels</li> <li> DivNoising/HDN 2D/3D/Channels</li> <li> muSplit 2D/3D</li> <li> denoiSplit 2D/3D</li> <li> EmbedSeg</li> </ul>"},{"location":"current_state/#features","title":"Features","text":"<ul> <li> Pydantic configuration</li> <li> TIFF dataloader</li> <li> In memory dataset</li> <li> Training/prediction</li> <li> Tiled prediction</li> <li> Checkpoint saving/loading</li> <li> Save/load bioimage.io format</li> <li> Zarr dataset</li> <li> AMP</li> <li> torch.compile</li> <li> napari plugin</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>CAREamics is a deep-learning library and we therefore recommend having GPU support as training the algorithms on the CPU can be very slow. MacOS users can also benefit from GPU-acceleration if they have the new chip generations (M1, M2, etc.).</p> <p>Support is provided directly from PyTorch, and is still experimental for macOS.</p>"},{"location":"installation/#step-by-step","title":"Step-by-step","text":"<p>We recommend using mamba (miniforge)  to install all packages in a virtual environment. As an alternative, you can use conda  (miniconda). </p> Linux and WindowsmacOS <ol> <li>Open the terminal and type <code>mamba</code> to verify that mamba is available.</li> <li> <p>Create a new environment:</p> <pre><code>mamba create -n careamics python=3.10\nmamba activate careamics\n</code></pre> </li> <li> <p>Install PyTorch following the official      instructions</p> <p>As an example, our test machine requires:</p> <pre><code>mamba install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia\n</code></pre> </li> <li> <p>Verify that the GPU is available:</p> <pre><code>python -c \"import torch; print([torch.cuda.get_device_properties(i) for i in range(torch.cuda.device_count())])\"\n</code></pre> <p>This should show a list of available GPUs. If the list is empty, then you will need to change the <code>pytorch</code> and <code>pytorch-cuda</code> versions to match your hardware (linux and windows).</p> </li> <li> <p>Install CAREamics. We have several extra options (<code>dev</code>, <code>examples</code>, <code>wandb</code>     and <code>tensorboard</code>). If you wish to run the example notebooks,     we recommend the following:</p> <pre><code>pip install --pre \"careamics[examples]\"\n</code></pre> </li> </ol> <p>These instructions were tested on a linux virtual machine (RedHat 8.6) with a  NVIDIA A40-8Q GPU.</p> <ol> <li>Open the terminal and type <code>mamba</code> to verify that mamba is available.</li> <li> <p>Create a new environment:</p> <pre><code>mamba create -n careamics python=3.10\nmamba activate careamics\n</code></pre> </li> <li> <p>Install PyTorch following the official      instructions</p> <p>As an example, our test machine requires:</p> <pre><code>mamba install pytorch::pytorch torchvision torchaudio -c pytorch\n</code></pre> <p> Note that accelerated-training is only available on macOS silicon.</p> </li> <li> <p>Install CAREamics. We have several extra options (<code>dev</code>, <code>examples</code>, <code>wandb</code>     and <code>tensorboard</code>). If you wish to run the example notebooks,     we recommend the following:</p> <pre><code>pip install --pre \"careamics[examples]\"\n</code></pre> </li> </ol>"},{"location":"installation/#extra-dependencies","title":"Extra dependencies","text":"<p>CAREamics extra dependencies can be installed by specifying them in brackets. In the previous section we installed <code>careamics[examples]</code>. You can add other extra dependencies, for instance <code>wandb</code> by doing:</p> <pre><code>pip install --pre \"careamics[examples, wandb]\"\n</code></pre> <p>Here is a list of the extra dependencies:</p> <ul> <li><code>examples</code>: Dependencies required to run the example notebooks.</li> <li><code>wandb</code>: Dependencies to use WandB as a logger.</li> <li><code>tensorboard</code>: Dependencies to use TensorBoard as a logger.</li> <li><code>dev</code>: Dependencies required to run all the tooling necessary to develop with CAREamics.</li> </ul>"},{"location":"installation/#quickstart","title":"Quickstart","text":"<p>Once you have installed CAREamics, the easiest way to get started is to look at the applications for full examples and the  guides for in-depth tweaking.</p>"},{"location":"algorithms/","title":"Algorithms","text":"<p>Work in progress</p> <p>These pages are still under construction and we expect a lot more details  descriptions of each algorithm in the near future.</p>"},{"location":"algorithms/#self-supervised-restoration","title":"Self-supervised restoration","text":"Noise2Void <p>                                     A self-supervised denoising algorithm based on a                                      pixel masking scheme.                                 </p> N2V2 <p>                                     A variant of Noise2Void capable of removing                                      checkboard artefacts.                                 </p> StructN2V <p>                                     A variant of Noise2Void that uses an enhanced mask                                     to remove structured noise.                                 </p>"},{"location":"algorithms/#supervised-restoration","title":"Supervised restoration","text":"CARE <p>                                     The original supervised method to restore microscopy                                     images.                                 </p> Noise2Noise <p>                                     A supervised methods that cna denoise images without                                     corresponding clean data.                                 </p>"},{"location":"algorithms/care/","title":"Content-Aware image Restoration (CARE)","text":""},{"location":"algorithms/care/#overview","title":"Overview","text":""},{"location":"algorithms/care/#various-applications","title":"Various applications","text":""},{"location":"algorithms/care/#reference","title":"Reference","text":""},{"location":"algorithms/n2n/","title":"Noise2Noise","text":""},{"location":"algorithms/n2n/#overview","title":"Overview","text":""},{"location":"algorithms/n2n/#reference","title":"Reference","text":""},{"location":"algorithms/n2v/","title":"Noise2Void","text":""},{"location":"algorithms/n2v/#overview","title":"Overview","text":"<p>Noise2Void (N2V) is a self-supervised denoising method. It trains by randomly masking pixels in the input image and predicting their masked value from the surrounding pixels.</p> <p>N2V relies on two fundamental hypotheses:</p> <ul> <li>The underlying structures are continuous</li> <li>The noise is pixel-wise independent</li> </ul> <p>The corollory from these hypotheses is that if we consider the value of a pixel being the sum of the true signal value and a certain amount of noise, then:</p> <ul> <li>The true signal value can be estimated from the surrounding pixels</li> <li>The noise cannot be estimated from the surrounding pixels</li> </ul> <p>Therefore, in cases where the hypotheses hold, N2V can be use to estimate the true signal and thereby removing the noise.</p>"},{"location":"algorithms/n2v/#masking-scheme","title":"Masking scheme","text":""},{"location":"algorithms/n2v/#interpreting-the-loss","title":"Interpreting the loss","text":""},{"location":"algorithms/n2v/#artefacts","title":"Artefacts","text":"<p>(todo)</p> <ul> <li>checkboard</li> <li>structured noise</li> </ul>"},{"location":"algorithms/n2v/#references","title":"References","text":"<p>Alexander Krull, Tim-Oliver Buchholz, and Florian Jug. \"Noise2Void - learning denoising from single noisy images.\" Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition, 2019.</p> <p>Joshua Batson, and Loic Royer. \"Noise2Self: Blind denoising by self-supervision.\"  International Conference on Machine Learning. Proceedings of Machine Learning Research, 2019.</p>"},{"location":"algorithms/n2v2/","title":"N2V2","text":""},{"location":"algorithms/n2v2/#overview","title":"Overview","text":""},{"location":"algorithms/n2v2/#changes-to-the-model-architecture","title":"Changes to the model architecture","text":""},{"location":"algorithms/n2v2/#masking-scheme","title":"Masking scheme","text":""},{"location":"algorithms/n2v2/#comparison-with-noise2void","title":"Comparison with Noise2Void","text":""},{"location":"algorithms/n2v2/#reference","title":"Reference","text":""},{"location":"algorithms/structn2v/","title":"structN2V","text":""},{"location":"algorithms/structn2v/#overview","title":"Overview","text":""},{"location":"algorithms/structn2v/#masking-scheme","title":"Masking scheme","text":""},{"location":"algorithms/structn2v/#reference","title":"Reference","text":""},{"location":"applications/","title":"Applications","text":"<p>This section contains a list of example applications.</p>"},{"location":"applications/SUMMARY/","title":"SUMMARY","text":"<ul> <li>Applications</li> </ul>"},{"location":"guides/","title":"Guides","text":"<p>The basic usage of CAREamics follows this pattern:</p> CAREamics workflow<pre><code>\"\"\"Example showcasing the basic usage of CAREamics.\"\"\"\nimport numpy as np\nfrom careamics import CAREamist\nfrom careamics.config import create_n2v_configuration\n\n# create a configuration\nconfig = create_n2v_configuration( # (1)!\n    experiment_name=\"n2v_2D\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=1,\n    num_epochs=1,\n)\n\n# instantiate a careamist\ncareamist = CAREamist(config) # (2)!\n\n# train the model\ntrain_data = np.random.randint(0, 255, (256, 256))\ncareamist.train(train_source=train_data)\n\n# once trained, predict\npred_data = np.random.randint(0, 255, (128, 128))\npredction = careamist.predict(source=pred_data)\n\n# export to BMZ format\ncareamist.export_to_bmz( # (3)!\n    path=\"my_model.bmz\", name=\"N2V 2D\", authors=[{\"name\": \"CAREamics authors\"}]\n)\n</code></pre> <ol> <li> <p>There are several convenience functions to create a configuration, but you can also create it entirely manually. Head to the configuration section to know more!</p> </li> <li> <p>The CAREamist allows training, predicting and exporting the model. Refer to the  CAREamist section to learn more about it. There is also an alternative for more advance users, which we call the Lightning API.</p> </li> <li> <p>Models can be exported to the BioImage Model Zoo format.</p> </li> </ol> <p>Work in progress</p> <p>These pages are still under construction.</p> Configuration <p>                                     The configuration is at the heart of CAREamics, it                                      allow users to define how and which algorithm will be                                     trained.                                 </p> Using CAREAmics <p>                                     The CAREamist is the core element allowing training                                     and prediction using the model defined in the configuration.                                 </p> Lightning API <p>                                     Advanced users can re-use part of CAREamics in their                                     Lightning pipeline, with more customization potential                                     available.                                 </p> Developer resources <p>                                     More insights on how CAREamics is organized and how                                     to tweak it to your needs.                                 </p>"},{"location":"guides/careamist/","title":"Training and predicting","text":"<p>In this section, we will explore the many facets of the <code>CAREamist</code> class, which allors training and predicting using the various algorithms in CAREamics.</p> <p>The workflow in CAREamics has five steps: creating a configuration, instantiating a <code>CAREamist</code> object, training, prediction, and model export.</p> CAREamics workflow<pre><code>\"\"\"Example showcasing the basic usage of CAREamics.\"\"\"\nimport numpy as np\nfrom careamics import CAREamist\nfrom careamics.config import create_n2v_configuration\n\n# create a configuration\nconfig = create_n2v_configuration(\n    experiment_name=\"n2v_2D\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=1,\n    num_epochs=1,\n)\n\n# instantiate a careamist\ncareamist = CAREamist(config)\n\n# train the model\ntrain_data = np.random.randint(0, 255, (256, 256))\ncareamist.train(train_source=train_data)\n\n# once trained, predict\npred_data = np.random.randint(0, 255, (128, 128))\npredction = careamist.predict(source=pred_data)\n\n# export to BMZ format\ncareamist.export_to_bmz(\n    path=\"my_model.bmz\", name=\"N2V 2D\", authors=[{\"name\": \"CAREamics authors\"}]\n)\n</code></pre> <ul> <li>Training<ul> <li>source</li> <li>Callbacks</li> <li>datasets<ul> <li>read source</li> </ul> </li> </ul> </li> <li>Prediction<ul> <li>tiling<ul> <li>tta</li> <li>read source</li> </ul> </li> </ul> </li> <li>Model export</li> </ul>"},{"location":"guides/careamist/datasets/","title":"Datasets","text":"<p>Datasets are the internal classes providing the individual patches for training,  validation and prediction. In CAREamics, we provide a <code>CAREamicsTrainData</code> class that  creates the datasets for training and validation (there is a class for prediction as well, which is simpler and shares some parameters with the training one). In most cases, it is created internally. In this section, we describe what it does and shed light on some of its parameters that are passed to the train methods.</p>"},{"location":"guides/careamist/datasets/#overview","title":"Overview","text":"<p>The <code>CAREamicsTrainData</code> receives both data configuration and data itself. The data can be passed a path to a folder, to a file or as <code>numpy</code> array. It has the following  parameters:</p> <ul> <li><code>data_config</code></li> <li><code>train_data</code></li> <li><code>(optional) val_data</code></li> <li><code>(optional) train_data_target</code></li> <li><code>(optional) val_data_target</code></li> <li><code>(optional) read_source_func</code></li> <li><code>(optional) extension_filter</code></li> <li><code>(optional) val_percentage</code></li> <li><code>(optional) val_minimum_split</code></li> <li><code>(optional) use_in_memory</code></li> </ul> <p>Depending on the type of the data, which is specified in the <code>data_config</code> parameter and is compared to the data received, the <code>CAREamicsTrainData</code> will create the appropriate dataset.</p> <p>CAREamics currently support two datasets:</p> <ul> <li><code>InMemoryDataset</code>: This dataset is used when the data fits in memory.</li> <li><code>IterableDataset</code>: This dataset is used when the data is too large to fit in memory.</li> </ul> <p>If the data is a <code>numpy</code> array, the <code>InMemoryDataset</code> is used automatically. Otherwise, we list the files contained in the path, compute the size of the data and instantiate an <code>InMemoryDataset</code> if the data is less than 80% of the total RAM size. Otherwise, we instantiate an <code>IterableDataset</code>.</p> <p>Both datasets work differently.</p> <p>mean and std calculation</p>"},{"location":"guides/careamist/datasets/#in-memory-dataset","title":"In-memory dataset","text":"<p>memory calculation random patching</p>"},{"location":"guides/careamist/datasets/#iterable-dataset","title":"Iterable dataset","text":"<p>sequential patching</p>"},{"location":"guides/careamist/datasets/#advanced-custom-data-types","title":"(Advanced) Custom data types","text":""},{"location":"guides/careamist/instantiating_careamist/","title":"Instantiating CAREamist","text":"<p>There are three ways to create a <code>CAREamist</code> object: with a configuration, with a path to a configuration, or with a path to a model.</p>"},{"location":"guides/careamist/instantiating_careamist/#instantiating-with-a-configuration","title":"Instantiating with a configuration","text":"<p>When passing a configuration to the <code>CAREamist</code> constructor, the model is initialized with random weights and prediction will not be possible until the model is trained.</p> Instantiating CAREamist with a configuration<pre><code>from careamics import CAREamist\nfrom careamics.config import create_n2v_configuration\n\nconfig = create_n2v_configuration(\n    experiment_name=\"n2v_2D\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=1,\n    num_epochs=1,\n) # (1)!\n\ncareamist = CAREamist(config)\n</code></pre> <ol> <li>Any valid configuration will do!</li> </ol>"},{"location":"guides/careamist/instantiating_careamist/#instantiating-with-a-path-to-a-configuration","title":"Instantiating with a path to a configuration","text":"<p>This is similar to the previous section, except that the configuration is loaded from a file on disk.</p> Instantiating CAREamist with a path to a configuration<pre><code>from careamics import CAREamist\nfrom careamics.config import create_n2v_configuration, save_configuration\n\nconfig = create_n2v_configuration(\n    experiment_name=\"n2v_2D\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=1,\n    num_epochs=1,\n)\n\n# save a configuration to disk\nsave_configuration(config, \"configuration_example.yml\")\n\n# load it from within CAREamist\ncareamist = CAREamist(\"configuration_example.yml\")\n</code></pre>"},{"location":"guides/careamist/instantiating_careamist/#instantiating-with-a-path-to-a-model","title":"Instantiating with a path to a model","text":"<p>There are two types of models exported from CAREamics. During training, the model is saved as checkpoints (<code>.ckpt</code>). After training, users can export the model to the  bioimage model zoo format (saved as a<code>.zip</code>). Both can be loaded into CAREamics to either retrain or predict. Alternatively, a checkpoint can be loaded in order to  export it as a bioimage model zoo model.</p> <p>In any case, both types of pre-trained models can be loaded into CAREamics by passing the path to the model file. The instantiated CAREamist is then ready to predict on new images!</p> Instantiating CAREamist with a path to a model<pre><code>from careamics import CAREamist\n\npath_to_model = \"model.zip\" # (1)!\n\ncareamist = CAREamist(path_to_model)\n</code></pre> <ol> <li>Any valid path to a model, as a string or a <code>Path.path</code> object, will work.</li> </ol> <p>When loading a pre-trained model, the experiment name, used in the loggers (e.g. WandB), or to name the checkpoints, is automatically set to <code>CAREamics</code>. But you can change that by passing it to the <code>CAREamist</code> constructor.</p> Changing the experiment name<pre><code>careamist = CAREamist(path_to_model, experiment_name=\"a_new_experiment\")\n</code></pre>"},{"location":"guides/careamist/instantiating_careamist/#setting-the-working-directory","title":"Setting the working directory","text":"<p>By default, CAREamics will save the checkpoints in the current working directory. When creating a new CAREamist, you can indicate a different working directory in which to save the logs and checkpoints during training.</p> Changing the working directory<pre><code>careamist = CAREamist(config, work_dir=\"work_dir\")\n</code></pre>"},{"location":"guides/careamist/training/","title":"Training","text":"<p>You can provide data in various way to train your model: as a <code>numpy</code> array, using a path to a folder or files, or by using CAREamics data module class for more control (advanced).</p> <p>The details of how CAREamics deals with the loading and patching is detailed in the dataset section.</p> <p>Data type</p> <p>The data type of the source and targets must be the same as the one specified in the configuration. That is to say <code>array</code> in the case of <code>np.ndarray</code>, and <code>tiff</code> in the case of paths.</p>"},{"location":"guides/careamist/training/#training-by-passing-an-array","title":"Training by passing an array","text":"<p>CAREamics can be trained by simply passing numpy arrays.</p> Training by passing an array<pre><code>import numpy as np\n\ntrain_array = np.random.rand(128, 128)\nval_array = np.random.rand(128, 128)\n\ncareamist.train(\n    train_source=train_array, # (1)!\n    val_source=val_array, # (2)!\n)\n</code></pre> <ol> <li>All parameters to the <code>train</code> method must be specified by keyword.</li> <li>If you don't provide a validation source, CAREamics will use a fraction of the training data    to validate the model.</li> </ol> <p>Supervised training</p> <p>If you are training a supervised model, you must provide the target data as well.</p> <pre><code>careamist.train(\n    train_source=train_array,\n    train_target=target_array,\n    val_source=val_array,\n    val_target=val_target_array,\n)\n</code></pre>"},{"location":"guides/careamist/training/#training-by-passing-a-path","title":"Training by passing a path","text":"<p>The same thing can be done by passing a path to a folder or files.</p> Training by passing a path<pre><code>careamist.train(\n    train_source=\"path/to/my/train_data.tiff\", # (1)!\n    val_source=\"path/to/my/val_data.tiff\",\n)\n</code></pre> <ol> <li>The path can point to a single file, or contain multiple files.</li> </ol>"},{"location":"guides/careamist/training/#splitting-validation-from-training-data","title":"Splitting validation from training data","text":"<p>If you only provide training data, CAREamics will extract the validation data directly from the training set. There are two parameters controlling that behaviour: <code>val_percentage</code> and <code>val_minimum_split</code>.</p> <p><code>val_percentage</code> is the fraction of the training data that will be used for validation, and <code>val_minimum_split</code> is the minimum number of iamges used. If the percentage leads to a  number of patches smaller than <code>val_minimum_split</code>, CAREamics will use <code>val_minimum_split</code>.</p> Splitting validation from training data<pre><code>careamist.train(\n    train_source=train_array,\n    val_percentage=0.1, # (1)!\n    val_minimum_split=5, # (2)!\n)\n</code></pre> <ol> <li>10% of the training data will be used for validation.</li> <li>If the number of images is less than 5, CAREamics will use 5 images for validation.</li> </ol> <p>Patches vs images</p> <p>The behaviour of <code>val_percentage</code> and <code>val_minimum_split</code> is based different depending on whether the source data is an array or a path. If the source is an array, the split is done on the patches (<code>N</code> patches are used for validation). If the source is a path, the split is done on the files (<code>N</code> files are used for validation).</p>"},{"location":"guides/careamist/training/#training-by-passing-a-careamicstraindata-object","title":"Training by passing a CAREamicsTrainData object","text":"<p>CAREamics provides a class to handle the data loading of custom data type. We will dive  in more details in the next section into what this class can be used for.</p> Training by passing a CAREamicsTrainData object<pre><code>from careamics import CAREamicsTrainData\n\ndata_module = CAREamicsTrainData( # (1)!\n    data_config=config.data_config,\n    train_source=train_array\n)\n\ncareamist.train(\n    datamodule=data_module\n)\n</code></pre> <ol> <li>Here this does the same thing as passing the <code>train_source</code> directly into the <code>train</code> method.     In the next section, we will see a more useful example.</li> </ol>"},{"location":"guides/careamist/training/#callbacks","title":"Callbacks","text":"<p>CAREamics currently allows two different callbacks from PyTorch Lightning:</p> <ul> <li><code>ModelCheckpoint</code>: to save the model at different points during the training.</li> <li><code>EarlyStopping</code>: to stop the training based on a few parameters.</li> </ul> <p>The parameters for the callbacks are the same as the ones from PyTorch Lightning, and can be set in the configuration.</p>"},{"location":"guides/careamist/training/#logging-the-training","title":"Logging the training","text":"<p>By default, CAREamics simply log the training progress in the console. However, it is  possible to use either WandB or TensorBoard.</p> <p>To decide on the logger, check out the Configuration section.</p> <p>Loggers installation</p> <p>Using WandB or TensorBoard require the installation of <code>extra</code> dependencies. Check out the installation section to know more about it.</p>"},{"location":"guides/configuration/","title":"Configuration","text":"<p>The configuration summarizes all the parameters used internally by CAREamics. It is  used to create a <code>CAREamist</code> instance and is saved together with the checkpoints and  saved models.</p> <p>It is composed of four members:</p> Anatomy of the configuration<pre><code>from careamics import Configuration\n\nconfig_as_dict = {\n    \"experiment_name\": \"my_experiment\", # (1)!\n    \"algorithm_config\": { # (2)!\n        \"algorithm\": \"n2v\",\n        \"loss\": \"n2v\",\n        \"model\": {\n            \"architecture\": \"UNet\",\n        }\n    },\n    \"data_config\": { # (3)!\n        \"data_type\": \"array\",\n        \"patch_size\": [128, 128],\n        \"axes\": \"YX\",\n    },\n    \"training_config\": { # (4)!\n        \"num_epochs\": 1,\n    }\n}\nconfig = Configuration(**config_as_dict) # (5)!\n</code></pre> <ol> <li>The name of the experiment, used to differentiate trained models.</li> <li>Configuration specific to the model.</li> <li>Configuration related to the data.</li> <li>Training parameters.</li> <li>The configuration is an object! </li> </ol> <p>If the number of parameters looks too limited, it is because the configuration is hiding a lot of default values! But don't be afraid, we have designed convenience functions to help you create a configuration for each of the algorithm CAREamics offers.</p> <p>In the next sections, you can dive deeper on how to use CAREamics  configuration with different levels of expertise.</p> <ul> <li>(beginner) Convenience functions</li> <li>(beginner) Save and load configurations</li> <li>(intermediate) Build the configuration from scratch</li> <li>(intermediate) Full specification</li> <li>(intermediate) Algorithm requirements</li> <li>(advanced) Custom models</li> <li>(all) Understanding the errors</li> </ul>"},{"location":"guides/configuration/advanced_configuration/","title":"Advanced configuration","text":"<p>We have implemented several mechanism to allow users to use CAREamics in contexts we  do not explicitely support. In this section, we describe several of these mechanisms.</p> <p>In the future, we hope to add more depending on user requests.</p>"},{"location":"guides/configuration/advanced_configuration/#custom-data-type","title":"Custom data type","text":"<p>The <code>data_type</code> parameter of the <code>DataConfig</code> class is a string that is used to choose the data loader within CAREamics. We currently only support <code>array</code> and <code>tiff</code> explicitely.</p> <p>However, users can set the <code>data_type</code> to <code>custom</code> and use their own read function.</p> Custom data type<pre><code>from careamics.config import DataConfig\n\ndata_config = DataConfig(\n    data_type=\"custom\", # (1)!\n    axes=\"YX\",\n    patch_size=[128, 128],\n    batch_size=8,\n    num_epochs=20,\n)\n</code></pre> <ol> <li>As far as the configuration is concerned, you only set the <code>data_type</code> to <code>custom</code>. The     rest happens in the <code>CAREamist</code> instance.</li> </ol> <p>Full example in other sections</p> <p>A full example of the use of a custom data type is available in the CAREamist  and Applications sections.</p>"},{"location":"guides/configuration/advanced_configuration/#custom-ai-model","title":"Custom AI model","text":"<p>CAREamics currently only support UNet models, but users can create their own model and use it in CAREamics. First, the model needs to be registered with the  <code>register_model</code> decorator, then both the <code>algorithm</code> of <code>AlgorithmConfig</code> and the  <code>architecture</code> of the <code>model</code> need to be set to custom.</p> Custom AI model<pre><code>from torch import nn, ones\nfrom careamics.config import AlgorithmConfig, register_model\n\n@register_model(name=\"linear_model\")  # (1)!\nclass LinearModel(nn.Module):\n    def __init__(self, in_features, out_features, *args, **kwargs):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(ones(in_features, out_features))\n        self.bias = nn.Parameter(ones(out_features))\n\n    def forward(self, input):\n        return (input @ self.weight) + self.bias\n\nconfig = AlgorithmConfig(\n    algorithm=\"custom\",  # (2)!\n    loss=\"mse\",\n    model={\n        \"architecture\": \"Custom\", # (3)!\n        \"name\": \"linear_model\", # (4)!\n        \"in_features\": 10,\n        \"out_features\": 5,\n    },\n)\n</code></pre> <ol> <li>Register your model using the decorator and indicates its <code>name</code>.</li> <li>Set the <code>algorithm</code> to <code>custom</code>.</li> <li>In the <code>model</code>, set the <code>architecture</code> to <code>Custom</code>. Watch the capital letter!</li> <li>Indicate the name of the model.</li> </ol> <p>Full example in other sections</p> <p>A full example of the use of a custom data type is available in the CAREamist  and Applications sections.</p>"},{"location":"guides/configuration/algorithm_requirements/","title":"Algorithm requirements","text":"<p>In this section we detail the constraints of each algorithm on the configuration.</p>"},{"location":"guides/configuration/algorithm_requirements/#noise2void-family","title":"Noise2Void family","text":"<p>This is valid for <code>Noise2Void</code>, <code>N2V2</code> and <code>structN2V</code>.</p>"},{"location":"guides/configuration/algorithm_requirements/#algorithm-configuration","title":"Algorithm configuration","text":"<ul> <li><code>algorithm=\"n2v\"</code></li> <li><code>loss=\"n2v\"</code></li> <li><code>model</code>: <ul> <li>must be a UNet (<code>architecture=\"UNet\"</code>)</li> <li><code>in_channels</code> and <code>num_classes</code> must be equal</li> </ul> </li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#data-configuration","title":"Data configuration","text":"<ul> <li><code>transforms</code>: must contain <code>N2VManipulateModel</code> as the last transform</li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#care","title":"CARE","text":""},{"location":"guides/configuration/algorithm_requirements/#algorithm-configuration_1","title":"Algorithm configuration","text":"<ul> <li><code>algorithm=\"care\"</code></li> <li><code>loss</code>: any but <code>n2v</code></li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#data-configuration_1","title":"Data configuration","text":"<ul> <li><code>transforms</code>: must not contain <code>N2VManipulateModel</code></li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#noise2noise","title":"Noise2Noise","text":""},{"location":"guides/configuration/algorithm_requirements/#algorithm-configuration_2","title":"Algorithm configuration","text":"<ul> <li><code>algorithm=\"care\"</code></li> <li><code>loss</code>: any but <code>n2v</code></li> <li><code>model</code>: <code>in_channels</code> and <code>num_classes</code> must be equal</li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#data-configuration_2","title":"Data configuration","text":"<ul> <li><code>transforms</code>: must not contain <code>N2VManipulateModel</code></li> </ul>"},{"location":"guides/configuration/build_configuration/","title":"Build the configuration","text":"<p>Beginner vs Intermediate</p> <p>This is an intermediate level way to create CAREamics configuration. Do check the convenience functions if you are looking for a simpler way to create CAREanics configurations!</p> <p>CAREamics configuration is validated using Pydantic,  a library that allows you to define schemas and automatically check the types of the  input data you provide. </p> <p>In addition, it allows great flexibility in writing custom validators. In turns this ensures that the configuration is always valid and coherent, protecting against errors deep in the library.</p> <p>As shown in the introduction, CAREamics configuration is composed of four main elements:</p> <ol> <li>Experiment name, a simple string</li> <li>Algorithm configuration, also a Pydantic model</li> <li>Data configuration, also a Pydantic model</li> <li>Training configuration, also a Pydantic model</li> </ol> <p>Each of the parameters and models are validated independently, and the configuration as a whole is validated at the end.</p> <p>There are two ways to build Pydantic models: by passing a dictionnary that reproduces the model structure, or by calling all Pydantic models explicitely. While the first method is  more concise, the second method is less error prone and allow you to explore all parameters available easily if you are using an IDE (e.g. VSCode, JupyterLab etc.).</p>"},{"location":"guides/configuration/build_configuration/#using-nested-dictionaries","title":"Using nested dictionaries","text":"<p>In the introduction, we have seen a minimum example on how to build the configuration with a dictionnary, reproduced here:</p> Building the configuration with a dictionary<pre><code>from careamics import Configuration\n\nconfig_as_dict = {\n    \"experiment_name\": \"my_experiment\", # (1)!\n    \"algorithm_config\": { # (2)!\n        \"algorithm\": \"n2v\",\n        \"loss\": \"n2v\",\n        \"model\": { # (3)!\n            \"architecture\": \"UNet\",\n        }\n    },\n    \"data_config\": { # (4)!\n        \"data_type\": \"array\",\n        \"patch_size\": [128, 128],\n        \"axes\": \"YX\",\n    },\n    \"training_config\": { \n        \"num_epochs\": 1,\n    }\n}\nconfig = Configuration(**config_as_dict) # (5)!\n</code></pre> <ol> <li>The first parameter is just a string!</li> <li>But this one is itself a Pydantic model, so we need to pass a dictionnary that     respects the structure of the model.</li> <li>Don't be surprised, the deep neural network model is also a Pydantic model.</li> <li>Same here, and so on...</li> <li>The configuration is instantiated by passing keywords arguments rather than a dictionary,      and Pydantic knows how to interpret the sub-dictionaries to correctly instantiate the member      models.</li> </ol> <p>While this is neat, because you are dealing with nested dictionaries, it is easy to add the parameters at the wrong level and you need to constantly refer to the code documentation to know which parameters are available.</p> <p>Finally, because you are validating the configuration at once, you will get all the validation errors in one go.</p>"},{"location":"guides/configuration/build_configuration/#using-pydantic-models-preferred","title":"Using Pydantic models (preferred)","text":"<p>The preferred way to build the configuration is to call the Pydantic models directly. This allows you to explore the parameters throught your IDE, but also to get the validation errors closer to the source of the error.</p> Building the configuration using Pydantic models<pre><code>from careamics import Configuration\nfrom careamics.config import ( # (1)!\n    AlgorithmConfig,\n    DataConfig,\n    TrainingConfig,\n)\nfrom careamics.config.architectures import UNetModel\nfrom careamics.config.transformations import N2VManipulateModel\nfrom careamics.config.support import (\n    SupportedAlgorithm,\n    SupportedArchitecture,\n    SupportedData,\n    SupportedLogger,\n    SupportedLoss,\n    SupportedTransform,\n)\n\nexperiment_name = \"Pydantic N2V2 example\"\n\n# build AlgorithmConfig \nalgorithm_model = AlgorithmConfig( # (2)!\n    algorithm=SupportedAlgorithm.N2V.value, # (3)!\n    loss=SupportedLoss.N2V.value,\n    model=UNetModel( # (4)!\n        architecture=SupportedArchitecture.UNET.value,\n        in_channels=1,\n        num_classes=1,\n    ),\n)\n\n# then the DataConfig\ndata_model = DataConfig(\n    data_type=SupportedData.ARRAY.value,\n    patch_size=(256, 256),\n    batch_size=8,\n    axes=\"YX\",\n    transforms=[ \n        { # (5)!\n            \"name\": SupportedTransform.NORMALIZE.value,\n        },\n        {\n            \"name\": SupportedTransform.NDFLIP.value,\n            \"is_3D\": False,\n        },\n        N2VManipulateModel( # (6)!\n            masked_pixel_percentage=0.15,\n        ),\n    ],\n    dataloader_params={ # (7)!\n        \"num_workers\": 4,\n    },\n)\n\n# then the TrainingConfig\ntraining_model = TrainingConfig(\n    num_epochs=30,\n    logger=SupportedLogger.WANDB.value,\n)\n\n# finally, build the Configuration\nconfig = Configuration( # (8)!\n    experiment_name=experiment_name,\n    algorithm_config=algorithm_model,\n    data_config=data_model,\n    training_config=training_model,\n)\n</code></pre> <ol> <li>The main Pydantic models are imported from the <code>careamics</code> and <code>careamics.config</code>      submodules, the others are organized in different submodules.</li> <li>A Pydantic model is instantiated like any other class.</li> <li>In CAREamics, we store constant values in <code>enum</code> classes in the <code>careamics.config.support</code>      submodule. This allows to have a single source of truth for the values. But you have     to remember to use the <code>.value</code> attribute to get the string value.</li> <li>You can instantiate the nested models directly in the parent model or outside (outside     is better to track down the errors!).</li> <li>The <code>transforms</code> parameter is a list, you can mix and match the different transformations,     but also use dictionnaries or the Pydantic model classes directly. Make sure to pass     the <code>name</code> as it is used to identify the correct Pydantic model to instantiate for the     transformation.</li> <li>Here for instance, we use the Pydantic model directly.</li> <li>The <code>dataloader_params</code> is a dictionnary, you can pass any parameter that is accepted by     the <code>torch.utils.data.DataLoader</code> class.</li> <li>Finally, the configuration is instantiated by passing the Pydantic models directly.</li> </ol>"},{"location":"guides/configuration/convenience_functions/","title":"Convenience functions","text":"<p>As building a full CAREamics configuration requires a complete understanding of the  various parameters and experience with Pydantic, we provide convenience functions to create configurations with a only few parameters related to the algorithm users want to train.</p> <p>All convenience methods can be found in the <code>careamics.config</code> modules. CAREamics  currently supports Noise2Void and its variants, CARE and Noise2Noise. </p> Import convenience functions<pre><code>from careamics.config import (\n    create_n2v_configuration, # Noise2Void, N2V2, structN2V\n    create_care_configuration, # CARE\n    create_n2n_configuration, # Noise2Noise\n)\n</code></pre> <p>Each method does all the heavy lifting to make the configuration coherent. They share a certain numbers of mandatory parameters:</p> <ul> <li><code>experiment_name</code>: The name of the experiment, used to differentiate trained models.</li> <li><code>data_type</code>: One of the types supported by CAREamics (<code>array</code>, <code>tiff</code> or <code>custom</code>).</li> <li><code>axes</code>: Axes of the data (e.g. SYX), can only the following letters: <code>STCZYX</code>.</li> <li><code>patch_size</code>: Size of the patches along the spatial dimensions (e.g. [64, 64]).</li> <li><code>batch_size</code>: Batch size to use during training (e.g. 8). This parameter affects the     memory footprint on the GPU.</li> <li><code>num_epochs</code>: Number of epochs.</li> </ul> <p>Additional optional parameters can be passed to tweak the configuration. </p>"},{"location":"guides/configuration/convenience_functions/#general-optional-parameters","title":"General optional parameters","text":""},{"location":"guides/configuration/convenience_functions/#training-with-channels","title":"Training with channels","text":"<p>When training with multiple channels, the <code>axes</code> parameter should contain <code>C</code> (e.g. <code>YXC</code>). An error will be then thrown if the optional parameter <code>n_channels</code> is not specified!  Likewise if <code>n_channels</code> is specified but <code>C</code> is not in <code>axes</code>.</p> <p>The correct way is to specify them both at the same time.</p> Configuration with multiple channels<pre><code>config = create_n2n_configuration(\n    experiment_name='n2n_2D', \n    data_type=\"tiff\", \n    axes=\"YXC\", # (1)!\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    n_channels=3 # (2)!\n)\n</code></pre> <ol> <li>The axes contain the letter <code>C</code>.</li> <li>The number of channels is specified.</li> </ol>"},{"location":"guides/configuration/convenience_functions/#using-augmentations","title":"Using augmentations","text":"<p>By default CAREamics configuration uses augmentations that are specific to the algorithm (e.g. Noise2Void) and that are compatible with microscopy images (e.g. flip and 90 degrees rotations).</p> <p>However in certain cases, users might want to disable augmentations. For instance if you have structures that are always oriented in the same direction. To do so there is a single <code>use_agumentations</code> parameter:</p> Configuration without augmentations<pre><code>config = create_care_configuration(\n    experiment_name='care_2D', \n    data_type=\"tiff\", \n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    use_augmentations=False # (1)!\n)\n</code></pre> <ol> <li>Augmentations are disabled (but normalization is still there!).</li> </ol>"},{"location":"guides/configuration/convenience_functions/#choosing-a-logger","title":"Choosing a logger","text":"<p>By default, CAREamics simply log the training progress in the console. However, it is  possible to use either WandB or TensorBoard.</p> <p>Loggers installation</p> <p>Using WandB or TensorBoard require the installation of <code>extra</code> dependencies. Check out the installation section to know more about it.</p> Configuration with WandB<pre><code>config = create_n2n_configuration(\n    experiment_name='n2n_2D', \n    data_type=\"tiff\", \n    axes=\"YXC\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    logger=\"wandb\" # (1)!\n)\n</code></pre> <ol> <li><code>wandb</code> or <code>tensorboard</code></li> </ol>"},{"location":"guides/configuration/convenience_functions/#advanced-passing-model-specific-parameters","title":"(Advanced) Passing model specific parameters","text":"<p>By default, the convenience functions use the default UNet model parameters. But if  you are feeling brave, you can pass model specific parameters in the <code>model_kwargs</code> dictionary. </p> Configuration with model specific parameters<pre><code>config = create_care_configuration(\n    experiment_name='care_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    model_kwargs={\n        \"depth\": 3, # (1)!\n        \"num_channels_init\": 64, # (2)!\n        # (3)!\n    }\n)\n</code></pre> <ol> <li>The depth of the UNet.</li> <li>The number of channels in the first layer.</li> <li>Add any other parameter specific to the model!</li> </ol> <p>Model parameters overwriting</p> <p>Some values of the model parameters are not compatible with certain algorithms.  Therefore, these are overwritten by the convenience functions. For instance, if you pass <code>in_channels</code> in the <code>model_kwargs</code> dictionary, it will be ignored and replaced by the <code>n_channels</code> parameter of the convenience function.</p>"},{"location":"guides/configuration/convenience_functions/#care-and-noise2noise-specific-parameters","title":"CARE and Noise2Noise specific parameters","text":"<p>As opposed to Noise2Void, CARE and Noise2Noise can be trained with different loss functions. This can be set using the <code>loss</code> parameter (surprise, surprise!).</p> Configuration with different loss<pre><code>config = create_care_configuration(\n    experiment_name='care_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    loss=\"mae\" # (1)!\n)\n</code></pre> <ol> <li><code>mae</code> or <code>mse</code></li> </ol>"},{"location":"guides/configuration/convenience_functions/#noise2void-specific-parameters","title":"Noise2Void specific parameters","text":"<p>Noise2Void has a few additional parameters that can be set, including for using its  variants N2V2 and structN2V.</p> <p>Understanding Noise2Void and its variants</p> <p>Before deciding which variant to use, and how to modify the parameters, we recommend to die a little a bit on how each algorithm works!</p>"},{"location":"guides/configuration/convenience_functions/#noise2void-parameters","title":"Noise2Void parameters","text":"<p>There are two Noise2Void parameters that influence how the patches are manipulated during training:</p> <ul> <li><code>roi_size</code>: This parameter specifies the size of the area used to replace the masked pixel value.</li> <li><code>masked_pixel_percentage</code>: This parameter specifies how many pixels per patch will be manipulated.</li> </ul> <p>While the default values are usually fine, they can be tweaked to improve the training in certain cases.</p> Configuration with N2V parameters<pre><code>config = create_n2v_configuration(\n    experiment_name='n2v_2D', \n    data_type=\"tiff\", \n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    roi_size=7,\n    masked_pixel_percentage=0.5\n)\n</code></pre>"},{"location":"guides/configuration/convenience_functions/#n2v2","title":"N2V2","text":"<p>To use N2V2, the <code>use_n2v2</code> parameter should simply be set to <code>True</code>.</p> Configuration with N2V2<pre><code>config = create_n2v_configuration(\n    experiment_name='n2v2_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    use_n2v2=True # (1)!\n)\n</code></pre> <ol> <li>What it does is modifying the architecture of the UNet model and the way the masked     pixels are replaced.</li> </ol>"},{"location":"guides/configuration/convenience_functions/#structn2v","title":"structN2V","text":"<p>StructN2V has two parameters that can be set:</p> <ul> <li><code>struct_n2v_axis</code>: The axis along which the structN2V mask will be applied. By default it     is set to <code>none</code> (structN2V is disabled), you can set it to either <code>horizontal</code> or <code>vertical</code>.</li> <li><code>struct_n2v_span</code>: The size of the structN2V mask.</li> </ul> Configuration with structN2V<pre><code>config = create_n2v_configuration(\n    experiment_name='structn2v_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    struct_n2v_axis=\"horizontal\",\n    struct_n2v_span=5\n)\n</code></pre>"},{"location":"guides/configuration/full_spec/","title":"Full specification","text":"<p>The full specification of the configuration is a detailed description of all the parameters  that can be used to configure CAREamics. It is useful for advanced users who want to  have full control over the training process.</p> <p>You can also explore all the Pydantic models using the reference documentation.</p> Full specification<pre><code>from careamics import Configuration\nfrom careamics.config import (\n    AlgorithmConfig,\n    DataConfig,\n    TrainingConfig,\n)\nfrom careamics.config.architectures import UNetModel\nfrom careamics.config.callback_model import EarlyStoppingModel\nfrom careamics.config.optimizer_models import LrSchedulerModel, OptimizerModel\nfrom careamics.config.support import (\n    SupportedActivation,\n    SupportedAlgorithm,\n    SupportedArchitecture,\n    SupportedData,\n    SupportedLogger,\n    SupportedLoss,\n    SupportedOptimizer,\n    SupportedPixelManipulation,\n    SupportedScheduler,\n    SupportedStructAxis,\n)\nfrom careamics.config.transformations import (\n    N2VManipulateModel,\n    NDFlipModel,\n    NormalizeModel,\n    XYRandomRotate90Model,\n)\n\nexperiment_name = \"Full example\"\n\n# Algorithm\nmodel = UNetModel( # (1)!\n    architecture=SupportedArchitecture.UNET.value,\n    in_channels=1,\n    num_classes=1,\n    depth=2,\n    num_channels_init=32,\n    final_activation=SupportedActivation.NONE.value,\n    n2v2=False,\n)\n\noptimizer = OptimizerModel(\n    name=SupportedOptimizer.ADAM.value, parameters={\"lr\": 0.0001}\n)\n\nscheduler = LrSchedulerModel(\n    name=SupportedScheduler.REDUCE_LR_ON_PLATEAU.value,\n)\n\nalgorithm_model = AlgorithmConfig(\n    algorithm=SupportedAlgorithm.N2V.value,\n    loss=SupportedLoss.N2V.value,\n    model=model,\n    optimizer=optimizer,\n    lr_scheduler=scheduler,\n)\n\n# Data\nnorm = NormalizeModel()\nndflip = NDFlipModel(is_3D=False)\nrotate = XYRandomRotate90Model(is_3D=False)\nn2vmanipulate = N2VManipulateModel(\n    roi_size=11,\n    masked_pixel_percentage=0.2,\n    strategy=SupportedPixelManipulation.MEDIAN.value,\n    struct_mask_axis=SupportedStructAxis.NONE.value,\n    struct_mask_span=7,\n)\n\ndata_model = DataConfig(\n    data_type=SupportedData.ARRAY.value,\n    patch_size=(256, 256),\n    batch_size=8,\n    axes=\"YX\",\n    transforms=[norm, ndflip, rotate, n2vmanipulate],\n    dataloader_params={\n        \"num_workers\": 4,\n        # (2)!\n    },\n    # (3)!\n)\n\n# Traning\nearlystopping = EarlyStoppingModel(\n    # (4)!\n)\n\ntraining_model = TrainingConfig(\n    num_epochs=30,\n    logger=SupportedLogger.WANDB.value,\n    early_stopping_callback=earlystopping,\n)\n\nconfig = Configuration(\n    experiment_name=experiment_name,\n    algorithm_config=algorithm_model,\n    data_config=data_model,\n    training_config=training_model,\n)\n</code></pre> <ol> <li>Currently, we only support the UNet architecture and custom models (see advanced     configuration). But in the future, there will be more     models to use here.</li> <li>Here the parameters are those from Pytorch DataLoaders.</li> <li>There are also the <code>mean</code> and <code>std</code> parameters, used to normalize the data. But they are typically     calculated from the data itself, and then later stored in the configuration.</li> <li>The <code>EarlyStoppingModel</code> has a lot of parameters not reproduced here.</li> </ol> <p>However, not all algorithms are compatible with all parameters. The configuration does some heavy lifting to correct the obvious incompatibilities, but some are left to the user. In the next section, we will see the constraints on each algorithm.</p>"},{"location":"guides/configuration/save_load/","title":"Save and load","text":"<p>CAREamics configurations can be saved to the disk as <code>.yml</code> file and loaded easily to start similar experiments.</p>"},{"location":"guides/configuration/save_load/#save-a-configuration","title":"Save a configuration","text":"Save a configuration<pre><code>from careamics import save_configuration\nfrom careamics.config import create_n2v_configuration\n\nconfig =  create_n2v_configuration(\n    experiment_name=\"Config_to_save\",\n    data_type=\"tiff\",\n    axes=\"ZYX\",\n    patch_size=(8, 64, 64),\n    batch_size=8,\n    num_epochs=20\n)\nsave_configuration(config, \"config.yml\")\n</code></pre> <p>In the resulting file, you can see all the parameters that are defaults and hidden from you.</p> resulting config.yml file <pre><code>version: 0.1.0\nexperiment_name: Config_to_save\nalgorithm_config:\nalgorithm: n2v\nloss: n2v\nmodel:\n    architecture: UNet\n    conv_dims: 3\n    num_classes: 1\n    in_channels: 1\n    depth: 2\n    num_channels_init: 32\n    final_activation: None\n    n2v2: false\noptimizer:\n    name: Adam\n    parameters:\n    lr: 0.0001\nlr_scheduler:\n    name: ReduceLROnPlateau\n    parameters: {}\ndata_config:\ndata_type: tiff\npatch_size:\n- 8\n- 64\n- 64\nbatch_size: 8\naxes: ZYX\ntransforms:\n- name: Normalize\n    mean: 0.485\n    std: 0.229\n- name: NDFlip\n    p: 0.5\n    is_3D: true\n    flip_z: true\n- name: XYRandomRotate90\n    p: 0.5\n    is_3D: true\n- name: N2VManipulate\n    roi_size: 11\n    masked_pixel_percentage: 0.2\n    strategy: uniform\n    struct_mask_axis: none\n    struct_mask_span: 5\ntraining_config:\nnum_epochs: 20\ncheckpoint_callback:\n    monitor: val_loss\n    verbose: false\n    save_weights_only: false\n    mode: min\n    auto_insert_metric_name: false\n    save_last: true\n    save_top_k: 3\n</code></pre>"},{"location":"guides/configuration/save_load/#load-a-configuration","title":"Load a configuration","text":"Load a configuration<pre><code>from careamics import load_configuration\n\nconfig = load_configuration(\"config.yml\")\n</code></pre>"},{"location":"guides/configuration/understanding_errors/","title":"Configuration errors","text":"<p>Work in progress</p> <p>These pages are still under construction and will come soon.</p>"},{"location":"guides/dev_resource/","title":"Developer's guide","text":"<p>Work in progress</p> <p>These pages are still under construction.</p>"},{"location":"guides/lightning_api/","title":"Lightning API","text":"<p>Work in progress</p> <p>These pages are still under construction.</p>"}]}