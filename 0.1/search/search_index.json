{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#documentation","title":"Documentation","text":"<p>CAREamics is a PyTorch library aimed at simplifying the use of Noise2Void and its many variants and cousins (CARE, Noise2Noise, N2V2, P(P)N2V, HDN, muSplit etc.).</p>"},{"location":"#why-careamics","title":"Why CAREamics?","text":"<p>Noise2Void is a widely used denoising algorithm, and is readily available from the <code>n2v</code> python package. However, n2v is based on TensorFlow and Keras and we found it  increasingly hard to maintain. In addition, more recent methods (PPN2V, DivNoising, HDN) are all implemented in PyTorch, but are lacking the extra features that would make them usable by the community.</p> <p>The aim of CAREamics is to provide a PyTorch library reuniting all the latest methods in one package, while providing a simple and consistent API. The library relies on  PyTorch Lightning as a back-end. In addition, we will provide extensive documentation and  tutorials on how to best apply these methods in a scientific context.</p> <p>Work in progress</p> <p>These pages are still under construction.</p>"},{"location":"#getting-started","title":"Getting Started","text":"Installation <p>                                     Get started with CAREamics installation.                                 </p> Current State <p>                                     Check out where we stand and where we want to go.                                 </p> Guides <p>                                     In-depth guides on CAREamics usage and features.                                 </p> Applications <p>                                     Examples of CAREamics in action on various datasets.                                 </p> Algorithms <p>                                     Dive into the various CAREamics algorithms.                                 </p> Code Reference <p>                                     Code documentation for all CAREamics libraries.                                 </p>"},{"location":"#feedback","title":"Feedback","text":"<p>We are always welcoming feedback on what to improve of what features could be useful, therefore do not hesitate to open an issue on the Github repository!</p>"},{"location":"current_state/","title":"Current state","text":"<p>CAREamics is an on-going project and will include new algorithms in the next releases.  We are currently reaching Milestone 1. Here is a list of the current features:</p>"},{"location":"current_state/#algorithms","title":"Algorithms","text":"<ul> <li> Noise2Void 2D/3D/Channels</li> <li> structN2V 2D/3D/Channels</li> <li> N2V2 2D/3D/Channels</li> <li> CARE 2D/3D/Channels</li> <li> Noise2Noise 2D/3D/Channels</li> <li> CryoCARE 2D/3D</li> <li> PN2V 2D/3D/Channels</li> <li> PPN2V 2D/3D/Channels</li> <li> DivNoising/HDN 2D/3D/Channels</li> <li> muSplit 2D/3D</li> <li> denoiSplit 2D/3D</li> <li> EmbedSeg</li> </ul>"},{"location":"current_state/#features","title":"Features","text":"<ul> <li> Pydantic configuration</li> <li> TIFF dataloader</li> <li> In memory dataset</li> <li> Training/prediction</li> <li> Tiled prediction</li> <li> Checkpoint saving/loading</li> <li> Save/load bioimage.io format</li> <li> Zarr dataset</li> <li> Automated Mixed-Precision</li> <li> torch.compile</li> <li> napari plugin</li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>CAREamics is a deep-learning library and we therefore recommend having GPU support as training the algorithms on the CPU can be very slow. MacOS users can also benefit from GPU-acceleration if they have the new chip generations (M1, M2, etc.).</p> <p>Support is provided directly from PyTorch, and is still experimental for macOS.</p>"},{"location":"installation/#step-by-step","title":"Step-by-step","text":"<p>We recommend using mamba (miniforge)  to install all packages in a virtual environment. As an alternative, you can use conda  (miniconda). </p> Linux and WindowsmacOS <ol> <li>Open the terminal and type <code>mamba</code> to verify that mamba is available.</li> <li> <p>Create a new environment:</p> <pre><code>mamba create -n careamics python=3.10\nmamba activate careamics\n</code></pre> </li> <li> <p>Install PyTorch following the official      instructions</p> <p>As an example, our test machine requires:</p> <pre><code>mamba install pytorch torchvision pytorch-cuda=11.8 -c pytorch -c nvidia\n</code></pre> </li> <li> <p>Verify that the GPU is available:</p> <pre><code>python -c \"import torch; print([torch.cuda.get_device_properties(i) for i in range(torch.cuda.device_count())])\"\n</code></pre> <p>This should show a list of available GPUs. If the list is empty, then you will need to change the <code>pytorch</code> and <code>pytorch-cuda</code> versions to match your hardware (linux and windows).</p> </li> <li> <p>Install CAREamics. We have several extra options (<code>dev</code>, <code>examples</code>, <code>wandb</code>     and <code>tensorboard</code>). If you wish to run the example notebooks,     we recommend the following:</p> <pre><code>pip install --pre \"careamics[examples]\"\n</code></pre> </li> </ol> <p>These instructions were tested on a linux virtual machine (RedHat 8.6) with a  NVIDIA A40-8Q GPU.</p> <ol> <li>Open the terminal and type <code>mamba</code> to verify that mamba is available.</li> <li> <p>Create a new environment:</p> <pre><code>mamba create -n careamics python=3.10\nmamba activate careamics\n</code></pre> </li> <li> <p>Install PyTorch following the official      instructions</p> <p>As an example, our test machine requires:</p> <pre><code>mamba install pytorch::pytorch torchvision torchaudio -c pytorch\n</code></pre> <p> Note that accelerated-training is only available on macOS silicon.</p> </li> <li> <p>Install CAREamics. We have several extra options (<code>dev</code>, <code>examples</code>, <code>wandb</code>     and <code>tensorboard</code>). If you wish to run the example notebooks,     we recommend the following:</p> <pre><code>pip install --pre \"careamics[examples]\"\n</code></pre> </li> </ol>"},{"location":"installation/#extra-dependencies","title":"Extra dependencies","text":"<p>CAREamics extra dependencies can be installed by specifying them in brackets. In the previous section we installed <code>careamics[examples]</code>. You can add other extra dependencies, for instance <code>wandb</code> by doing:</p> <pre><code>pip install --pre \"careamics[examples, wandb]\"\n</code></pre> <p>Here is a list of the extra dependencies:</p> <ul> <li><code>examples</code>: Dependencies required to run the example notebooks.</li> <li><code>wandb</code>: Dependencies to use WandB as a logger.</li> <li><code>tensorboard</code>: Dependencies to use TensorBoard as a logger.</li> <li><code>dev</code>: Dependencies required to run all the tooling necessary to develop with CAREamics.</li> </ul>"},{"location":"installation/#quickstart","title":"Quickstart","text":"<p>Once you have installed CAREamics, the easiest way to get started is to look at the applications for full examples and the  guides for in-depth tweaking.</p>"},{"location":"algorithms/","title":"Algorithms","text":"<p>Work in progress</p> <p>These pages are still under construction and we expect a lot more details  descriptions of each algorithm in the near future.</p>"},{"location":"algorithms/#self-supervised-restoration","title":"Self-supervised restoration","text":"Noise2Void <p>                                     A self-supervised denoising algorithm based on a                                      pixel masking scheme.                                 </p> N2V2 <p>                                     A variant of Noise2Void capable of removing                                      checkboard artefacts.                                 </p> StructN2V <p>                                     A variant of Noise2Void that uses an enhanced mask                                     to remove structured noise.                                 </p>"},{"location":"algorithms/#supervised-restoration","title":"Supervised restoration","text":"CARE <p>                                     The original supervised method to restore microscopy                                     images.                                 </p> Noise2Noise <p>                                     A supervised methods that cna denoise images without                                     corresponding clean data.                                 </p>"},{"location":"algorithms/care/","title":"Content-Aware image Restoration (CARE)","text":""},{"location":"algorithms/care/#overview","title":"Overview","text":""},{"location":"algorithms/care/#various-applications","title":"Various applications","text":""},{"location":"algorithms/care/#reference","title":"Reference","text":""},{"location":"algorithms/n2n/","title":"Noise2Noise","text":""},{"location":"algorithms/n2n/#overview","title":"Overview","text":""},{"location":"algorithms/n2n/#reference","title":"Reference","text":""},{"location":"algorithms/n2v/","title":"Noise2Void","text":""},{"location":"algorithms/n2v/#overview","title":"Overview","text":"<p>Noise2Void (N2V) is a self-supervised denoising method. It trains by randomly masking pixels in the input image and predicting their masked value from the surrounding pixels.</p> <p>N2V relies on two fundamental hypotheses:</p> <ul> <li>The underlying structures are continuous</li> <li>The noise is pixel-wise independent</li> </ul> <p>The corollory from these hypotheses is that if we consider the value of a pixel being the sum of the true signal value and a certain amount of noise, then:</p> <ul> <li>The true signal value can be estimated from the surrounding pixels</li> <li>The noise cannot be estimated from the surrounding pixels</li> </ul> <p>Therefore, in cases where the hypotheses hold, N2V can be use to estimate the true signal and thereby removing the noise.</p>"},{"location":"algorithms/n2v/#masking-scheme","title":"Masking scheme","text":""},{"location":"algorithms/n2v/#interpreting-the-loss","title":"Interpreting the loss","text":""},{"location":"algorithms/n2v/#artefacts","title":"Artefacts","text":"<p>(todo)</p> <ul> <li>checkboard</li> <li>structured noise</li> </ul>"},{"location":"algorithms/n2v/#references","title":"References","text":"<p>Alexander Krull, Tim-Oliver Buchholz, and Florian Jug. \"Noise2Void - learning denoising from single noisy images.\" Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition, 2019.</p> <p>Joshua Batson, and Loic Royer. \"Noise2Self: Blind denoising by self-supervision.\"  International Conference on Machine Learning. Proceedings of Machine Learning Research, 2019.</p>"},{"location":"algorithms/n2v2/","title":"N2V2","text":""},{"location":"algorithms/n2v2/#overview","title":"Overview","text":""},{"location":"algorithms/n2v2/#changes-to-the-model-architecture","title":"Changes to the model architecture","text":""},{"location":"algorithms/n2v2/#masking-scheme","title":"Masking scheme","text":""},{"location":"algorithms/n2v2/#comparison-with-noise2void","title":"Comparison with Noise2Void","text":""},{"location":"algorithms/n2v2/#reference","title":"Reference","text":""},{"location":"algorithms/structn2v/","title":"structN2V","text":""},{"location":"algorithms/structn2v/#overview","title":"Overview","text":""},{"location":"algorithms/structn2v/#masking-scheme","title":"Masking scheme","text":""},{"location":"algorithms/structn2v/#reference","title":"Reference","text":""},{"location":"applications/","title":"Applications","text":"<p>This section contains a list of example applications. These pages were automatically generated from the notebooks in careamics-example</p>"},{"location":"applications/#noise2void","title":"Noise2Void","text":"<ul> <li>2D SEM</li> </ul>"},{"location":"applications/SUMMARY/","title":"SUMMARY","text":"<ul> <li>Applications</li> <li>Noise2Void<ul> <li>2D SEM</li> </ul> </li> </ul>"},{"location":"applications/Noise2Void/2D_SEM/","title":"2D SEM","text":"<p>The SEM dataset is composed of a training and a validation images acquired on a scanning electron microscopy (SEM). They were originally used in Buchholtz et al (2019) to showcase CARE denoising. Here, we demonstrate the performances of Noise2Void on this particular dataset!</p> In\u00a0[1]: Copied! <pre># Imports necessary to execute the code\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport tifffile\nfrom careamics import CAREamist\nfrom careamics.config import create_n2v_configuration\nfrom careamics_portfolio import PortfolioManager\n</pre> # Imports necessary to execute the code from pathlib import Path  import matplotlib.pyplot as plt import tifffile from careamics import CAREamist from careamics.config import create_n2v_configuration from careamics_portfolio import PortfolioManager In\u00a0[\u00a0]: remove_output Copied! <pre># instantiate data portfolio manage\nportfolio = PortfolioManager()\n\n# and download the data\nroot_path = Path(\"./data\")\nfiles = portfolio.denoising.N2V_SEM.download(root_path)\n</pre> # instantiate data portfolio manage portfolio = PortfolioManager()  # and download the data root_path = Path(\"./data\") files = portfolio.denoising.N2V_SEM.download(root_path) In\u00a0[3]: Copied! <pre># load training and validation image and show them side by side\ntrain_image = tifffile.imread(files[0])\nval_image = tifffile.imread(files[1])\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nax[0].imshow(train_image, cmap=\"gray\")\nax[0].set_title(\"Training Image\")\nax[1].imshow(val_image, cmap=\"gray\")\nax[1].set_title(\"Validation Image\")\n</pre> # load training and validation image and show them side by side train_image = tifffile.imread(files[0]) val_image = tifffile.imread(files[1])  fig, ax = plt.subplots(1, 2, figsize=(10, 5)) ax[0].imshow(train_image, cmap=\"gray\") ax[0].set_title(\"Training Image\") ax[1].imshow(val_image, cmap=\"gray\") ax[1].set_title(\"Validation Image\") Out[3]: <pre>Text(0.5, 1.0, 'Validation Image')</pre> In\u00a0[4]: Copied! <pre>config = create_n2v_configuration(\n    experiment_name=\"sem_n2v\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=(64, 64),\n    batch_size=32,\n    num_epochs=30,\n)\n\nprint(config)\n</pre> config = create_n2v_configuration(     experiment_name=\"sem_n2v\",     data_type=\"array\",     axes=\"YX\",     patch_size=(64, 64),     batch_size=32,     num_epochs=30, )  print(config) <pre>{'algorithm_config': {'algorithm': 'n2v',\n                      'loss': 'n2v',\n                      'lr_scheduler': {'name': 'ReduceLROnPlateau',\n                                       'parameters': {}},\n                      'model': {'architecture': 'UNet',\n                                'conv_dims': 2,\n                                'depth': 2,\n                                'final_activation': 'None',\n                                'in_channels': 1,\n                                'independent_channels': True,\n                                'n2v2': False,\n                                'num_channels_init': 32,\n                                'num_classes': 1},\n                      'optimizer': {'name': 'Adam',\n                                    'parameters': {'lr': 0.0001}}},\n 'data_config': {'axes': 'YX',\n                 'batch_size': 32,\n                 'data_type': 'array',\n                 'patch_size': [64, 64],\n                 'transforms': [{'mean': 0.485,\n                                 'name': 'Normalize',\n                                 'std': 0.229},\n                                {'name': 'NDFlip'},\n                                {'name': 'XYRandomRotate90'},\n                                {'masked_pixel_percentage': 0.2,\n                                 'name': 'N2VManipulate',\n                                 'roi_size': 11,\n                                 'strategy': 'uniform',\n                                 'struct_mask_axis': 'none',\n                                 'struct_mask_span': 5}]},\n 'experiment_name': 'sem_n2v',\n 'training_config': {'checkpoint_callback': {'auto_insert_metric_name': False,\n                                             'mode': 'min',\n                                             'monitor': 'val_loss',\n                                             'save_last': True,\n                                             'save_top_k': 3,\n                                             'save_weights_only': False,\n                                             'verbose': False},\n                     'num_epochs': 30},\n 'version': '0.1.0'}\n</pre> In\u00a0[\u00a0]: remove_output Copied! <pre># instantiate a CAREamist\ncareamist = CAREamist(source=config)\n\n# train\ncareamist.train(\n    train_source=train_image,\n    val_source=val_image,\n)\n</pre> # instantiate a CAREamist careamist = CAREamist(source=config)  # train careamist.train(     train_source=train_image,     val_source=val_image, ) In\u00a0[\u00a0]: remove_output Copied! <pre>prediction = careamist.predict(source=train_image, tile_size=(256, 256))\n</pre> prediction = careamist.predict(source=train_image, tile_size=(256, 256)) In\u00a0[7]: Copied! <pre># Show the full image and crops\nx_start, x_end = 600, 850\ny_start, y_end = 200, 450\n\nfig, ax = plt.subplots(2, 2, figsize=(10, 10))\nax[0, 0].imshow(train_image, cmap=\"gray\")\nax[0, 1].imshow(prediction.squeeze(), cmap=\"gray\")\nax[1, 0].imshow(train_image[y_start:y_end, x_start:x_end], cmap=\"gray\")\nax[1, 1].imshow(prediction.squeeze()[y_start:y_end, x_start:x_end], cmap=\"gray\")\n</pre> # Show the full image and crops x_start, x_end = 600, 850 y_start, y_end = 200, 450  fig, ax = plt.subplots(2, 2, figsize=(10, 10)) ax[0, 0].imshow(train_image, cmap=\"gray\") ax[0, 1].imshow(prediction.squeeze(), cmap=\"gray\") ax[1, 0].imshow(train_image[y_start:y_end, x_start:x_end], cmap=\"gray\") ax[1, 1].imshow(prediction.squeeze()[y_start:y_end, x_start:x_end], cmap=\"gray\") Out[7]: <pre>&lt;matplotlib.image.AxesImage at 0x7fdd842a75b0&gt;</pre> In\u00a0[\u00a0]: remove_output Copied! <pre>careamist.export_to_bmz(\n    path=\"sem_n2v_model.zip\",\n    name=\"SEM_N2V\",\n    authors=[{\"name\": \"CAREamics authors\", \"affiliation\": \"Human Technopole\"}],\n)\n</pre> careamist.export_to_bmz(     path=\"sem_n2v_model.zip\",     name=\"SEM_N2V\",     authors=[{\"name\": \"CAREamics authors\", \"affiliation\": \"Human Technopole\"}], )"},{"location":"applications/Noise2Void/2D_SEM/#import-the-dataset","title":"Import the dataset\u00b6","text":"<p>The dataset can be directly downloaded using the <code>careamics-portfolio</code> package, which uses <code>pooch</code> to download the data.</p>"},{"location":"applications/Noise2Void/2D_SEM/#visualize-data","title":"Visualize data\u00b6","text":""},{"location":"applications/Noise2Void/2D_SEM/#train-with-careamics","title":"Train with CAREamics\u00b6","text":"<p>The easiest way to use CAREamics is to create a configuration and a <code>CAREamist</code>.</p>"},{"location":"applications/Noise2Void/2D_SEM/#create-configuration","title":"Create configuration\u00b6","text":"<p>The configuration can be built from scratch, giving the user full control over the various parameters available in CAREamics. However, a straightforward way to create a configuration for a particular algorithm is to use one of the convenience functions.</p>"},{"location":"applications/Noise2Void/2D_SEM/#train","title":"Train\u00b6","text":"<p>A <code>CAREamist</code> can be created using a configuration alone, and then be trained by using the data already loaded in memory.</p>"},{"location":"applications/Noise2Void/2D_SEM/#predict-with-careamics","title":"Predict with CAREamics\u00b6","text":"<p>Prediction is done with the same <code>CAREamist</code> used for training. Because the image is large we predict using tiling.</p>"},{"location":"applications/Noise2Void/2D_SEM/#visualize-the-prediction","title":"Visualize the prediction\u00b6","text":""},{"location":"applications/Noise2Void/2D_SEM/#export-the-model","title":"Export the model\u00b6","text":"<p>The model is automatically saved during training (the so-called <code>checkpoints</code>) and can be loaded back easily, but you can also export the model to the BioImage Model Zoo format.</p>"},{"location":"guides/","title":"Guides","text":"<p>The basic usage of CAREamics follows this pattern:</p> CAREamics workflow<pre><code>\"\"\"Example showcasing the basic usage of CAREamics.\"\"\"\nimport numpy as np\nfrom careamics import CAREamist\nfrom careamics.config import create_n2v_configuration\n\n# create a configuration\nconfig = create_n2v_configuration( # (1)!\n    experiment_name=\"n2v_2D\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=1,\n    num_epochs=1, # (2)!\n)\n\n# instantiate a careamist\ncareamist = CAREamist(config) # (3)!\n\n# train the model\ntrain_data = np.random.randint(0, 255, (256, 256)) # (4)!\ncareamist.train(train_source=train_data)\n\n# once trained, predict\npred_data = np.random.randint(0, 255, (128, 128))\npredction = careamist.predict(source=pred_data)\n\n# export to BMZ format\ncareamist.export_to_bmz( # (5)!\n    path=\"my_model.bmz\", name=\"N2V 2D\", authors=[{\"name\": \"CAREamics authors\"}]\n)\n</code></pre> <ol> <li> <p>There are several convenience functions to create a configuration, but you can also create it entirely manually. Head to the configuration section to know more!</p> </li> <li> <p>Obviously, one should choose a more reasonable number of epochs for training.</p> </li> <li> <p>The CAREamist allows training, predicting and exporting the model. Refer to the  CAREamist section to learn more about it. There is also an alternative for more advance users, which we call the Lightning API.</p> </li> <li> <p>One should use real data for training!</p> </li> <li> <p>Models can be exported to the BioImage Model Zoo format.</p> </li> </ol> <p>Work in progress</p> <p>These pages are still under construction.</p> Configuration <p>                                     The configuration is at the heart of CAREamics, it                                      allow users to define how and which algorithm will be                                     trained.                                 </p> Using CAREAmics <p>                                     The CAREamist is the core element allowing training                                     and prediction using the model defined in the configuration.                                 </p> Lightning API <p>                                     Advanced users can re-use part of CAREamics in their                                     Lightning pipeline, with more customization potential                                     available.                                 </p> Developer resources <p>                                     More insights on how CAREamics is organized and how                                     to tweak it to your needs.                                 </p>"},{"location":"guides/configuration/","title":"Configuration","text":"<p>The configuration summarizes all the parameters used internally by CAREamics. It is  used to create a <code>CAREamist</code> instance and is saved together with the checkpoints and  saved models.</p> <p>It is composed of four members:</p> Anatomy of the configuration<pre><code>from careamics import Configuration\n\nconfig_as_dict = {\n    \"experiment_name\": \"my_experiment\", # (1)!\n    \"algorithm_config\": { # (2)!\n        \"algorithm\": \"n2v\",\n        \"loss\": \"n2v\",\n        \"model\": {\n            \"architecture\": \"UNet\",\n        }\n    },\n    \"data_config\": { # (3)!\n        \"data_type\": \"array\",\n        \"patch_size\": [128, 128],\n        \"axes\": \"YX\",\n    },\n    \"training_config\": { # (4)!\n        \"num_epochs\": 1,\n    }\n}\nconfig = Configuration(**config_as_dict) # (5)!\n</code></pre> <ol> <li>The name of the experiment, used to differentiate trained models.</li> <li>Configuration specific to the model.</li> <li>Configuration related to the data.</li> <li>Training parameters.</li> <li>The configuration is an object! </li> </ol> <p>If the number of parameters looks too limited, it is because the configuration is hiding a lot of default values! But don't be afraid, we have designed convenience functions to help you create a configuration for each of the algorithm CAREamics offers.</p> <p>In the next sections, you can dive deeper on how to use CAREamics  configuration with different levels of expertise.</p> <ul> <li>(beginner) Convenience functions</li> <li>(beginner) Save and load configurations</li> <li>(intermediate) Build the configuration from scratch</li> <li>(intermediate) Full specification</li> <li>(intermediate) Algorithm requirements</li> <li>(advanced) Custom models</li> <li>(all) Understanding the errors</li> </ul>"},{"location":"guides/configuration/advanced_configuration/","title":"Advanced configuration","text":"<p>We have implemented several mechanism to allow users to use CAREamics in contexts we  do not explicitely support. In this section, we describe several of these mechanisms.</p> <p>In the future, we hope to add more depending on user requests.</p>"},{"location":"guides/configuration/advanced_configuration/#custom-data-type","title":"Custom data type","text":"<p>The <code>data_type</code> parameter of the <code>DataConfig</code> class is a string that is used to choose the data loader within CAREamics. We currently only support <code>array</code> and <code>tiff</code> explicitely.</p> <p>However, users can set the <code>data_type</code> to <code>custom</code> and use their own read function.</p> Custom data type<pre><code>from careamics.config import DataConfig\n\ndata_config = DataConfig(\n    data_type=\"custom\", # (1)!\n    axes=\"YX\",\n    patch_size=[128, 128],\n    batch_size=8,\n    num_epochs=20,\n)\n</code></pre> <ol> <li>As far as the configuration is concerned, you only set the <code>data_type</code> to <code>custom</code>. The     rest happens in the <code>CAREamist</code> instance.</li> </ol> <p>Full example in other sections</p> <p>A full example of the use of a custom data type is available in the CAREamist  and Applications sections.</p>"},{"location":"guides/configuration/advanced_configuration/#custom-ai-model","title":"Custom AI model","text":"<p>CAREamics currently only support UNet models, but users can create their own model and use it in CAREamics. First, the model needs to be registered with the  <code>register_model</code> decorator, then both the <code>algorithm</code> of <code>AlgorithmConfig</code> and the  <code>architecture</code> of the <code>model</code> need to be set to custom.</p> Custom AI model<pre><code>from torch import nn, ones\nfrom careamics.config import AlgorithmConfig, register_model\n\n@register_model(name=\"linear_model\")  # (1)!\nclass LinearModel(nn.Module):\n    def __init__(self, in_features, out_features, *args, **kwargs):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = nn.Parameter(ones(in_features, out_features))\n        self.bias = nn.Parameter(ones(out_features))\n\n    def forward(self, input):\n        return (input @ self.weight) + self.bias\n\nconfig = AlgorithmConfig(\n    algorithm=\"custom\",  # (2)!\n    loss=\"mse\",\n    model={\n        \"architecture\": \"Custom\", # (3)!\n        \"name\": \"linear_model\", # (4)!\n        \"in_features\": 10,\n        \"out_features\": 5,\n    },\n)\n</code></pre> <ol> <li>Register your model using the decorator and indicates its <code>name</code>.</li> <li>Set the <code>algorithm</code> to <code>custom</code>.</li> <li>In the <code>model</code>, set the <code>architecture</code> to <code>Custom</code>. Watch the capital letter!</li> <li>Indicate the name of the model.</li> </ol> <p>Full example in other sections</p> <p>A full example of the use of a custom data type is available in the CAREamist  and Applications sections.</p>"},{"location":"guides/configuration/algorithm_requirements/","title":"Algorithm requirements","text":"<p>In this section we detail the constraints of each algorithm on the configuration.</p>"},{"location":"guides/configuration/algorithm_requirements/#noise2void-family","title":"Noise2Void family","text":"<p>This is valid for <code>Noise2Void</code>, <code>N2V2</code> and <code>structN2V</code>.</p>"},{"location":"guides/configuration/algorithm_requirements/#algorithm-configuration","title":"Algorithm configuration","text":"<ul> <li><code>algorithm=\"n2v\"</code></li> <li><code>loss=\"n2v\"</code></li> <li><code>model</code>: <ul> <li>must be a UNet (<code>architecture=\"UNet\"</code>)</li> <li><code>in_channels</code> and <code>num_classes</code> must be equal</li> </ul> </li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#data-configuration","title":"Data configuration","text":"<ul> <li><code>transforms</code>: must contain <code>N2VManipulateModel</code> as the last transform</li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#care","title":"CARE","text":""},{"location":"guides/configuration/algorithm_requirements/#algorithm-configuration_1","title":"Algorithm configuration","text":"<ul> <li><code>algorithm=\"care\"</code></li> <li><code>loss</code>: any but <code>n2v</code></li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#data-configuration_1","title":"Data configuration","text":"<ul> <li><code>transforms</code>: must not contain <code>N2VManipulateModel</code></li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#noise2noise","title":"Noise2Noise","text":""},{"location":"guides/configuration/algorithm_requirements/#algorithm-configuration_2","title":"Algorithm configuration","text":"<ul> <li><code>algorithm=\"care\"</code></li> <li><code>loss</code>: any but <code>n2v</code></li> <li><code>model</code>: <code>in_channels</code> and <code>num_classes</code> must be equal</li> </ul>"},{"location":"guides/configuration/algorithm_requirements/#data-configuration_2","title":"Data configuration","text":"<ul> <li><code>transforms</code>: must not contain <code>N2VManipulateModel</code></li> </ul>"},{"location":"guides/configuration/build_configuration/","title":"Build the configuration","text":"<p>Beginner vs Intermediate</p> <p>This is an intermediate level way to create CAREamics configuration. Do check the convenience functions if you are looking for a simpler way to create CAREanics configurations!</p> <p>CAREamics configuration is validated using Pydantic,  a library that allows you to define schemas and automatically check the types of the  input data you provide. </p> <p>In addition, it allows great flexibility in writing custom validators. In turns this ensures that the configuration is always valid and coherent, protecting against errors deep in the library.</p> <p>As shown in the introduction, CAREamics configuration is composed of four main elements:</p> <ol> <li>Experiment name, a simple string</li> <li>Algorithm configuration, also a Pydantic model</li> <li>Data configuration, also a Pydantic model</li> <li>Training configuration, also a Pydantic model</li> </ol> <p>Each of the parameters and models are validated independently, and the configuration as a whole is validated at the end.</p> <p>There are two ways to build Pydantic models: by passing a dictionnary that reproduces the model structure, or by calling all Pydantic models explicitely. While the first method is  more concise, the second method is less error prone and allow you to explore all parameters available easily if you are using an IDE (e.g. VSCode, JupyterLab etc.).</p>"},{"location":"guides/configuration/build_configuration/#using-nested-dictionaries","title":"Using nested dictionaries","text":"<p>In the introduction, we have seen a minimum example on how to build the configuration with a dictionnary, reproduced here:</p> Building the configuration with a dictionary<pre><code>from careamics import Configuration\n\nconfig_as_dict = {\n    \"experiment_name\": \"my_experiment\", # (1)!\n    \"algorithm_config\": { # (2)!\n        \"algorithm\": \"n2v\",\n        \"loss\": \"n2v\",\n        \"model\": { # (3)!\n            \"architecture\": \"UNet\",\n        }\n    },\n    \"data_config\": { # (4)!\n        \"data_type\": \"array\",\n        \"patch_size\": [128, 128],\n        \"axes\": \"YX\",\n    },\n    \"training_config\": { \n        \"num_epochs\": 1,\n    }\n}\nconfig = Configuration(**config_as_dict) # (5)!\n</code></pre> <ol> <li>The first parameter is just a string!</li> <li>But this one is itself a Pydantic model, so we need to pass a dictionnary that     respects the structure of the model.</li> <li>Don't be surprised, the deep neural network model is also a Pydantic model.</li> <li>Same here, and so on...</li> <li>The configuration is instantiated by passing keywords arguments rather than a dictionary,      and Pydantic knows how to interpret the sub-dictionaries to correctly instantiate the member      models.</li> </ol> <p>While this is neat, because you are dealing with nested dictionaries, it is easy to add the parameters at the wrong level and you need to constantly refer to the code documentation to know which parameters are available.</p> <p>Finally, because you are validating the configuration at once, you will get all the validation errors in one go.</p>"},{"location":"guides/configuration/build_configuration/#using-pydantic-models-preferred","title":"Using Pydantic models (preferred)","text":"<p>The preferred way to build the configuration is to call the Pydantic models directly. This allows you to explore the parameters throught your IDE, but also to get the validation errors closer to the source of the error.</p> Building the configuration using Pydantic models<pre><code>from careamics import Configuration\nfrom careamics.config import ( # (1)!\n    AlgorithmConfig,\n    DataConfig,\n    TrainingConfig,\n)\nfrom careamics.config.architectures import UNetModel\nfrom careamics.config.transformations import N2VManipulateModel\nfrom careamics.config.support import (\n    SupportedAlgorithm,\n    SupportedArchitecture,\n    SupportedData,\n    SupportedLogger,\n    SupportedLoss,\n    SupportedTransform,\n)\n\nexperiment_name = \"Pydantic N2V2 example\"\n\n# build AlgorithmConfig \nalgorithm_model = AlgorithmConfig( # (2)!\n    algorithm=SupportedAlgorithm.N2V.value, # (3)!\n    loss=SupportedLoss.N2V.value,\n    model=UNetModel( # (4)!\n        architecture=SupportedArchitecture.UNET.value,\n        in_channels=1,\n        num_classes=1,\n    ),\n)\n\n# then the DataConfig\ndata_model = DataConfig(\n    data_type=SupportedData.ARRAY.value,\n    patch_size=(256, 256),\n    batch_size=8,\n    axes=\"YX\",\n    transforms=[ \n        { # (5)!\n            \"name\": SupportedTransform.NORMALIZE.value,\n        },\n        {\n            \"name\": SupportedTransform.NDFLIP.value,\n            \"is_3D\": False,\n        },\n        N2VManipulateModel( # (6)!\n            masked_pixel_percentage=0.15,\n        ),\n    ],\n    dataloader_params={ # (7)!\n        \"num_workers\": 4,\n    },\n)\n\n# then the TrainingConfig\ntraining_model = TrainingConfig(\n    num_epochs=30,\n    logger=SupportedLogger.WANDB.value,\n)\n\n# finally, build the Configuration\nconfig = Configuration( # (8)!\n    experiment_name=experiment_name,\n    algorithm_config=algorithm_model,\n    data_config=data_model,\n    training_config=training_model,\n)\n</code></pre> <ol> <li>The main Pydantic models are imported from the <code>careamics</code> and <code>careamics.config</code>      submodules, the others are organized in different submodules.</li> <li>A Pydantic model is instantiated like any other class.</li> <li>In CAREamics, we store constant values in <code>enum</code> classes in the <code>careamics.config.support</code>      submodule. This allows to have a single source of truth for the values. But you have     to remember to use the <code>.value</code> attribute to get the string value.</li> <li>You can instantiate the nested models directly in the parent model or outside (outside     is better to track down the errors!).</li> <li>The <code>transforms</code> parameter is a list, you can mix and match the different transformations,     but also use dictionnaries or the Pydantic model classes directly. Make sure to pass     the <code>name</code> as it is used to identify the correct Pydantic model to instantiate for the     transformation.</li> <li>Here for instance, we use the Pydantic model directly.</li> <li>The <code>dataloader_params</code> is a dictionnary, you can pass any parameter that is accepted by     the <code>torch.utils.data.DataLoader</code> class.</li> <li>Finally, the configuration is instantiated by passing the Pydantic models directly.</li> </ol>"},{"location":"guides/configuration/convenience_functions/","title":"Convenience functions","text":"<p>As building a full CAREamics configuration requires a complete understanding of the  various parameters and experience with Pydantic, we provide convenience functions to create configurations with a only few parameters related to the algorithm users want to train.</p> <p>All convenience methods can be found in the <code>careamics.config</code> modules. CAREamics  currently supports Noise2Void and its variants, CARE and Noise2Noise. </p> Import convenience functions<pre><code>from careamics.config import (\n    create_n2v_configuration, # Noise2Void, N2V2, structN2V\n    create_care_configuration, # CARE\n    create_n2n_configuration, # Noise2Noise\n)\n</code></pre> <p>Each method does all the heavy lifting to make the configuration coherent. They share a certain numbers of mandatory parameters:</p> <ul> <li><code>experiment_name</code>: The name of the experiment, used to differentiate trained models.</li> <li><code>data_type</code>: One of the types supported by CAREamics (<code>array</code>, <code>tiff</code> or <code>custom</code>).</li> <li><code>axes</code>: Axes of the data (e.g. SYX), can only the following letters: <code>STCZYX</code>.</li> <li><code>patch_size</code>: Size of the patches along the spatial dimensions (e.g. [64, 64]).</li> <li><code>batch_size</code>: Batch size to use during training (e.g. 8). This parameter affects the     memory footprint on the GPU.</li> <li><code>num_epochs</code>: Number of epochs.</li> </ul> <p>Additional optional parameters can be passed to tweak the configuration. </p> Noise2VoidNoise2NoiseCARE"},{"location":"guides/configuration/convenience_functions/#noise2void","title":"Noise2Void","text":""},{"location":"guides/configuration/convenience_functions/#training-with-channels","title":"Training with channels","text":"<p>When training with multiple channels, the <code>axes</code> parameter should contain <code>C</code> (e.g. <code>YXC</code>). An error will be then thrown if the optional parameter <code>n_channels</code> is not specified!  Likewise if <code>n_channels</code> is specified but <code>C</code> is not in <code>axes</code>.</p> <p>The correct way is to specify them both at the same time.</p> Configuration with multiple channels<pre><code>config = create_n2v_configuration(\n    experiment_name='n2v_2D_channels', \n    data_type=\"tiff\", \n    axes=\"YXC\", # (1)!\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    n_channels=3 # (2)!\n)\n</code></pre> <ol> <li>The axes contain the letter <code>C</code>.</li> <li>The number of channels is specified.</li> </ol> <p>Independent channels</p> <p>By default, the channels are trained independently: that means that they have no influence on each other. As they might have completely different noise models, this can lead to better results.</p> <p>However, in some cases, you might want to train the channels together to get more structural information.</p> <p>To control whether the channels are trained independently, you can use the  <code>independent_channels</code> parameter:</p> Training channels together<pre><code>config = create_n2v_configuration(\n    experiment_name=\"n2v_2D_mix_channels\",\n    data_type=\"tiff\",\n    axes=\"YXC\",  # (1)!\n    patch_size=[64, 64],\n    batch_size=8,\n    num_epochs=20,\n    n_channels=3,\n    independent_channels=False,  # (2)!\n)\n</code></pre> <ol> <li>As previously, we specify the channels in <code>axes</code> and <code>n_channels</code>.</li> <li>This ensures that the channels are trained together!</li> </ol>"},{"location":"guides/configuration/convenience_functions/#using-augmentations","title":"Using augmentations","text":"<p>By default CAREamics configuration uses augmentations that are specific to the algorithm (e.g. Noise2Void) and that are compatible with microscopy images (e.g. flip and 90 degrees rotations).</p> <p>However in certain cases, users might want to disable augmentations. For instance if you have structures that are always oriented in the same direction. To do so there is a single <code>use_agumentations</code> parameter:</p> Configuration without augmentations<pre><code>config = create_n2v_configuration(\n    experiment_name='n2v_2D_no_aug', \n    data_type=\"tiff\", \n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    use_augmentations=False # (1)!\n)\n</code></pre> <ol> <li>Augmentations are disabled (but normalization and N2V pixel manipulation are still there!).</li> </ol>"},{"location":"guides/configuration/convenience_functions/#choosing-a-logger","title":"Choosing a logger","text":"<p>By default, CAREamics simply log the training progress in the console. However, it is  possible to use either WandB or TensorBoard.</p> <p>Loggers installation</p> <p>Using WandB or TensorBoard require the installation of <code>extra</code> dependencies. Check out the installation section to know more about it.</p> Configuration with WandB<pre><code>config = create_n2v_configuration(\n    experiment_name='n2v_2D_wandb', \n    data_type=\"tiff\", \n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    logger=\"wandb\" # (1)!\n)\n</code></pre> <ol> <li><code>wandb</code> or <code>tensorboard</code></li> </ol>"},{"location":"guides/configuration/convenience_functions/#advanced-passing-model-specific-parameters","title":"(Advanced) Passing model specific parameters","text":"<p>By default, the convenience functions use the default UNet model parameters. But if  you are feeling brave, you can pass model specific parameters in the <code>model_kwargs</code> dictionary. </p> Configuration with model specific parameters<pre><code>config = create_n2v_configuration(\n    experiment_name='n2v_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    model_kwargs={\n        \"depth\": 3, # (1)!\n        \"num_channels_init\": 64, # (2)!\n        # (3)!\n    }\n)\n</code></pre> <ol> <li>The depth of the UNet.</li> <li>The number of channels in the first layer.</li> <li>Add any other parameter specific to the model!</li> </ol> <p>Model parameters overwriting</p> <p>Some values of the model parameters are not compatible with certain algorithms.  Therefore, these are overwritten by the convenience functions. For instance, if you pass <code>in_channels</code> or <code>independent_channels</code> in the <code>model_kwargs</code> dictionary,  they will be ignored and replaced by the explicit parameters passed to the convenience function.</p>"},{"location":"guides/configuration/convenience_functions/#noise2void-specific-parameters","title":"Noise2Void specific parameters","text":"<p>Noise2Void has a few additional parameters that can be set, including for using its  variants N2V2 and structN2V.</p> <p>Understanding Noise2Void and its variants</p> <p>Before deciding which variant to use, and how to modify the parameters, we recommend to die a little a bit on how each algorithm works!</p>"},{"location":"guides/configuration/convenience_functions/#noise2void-parameters","title":"Noise2Void parameters","text":"<p>There are two Noise2Void parameters that influence how the patches are manipulated during training:</p> <ul> <li><code>roi_size</code>: This parameter specifies the size of the area used to replace the masked pixel value.</li> <li><code>masked_pixel_percentage</code>: This parameter specifies how many pixels per patch will be manipulated.</li> </ul> <p>While the default values are usually fine, they can be tweaked to improve the training in certain cases.</p> Configuration with N2V parameters<pre><code>config = create_n2v_configuration(\n    experiment_name='n2v_2D', \n    data_type=\"tiff\", \n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    roi_size=7,\n    masked_pixel_percentage=0.5\n)\n</code></pre>"},{"location":"guides/configuration/convenience_functions/#n2v2","title":"N2V2","text":"<p>To use N2V2, the <code>use_n2v2</code> parameter should simply be set to <code>True</code>.</p> Configuration with N2V2<pre><code>config = create_n2v_configuration(\n    experiment_name='n2v2_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    use_n2v2=True # (1)!\n)\n</code></pre> <ol> <li>What it does is modifying the architecture of the UNet model and the way the masked     pixels are replaced.</li> </ol>"},{"location":"guides/configuration/convenience_functions/#structn2v","title":"structN2V","text":"<p>StructN2V has two parameters that can be set:</p> <ul> <li><code>struct_n2v_axis</code>: The axis along which the structN2V mask will be applied. By default it     is set to <code>none</code> (structN2V is disabled), you can set it to either <code>horizontal</code> or <code>vertical</code>.</li> <li><code>struct_n2v_span</code>: The size of the structN2V mask.</li> </ul> Configuration with structN2V<pre><code>config = create_n2v_configuration(\n    experiment_name='structn2v_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    struct_n2v_axis=\"horizontal\",\n    struct_n2v_span=5\n)\n</code></pre>"},{"location":"guides/configuration/convenience_functions/#noise2noise","title":"Noise2Noise","text":""},{"location":"guides/configuration/convenience_functions/#training-with-channels_1","title":"Training with channels","text":"<p>When training with multiple channels, the <code>axes</code> parameter should contain <code>C</code> (e.g. <code>YXC</code>). An error will be then thrown if the optional parameter <code>n_channels</code> is not specified!  Likewise if <code>n_channels</code> is specified but <code>C</code> is not in <code>axes</code>.</p> <p>The correct way is to specify them both at the same time.</p> Configuration with multiple channels<pre><code>config = create_n2n_configuration(\n    experiment_name='n2n_2D_channels', \n    data_type=\"tiff\", \n    axes=\"YXC\", # (1)!\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    n_channels=3 # (2)!\n)\n</code></pre> <ol> <li>The axes contain the letter <code>C</code>.</li> <li>The number of channels is specified.</li> </ol> <p>Independent channels</p> <p>By default, the channels are trained independently: that means that they have no influence on each other. As they might have completely different noise models, this can lead to better results.</p> <p>However, in some cases, you might want to train the channels together to get more structural information.</p> <p>To control whether the channels are trained independently, you can use the  <code>independent_channels</code> parameter:</p> Training channels together<pre><code>config = create_n2n_configuration(\n    experiment_name=\"n2n_2D_mix_channels\",\n    data_type=\"tiff\",\n    axes=\"YXC\",  # (1)!\n    patch_size=[64, 64],\n    batch_size=8,\n    num_epochs=20,\n    n_channels=3,\n    independent_channels=False,  # (2)!\n)\n</code></pre> <ol> <li>As previously, we specify the channels in <code>axes</code> and <code>n_channels</code>.</li> <li>This ensures that the channels are trained together!</li> </ol>"},{"location":"guides/configuration/convenience_functions/#using-augmentations_1","title":"Using augmentations","text":"<p>By default CAREamics configuration uses augmentations that are specific to the algorithm (e.g. Noise2Void) and that are compatible with microscopy images (e.g. flip and 90 degrees rotations).</p> <p>However in certain cases, users might want to disable augmentations. For instance if you have structures that are always oriented in the same direction. To do so there is a single <code>use_agumentations</code> parameter:</p> Configuration without augmentations<pre><code>config = create_n2n_configuration(\n    experiment_name='n2n_2D_no_aug', \n    data_type=\"tiff\", \n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    use_augmentations=False # (1)!\n)\n</code></pre> <ol> <li>Augmentations are disabled (but normalization and N2V pixel manipulation are still there!).</li> </ol>"},{"location":"guides/configuration/convenience_functions/#choosing-a-logger_1","title":"Choosing a logger","text":"<p>By default, CAREamics simply log the training progress in the console. However, it is  possible to use either WandB or TensorBoard.</p> <p>Loggers installation</p> <p>Using WandB or TensorBoard require the installation of <code>extra</code> dependencies. Check out the installation section to know more about it.</p> Configuration with WandB<pre><code>config = create_n2n_configuration(\n    experiment_name='n2n_2D_wandb', \n    data_type=\"tiff\", \n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    logger=\"wandb\" # (1)!\n)\n</code></pre> <ol> <li><code>wandb</code> or <code>tensorboard</code></li> </ol>"},{"location":"guides/configuration/convenience_functions/#advanced-passing-model-specific-parameters_1","title":"(Advanced) Passing model specific parameters","text":"<p>By default, the convenience functions use the default UNet model parameters. But if  you are feeling brave, you can pass model specific parameters in the <code>model_kwargs</code> dictionary. </p> Configuration with model specific parameters<pre><code>config = create_n2n_configuration(\n    experiment_name='n2n_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    model_kwargs={\n        \"depth\": 3, # (1)!\n        \"num_channels_init\": 64, # (2)!\n        # (3)!\n    }\n)\n</code></pre> <ol> <li>The depth of the UNet.</li> <li>The number of channels in the first layer.</li> <li>Add any other parameter specific to the model!</li> </ol> <p>Model parameters overwriting</p> <p>Some values of the model parameters are not compatible with certain algorithms.  Therefore, these are overwritten by the convenience functions. For instance, if you pass <code>in_channels</code> or <code>independent_channels</code> in the <code>model_kwargs</code> dictionary,  they will be ignored and replaced by the explicit parameters passed to the convenience function.</p>"},{"location":"guides/configuration/convenience_functions/#noise2noise-specific-parameters","title":"Noise2Noise specific parameters","text":"<p>As opposed to Noise2Void, CARE and Noise2Noise can be trained with different loss functions. This can be set using the <code>loss</code> parameter (surprise, surprise!).</p> Configuration with different loss<pre><code>config = create_n2n_configuration(\n    experiment_name='n2n_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    loss=\"mae\" # (1)!\n)\n</code></pre> <ol> <li><code>mae</code> or <code>mse</code></li> </ol>"},{"location":"guides/configuration/convenience_functions/#care","title":"CARE","text":""},{"location":"guides/configuration/convenience_functions/#training-with-channels_2","title":"Training with channels","text":"<p>When training with multiple channels, the <code>axes</code> parameter should contain <code>C</code> (e.g. <code>YXC</code>). An error will be then thrown if the optional parameter <code>n_channels_in</code> is not specified!  Likewise if <code>n_channels_in</code> is specified but <code>C</code> is not in <code>axes</code>.</p> <p>The correct way is to specify them both at the same time.</p> Configuration with multiple channels<pre><code>config = create_care_configuration(\n    experiment_name='care_2D_channels', \n    data_type=\"tiff\", \n    axes=\"YXC\", # (1)!\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    n_channels_in=3, # (2)!\n    n_channels_out=2 # (3)!\n)\n</code></pre> <ol> <li>The axes contain the letter <code>C</code>.</li> <li>The number of channels is specified.</li> <li>Depending on the CARE task, you also see to set <code>n_channels_out</code></li> </ol> <p>Independent channels</p> <p>By default, the channels are trained independently: that means that they have no influence on each other. As they might have completely different noise models, this can lead to better results.</p> <p>However, in some cases, you might want to train the channels together to get more structural information.</p> <p>To control whether the channels are trained independently, you can use the  <code>independent_channels</code> parameter:</p> Training channels together<pre><code>config = create_care_configuration(\n    experiment_name=\"care_2D_mix_channels\",\n    data_type=\"tiff\",\n    axes=\"YXC\",  # (1)!\n    patch_size=[64, 64],\n    batch_size=8,\n    num_epochs=20,\n    n_channels_in=3,\n    n_channels_out=2,\n    independent_channels=False,  # (2)!\n)\n</code></pre> <ol> <li>As previously, we specify the channels in <code>axes</code> and <code>n_channels</code>.</li> <li>This ensures that the channels are trained together!</li> </ol>"},{"location":"guides/configuration/convenience_functions/#using-augmentations_2","title":"Using augmentations","text":"<p>By default CAREamics configuration uses augmentations that are specific to the algorithm (e.g. Noise2Void) and that are compatible with microscopy images (e.g. flip and 90 degrees rotations).</p> <p>However in certain cases, users might want to disable augmentations. For instance if you have structures that are always oriented in the same direction. To do so there is a single <code>use_agumentations</code> parameter:</p> Configuration without augmentations<pre><code>config = create_care_configuration(\n    experiment_name='care_2D_no_aug', \n    data_type=\"tiff\", \n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    use_augmentations=False # (1)!\n)\n</code></pre> <ol> <li>Augmentations are disabled (but normalization and N2V pixel manipulation are still there!).</li> </ol>"},{"location":"guides/configuration/convenience_functions/#choosing-a-logger_2","title":"Choosing a logger","text":"<p>By default, CAREamics simply log the training progress in the console. However, it is  possible to use either WandB or TensorBoard.</p> <p>Loggers installation</p> <p>Using WandB or TensorBoard require the installation of <code>extra</code> dependencies. Check out the installation section to know more about it.</p> Configuration with WandB<pre><code>config = create_care_configuration(\n    experiment_name='care_2D_wandb', \n    data_type=\"tiff\", \n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=8, \n    num_epochs=20,\n    logger=\"wandb\" # (1)!\n)\n</code></pre> <ol> <li><code>wandb</code> or <code>tensorboard</code></li> </ol>"},{"location":"guides/configuration/convenience_functions/#advanced-passing-model-specific-parameters_2","title":"(Advanced) Passing model specific parameters","text":"<p>By default, the convenience functions use the default UNet model parameters. But if  you are feeling brave, you can pass model specific parameters in the <code>model_kwargs</code> dictionary. </p> Configuration with model specific parameters<pre><code>config = create_care_configuration(\n    experiment_name='care_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    model_kwargs={\n        \"depth\": 3, # (1)!\n        \"num_channels_init\": 64, # (2)!\n        # (3)!\n    }\n)\n</code></pre> <ol> <li>The depth of the UNet.</li> <li>The number of channels in the first layer.</li> <li>Add any other parameter specific to the model!</li> </ol> <p>Model parameters overwriting</p> <p>Some values of the model parameters are not compatible with certain algorithms.  Therefore, these are overwritten by the convenience functions. For instance, if you pass <code>in_channels</code> or <code>independent_channels</code> in the <code>model_kwargs</code> dictionary,  they will be ignored and replaced by the explicit parameters passed to the convenience function.</p>"},{"location":"guides/configuration/convenience_functions/#care-specific-parameters","title":"CARE specific parameters","text":"<p>CARE can be trained with different loss functions. This can be set using the <code>loss</code> parameter (surprise, surprise!).</p> Configuration with different loss<pre><code>config = create_care_configuration(\n    experiment_name='care_3D', \n    data_type=\"tiff\", \n    axes=\"ZYX\",\n    patch_size=[16, 64, 64],\n    batch_size=8, \n    num_epochs=20,\n    loss=\"mae\" # (1)!\n)\n</code></pre> <ol> <li><code>mae</code> or <code>mse</code></li> </ol>"},{"location":"guides/configuration/full_spec/","title":"Full specification","text":"<p>The full specification of the configuration is a detailed description of all the parameters  that can be used to configure CAREamics. It is useful for advanced users who want to  have full control over the training process.</p> <p>You can also explore all the Pydantic models using the reference documentation.</p> Full specification<pre><code>from careamics import Configuration\nfrom careamics.config import (\n    AlgorithmConfig,\n    DataConfig,\n    TrainingConfig,\n)\nfrom careamics.config.architectures import UNetModel\nfrom careamics.config.callback_model import EarlyStoppingModel\nfrom careamics.config.optimizer_models import LrSchedulerModel, OptimizerModel\nfrom careamics.config.support import (\n    SupportedActivation,\n    SupportedAlgorithm,\n    SupportedArchitecture,\n    SupportedData,\n    SupportedLogger,\n    SupportedLoss,\n    SupportedOptimizer,\n    SupportedPixelManipulation,\n    SupportedScheduler,\n    SupportedStructAxis,\n)\nfrom careamics.config.transformations import (\n    N2VManipulateModel,\n    NDFlipModel,\n    NormalizeModel,\n    XYRandomRotate90Model,\n)\n\nexperiment_name = \"Full example\"\n\n# Algorithm\nmodel = UNetModel( # (1)!\n    architecture=SupportedArchitecture.UNET.value,\n    in_channels=1,\n    num_classes=1,\n    depth=2,\n    num_channels_init=32,\n    final_activation=SupportedActivation.NONE.value,\n    n2v2=False,\n)\n\noptimizer = OptimizerModel(\n    name=SupportedOptimizer.ADAM.value, parameters={\"lr\": 0.0001}\n)\n\nscheduler = LrSchedulerModel(\n    name=SupportedScheduler.REDUCE_LR_ON_PLATEAU.value,\n)\n\nalgorithm_model = AlgorithmConfig(\n    algorithm=SupportedAlgorithm.N2V.value,\n    loss=SupportedLoss.N2V.value,\n    model=model,\n    optimizer=optimizer,\n    lr_scheduler=scheduler,\n)\n\n# Data\nnorm = NormalizeModel()\nndflip = NDFlipModel(is_3D=False)\nrotate = XYRandomRotate90Model(is_3D=False)\nn2vmanipulate = N2VManipulateModel(\n    roi_size=11,\n    masked_pixel_percentage=0.2,\n    strategy=SupportedPixelManipulation.MEDIAN.value,\n    struct_mask_axis=SupportedStructAxis.NONE.value,\n    struct_mask_span=7,\n)\n\ndata_model = DataConfig(\n    data_type=SupportedData.ARRAY.value,\n    patch_size=(256, 256),\n    batch_size=8,\n    axes=\"YX\",\n    transforms=[norm, ndflip, rotate, n2vmanipulate],\n    dataloader_params={\n        \"num_workers\": 4,\n        # (2)!\n    },\n    # (3)!\n)\n\n# Traning\nearlystopping = EarlyStoppingModel(\n    # (4)!\n)\n\ntraining_model = TrainingConfig(\n    num_epochs=30,\n    logger=SupportedLogger.WANDB.value,\n    early_stopping_callback=earlystopping,\n)\n\nconfig = Configuration(\n    experiment_name=experiment_name,\n    algorithm_config=algorithm_model,\n    data_config=data_model,\n    training_config=training_model,\n)\n</code></pre> <ol> <li>Currently, we only support the UNet architecture and custom models (see advanced     configuration). But in the future, there will be more     models to use here.</li> <li>Here the parameters are those from Pytorch DataLoaders.</li> <li>There are also the <code>mean</code> and <code>std</code> parameters, used to normalize the data. But they are typically     calculated from the data itself, and then later stored in the configuration.</li> <li>The <code>EarlyStoppingModel</code> has a lot of parameters not reproduced here.</li> </ol> <p>However, not all algorithms are compatible with all parameters. The configuration does some heavy lifting to correct the obvious incompatibilities, but some are left to the user. In the next section, we will see the constraints on each algorithm.</p>"},{"location":"guides/configuration/save_load/","title":"Save and load","text":"<p>CAREamics configurations can be saved to the disk as <code>.yml</code> file and loaded easily to start similar experiments.</p>"},{"location":"guides/configuration/save_load/#save-a-configuration","title":"Save a configuration","text":"Save a configuration<pre><code>from careamics import save_configuration\nfrom careamics.config import create_n2v_configuration\n\nconfig =  create_n2v_configuration(\n    experiment_name=\"Config_to_save\",\n    data_type=\"tiff\",\n    axes=\"ZYX\",\n    patch_size=(8, 64, 64),\n    batch_size=8,\n    num_epochs=20\n)\nsave_configuration(config, \"config.yml\")\n</code></pre> <p>In the resulting file, you can see all the parameters that are defaults and hidden from you.</p> resulting config.yml file <pre><code>version: 0.1.0\nexperiment_name: Config_to_save\nalgorithm_config:\nalgorithm: n2v\nloss: n2v\nmodel:\n    architecture: UNet\n    conv_dims: 3\n    num_classes: 1\n    in_channels: 1\n    depth: 2\n    num_channels_init: 32\n    final_activation: None\n    n2v2: false\noptimizer:\n    name: Adam\n    parameters:\n    lr: 0.0001\nlr_scheduler:\n    name: ReduceLROnPlateau\n    parameters: {}\ndata_config:\ndata_type: tiff\npatch_size:\n- 8\n- 64\n- 64\nbatch_size: 8\naxes: ZYX\ntransforms:\n- name: Normalize\n    mean: 0.485\n    std: 0.229\n- name: NDFlip\n    p: 0.5\n    is_3D: true\n    flip_z: true\n- name: XYRandomRotate90\n    p: 0.5\n    is_3D: true\n- name: N2VManipulate\n    roi_size: 11\n    masked_pixel_percentage: 0.2\n    strategy: uniform\n    struct_mask_axis: none\n    struct_mask_span: 5\ntraining_config:\nnum_epochs: 20\ncheckpoint_callback:\n    monitor: val_loss\n    verbose: false\n    save_weights_only: false\n    mode: min\n    auto_insert_metric_name: false\n    save_last: true\n    save_top_k: 3\n</code></pre>"},{"location":"guides/configuration/save_load/#load-a-configuration","title":"Load a configuration","text":"Load a configuration<pre><code>from careamics import load_configuration\n\nconfig = load_configuration(\"config.yml\")\n</code></pre>"},{"location":"guides/configuration/understanding_errors/","title":"Configuration errors","text":"<p>Work in progress</p> <p>These pages are still under construction and will come soon.</p>"},{"location":"guides/dev_resources/","title":"Developer's guide","text":"<p>Work in progress</p> <p>These pages are still under construction.</p>"},{"location":"guides/dev_resources/website/","title":"Website","text":"<p>The website is built using mkdocs, more specifically the  mkdocs-material theme. Modifications to the theme were greatly inspired from pydev-guide.</p> <p>In this page, we describe some of the technical details on how to maintain this website.</p>"},{"location":"guides/dev_resources/website/#environement","title":"Environement","text":"<p>The <code>requirements.txt</code> file contains all the packages used to generate this website.</p>"},{"location":"guides/dev_resources/website/#build-the-pages-locally","title":"Build the pages locally","text":"<p>In order to build the pages locally, follow these steps:</p> <ol> <li>Fork this repository and clone it.</li> <li>Create a new environment and install the dependencies:     <pre><code>conda create -n careamics-docs python=3.11\npip install -r requirements.txt\n</code></pre></li> <li>Run the following scripts (which are normally run by the CI):     <pre><code>python scripts/check_out_repos.sh\npython scripts/check_out_notebooks.sh\n</code></pre></li> <li>Build the pages:     <pre><code>mkdocs serve\n</code></pre></li> <li>Open the local link in your browser.</li> </ol> <p>Note: This will not show you the version mechanism. For this, check out the  Version release section.</p>"},{"location":"guides/dev_resources/website/#code-snippets","title":"Code snippets","text":"<p>Code snippets are all automatically tested in careamics-example and are currently manually added to the markdown pages in the guides.</p>"},{"location":"guides/dev_resources/website/#jupyter-notebooks-applications","title":"Jupyter notebooks applications","text":"<p>The pages in the application section are automatically generated from the Jupyter notebooks in careamics-example  using mkdocs-jupyter. A bash script (<code>scripts/check_out_notebooks.sh</code>) checks out the repository and copies  all the notebooks referenced in a text files into the correct path in the application  folder. Finally, the script <code>scripts/gen_jupyter_nav.py</code> creates entries for each notebook  in the navigation file of mkdocs.</p>"},{"location":"guides/dev_resources/website/#adding-a-new-notebook","title":"Adding a new notebook","text":"<ol> <li>Add the notebook to <code>scripts/notebooks.csv</code>, without using spaces. The third column   specifies the path to the page in the application section, while the last column is used    as title.</li> <li>You can test the notebook by running <code>sh scripts/notebooks.sh</code> then <code>mkdocs serve</code>.</li> </ol> <p>!!! info title=\"Cell tags\"</p> <pre><code>By default, all cell outputs are shown. To hide the output of a particular cell,\nadd the tag `remove_output` to the cell. The `mkdocs.ynml` specifies that this \ntag is used to hide cell outputs.\n</code></pre> <p>!!! info title=\"CSV ending on a new line\"</p> <pre><code>In is important to end the `.csv` file with a new line, otherwise the last line might\nbe ignored.\n</code></pre>"},{"location":"guides/dev_resources/website/#code-reference","title":"Code reference","text":"<p>The code reference is generated using mkdocstrings,  the script <code>scripts/checkout_repos.sh</code> and the page building script <code>scripts/gen_ref_pages.py</code>.  To include a new package, simply add it to the <code>scripts/git_repositories.txt</code> file.</p> <pre><code>https://github.com/CAREamics/careamics\nhttps://github.com/CAREamics/careamics-portfolio\n&lt;new project here&gt;\n</code></pre>"},{"location":"guides/dev_resources/website/#updating-the-website-version","title":"Updating the website version","text":"<p>In principle, when a new release of CAREamics is made, the state of the documentation is saved into the corresponding version, and the documentation is tagged with the next (ongoing) version.</p> <p>For instance, the documentation is showing version <code>0.4</code>, upon release of verson  <code>0.4</code>, the state of the documentation is saved. The latest documentation is then  tagged with version <code>0.5</code> (the next version) until this one is released.</p> <p>In order to keep track of versions, we use mike.  We apply the following procedure:</p> <ol> <li>Release version MAJOR.MINOR of CAREamics</li> <li>Tag the latest documentation with version MAJOR.(MINOR+1)   <pre><code>git tag MAJOR.(MINOR+1)\ngit push --tags\n</code></pre></li> </ol> <p>To visualize the pages with the versions, you can use:</p> <pre><code>mike serve\n</code></pre>"},{"location":"guides/dev_resources/website/#correcting-a-version-error","title":"Correcting a version error","text":"<p>All the versions are stored in the <code>gh-pages</code> branch. If you made a mistake in the version tagging, you can correct it by deleting the tag and pushing the changes.</p>"},{"location":"guides/lightning_api/","title":"Lightning API","text":"<p>Work in progress</p> <p>These pages are still under construction.</p>"},{"location":"guides/usage/","title":"Using CAREamics","text":"<p>In this section, we will explore the many facets of the <code>CAREamist</code> class, which allors training and predicting using the various algorithms in CAREamics.</p> <p>The workflow in CAREamics has five steps: creating a configuration, instantiating a <code>CAREamist</code> object, training, prediction, and model export.</p> Basic CAREamics usage<pre><code>import numpy as np\nfrom careamics import CAREamist\nfrom careamics.config import create_n2v_configuration\n\n# create a configuration\nconfig = create_n2v_configuration(\n    experiment_name=\"n2v_2D\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=1,\n    num_epochs=1, # (1)!\n)\n\n# instantiate a careamist\ncareamist = CAREamist(config)\n\n# train the model\ntrain_data = np.random.randint(0, 255, (256, 256)) # (2)!\ncareamist.train(train_source=train_data)\n\n# once trained, predict\npred_data = np.random.randint(0, 255, (128, 128))\npredction = careamist.predict(source=pred_data)\n\n# export to BMZ format\ncareamist.export_to_bmz(\n    path=\"my_model.bmz\", name=\"N2V 2D\", authors=[{\"name\": \"CAREamics authors\"}]\n)\n</code></pre> <ol> <li> <p>Obviously, one should choose a more reasonable number of epochs for training.</p> </li> <li> <p>One should use real data for training!</p> </li> </ol>"},{"location":"guides/usage/careamist/","title":"CAREamist","text":"<p>The <code>CAREamist</code> is the central class in CAREamics, it provides the API to train, predict and save models. There are three ways to create a <code>CAREamist</code> object: with a configuration,  with a path to a configuration, or with a path to a trained model.</p>"},{"location":"guides/usage/careamist/#instantiating-with-a-configuration","title":"Instantiating with a configuration","text":"<p>When passing a configuration to the <code>CAREamist</code> constructor, the model is initialized with random weights and prediction will not be possible until the model is trained.</p> Instantiating CAREamist with a configuration<pre><code>from careamics import CAREamist\nfrom careamics.config import create_n2v_configuration\n\nconfig = create_n2v_configuration(\n    experiment_name=\"n2v_2D\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=1,\n    num_epochs=1,\n) # (1)!\n\ncareamist = CAREamist(config)\n</code></pre> <ol> <li>Any valid configuration will do!</li> </ol>"},{"location":"guides/usage/careamist/#instantiating-with-a-path-to-a-configuration","title":"Instantiating with a path to a configuration","text":"<p>This is similar to the previous section, except that the configuration is loaded from a file on disk.</p> Instantiating CAREamist with a path to a configuration<pre><code>from careamics import CAREamist\nfrom careamics.config import create_n2v_configuration, save_configuration\n\nconfig = create_n2v_configuration(\n    experiment_name=\"n2v_2D\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=1,\n    num_epochs=1,\n)\n\n# save a configuration to disk\nsave_configuration(config, \"configuration_example.yml\")\n\n# load it from within CAREamist\ncareamist = CAREamist(\"configuration_example.yml\")\n</code></pre>"},{"location":"guides/usage/careamist/#instantiating-with-a-path-to-a-model","title":"Instantiating with a path to a model","text":"<p>There are two types of models exported from CAREamics. During training, the model is saved as checkpoints (<code>.ckpt</code>). After training, users can export the model to the  bioimage model zoo format (saved as a<code>.zip</code>). Both can be loaded into CAREamics to either retrain or predict. Alternatively, a checkpoint can be loaded in order to  export it as a bioimage model zoo model.</p> <p>In any case, both types of pre-trained models can be loaded into CAREamics by passing the path to the model file. The instantiated CAREamist is then ready to predict on new images!</p> Instantiating CAREamist with a path to a model<pre><code>from careamics import CAREamist\n\npath_to_model = \"model.zip\" # (1)!\n\ncareamist = CAREamist(path_to_model)\n</code></pre> <ol> <li>Any valid path to a model, as a string or a <code>Path.path</code> object, will work.</li> </ol> <p>When loading a pre-trained model, the experiment name, used in the loggers (e.g. WandB), or to name the checkpoints, is automatically set to <code>CAREamics</code>. But you can change that by passing it to the <code>CAREamist</code> constructor.</p> Changing the experiment name<pre><code>careamist = CAREamist(path_to_model, experiment_name=\"a_new_experiment\")\n</code></pre>"},{"location":"guides/usage/careamist/#setting-the-working-directory","title":"Setting the working directory","text":"<p>By default, CAREamics will save the checkpoints in the current working directory. When creating a new CAREamist, you can indicate a different working directory in which to save the logs and checkpoints during training.</p> Changing the working directory<pre><code>careamist = CAREamist(config, work_dir=\"work_dir\")\n</code></pre>"},{"location":"guides/usage/datasets/","title":"Datasets","text":"<p>Datasets are the internal classes providing the individual patches for training,  validation and prediction. In CAREamics, we provide a <code>CAREamicsTrainData</code> class that  creates the datasets for training and validation (there is a class for prediction as well, which is simpler and shares some parameters with the training one). In most cases, it is created internally. In this section, we describe what it does and shed light on some of its parameters that are passed to the train methods.</p>"},{"location":"guides/usage/datasets/#overview","title":"Overview","text":"<p>The <code>CAREamicsTrainData</code> receives both data configuration and data itself. The data can be passed a path to a folder, to a file or as <code>numpy</code> array. </p> Simplest way to instantiate CAREamicsTrainData<pre><code>from careamics.config import create_n2v_configuration\nfrom careamics import CAREamicsTrainData\nimport numpy as np\n\ntrain_array = np.random.rand(128, 128)\n\nconfig = create_n2v_configuration(\n    experiment_name=\"n2v_2D\",\n    data_type=\"array\",\n    axes=\"YX\",\n    patch_size=[64, 64],\n    batch_size=1,\n    num_epochs=1,\n)\n\ndata_module = CAREamicsTrainData( # (1)!\n    data_config=config.data_config,\n    train_data=train_array\n)\n</code></pre> <p>It has the following parameters:</p> <ul> <li><code>data_config</code>: data configuration</li> <li><code>train_data</code>: training data (array or path)</li> <li><code>(optional) val_data</code>: validation data, if not provided, the validation data is taken from the training data</li> <li><code>(optional) train_data_target</code>: target data for training (if applicable)</li> <li><code>(optional) val_data_target</code>: target data for validation (if applicable)</li> <li><code>(optional) read_source_func</code>: function to read custom data types      (see custom data types)</li> <li><code>(optional) extension_filter</code>: filter to select custom types     (see custom data types)</li> <li><code>(optional) val_percentage</code>: percentage of validation data to extract from the training     (see splitting validation)</li> <li><code>(optional) val_minimum_split</code>: minimum validation split      (see splitting validation)</li> <li><code>(optional) use_in_memory</code>: whether to use in-memory dataset if possible (Default is <code>True</code>),      not applicable to mnumpy arrays.</li> </ul> <p>Depending on the type of the data, which is specified in the <code>data_config</code> and is compared to the type of <code>train_data</code>, the <code>CAREamicsTrainData</code> will create the appropriate dataset for both training and validation data.</p> <p>In the absence of validation, validation data is extracted from training data (see splitting validation).</p>"},{"location":"guides/usage/datasets/#available-datasets","title":"Available datasets","text":"<p>CAREamics currently support two datasets:</p> <ul> <li>InMemoryDataset: used when the data fits in memory.</li> <li>IterableDataset: used when the data is too large to fit in memory.</li> </ul> <p>If the data is a <code>numpy</code> array, the <code>InMemoryDataset</code> is used automatically. Otherwise, we list the files contained in the path, compute the size of the data and instantiate an <code>InMemoryDataset</code> if the data is less than 80% of the total RAM size. If not, CAREamics instantiate an <code>IterableDataset</code>.</p> <p>Both datasets work differently, and the main differences can be summarized as follows:</p> Feature <code>InMemoryDataset</code> <code>IterableDataset</code> Used with arrays  Yes  No Patch extraction Sequential Random Data loading All in memory One file at a time <p>In the next sections, we describe the different steps they perform.</p>"},{"location":"guides/usage/datasets/#in-memory-dataset","title":"In-memory dataset","text":"<p>As the name implies, the in-memory dataset loads all the data in memory. It is used when the data on the disk seems to fit in memory, or when the data is already in memory and  passed as a numpy array. The advantage of the dataset is that is allows faster access to the patches, and therefore faster training time.</p> <p>It performs the following steps:</p>  On numpy arrays On Paths <ol> <li>Compute the <code>mean</code> and <code>std</code> of the dataset over all images.</li> <li>Reshape the array so that the axes are ordered following the convention <code>SC(Z)YX</code>.</li> <li>Extract patches sequentially so that they cover all images and keep them     in memory.</li> <li>Update the <code>mean</code> and <code>std</code> in the configuration if they were not provided. This step     also updates the <code>mean</code> and <code>std</code> of the normalization transform.</li> <li>Get the transforms from the configuration.</li> <li>Each time a patch is requested:<ol> <li>A patch is extracted from the in-memory patches, it has dimensions <code>(1, C, (Z), Y, X)</code>,      where <code>C</code> is the number of channels, <code>Z</code> is present only if the data is 3D, and     <code>Z, Y, X</code> are the patch sizes in each dimension.</li> <li>The transformations are applied to the patch (see transforms).</li> <li>The result of the transformation is returned.</li> </ol> </li> </ol> <ol> <li>For each file in the path, the corresponding image is loaded.</li> <li>The <code>mean</code> and <code>std</code> are computed for the loaded image.</li> <li>The image is reshaped so that the axes are ordered following the convention <code>SC(Z)YX</code>.</li> <li>Extract patches sequentially so that they cover the whole image and keept them     in memory.</li> <li>Once all files have been processed, the average <code>mean</code> and <code>std</code> are computed.</li> <li>Update the <code>mean</code> and <code>std</code> in the configuration if they were not provided. This step     also updates the <code>mean</code> and <code>std</code> of the normalization transform.</li> <li>All patches are concatenated together.</li> <li>Get the transforms from the configuration.</li> <li>Each time a patch is requested:<ol> <li>A patch is extracted from the in-memory patches, it has dimensions <code>(1, C, (Z), Y, X)</code>,      where <code>C</code> is the number of channels, <code>Z</code> is present only if the data is 3D, and     <code>Z, Y, X</code> are the patch sizes in each dimension.</li> <li>The transformations are applied to the patch (see transforms).</li> <li>The result of the transformation is returned.</li> </ol> </li> </ol> <p>What about supervised training?</p> <p>For supervised training, the steps are the same and are performed for the targets alongside the source.</p> <p>What if I have a time (<code>T</code>) axis?</p> <p><code>T</code> axes are accepted by the CAREamics configuration, but are treated as a sample dimension (<code>S</code>). If both <code>S</code> and <code>T</code> are present, the two axes are concatenated.</p>"},{"location":"guides/usage/datasets/#iterable-dataset","title":"Iterable dataset","text":"<p>The iterable dataset is used to load patches from a single file at a time, one file after another. This allows training on datasets that are too large to fit in memory. This dataset is exclusively used with files input (data passed as paths).</p> <p>It performs the following steps:</p> <ol> <li>The dataset does a first pass of all the data to compute the average <code>mean</code> and <code>std</code>,     if these have not been specified in the configuration.</li> <li>Update the configuration and the transforms with the computed <code>mean</code> and <code>std</code>.</li> <li>Get the list of transforms from the configuration.</li> <li>Each time a patch is requested:<ol> <li>If there is no more patches (see point 6), the next image is loaded.</li> <li>The image is reshaped so that the axes are ordered following the convention <code>SC(Z)YX</code>.</li> <li>Random patches are extracted from the image, they have dimensions <code>(N, C, (Z), Y, X)</code>,      where <code>C</code> is the number of channels, <code>Z</code> is present only if the data is 3D,     <code>Z, Y, X</code> are the patch sizes in each dimension, and <code>N</code> is the number of patches.</li> <li>The transformations are applied to the patches (see transforms).</li> <li>The next patch is yielded. The patches are yielded one at a time until there are no more patches     in the image, at which point the next image is loaded when the next patch is requested (see point 1).</li> </ol> </li> </ol> <p>What about supervised training?</p> <p>For supervised training, the steps are the same and are performed for the targets alongside the source.</p> <p>What if I have a time (<code>T</code>) axis?</p> <p><code>T</code> axes are accepted by the CAREamics configuration, but are treated as a sample dimension (<code>S</code>). If both <code>S</code> and <code>T</code> are present, the two axes are concatenated.</p>"},{"location":"guides/usage/datasets/#intermediate-transforms","title":"(Intermediate) Transforms","text":"<p>Transforms are augmentations and any operation applied to the patches before feeding them into the network. CAREamics supports the following transforms (see  configuration full spec for an example on how to configure them):</p> Transform Description Notes <code>Normalize</code> Normalize (zero mean, unit variance) Necessary <code>NDFlip</code> Flip the image along one of the spatial axis X, Y and Z (not by default), optional <code>XYRandomRotate90Model</code> Rotate by 90 degrees the XY axes Optional <code>N2VManipulateModel</code> N2V pixel manipulation Only for N2V, necessary <p>The <code>Normalize</code> transform is always applied, and the rest are optional. The exception is <code>N2VManipulateModel</code>, which is only applied when training with N2V (see Noise2Void).</p> <p>When to turn off transforms?</p> <p>The configuration allows turning off transforms. In this case, only normalization (and potentially the <code>N2VManipulateModel</code> for N2V) is applied. This is useful when the structures in your sample are always in the same orientation, and flipping and rotation do not make sense.</p>"},{"location":"guides/usage/datasets/#advanced-custom-data-types","title":"(Advanced) Custom data types","text":"<p>To read custom data types, you can set <code>data_type</code> to <code>custom</code> in <code>data_config</code> and provide a function that returns a numpy array from a path as <code>read_source_func</code> parameter. The function will receive a Path object and an axies string as arguments, the axes being derived from the <code>data_config</code>.</p> <p>You should also provide a <code>fnmatch</code> and <code>Path.rglob</code> compatible expression (e.g. \"*.npy\") to filter the files extension using <code>extension_filter</code>.</p> Read custom data types<pre><code>from pathlib import Path\nfrom typing import Any\n\nimport numpy as np\nfrom careamics import CAREamicsTrainData\nfrom careamics.config import create_n2v_configuration\n\ndef read_npy( # (1)!\n        path: Path, # (2)!\n        *args: Any,\n        **kwargs: Any, # (3)!\n    ) -&gt; np.ndarray:\n    return np.load(path) # (4)! \n\n# example data\ntrain_array = np.random.rand(128, 128)\nnp.save(\"train_array.npy\", train_array)\n\n# configuration\nconfig = create_n2v_configuration(\n    experiment_name=\"n2v_2D\",\n    data_type=\"custom\", # (5)!\n    axes=\"YX\",\n    patch_size=[32, 32],\n    batch_size=1,\n    num_epochs=1,\n)\n\ndata_module = CAREamicsTrainData(\n    data_config=config.data_config, \n    train_data=\"train_array.npy\", # (6)!\n    read_source_func=read_npy, # (7)!\n    extension_filter=\"*.npy\", # (8)!\n)\ndata_module.prepare_data()\ndata_module.setup() # (9)!\n\n# check dataset output\ndataloader = data_module.train_dataloader()\nprint(dataloader.dataset[0][0].shape) # (10)!\n</code></pre> <ol> <li> <p>We define a function that reads the custom data type.</p> </li> <li> <p>It takes a path as argument!</p> </li> <li> <p>But it also need to receive <code>*args</code> and <code>**kwargs</code> to be compatible with the <code>read_source_func</code> signature.</p> </li> <li> <p>It simply returns a <code>numpy</code> array.</p> </li> <li> <p>The data type must be <code>custom</code>!</p> </li> <li> <p>And we pass a <code>Path | str</code>.</p> </li> <li> <p>Simply pass the method by name.</p> </li> <li> <p>We also need to provide an extension filter that is compatible with <code>fnmatch</code> and <code>Path.rglob</code>.</p> </li> <li> <p>These two lines are necessary to instantiate the training dataset that we call at the end. They are     called automatically by PyTorch Lightning during training.</p> </li> <li> <p>The dataloader gives access to the dataset, we choose the first element, and since     we configured CAREamics to use N2V, the output is a tuple whose first element is our     first patch!</p> </li> </ol>"},{"location":"guides/usage/datasets/#prediction-datasets","title":"Prediction datasets","text":"<p>The prediction data module, <code>CAREamicsPredictData</code> works similarly to <code>CAREamicsTrainData</code>, albeit with fewer parameters:</p> <ul> <li><code>pred_config</code>: data configuration</li> <li><code>pred_data</code>: prediction data (array or path)</li> <li><code>(optional) read_source_func</code>: function to read custom data types      (see custom data types)</li> <li><code>(optional) extension_filter</code>: filter to select custom types     (see custom data types)</li> </ul> <p>It uses <code>InMemoryPredictionDataset</code> for arrays and <code>IterablePredictionDataset</code> for paths. These are similar to their training counterparts, but they have simpler transforms and offer the possibility to run test-time augmentation. For more details, refer to the prediction section.</p>"},{"location":"guides/usage/model_export/","title":"Export to BMZ","text":"<p>The BioImage Model Zoo is a zoo of models that can be run in a variety of software thanks to the BMZ format. CAREamics is compatible with the BMZ format and can export and load (CAREamics) models in this format.</p> Export to BMZ format<pre><code>tada\n</code></pre> <p>example of generated readme</p>"},{"location":"guides/usage/prediction/","title":"Prediction","text":""},{"location":"guides/usage/prediction/#predict-on-arrays-or-paths","title":"Predict on arrays or paths","text":"On numpy arrays On Paths <p>blah</p> <p>blah</p>"},{"location":"guides/usage/prediction/#tiling","title":"Tiling","text":"<p>tile size and overlaps</p>"},{"location":"guides/usage/prediction/#test-time-augmentation","title":"Test time augmentation","text":"<p>tta</p>"},{"location":"guides/usage/prediction/#transforms","title":"Transforms","text":"<p>normalization</p>"},{"location":"guides/usage/prediction/#intermediate-predict-from-a-checkpoint","title":"(Intermediate) Predict from a checkpoint","text":""},{"location":"guides/usage/prediction/#advanced-predict-on-custom-data-type","title":"(Advanced) Predict on custom data type","text":""},{"location":"guides/usage/training/","title":"Training","text":"<p>You can provide data in various way to train your model: as a <code>numpy</code> array, using a path to a folder or files, or by using CAREamics data module class for more control (advanced).</p> <p>The details of how CAREamics deals with the loading and patching is detailed in the dataset section.</p> <p>Data type</p> <p>The data type of the source and targets must be the same as the one specified in the configuration. That is to say <code>array</code> in the case of <code>np.ndarray</code>, and <code>tiff</code> in the case of paths.</p>"},{"location":"guides/usage/training/#training-by-passing-an-array","title":"Training by passing an array","text":"<p>CAREamics can be trained by simply passing numpy arrays.</p> Training by passing an array<pre><code>import numpy as np\n\ntrain_array = np.random.rand(256, 256)\nval_array = np.random.rand(256, 256)\n\ncareamist.train(\n    train_source=train_array, # (1)!\n    val_source=val_array, # (2)!\n)\n</code></pre> <ol> <li>All parameters to the <code>train</code> method must be specified by keyword.</li> <li>If you don't provide a validation source, CAREamics will use a fraction of the training data    to validate the model.</li> </ol> <p>Supervised training</p> <p>If you are training a supervised model, you must provide the target data as well.</p> <pre><code>careamist.train(\n    train_source=train_array,\n    train_target=target_array,\n    val_source=val_array,\n    val_target=val_target_array,\n)\n</code></pre>"},{"location":"guides/usage/training/#training-by-passing-a-path","title":"Training by passing a path","text":"<p>The same thing can be done by passing a path to a folder or files.</p> Training by passing a path<pre><code>careamist.train(\n    train_source=path_to_train_data,  # (1)!\n    val_source=path_to_val_data,\n)\n</code></pre> <ol> <li>The path can point to a single file, or contain multiple files.</li> </ol> <p>Training from path</p> <p>To train from a path, the data type must be set to <code>tiff</code> or <code>custom</code> in the  configuration.</p>"},{"location":"guides/usage/training/#splitting-validation-from-training-data","title":"Splitting validation from training data","text":"<p>If you only provide training data, CAREamics will extract the validation data directly from the training set. There are two parameters controlling that behaviour: <code>val_percentage</code> and <code>val_minimum_split</code>.</p> <p><code>val_percentage</code> is the fraction of the training data that will be used for validation, and <code>val_minimum_split</code> is the minimum number of iamges used. If the percentage leads to a  number of patches smaller than <code>val_minimum_split</code>, CAREamics will use <code>val_minimum_split</code>.</p> Splitting validation from training data<pre><code>careamist.train(\n    train_source=train_array,\n    val_percentage=0.1, # (1)!\n    val_minimum_split=5, # (2)!\n)\n</code></pre> <ol> <li>10% of the training data will be used for validation.</li> <li>If the number of images is less than 5, CAREamics will use 5 images for validation.</li> </ol> <p>Arrays vs files</p> <p>The behaviour of <code>val_percentage</code> and <code>val_minimum_split</code> is based different depending on whether the source data is an array or a path. If the source is an array, the split is done on the patches (<code>N</code> patches are used for validation). If the source is a path, the split is done on the files (<code>N</code> files are used for validation).</p>"},{"location":"guides/usage/training/#training-by-passing-a-careamicstraindata-object","title":"Training by passing a CAREamicsTrainData object","text":"<p>CAREamics provides a class to handle the data loading of custom data type. We will dive  in more details in the next section into what this class can be used for. Here is a  brief overview of how it passed to the <code>train</code> method.</p> Training by passing a CAREamicsTrainData object<pre><code>from careamics import CAREamicsTrainData\n\ndata_module = CAREamicsTrainData(  # (1)!\n    data_config=config.data_config, \n    train_data=train_array\n)\n\ncareamist.train(datamodule=data_module)\n</code></pre> <ol> <li>Here this does the same thing as passing the <code>train_source</code> directly into the <code>train</code> method.     In the next section, we will see a more useful example.</li> </ol>"},{"location":"guides/usage/training/#callbacks","title":"Callbacks","text":"<p>CAREamics currently allows two different callbacks from PyTorch Lightning:</p> <ul> <li><code>ModelCheckpoint</code>: to save the model at different points during the training.</li> <li><code>EarlyStopping</code>: to stop the training based on a few parameters.</li> </ul> <p>The parameters for the callbacks are the same as the ones from PyTorch Lightning, and can be set in the configuration.</p>"},{"location":"guides/usage/training/#logging-the-training","title":"Logging the training","text":"<p>By default, CAREamics simply log the training progress in the console. However, it is  possible to use either WandB or TensorBoard.</p> <p>To decide on the logger, check out the Configuration section.</p> <p>Loggers installation</p> <p>Using WandB or TensorBoard require the installation of <code>extra</code> dependencies. Check out the installation section to know more about it.</p>"},{"location":"reference/","title":"Code Reference","text":"CAREamics CAREamics portfolio"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>index.md</li> <li>careamics<ul> <li>index.md</li> <li>callbacks<ul> <li>hyperparameters_callback</li> <li>progress_bar_callback</li> </ul> </li> <li>careamist</li> <li>config<ul> <li>algorithm_model</li> <li>architectures<ul> <li>architecture_model</li> <li>custom_model</li> <li>register_model</li> <li>unet_model</li> <li>vae_model</li> </ul> </li> <li>callback_model</li> <li>configuration_example</li> <li>configuration_factory</li> <li>configuration_model</li> <li>data_model</li> <li>inference_model</li> <li>optimizer_models</li> <li>references<ul> <li>algorithm_descriptions</li> <li>references</li> </ul> </li> <li>support<ul> <li>supported_activations</li> <li>supported_algorithms</li> <li>supported_architectures</li> <li>supported_data</li> <li>supported_loggers</li> <li>supported_losses</li> <li>supported_optimizers</li> <li>supported_pixel_manipulations</li> <li>supported_struct_axis</li> <li>supported_transforms</li> </ul> </li> <li>tile_information</li> <li>training_model</li> <li>transformations<ul> <li>n2v_manipulate_model</li> <li>normalize_model</li> <li>transform_model</li> <li>xy_flip_model</li> <li>xy_random_rotate90_model</li> </ul> </li> <li>validators<ul> <li>validator_utils</li> </ul> </li> </ul> </li> <li>conftest</li> <li>dataset<ul> <li>dataset_utils<ul> <li>dataset_utils</li> <li>file_utils</li> <li>read_tiff</li> <li>read_utils</li> <li>read_zarr</li> </ul> </li> <li>in_memory_dataset</li> <li>iterable_dataset</li> <li>patching<ul> <li>patching</li> <li>random_patching</li> <li>sequential_patching</li> <li>tiled_patching</li> <li>validate_patch_dimension</li> </ul> </li> <li>zarr_dataset</li> </ul> </li> <li>lightning_datamodule</li> <li>lightning_module</li> <li>lightning_prediction_datamodule</li> <li>lightning_prediction_loop</li> <li>losses<ul> <li>loss_factory</li> <li>losses</li> </ul> </li> <li>model_io<ul> <li>bioimage<ul> <li>_readme_factory</li> <li>bioimage_utils</li> <li>model_description</li> </ul> </li> <li>bmz_io</li> <li>model_io_utils</li> </ul> </li> <li>models<ul> <li>activation</li> <li>layers</li> <li>model_factory</li> <li>unet</li> </ul> </li> <li>prediction<ul> <li>stitch_prediction</li> </ul> </li> <li>transforms<ul> <li>compose</li> <li>n2v_manipulate</li> <li>normalize</li> <li>pixel_manipulation</li> <li>struct_mask_parameters</li> <li>transform</li> <li>tta</li> <li>xy_flip</li> <li>xy_random_rotate90</li> </ul> </li> <li>utils<ul> <li>base_enum</li> <li>context</li> <li>logging</li> <li>metrics</li> <li>path_utils</li> <li>ram</li> <li>receptive_field</li> <li>running_stats</li> <li>torch_utils</li> </ul> </li> </ul> </li> <li>careamics_portfolio<ul> <li>index.md</li> <li>denoiseg_datasets</li> <li>denoising_datasets</li> <li>portfolio</li> <li>portfolio_entry</li> <li>utils<ul> <li>download_utils</li> <li>pale_blue_dot</li> <li>pale_blue_dot_zip</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/careamics/","title":"CAREamics","text":"<p>Use the navigation index on the left to explore the documentation.</p>"},{"location":"reference/careamics/careamist/","title":"careamist","text":"<p>A class to train, predict and export models in CAREamics.</p>"},{"location":"reference/careamics/careamist/#careamics.careamist.CAREamist","title":"<code>CAREamist</code>","text":"<p>Main CAREamics class, allowing training and prediction using various algorithms.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[Path, str, Configuration]</code> <p>Path to a configuration file or a trained model.</p> required <code>work_dir</code> <code>Optional[str]</code> <p>Path to working directory in which to save checkpoints and logs, by default None.</p> <code>None</code> <code>experiment_name</code> <code>str</code> <p>Experiment name used for checkpoints, by default \"CAREamics\".</p> <code>'CAREamics'</code> <p>Attributes:</p> Name Type Description <code>model</code> <code>CAREamicsKiln</code> <p>CAREamics model.</p> <code>cfg</code> <code>Configuration</code> <p>CAREamics configuration.</p> <code>trainer</code> <code>Trainer</code> <p>PyTorch Lightning trainer.</p> <code>experiment_logger</code> <code>Optional[Union[TensorBoardLogger, WandbLogger]]</code> <p>Experiment logger, \"wandb\" or \"tensorboard\".</p> <code>work_dir</code> <code>Path</code> <p>Working directory.</p> <code>train_datamodule</code> <code>Optional[CAREamicsWood]</code> <p>Training datamodule.</p> <code>pred_datamodule</code> <code>Optional[CAREamicsClay]</code> <p>Prediction datamodule.</p> Source code in <code>src/careamics/careamist.py</code> <pre><code>class CAREamist:\n    \"\"\"Main CAREamics class, allowing training and prediction using various algorithms.\n\n    Parameters\n    ----------\n    source : Union[Path, str, Configuration]\n        Path to a configuration file or a trained model.\n    work_dir : Optional[str], optional\n        Path to working directory in which to save checkpoints and logs,\n        by default None.\n    experiment_name : str, optional\n        Experiment name used for checkpoints, by default \"CAREamics\".\n\n    Attributes\n    ----------\n    model : CAREamicsKiln\n        CAREamics model.\n    cfg : Configuration\n        CAREamics configuration.\n    trainer : Trainer\n        PyTorch Lightning trainer.\n    experiment_logger : Optional[Union[TensorBoardLogger, WandbLogger]]\n        Experiment logger, \"wandb\" or \"tensorboard\".\n    work_dir : Path\n        Working directory.\n    train_datamodule : Optional[CAREamicsWood]\n        Training datamodule.\n    pred_datamodule : Optional[CAREamicsClay]\n        Prediction datamodule.\n    \"\"\"\n\n    @overload\n    def __init__(  # numpydoc ignore=GL08\n        self,\n        source: Union[Path, str],\n        work_dir: Optional[str] = None,\n        experiment_name: str = \"CAREamics\",\n    ) -&gt; None: ...\n\n    @overload\n    def __init__(  # numpydoc ignore=GL08\n        self,\n        source: Configuration,\n        work_dir: Optional[str] = None,\n        experiment_name: str = \"CAREamics\",\n    ) -&gt; None: ...\n\n    def __init__(\n        self,\n        source: Union[Path, str, Configuration],\n        work_dir: Optional[Union[Path, str]] = None,\n        experiment_name: str = \"CAREamics\",\n    ) -&gt; None:\n        \"\"\"\n        Initialize CAREamist with a configuration object or a path.\n\n        A configuration object can be created using directly by calling `Configuration`,\n        using the configuration factory or loading a configuration from a yaml file.\n\n        Path can contain either a yaml file with parameters, or a saved checkpoint.\n\n        If no working directory is provided, the current working directory is used.\n\n        If `source` is a checkpoint, then `experiment_name` is used to name the\n        checkpoint, and is recorded in the configuration.\n\n        Parameters\n        ----------\n        source : Union[Path, str, Configuration]\n            Path to a configuration file or a trained model.\n        work_dir : Optional[str], optional\n            Path to working directory in which to save checkpoints and logs,\n            by default None.\n        experiment_name : str, optional\n            Experiment name used for checkpoints, by default \"CAREamics\".\n\n        Raises\n        ------\n        NotImplementedError\n            If the model is loaded from BioImage Model Zoo.\n        ValueError\n            If no hyper parameters are found in the checkpoint.\n        ValueError\n            If no data module hyper parameters are found in the checkpoint.\n        \"\"\"\n        super().__init__()\n\n        # select current working directory if work_dir is None\n        if work_dir is None:\n            self.work_dir = Path.cwd()\n            logger.warning(\n                f\"No working directory provided. Using current working directory: \"\n                f\"{self.work_dir}.\"\n            )\n        else:\n            self.work_dir = Path(work_dir)\n\n        # configuration object\n        if isinstance(source, Configuration):\n            self.cfg = source\n\n            # instantiate model\n            self.model = CAREamicsModule(\n                algorithm_config=self.cfg.algorithm_config,\n            )\n\n        # path to configuration file or model\n        else:\n            source = check_path_exists(source)\n\n            # configuration file\n            if source.is_file() and (\n                source.suffix == \".yaml\" or source.suffix == \".yml\"\n            ):\n                # load configuration\n                self.cfg = load_configuration(source)\n\n                # instantiate model\n                self.model = CAREamicsModule(\n                    algorithm_config=self.cfg.algorithm_config,\n                )\n\n            # attempt loading a pre-trained model\n            else:\n                self.model, self.cfg = load_pretrained(source)\n\n        # define the checkpoint saving callback\n        self.callbacks = self._define_callbacks()\n\n        # instantiate logger\n        if self.cfg.training_config.has_logger():\n            if self.cfg.training_config.logger == SupportedLogger.WANDB:\n                self.experiment_logger: LOGGER_TYPES = WandbLogger(\n                    name=experiment_name,\n                    save_dir=self.work_dir / Path(\"logs\"),\n                )\n            elif self.cfg.training_config.logger == SupportedLogger.TENSORBOARD:\n                self.experiment_logger = TensorBoardLogger(\n                    save_dir=self.work_dir / Path(\"logs\"),\n                )\n        else:\n            self.experiment_logger = None\n\n        # instantiate trainer\n        self.trainer = Trainer(\n            max_epochs=self.cfg.training_config.num_epochs,\n            callbacks=self.callbacks,\n            default_root_dir=self.work_dir,\n            logger=self.experiment_logger,\n        )\n\n        # change the prediction loop, necessary for tiled prediction\n        self.trainer.predict_loop = CAREamicsPredictionLoop(self.trainer)\n\n        # place holder for the datamodules\n        self.train_datamodule: Optional[CAREamicsTrainData] = None\n        self.pred_datamodule: Optional[CAREamicsPredictData] = None\n\n    def _define_callbacks(self) -&gt; List[Callback]:\n        \"\"\"\n        Define the callbacks for the training loop.\n\n        Returns\n        -------\n        List[Callback]\n            List of callbacks to be used during training.\n        \"\"\"\n        # checkpoint callback saves checkpoints during training\n        self.callbacks = [\n            HyperParametersCallback(self.cfg),\n            ModelCheckpoint(\n                dirpath=self.work_dir / Path(\"checkpoints\"),\n                filename=self.cfg.experiment_name,\n                **self.cfg.training_config.checkpoint_callback.model_dump(),\n            ),\n            ProgressBarCallback(),\n        ]\n\n        # early stopping callback\n        if self.cfg.training_config.early_stopping_callback is not None:\n            self.callbacks.append(\n                EarlyStopping(self.cfg.training_config.early_stopping_callback)\n            )\n\n        return self.callbacks\n\n    def train(\n        self,\n        *,\n        datamodule: Optional[CAREamicsTrainData] = None,\n        train_source: Optional[Union[Path, str, np.ndarray]] = None,\n        val_source: Optional[Union[Path, str, np.ndarray]] = None,\n        train_target: Optional[Union[Path, str, np.ndarray]] = None,\n        val_target: Optional[Union[Path, str, np.ndarray]] = None,\n        use_in_memory: bool = True,\n        val_percentage: float = 0.1,\n        val_minimum_split: int = 1,\n    ) -&gt; None:\n        \"\"\"\n        Train the model on the provided data.\n\n        If a datamodule is provided, then training will be performed using it.\n        Alternatively, the training data can be provided as arrays or paths.\n\n        If `use_in_memory` is set to True, the source provided as Path or str will be\n        loaded in memory if it fits. Otherwise, training will be performed by loading\n        patches from the files one by one. Training on arrays is always performed\n        in memory.\n\n        If no validation source is provided, then the validation is extracted from\n        the training data using `val_percentage` and `val_minimum_split`. In the case\n        of data provided as Path or str, the percentage and minimum number are applied\n        to the number of files. For arrays, it is the number of patches.\n\n        Parameters\n        ----------\n        datamodule : Optional[CAREamicsWood], optional\n            Datamodule to train on, by default None.\n        train_source : Optional[Union[Path, str, np.ndarray]], optional\n            Train source, if no datamodule is provided, by default None.\n        val_source : Optional[Union[Path, str, np.ndarray]], optional\n            Validation source, if no datamodule is provided, by default None.\n        train_target : Optional[Union[Path, str, np.ndarray]], optional\n            Train target source, if no datamodule is provided, by default None.\n        val_target : Optional[Union[Path, str, np.ndarray]], optional\n            Validation target source, if no datamodule is provided, by default None.\n        use_in_memory : bool, optional\n            Use in memory dataset if possible, by default True.\n        val_percentage : float, optional\n            Percentage of validation extracted from training data, by default 0.1.\n        val_minimum_split : int, optional\n            Minimum number of validation (patch or file) extracted from training data,\n            by default 1.\n\n        Raises\n        ------\n        ValueError\n            If both `datamodule` and `train_source` are provided.\n        ValueError\n            If sources are not of the same type (e.g. train is an array and val is\n            a Path).\n        ValueError\n            If the training target is provided to N2V.\n        ValueError\n            If neither a datamodule nor a source is provided.\n        \"\"\"\n        if datamodule is not None and train_source:\n            raise ValueError(\n                \"Only one of `datamodule` and `train_source` can be provided.\"\n            )\n\n        # check that inputs are the same type\n        source_types = {\n            type(s)\n            for s in (train_source, val_source, train_target, val_target)\n            if s is not None\n        }\n        if len(source_types) &gt; 1:\n            raise ValueError(\"All sources should be of the same type.\")\n\n        # train\n        if datamodule is not None:\n            self._train_on_datamodule(datamodule=datamodule)\n\n        else:\n            # raise error if target is provided to N2V\n            if self.cfg.algorithm_config.algorithm == SupportedAlgorithm.N2V.value:\n                if train_target is not None:\n                    raise ValueError(\n                        \"Training target not compatible with N2V training.\"\n                    )\n\n            # dispatch the training\n            if isinstance(train_source, np.ndarray):\n                # mypy checks\n                assert isinstance(val_source, np.ndarray) or val_source is None\n                assert isinstance(train_target, np.ndarray) or train_target is None\n                assert isinstance(val_target, np.ndarray) or val_target is None\n\n                self._train_on_array(\n                    train_source,\n                    val_source,\n                    train_target,\n                    val_target,\n                    val_percentage,\n                    val_minimum_split,\n                )\n\n            elif isinstance(train_source, Path) or isinstance(train_source, str):\n                # mypy checks\n                assert (\n                    isinstance(val_source, Path)\n                    or isinstance(val_source, str)\n                    or val_source is None\n                )\n                assert (\n                    isinstance(train_target, Path)\n                    or isinstance(train_target, str)\n                    or train_target is None\n                )\n                assert (\n                    isinstance(val_target, Path)\n                    or isinstance(val_target, str)\n                    or val_target is None\n                )\n\n                self._train_on_path(\n                    train_source,\n                    val_source,\n                    train_target,\n                    val_target,\n                    use_in_memory,\n                    val_percentage,\n                    val_minimum_split,\n                )\n\n            else:\n                raise ValueError(\n                    f\"Invalid input, expected a str, Path, array or CAREamicsWood \"\n                    f\"instance (got {type(train_source)}).\"\n                )\n\n    def _train_on_datamodule(self, datamodule: CAREamicsTrainData) -&gt; None:\n        \"\"\"\n        Train the model on the provided datamodule.\n\n        Parameters\n        ----------\n        datamodule : CAREamicsWood\n            Datamodule to train on.\n        \"\"\"\n        # record datamodule\n        self.train_datamodule = datamodule\n\n        self.trainer.fit(self.model, datamodule=datamodule)\n\n    def _train_on_array(\n        self,\n        train_data: np.ndarray,\n        val_data: Optional[np.ndarray] = None,\n        train_target: Optional[np.ndarray] = None,\n        val_target: Optional[np.ndarray] = None,\n        val_percentage: float = 0.1,\n        val_minimum_split: int = 5,\n    ) -&gt; None:\n        \"\"\"\n        Train the model on the provided data arrays.\n\n        Parameters\n        ----------\n        train_data : np.ndarray\n            Training data.\n        val_data : Optional[np.ndarray], optional\n            Validation data, by default None.\n        train_target : Optional[np.ndarray], optional\n            Train target data, by default None.\n        val_target : Optional[np.ndarray], optional\n            Validation target data, by default None.\n        val_percentage : float, optional\n            Percentage of patches to use for validation, by default 0.1.\n        val_minimum_split : int, optional\n            Minimum number of patches to use for validation, by default 5.\n        \"\"\"\n        # create datamodule\n        datamodule = CAREamicsTrainData(\n            data_config=self.cfg.data_config,\n            train_data=train_data,\n            val_data=val_data,\n            train_data_target=train_target,\n            val_data_target=val_target,\n            val_percentage=val_percentage,\n            val_minimum_split=val_minimum_split,\n        )\n\n        # train\n        self.train(datamodule=datamodule)\n\n    def _train_on_path(\n        self,\n        path_to_train_data: Union[Path, str],\n        path_to_val_data: Optional[Union[Path, str]] = None,\n        path_to_train_target: Optional[Union[Path, str]] = None,\n        path_to_val_target: Optional[Union[Path, str]] = None,\n        use_in_memory: bool = True,\n        val_percentage: float = 0.1,\n        val_minimum_split: int = 1,\n    ) -&gt; None:\n        \"\"\"\n        Train the model on the provided data paths.\n\n        Parameters\n        ----------\n        path_to_train_data : Union[Path, str]\n            Path to the training data.\n        path_to_val_data : Optional[Union[Path, str]], optional\n            Path to validation data, by default None.\n        path_to_train_target : Optional[Union[Path, str]], optional\n            Path to train target data, by default None.\n        path_to_val_target : Optional[Union[Path, str]], optional\n            Path to validation target data, by default None.\n        use_in_memory : bool, optional\n            Use in memory dataset if possible, by default True.\n        val_percentage : float, optional\n            Percentage of files to use for validation, by default 0.1.\n        val_minimum_split : int, optional\n            Minimum number of files to use for validation, by default 1.\n        \"\"\"\n        # sanity check on data (path exists)\n        path_to_train_data = check_path_exists(path_to_train_data)\n\n        if path_to_val_data is not None:\n            path_to_val_data = check_path_exists(path_to_val_data)\n\n        if path_to_train_target is not None:\n            path_to_train_target = check_path_exists(path_to_train_target)\n\n        if path_to_val_target is not None:\n            path_to_val_target = check_path_exists(path_to_val_target)\n\n        # create datamodule\n        datamodule = CAREamicsTrainData(\n            data_config=self.cfg.data_config,\n            train_data=path_to_train_data,\n            val_data=path_to_val_data,\n            train_data_target=path_to_train_target,\n            val_data_target=path_to_val_target,\n            use_in_memory=use_in_memory,\n            val_percentage=val_percentage,\n            val_minimum_split=val_minimum_split,\n        )\n\n        # train\n        self.train(datamodule=datamodule)\n\n    @overload\n    def predict(  # numpydoc ignore=GL08\n        self,\n        source: CAREamicsPredictData,\n        *,\n        checkpoint: Optional[Literal[\"best\", \"last\"]] = None,\n    ) -&gt; Union[list, np.ndarray]: ...\n\n    @overload\n    def predict(  # numpydoc ignore=GL08\n        self,\n        source: Union[Path, str],\n        *,\n        batch_size: int = 1,\n        tile_size: Optional[Tuple[int, ...]] = None,\n        tile_overlap: Tuple[int, ...] = (48, 48),\n        axes: Optional[str] = None,\n        data_type: Optional[Literal[\"tiff\", \"custom\"]] = None,\n        tta_transforms: bool = True,\n        dataloader_params: Optional[Dict] = None,\n        read_source_func: Optional[Callable] = None,\n        extension_filter: str = \"\",\n        checkpoint: Optional[Literal[\"best\", \"last\"]] = None,\n    ) -&gt; Union[list, np.ndarray]: ...\n\n    @overload\n    def predict(  # numpydoc ignore=GL08\n        self,\n        source: np.ndarray,\n        *,\n        batch_size: int = 1,\n        tile_size: Optional[Tuple[int, ...]] = None,\n        tile_overlap: Tuple[int, ...] = (48, 48),\n        axes: Optional[str] = None,\n        data_type: Optional[Literal[\"array\"]] = None,\n        tta_transforms: bool = True,\n        dataloader_params: Optional[Dict] = None,\n        checkpoint: Optional[Literal[\"best\", \"last\"]] = None,\n    ) -&gt; Union[list, np.ndarray]: ...\n\n    def predict(\n        self,\n        source: Union[CAREamicsPredictData, Path, str, np.ndarray],\n        *,\n        batch_size: int = 1,\n        tile_size: Optional[Tuple[int, ...]] = None,\n        tile_overlap: Tuple[int, ...] = (48, 48),\n        axes: Optional[str] = None,\n        data_type: Optional[Literal[\"array\", \"tiff\", \"custom\"]] = None,\n        tta_transforms: bool = True,\n        dataloader_params: Optional[Dict] = None,\n        read_source_func: Optional[Callable] = None,\n        extension_filter: str = \"\",\n        checkpoint: Optional[Literal[\"best\", \"last\"]] = None,\n        **kwargs: Any,\n    ) -&gt; Union[List[np.ndarray], np.ndarray]:\n        \"\"\"\n        Make predictions on the provided data.\n\n        Input can be a CAREamicsClay instance, a path to a data file, or a numpy array.\n\n        If `data_type`, `axes` and `tile_size` are not provided, the training\n        configuration parameters will be used, with the `patch_size` instead of\n        `tile_size`.\n\n        Test-time augmentation (TTA) can be switched off using the `tta_transforms`\n        parameter.\n\n        Note that if you are using a UNet model and tiling, the tile size must be\n        divisible in every dimension by 2**d, where d is the depth of the model. This\n        avoids artefacts arising from the broken shift invariance induced by the\n        pooling layers of the UNet. If your image has less dimensions, as it may\n        happen in the Z dimension, consider padding your image.\n\n        Parameters\n        ----------\n        source : Union[CAREamicsClay, Path, str, np.ndarray]\n            Data to predict on.\n        batch_size : int, optional\n            Batch size for prediction, by default 1.\n        tile_size : Optional[Tuple[int, ...]], optional\n            Size of the tiles to use for prediction, by default None.\n        tile_overlap : Tuple[int, ...], optional\n            Overlap between tiles, by default (48, 48).\n        axes : Optional[str], optional\n            Axes of the input data, by default None.\n        data_type : Optional[Literal[\"array\", \"tiff\", \"custom\"]], optional\n            Type of the input data, by default None.\n        tta_transforms : bool, optional\n            Whether to apply test-time augmentation, by default True.\n        dataloader_params : Optional[Dict], optional\n            Parameters to pass to the dataloader, by default None.\n        read_source_func : Optional[Callable], optional\n            Function to read the source data, by default None.\n        extension_filter : str, optional\n            Filter for the file extension, by default \"\".\n        checkpoint : Optional[Literal[\"best\", \"last\"]], optional\n            Checkpoint to use for prediction, by default None.\n        **kwargs : Any\n            Unused.\n\n        Returns\n        -------\n        Union[List[np.ndarray], np.ndarray]\n            Predictions made by the model.\n\n        Raises\n        ------\n        ValueError\n            If the input is not a CAREamicsClay instance, a path or a numpy array.\n        \"\"\"\n        if isinstance(source, CAREamicsPredictData):\n            # record datamodule\n            self.pred_datamodule = source\n\n            return self.trainer.predict(\n                model=self.model, datamodule=source, ckpt_path=checkpoint\n            )\n        else:\n            if self.cfg is None:\n                raise ValueError(\n                    \"No configuration found. Train a model or load from a \"\n                    \"checkpoint before predicting.\"\n                )\n            # create predict config, reuse training config if parameters missing\n            prediction_config = create_inference_configuration(\n                configuration=self.cfg,\n                tile_size=tile_size,\n                tile_overlap=tile_overlap,\n                data_type=data_type,\n                axes=axes,\n                tta_transforms=tta_transforms,\n                batch_size=batch_size,\n            )\n\n            # remove batch from dataloader parameters (priority given to config)\n            if dataloader_params is None:\n                dataloader_params = {}\n            if \"batch_size\" in dataloader_params:\n                del dataloader_params[\"batch_size\"]\n\n            if isinstance(source, Path) or isinstance(source, str):\n                # Check the source\n                source_path = check_path_exists(source)\n\n                # create datamodule\n                datamodule = CAREamicsPredictData(\n                    pred_config=prediction_config,\n                    pred_data=source_path,\n                    read_source_func=read_source_func,\n                    extension_filter=extension_filter,\n                    dataloader_params=dataloader_params,\n                )\n\n                # record datamodule\n                self.pred_datamodule = datamodule\n\n                return self.trainer.predict(\n                    model=self.model, datamodule=datamodule, ckpt_path=checkpoint\n                )\n\n            elif isinstance(source, np.ndarray):\n                # create datamodule\n                datamodule = CAREamicsPredictData(\n                    pred_config=prediction_config,\n                    pred_data=source,\n                    dataloader_params=dataloader_params,\n                )\n\n                # record datamodule\n                self.pred_datamodule = datamodule\n\n                return self.trainer.predict(\n                    model=self.model, datamodule=datamodule, ckpt_path=checkpoint\n                )\n\n            else:\n                raise ValueError(\n                    f\"Invalid input. Expected a CAREamicsWood instance, paths or \"\n                    f\"np.ndarray (got {type(source)}).\"\n                )\n\n    def export_to_bmz(\n        self,\n        path: Union[Path, str],\n        name: str,\n        authors: List[dict],\n        input_array: Optional[np.ndarray] = None,\n        general_description: str = \"\",\n        channel_names: Optional[List[str]] = None,\n        data_description: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"Export the model to the BioImage Model Zoo format.\n\n        Input array must be of shape SC(Z)YX, with S and C singleton dimensions.\n\n        Parameters\n        ----------\n        path : Union[Path, str]\n            Path to save the model.\n        name : str\n            Name of the model.\n        authors : List[dict]\n            List of authors of the model.\n        input_array : Optional[np.ndarray], optional\n            Input array for the model, must be of shape SC(Z)YX, by default None.\n        general_description : str\n            General description of the model, used in the metadata of the BMZ archive.\n        channel_names : Optional[List[str]], optional\n            Channel names, by default None.\n        data_description : Optional[str], optional\n            Description of the data, by default None.\n        \"\"\"\n        if input_array is None:\n            # generate images, priority is given to the prediction data module\n            if self.pred_datamodule is not None:\n                # unpack a batch, ignore masks or targets\n                input_patch, *_ = next(iter(self.pred_datamodule.predict_dataloader()))\n\n                # convert torch.Tensor to numpy\n                input_patch = input_patch.numpy()\n            elif self.train_datamodule is not None:\n                input_patch, *_ = next(iter(self.train_datamodule.train_dataloader()))\n                input_patch = input_patch.numpy()\n            else:\n                if (\n                    self.cfg.data_config.mean is None\n                    or self.cfg.data_config.std is None\n                ):\n                    raise ValueError(\n                        \"Mean and std cannot be None in the configuration in order to\"\n                        \"export to the BMZ format. Was the model trained?\"\n                    )\n\n                # create a random input array\n                input_patch = np.random.normal(\n                    loc=self.cfg.data_config.mean,\n                    scale=self.cfg.data_config.std,\n                    size=self.cfg.data_config.patch_size,\n                ).astype(np.float32)[\n                    np.newaxis, np.newaxis, ...\n                ]  # add S &amp; C dimensions\n        else:\n            input_patch = input_array\n\n        # if there is a batch dimension\n        if input_patch.shape[0] &gt; 1:\n            input_patch = input_patch[0:1, ...]  # keep singleton dim\n\n        # axes need to be reformated for the export because reshaping was done in the\n        # datamodule\n        if \"Z\" in self.cfg.data_config.axes:\n            axes = \"SCZYX\"\n        else:\n            axes = \"SCYX\"\n\n        # predict output, remove extra dimensions for the purpose of the prediction\n        output_patch = self.predict(\n            input_patch,\n            data_type=SupportedData.ARRAY.value,\n            axes=axes,\n            tta_transforms=False,\n        )\n\n        if not isinstance(output_patch, np.ndarray):\n            raise ValueError(\n                f\"Numpy array required for export to BioImage Model Zoo, got \"\n                f\"{type(output_patch)}.\"\n            )\n\n        export_to_bmz(\n            model=self.model,\n            config=self.cfg,\n            path=path,\n            name=name,\n            general_description=general_description,\n            authors=authors,\n            input_array=input_patch,\n            output_array=output_patch,\n            channel_names=channel_names,\n            data_description=data_description,\n        )\n</code></pre>"},{"location":"reference/careamics/careamist/#careamics.careamist.CAREamist.__init__","title":"<code>__init__(source, work_dir=None, experiment_name='CAREamics')</code>","text":"<p>Initialize CAREamist with a configuration object or a path.</p> <p>A configuration object can be created using directly by calling <code>Configuration</code>, using the configuration factory or loading a configuration from a yaml file.</p> <p>Path can contain either a yaml file with parameters, or a saved checkpoint.</p> <p>If no working directory is provided, the current working directory is used.</p> <p>If <code>source</code> is a checkpoint, then <code>experiment_name</code> is used to name the checkpoint, and is recorded in the configuration.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[Path, str, Configuration]</code> <p>Path to a configuration file or a trained model.</p> required <code>work_dir</code> <code>Optional[str]</code> <p>Path to working directory in which to save checkpoints and logs, by default None.</p> <code>None</code> <code>experiment_name</code> <code>str</code> <p>Experiment name used for checkpoints, by default \"CAREamics\".</p> <code>'CAREamics'</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the model is loaded from BioImage Model Zoo.</p> <code>ValueError</code> <p>If no hyper parameters are found in the checkpoint.</p> <code>ValueError</code> <p>If no data module hyper parameters are found in the checkpoint.</p> Source code in <code>src/careamics/careamist.py</code> <pre><code>def __init__(\n    self,\n    source: Union[Path, str, Configuration],\n    work_dir: Optional[Union[Path, str]] = None,\n    experiment_name: str = \"CAREamics\",\n) -&gt; None:\n    \"\"\"\n    Initialize CAREamist with a configuration object or a path.\n\n    A configuration object can be created using directly by calling `Configuration`,\n    using the configuration factory or loading a configuration from a yaml file.\n\n    Path can contain either a yaml file with parameters, or a saved checkpoint.\n\n    If no working directory is provided, the current working directory is used.\n\n    If `source` is a checkpoint, then `experiment_name` is used to name the\n    checkpoint, and is recorded in the configuration.\n\n    Parameters\n    ----------\n    source : Union[Path, str, Configuration]\n        Path to a configuration file or a trained model.\n    work_dir : Optional[str], optional\n        Path to working directory in which to save checkpoints and logs,\n        by default None.\n    experiment_name : str, optional\n        Experiment name used for checkpoints, by default \"CAREamics\".\n\n    Raises\n    ------\n    NotImplementedError\n        If the model is loaded from BioImage Model Zoo.\n    ValueError\n        If no hyper parameters are found in the checkpoint.\n    ValueError\n        If no data module hyper parameters are found in the checkpoint.\n    \"\"\"\n    super().__init__()\n\n    # select current working directory if work_dir is None\n    if work_dir is None:\n        self.work_dir = Path.cwd()\n        logger.warning(\n            f\"No working directory provided. Using current working directory: \"\n            f\"{self.work_dir}.\"\n        )\n    else:\n        self.work_dir = Path(work_dir)\n\n    # configuration object\n    if isinstance(source, Configuration):\n        self.cfg = source\n\n        # instantiate model\n        self.model = CAREamicsModule(\n            algorithm_config=self.cfg.algorithm_config,\n        )\n\n    # path to configuration file or model\n    else:\n        source = check_path_exists(source)\n\n        # configuration file\n        if source.is_file() and (\n            source.suffix == \".yaml\" or source.suffix == \".yml\"\n        ):\n            # load configuration\n            self.cfg = load_configuration(source)\n\n            # instantiate model\n            self.model = CAREamicsModule(\n                algorithm_config=self.cfg.algorithm_config,\n            )\n\n        # attempt loading a pre-trained model\n        else:\n            self.model, self.cfg = load_pretrained(source)\n\n    # define the checkpoint saving callback\n    self.callbacks = self._define_callbacks()\n\n    # instantiate logger\n    if self.cfg.training_config.has_logger():\n        if self.cfg.training_config.logger == SupportedLogger.WANDB:\n            self.experiment_logger: LOGGER_TYPES = WandbLogger(\n                name=experiment_name,\n                save_dir=self.work_dir / Path(\"logs\"),\n            )\n        elif self.cfg.training_config.logger == SupportedLogger.TENSORBOARD:\n            self.experiment_logger = TensorBoardLogger(\n                save_dir=self.work_dir / Path(\"logs\"),\n            )\n    else:\n        self.experiment_logger = None\n\n    # instantiate trainer\n    self.trainer = Trainer(\n        max_epochs=self.cfg.training_config.num_epochs,\n        callbacks=self.callbacks,\n        default_root_dir=self.work_dir,\n        logger=self.experiment_logger,\n    )\n\n    # change the prediction loop, necessary for tiled prediction\n    self.trainer.predict_loop = CAREamicsPredictionLoop(self.trainer)\n\n    # place holder for the datamodules\n    self.train_datamodule: Optional[CAREamicsTrainData] = None\n    self.pred_datamodule: Optional[CAREamicsPredictData] = None\n</code></pre>"},{"location":"reference/careamics/careamist/#careamics.careamist.CAREamist.export_to_bmz","title":"<code>export_to_bmz(path, name, authors, input_array=None, general_description='', channel_names=None, data_description=None)</code>","text":"<p>Export the model to the BioImage Model Zoo format.</p> <p>Input array must be of shape SC(Z)YX, with S and C singleton dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[Path, str]</code> <p>Path to save the model.</p> required <code>name</code> <code>str</code> <p>Name of the model.</p> required <code>authors</code> <code>List[dict]</code> <p>List of authors of the model.</p> required <code>input_array</code> <code>Optional[ndarray]</code> <p>Input array for the model, must be of shape SC(Z)YX, by default None.</p> <code>None</code> <code>general_description</code> <code>str</code> <p>General description of the model, used in the metadata of the BMZ archive.</p> <code>''</code> <code>channel_names</code> <code>Optional[List[str]]</code> <p>Channel names, by default None.</p> <code>None</code> <code>data_description</code> <code>Optional[str]</code> <p>Description of the data, by default None.</p> <code>None</code> Source code in <code>src/careamics/careamist.py</code> <pre><code>def export_to_bmz(\n    self,\n    path: Union[Path, str],\n    name: str,\n    authors: List[dict],\n    input_array: Optional[np.ndarray] = None,\n    general_description: str = \"\",\n    channel_names: Optional[List[str]] = None,\n    data_description: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Export the model to the BioImage Model Zoo format.\n\n    Input array must be of shape SC(Z)YX, with S and C singleton dimensions.\n\n    Parameters\n    ----------\n    path : Union[Path, str]\n        Path to save the model.\n    name : str\n        Name of the model.\n    authors : List[dict]\n        List of authors of the model.\n    input_array : Optional[np.ndarray], optional\n        Input array for the model, must be of shape SC(Z)YX, by default None.\n    general_description : str\n        General description of the model, used in the metadata of the BMZ archive.\n    channel_names : Optional[List[str]], optional\n        Channel names, by default None.\n    data_description : Optional[str], optional\n        Description of the data, by default None.\n    \"\"\"\n    if input_array is None:\n        # generate images, priority is given to the prediction data module\n        if self.pred_datamodule is not None:\n            # unpack a batch, ignore masks or targets\n            input_patch, *_ = next(iter(self.pred_datamodule.predict_dataloader()))\n\n            # convert torch.Tensor to numpy\n            input_patch = input_patch.numpy()\n        elif self.train_datamodule is not None:\n            input_patch, *_ = next(iter(self.train_datamodule.train_dataloader()))\n            input_patch = input_patch.numpy()\n        else:\n            if (\n                self.cfg.data_config.mean is None\n                or self.cfg.data_config.std is None\n            ):\n                raise ValueError(\n                    \"Mean and std cannot be None in the configuration in order to\"\n                    \"export to the BMZ format. Was the model trained?\"\n                )\n\n            # create a random input array\n            input_patch = np.random.normal(\n                loc=self.cfg.data_config.mean,\n                scale=self.cfg.data_config.std,\n                size=self.cfg.data_config.patch_size,\n            ).astype(np.float32)[\n                np.newaxis, np.newaxis, ...\n            ]  # add S &amp; C dimensions\n    else:\n        input_patch = input_array\n\n    # if there is a batch dimension\n    if input_patch.shape[0] &gt; 1:\n        input_patch = input_patch[0:1, ...]  # keep singleton dim\n\n    # axes need to be reformated for the export because reshaping was done in the\n    # datamodule\n    if \"Z\" in self.cfg.data_config.axes:\n        axes = \"SCZYX\"\n    else:\n        axes = \"SCYX\"\n\n    # predict output, remove extra dimensions for the purpose of the prediction\n    output_patch = self.predict(\n        input_patch,\n        data_type=SupportedData.ARRAY.value,\n        axes=axes,\n        tta_transforms=False,\n    )\n\n    if not isinstance(output_patch, np.ndarray):\n        raise ValueError(\n            f\"Numpy array required for export to BioImage Model Zoo, got \"\n            f\"{type(output_patch)}.\"\n        )\n\n    export_to_bmz(\n        model=self.model,\n        config=self.cfg,\n        path=path,\n        name=name,\n        general_description=general_description,\n        authors=authors,\n        input_array=input_patch,\n        output_array=output_patch,\n        channel_names=channel_names,\n        data_description=data_description,\n    )\n</code></pre>"},{"location":"reference/careamics/careamist/#careamics.careamist.CAREamist.predict","title":"<code>predict(source, *, batch_size=1, tile_size=None, tile_overlap=(48, 48), axes=None, data_type=None, tta_transforms=True, dataloader_params=None, read_source_func=None, extension_filter='', checkpoint=None, **kwargs)</code>","text":"<p>Make predictions on the provided data.</p> <p>Input can be a CAREamicsClay instance, a path to a data file, or a numpy array.</p> <p>If <code>data_type</code>, <code>axes</code> and <code>tile_size</code> are not provided, the training configuration parameters will be used, with the <code>patch_size</code> instead of <code>tile_size</code>.</p> <p>Test-time augmentation (TTA) can be switched off using the <code>tta_transforms</code> parameter.</p> <p>Note that if you are using a UNet model and tiling, the tile size must be divisible in every dimension by 2**d, where d is the depth of the model. This avoids artefacts arising from the broken shift invariance induced by the pooling layers of the UNet. If your image has less dimensions, as it may happen in the Z dimension, consider padding your image.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Union[CAREamicsClay, Path, str, ndarray]</code> <p>Data to predict on.</p> required <code>batch_size</code> <code>int</code> <p>Batch size for prediction, by default 1.</p> <code>1</code> <code>tile_size</code> <code>Optional[Tuple[int, ...]]</code> <p>Size of the tiles to use for prediction, by default None.</p> <code>None</code> <code>tile_overlap</code> <code>Tuple[int, ...]</code> <p>Overlap between tiles, by default (48, 48).</p> <code>(48, 48)</code> <code>axes</code> <code>Optional[str]</code> <p>Axes of the input data, by default None.</p> <code>None</code> <code>data_type</code> <code>Optional[Literal['array', 'tiff', 'custom']]</code> <p>Type of the input data, by default None.</p> <code>None</code> <code>tta_transforms</code> <code>bool</code> <p>Whether to apply test-time augmentation, by default True.</p> <code>True</code> <code>dataloader_params</code> <code>Optional[Dict]</code> <p>Parameters to pass to the dataloader, by default None.</p> <code>None</code> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read the source data, by default None.</p> <code>None</code> <code>extension_filter</code> <code>str</code> <p>Filter for the file extension, by default \"\".</p> <code>''</code> <code>checkpoint</code> <code>Optional[Literal['best', 'last']]</code> <p>Checkpoint to use for prediction, by default None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Union[List[ndarray], ndarray]</code> <p>Predictions made by the model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input is not a CAREamicsClay instance, a path or a numpy array.</p> Source code in <code>src/careamics/careamist.py</code> <pre><code>def predict(\n    self,\n    source: Union[CAREamicsPredictData, Path, str, np.ndarray],\n    *,\n    batch_size: int = 1,\n    tile_size: Optional[Tuple[int, ...]] = None,\n    tile_overlap: Tuple[int, ...] = (48, 48),\n    axes: Optional[str] = None,\n    data_type: Optional[Literal[\"array\", \"tiff\", \"custom\"]] = None,\n    tta_transforms: bool = True,\n    dataloader_params: Optional[Dict] = None,\n    read_source_func: Optional[Callable] = None,\n    extension_filter: str = \"\",\n    checkpoint: Optional[Literal[\"best\", \"last\"]] = None,\n    **kwargs: Any,\n) -&gt; Union[List[np.ndarray], np.ndarray]:\n    \"\"\"\n    Make predictions on the provided data.\n\n    Input can be a CAREamicsClay instance, a path to a data file, or a numpy array.\n\n    If `data_type`, `axes` and `tile_size` are not provided, the training\n    configuration parameters will be used, with the `patch_size` instead of\n    `tile_size`.\n\n    Test-time augmentation (TTA) can be switched off using the `tta_transforms`\n    parameter.\n\n    Note that if you are using a UNet model and tiling, the tile size must be\n    divisible in every dimension by 2**d, where d is the depth of the model. This\n    avoids artefacts arising from the broken shift invariance induced by the\n    pooling layers of the UNet. If your image has less dimensions, as it may\n    happen in the Z dimension, consider padding your image.\n\n    Parameters\n    ----------\n    source : Union[CAREamicsClay, Path, str, np.ndarray]\n        Data to predict on.\n    batch_size : int, optional\n        Batch size for prediction, by default 1.\n    tile_size : Optional[Tuple[int, ...]], optional\n        Size of the tiles to use for prediction, by default None.\n    tile_overlap : Tuple[int, ...], optional\n        Overlap between tiles, by default (48, 48).\n    axes : Optional[str], optional\n        Axes of the input data, by default None.\n    data_type : Optional[Literal[\"array\", \"tiff\", \"custom\"]], optional\n        Type of the input data, by default None.\n    tta_transforms : bool, optional\n        Whether to apply test-time augmentation, by default True.\n    dataloader_params : Optional[Dict], optional\n        Parameters to pass to the dataloader, by default None.\n    read_source_func : Optional[Callable], optional\n        Function to read the source data, by default None.\n    extension_filter : str, optional\n        Filter for the file extension, by default \"\".\n    checkpoint : Optional[Literal[\"best\", \"last\"]], optional\n        Checkpoint to use for prediction, by default None.\n    **kwargs : Any\n        Unused.\n\n    Returns\n    -------\n    Union[List[np.ndarray], np.ndarray]\n        Predictions made by the model.\n\n    Raises\n    ------\n    ValueError\n        If the input is not a CAREamicsClay instance, a path or a numpy array.\n    \"\"\"\n    if isinstance(source, CAREamicsPredictData):\n        # record datamodule\n        self.pred_datamodule = source\n\n        return self.trainer.predict(\n            model=self.model, datamodule=source, ckpt_path=checkpoint\n        )\n    else:\n        if self.cfg is None:\n            raise ValueError(\n                \"No configuration found. Train a model or load from a \"\n                \"checkpoint before predicting.\"\n            )\n        # create predict config, reuse training config if parameters missing\n        prediction_config = create_inference_configuration(\n            configuration=self.cfg,\n            tile_size=tile_size,\n            tile_overlap=tile_overlap,\n            data_type=data_type,\n            axes=axes,\n            tta_transforms=tta_transforms,\n            batch_size=batch_size,\n        )\n\n        # remove batch from dataloader parameters (priority given to config)\n        if dataloader_params is None:\n            dataloader_params = {}\n        if \"batch_size\" in dataloader_params:\n            del dataloader_params[\"batch_size\"]\n\n        if isinstance(source, Path) or isinstance(source, str):\n            # Check the source\n            source_path = check_path_exists(source)\n\n            # create datamodule\n            datamodule = CAREamicsPredictData(\n                pred_config=prediction_config,\n                pred_data=source_path,\n                read_source_func=read_source_func,\n                extension_filter=extension_filter,\n                dataloader_params=dataloader_params,\n            )\n\n            # record datamodule\n            self.pred_datamodule = datamodule\n\n            return self.trainer.predict(\n                model=self.model, datamodule=datamodule, ckpt_path=checkpoint\n            )\n\n        elif isinstance(source, np.ndarray):\n            # create datamodule\n            datamodule = CAREamicsPredictData(\n                pred_config=prediction_config,\n                pred_data=source,\n                dataloader_params=dataloader_params,\n            )\n\n            # record datamodule\n            self.pred_datamodule = datamodule\n\n            return self.trainer.predict(\n                model=self.model, datamodule=datamodule, ckpt_path=checkpoint\n            )\n\n        else:\n            raise ValueError(\n                f\"Invalid input. Expected a CAREamicsWood instance, paths or \"\n                f\"np.ndarray (got {type(source)}).\"\n            )\n</code></pre>"},{"location":"reference/careamics/careamist/#careamics.careamist.CAREamist.train","title":"<code>train(*, datamodule=None, train_source=None, val_source=None, train_target=None, val_target=None, use_in_memory=True, val_percentage=0.1, val_minimum_split=1)</code>","text":"<p>Train the model on the provided data.</p> <p>If a datamodule is provided, then training will be performed using it. Alternatively, the training data can be provided as arrays or paths.</p> <p>If <code>use_in_memory</code> is set to True, the source provided as Path or str will be loaded in memory if it fits. Otherwise, training will be performed by loading patches from the files one by one. Training on arrays is always performed in memory.</p> <p>If no validation source is provided, then the validation is extracted from the training data using <code>val_percentage</code> and <code>val_minimum_split</code>. In the case of data provided as Path or str, the percentage and minimum number are applied to the number of files. For arrays, it is the number of patches.</p> <p>Parameters:</p> Name Type Description Default <code>datamodule</code> <code>Optional[CAREamicsWood]</code> <p>Datamodule to train on, by default None.</p> <code>None</code> <code>train_source</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Train source, if no datamodule is provided, by default None.</p> <code>None</code> <code>val_source</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Validation source, if no datamodule is provided, by default None.</p> <code>None</code> <code>train_target</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Train target source, if no datamodule is provided, by default None.</p> <code>None</code> <code>val_target</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Validation target source, if no datamodule is provided, by default None.</p> <code>None</code> <code>use_in_memory</code> <code>bool</code> <p>Use in memory dataset if possible, by default True.</p> <code>True</code> <code>val_percentage</code> <code>float</code> <p>Percentage of validation extracted from training data, by default 0.1.</p> <code>0.1</code> <code>val_minimum_split</code> <code>int</code> <p>Minimum number of validation (patch or file) extracted from training data, by default 1.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>datamodule</code> and <code>train_source</code> are provided.</p> <code>ValueError</code> <p>If sources are not of the same type (e.g. train is an array and val is a Path).</p> <code>ValueError</code> <p>If the training target is provided to N2V.</p> <code>ValueError</code> <p>If neither a datamodule nor a source is provided.</p> Source code in <code>src/careamics/careamist.py</code> <pre><code>def train(\n    self,\n    *,\n    datamodule: Optional[CAREamicsTrainData] = None,\n    train_source: Optional[Union[Path, str, np.ndarray]] = None,\n    val_source: Optional[Union[Path, str, np.ndarray]] = None,\n    train_target: Optional[Union[Path, str, np.ndarray]] = None,\n    val_target: Optional[Union[Path, str, np.ndarray]] = None,\n    use_in_memory: bool = True,\n    val_percentage: float = 0.1,\n    val_minimum_split: int = 1,\n) -&gt; None:\n    \"\"\"\n    Train the model on the provided data.\n\n    If a datamodule is provided, then training will be performed using it.\n    Alternatively, the training data can be provided as arrays or paths.\n\n    If `use_in_memory` is set to True, the source provided as Path or str will be\n    loaded in memory if it fits. Otherwise, training will be performed by loading\n    patches from the files one by one. Training on arrays is always performed\n    in memory.\n\n    If no validation source is provided, then the validation is extracted from\n    the training data using `val_percentage` and `val_minimum_split`. In the case\n    of data provided as Path or str, the percentage and minimum number are applied\n    to the number of files. For arrays, it is the number of patches.\n\n    Parameters\n    ----------\n    datamodule : Optional[CAREamicsWood], optional\n        Datamodule to train on, by default None.\n    train_source : Optional[Union[Path, str, np.ndarray]], optional\n        Train source, if no datamodule is provided, by default None.\n    val_source : Optional[Union[Path, str, np.ndarray]], optional\n        Validation source, if no datamodule is provided, by default None.\n    train_target : Optional[Union[Path, str, np.ndarray]], optional\n        Train target source, if no datamodule is provided, by default None.\n    val_target : Optional[Union[Path, str, np.ndarray]], optional\n        Validation target source, if no datamodule is provided, by default None.\n    use_in_memory : bool, optional\n        Use in memory dataset if possible, by default True.\n    val_percentage : float, optional\n        Percentage of validation extracted from training data, by default 0.1.\n    val_minimum_split : int, optional\n        Minimum number of validation (patch or file) extracted from training data,\n        by default 1.\n\n    Raises\n    ------\n    ValueError\n        If both `datamodule` and `train_source` are provided.\n    ValueError\n        If sources are not of the same type (e.g. train is an array and val is\n        a Path).\n    ValueError\n        If the training target is provided to N2V.\n    ValueError\n        If neither a datamodule nor a source is provided.\n    \"\"\"\n    if datamodule is not None and train_source:\n        raise ValueError(\n            \"Only one of `datamodule` and `train_source` can be provided.\"\n        )\n\n    # check that inputs are the same type\n    source_types = {\n        type(s)\n        for s in (train_source, val_source, train_target, val_target)\n        if s is not None\n    }\n    if len(source_types) &gt; 1:\n        raise ValueError(\"All sources should be of the same type.\")\n\n    # train\n    if datamodule is not None:\n        self._train_on_datamodule(datamodule=datamodule)\n\n    else:\n        # raise error if target is provided to N2V\n        if self.cfg.algorithm_config.algorithm == SupportedAlgorithm.N2V.value:\n            if train_target is not None:\n                raise ValueError(\n                    \"Training target not compatible with N2V training.\"\n                )\n\n        # dispatch the training\n        if isinstance(train_source, np.ndarray):\n            # mypy checks\n            assert isinstance(val_source, np.ndarray) or val_source is None\n            assert isinstance(train_target, np.ndarray) or train_target is None\n            assert isinstance(val_target, np.ndarray) or val_target is None\n\n            self._train_on_array(\n                train_source,\n                val_source,\n                train_target,\n                val_target,\n                val_percentage,\n                val_minimum_split,\n            )\n\n        elif isinstance(train_source, Path) or isinstance(train_source, str):\n            # mypy checks\n            assert (\n                isinstance(val_source, Path)\n                or isinstance(val_source, str)\n                or val_source is None\n            )\n            assert (\n                isinstance(train_target, Path)\n                or isinstance(train_target, str)\n                or train_target is None\n            )\n            assert (\n                isinstance(val_target, Path)\n                or isinstance(val_target, str)\n                or val_target is None\n            )\n\n            self._train_on_path(\n                train_source,\n                val_source,\n                train_target,\n                val_target,\n                use_in_memory,\n                val_percentage,\n                val_minimum_split,\n            )\n\n        else:\n            raise ValueError(\n                f\"Invalid input, expected a str, Path, array or CAREamicsWood \"\n                f\"instance (got {type(train_source)}).\"\n            )\n</code></pre>"},{"location":"reference/careamics/conftest/","title":"conftest","text":"<p>File used to discover python modules and run doctest.</p> <p>See https://sybil.readthedocs.io/en/latest/use.html#pytest</p>"},{"location":"reference/careamics/conftest/#careamics.conftest.my_path","title":"<code>my_path(tmpdir_factory)</code>","text":"<p>Fixture used in doctest to create a temporary directory.</p> <p>Parameters:</p> Name Type Description Default <code>tmpdir_factory</code> <code>TempPathFactory</code> <p>Temporary path factory from pytest.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Temporary directory path.</p> Source code in <code>src/careamics/conftest.py</code> <pre><code>@pytest.fixture(scope=\"module\")\ndef my_path(tmpdir_factory: TempPathFactory) -&gt; Path:\n    \"\"\"Fixture used in doctest to create a temporary directory.\n\n    Parameters\n    ----------\n    tmpdir_factory : TempPathFactory\n        Temporary path factory from pytest.\n\n    Returns\n    -------\n    Path\n        Temporary directory path.\n    \"\"\"\n    return tmpdir_factory.mktemp(\"my_path\")\n</code></pre>"},{"location":"reference/careamics/lightning_datamodule/","title":"lightning_datamodule","text":"<p>Training and validation Lightning data modules.</p>"},{"location":"reference/careamics/lightning_datamodule/#careamics.lightning_datamodule.CAREamicsTrainData","title":"<code>CAREamicsTrainData</code>","text":"<p>               Bases: <code>LightningDataModule</code></p> <p>CAREamics Ligthning training and validation data module.</p> <p>The data module can be used with Path, str or numpy arrays. In the case of numpy arrays, it loads and computes all the patches in memory. For Path and str inputs, it calculates the total file size and estimate whether it can fit in memory. If it does not, it iterates through the files. This behaviour can be deactivated by setting <code>use_in_memory</code> to False, in which case it will always use the iterating dataset to train on a Path or str.</p> <p>The data can be either a folder containing images or a single file.</p> <p>Validation can be omitted, in which case the validation data is extracted from the training data. The percentage of the training data to use for validation, as well as the minimum number of patches or files to split from the training data can be set using <code>val_percentage</code> and <code>val_minimum_split</code>, respectively.</p> <p>To read custom data types, you can set <code>data_type</code> to <code>custom</code> in <code>data_config</code> and provide a function that returns a numpy array from a path as <code>read_source_func</code> parameter. The function will receive a Path object and an axies string as arguments, the axes being derived from the <code>data_config</code>.</p> <p>You can also provide a <code>fnmatch</code> and <code>Path.rglob</code> compatible expression (e.g. \"*.czi\") to filter the files extension using <code>extension_filter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>data_config</code> <code>DataModel</code> <p>Pydantic model for CAREamics data configuration.</p> required <code>train_data</code> <code>Union[Path, str, ndarray]</code> <p>Training data, can be a path to a folder, a file or a numpy array.</p> required <code>val_data</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Validation data, can be a path to a folder, a file or a numpy array, by default None.</p> <code>None</code> <code>train_data_target</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Training target data, can be a path to a folder, a file or a numpy array, by default None.</p> <code>None</code> <code>val_data_target</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Validation target data, can be a path to a folder, a file or a numpy array, by default None.</p> <code>None</code> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read the source data, by default None. Only used for <code>custom</code> data type (see DataModel).</p> <code>None</code> <code>extension_filter</code> <code>str</code> <p>Filter for file extensions, by default \"\". Only used for <code>custom</code> data types (see DataModel).</p> <code>''</code> <code>val_percentage</code> <code>float</code> <p>Percentage of the training data to use for validation, by default 0.1. Only used if <code>val_data</code> is None.</p> <code>0.1</code> <code>val_minimum_split</code> <code>int</code> <p>Minimum number of patches or files to split from the training data for validation, by default 5. Only used if <code>val_data</code> is None.</p> <code>5</code> <code>use_in_memory</code> <code>bool</code> <p>Use in memory dataset if possible, by default True.</p> <code>True</code> <p>Attributes:</p> Name Type Description <code>data_config</code> <code>DataModel</code> <p>CAREamics data configuration.</p> <code>data_type</code> <code>SupportedData</code> <p>Expected data type, one of \"tiff\", \"array\" or \"custom\".</p> <code>batch_size</code> <code>int</code> <p>Batch size.</p> <code>use_in_memory</code> <code>bool</code> <p>Whether to use in memory dataset if possible.</p> <code>train_data</code> <code>Union[Path, ndarray]</code> <p>Training data.</p> <code>val_data</code> <code>Optional[Union[Path, ndarray]]</code> <p>Validation data.</p> <code>train_data_target</code> <code>Optional[Union[Path, ndarray]]</code> <p>Training target data.</p> <code>val_data_target</code> <code>Optional[Union[Path, ndarray]]</code> <p>Validation target data.</p> <code>val_percentage</code> <code>float</code> <p>Percentage of the training data to use for validation, if no validation data is provided.</p> <code>val_minimum_split</code> <code>int</code> <p>Minimum number of patches or files to split from the training data for validation, if no validation data is provided.</p> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read the source data, used if <code>data_type</code> is <code>custom</code>.</p> <code>extension_filter</code> <code>str</code> <p>Filter for file extensions, used if <code>data_type</code> is <code>custom</code>.</p> Source code in <code>src/careamics/lightning_datamodule.py</code> <pre><code>class CAREamicsTrainData(L.LightningDataModule):\n    \"\"\"\n    CAREamics Ligthning training and validation data module.\n\n    The data module can be used with Path, str or numpy arrays. In the case of\n    numpy arrays, it loads and computes all the patches in memory. For Path and str\n    inputs, it calculates the total file size and estimate whether it can fit in\n    memory. If it does not, it iterates through the files. This behaviour can be\n    deactivated by setting `use_in_memory` to False, in which case it will\n    always use the iterating dataset to train on a Path or str.\n\n    The data can be either a folder containing images or a single file.\n\n    Validation can be omitted, in which case the validation data is extracted from\n    the training data. The percentage of the training data to use for validation,\n    as well as the minimum number of patches or files to split from the training\n    data can be set using `val_percentage` and `val_minimum_split`, respectively.\n\n    To read custom data types, you can set `data_type` to `custom` in `data_config`\n    and provide a function that returns a numpy array from a path as\n    `read_source_func` parameter. The function will receive a Path object and\n    an axies string as arguments, the axes being derived from the `data_config`.\n\n    You can also provide a `fnmatch` and `Path.rglob` compatible expression (e.g.\n    \"*.czi\") to filter the files extension using `extension_filter`.\n\n    Parameters\n    ----------\n    data_config : DataModel\n        Pydantic model for CAREamics data configuration.\n    train_data : Union[Path, str, np.ndarray]\n        Training data, can be a path to a folder, a file or a numpy array.\n    val_data : Optional[Union[Path, str, np.ndarray]], optional\n        Validation data, can be a path to a folder, a file or a numpy array, by\n        default None.\n    train_data_target : Optional[Union[Path, str, np.ndarray]], optional\n        Training target data, can be a path to a folder, a file or a numpy array, by\n        default None.\n    val_data_target : Optional[Union[Path, str, np.ndarray]], optional\n        Validation target data, can be a path to a folder, a file or a numpy array,\n        by default None.\n    read_source_func : Optional[Callable], optional\n        Function to read the source data, by default None. Only used for `custom`\n        data type (see DataModel).\n    extension_filter : str, optional\n        Filter for file extensions, by default \"\". Only used for `custom` data types\n        (see DataModel).\n    val_percentage : float, optional\n        Percentage of the training data to use for validation, by default 0.1. Only\n        used if `val_data` is None.\n    val_minimum_split : int, optional\n        Minimum number of patches or files to split from the training data for\n        validation, by default 5. Only used if `val_data` is None.\n    use_in_memory : bool, optional\n        Use in memory dataset if possible, by default True.\n\n    Attributes\n    ----------\n    data_config : DataModel\n        CAREamics data configuration.\n    data_type : SupportedData\n        Expected data type, one of \"tiff\", \"array\" or \"custom\".\n    batch_size : int\n        Batch size.\n    use_in_memory : bool\n        Whether to use in memory dataset if possible.\n    train_data : Union[Path, np.ndarray]\n        Training data.\n    val_data : Optional[Union[Path, np.ndarray]]\n        Validation data.\n    train_data_target : Optional[Union[Path, np.ndarray]]\n        Training target data.\n    val_data_target : Optional[Union[Path, np.ndarray]]\n        Validation target data.\n    val_percentage : float\n        Percentage of the training data to use for validation, if no validation data is\n        provided.\n    val_minimum_split : int\n        Minimum number of patches or files to split from the training data for\n        validation, if no validation data is provided.\n    read_source_func : Optional[Callable]\n        Function to read the source data, used if `data_type` is `custom`.\n    extension_filter : str\n        Filter for file extensions, used if `data_type` is `custom`.\n    \"\"\"\n\n    def __init__(\n        self,\n        data_config: DataConfig,\n        train_data: Union[Path, str, np.ndarray],\n        val_data: Optional[Union[Path, str, np.ndarray]] = None,\n        train_data_target: Optional[Union[Path, str, np.ndarray]] = None,\n        val_data_target: Optional[Union[Path, str, np.ndarray]] = None,\n        read_source_func: Optional[Callable] = None,\n        extension_filter: str = \"\",\n        val_percentage: float = 0.1,\n        val_minimum_split: int = 5,\n        use_in_memory: bool = True,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        data_config : DataModel\n            Pydantic model for CAREamics data configuration.\n        train_data : Union[Path, str, np.ndarray]\n            Training data, can be a path to a folder, a file or a numpy array.\n        val_data : Optional[Union[Path, str, np.ndarray]], optional\n            Validation data, can be a path to a folder, a file or a numpy array, by\n            default None.\n        train_data_target : Optional[Union[Path, str, np.ndarray]], optional\n            Training target data, can be a path to a folder, a file or a numpy array, by\n            default None.\n        val_data_target : Optional[Union[Path, str, np.ndarray]], optional\n            Validation target data, can be a path to a folder, a file or a numpy array,\n            by default None.\n        read_source_func : Optional[Callable], optional\n            Function to read the source data, by default None. Only used for `custom`\n            data type (see DataModel).\n        extension_filter : str, optional\n            Filter for file extensions, by default \"\". Only used for `custom` data types\n            (see DataModel).\n        val_percentage : float, optional\n            Percentage of the training data to use for validation, by default 0.1. Only\n            used if `val_data` is None.\n        val_minimum_split : int, optional\n            Minimum number of patches or files to split from the training data for\n            validation, by default 5. Only used if `val_data` is None.\n        use_in_memory : bool, optional\n            Use in memory dataset if possible, by default True.\n\n        Raises\n        ------\n        NotImplementedError\n            Raised if target data is provided.\n        ValueError\n            If the input types are mixed (e.g. Path and np.ndarray).\n        ValueError\n            If the data type is `custom` and no `read_source_func` is provided.\n        ValueError\n            If the data type is `array` and the input is not a numpy array.\n        ValueError\n            If the data type is `tiff` and the input is neither a Path nor a str.\n        \"\"\"\n        super().__init__()\n\n        # check input types coherence (no mixed types)\n        inputs = [train_data, val_data, train_data_target, val_data_target]\n        types_set = {type(i) for i in inputs}\n        if len(types_set) &gt; 2:  # None + expected type\n            raise ValueError(\n                f\"Inputs for `train_data`, `val_data`, `train_data_target` and \"\n                f\"`val_data_target` must be of the same type or None. Got \"\n                f\"{types_set}.\"\n            )\n\n        # check that a read source function is provided for custom types\n        if data_config.data_type == SupportedData.CUSTOM and read_source_func is None:\n            raise ValueError(\n                f\"Data type {SupportedData.CUSTOM} is not allowed without \"\n                f\"specifying a `read_source_func` and an `extension_filer`.\"\n            )\n\n        # check correct input type\n        if (\n            isinstance(train_data, np.ndarray)\n            and data_config.data_type != SupportedData.ARRAY\n        ):\n            raise ValueError(\n                f\"Received a numpy array as input, but the data type was set to \"\n                f\"{data_config.data_type}. Set the data type in the configuration \"\n                f\"to {SupportedData.ARRAY} to train on numpy arrays.\"\n            )\n\n        # and that Path or str are passed, if tiff file type specified\n        elif (isinstance(train_data, Path) or isinstance(train_data, str)) and (\n            data_config.data_type != SupportedData.TIFF\n            and data_config.data_type != SupportedData.CUSTOM\n        ):\n            raise ValueError(\n                f\"Received a path as input, but the data type was neither set to \"\n                f\"{SupportedData.TIFF} nor {SupportedData.CUSTOM}. Set the data type \"\n                f\"in the configuration to {SupportedData.TIFF} or \"\n                f\"{SupportedData.CUSTOM} to train on files.\"\n            )\n\n        # configuration\n        self.data_config: DataConfig = data_config\n        self.data_type: str = data_config.data_type\n        self.batch_size: int = data_config.batch_size\n        self.use_in_memory: bool = use_in_memory\n\n        # data: make data Path or np.ndarray, use type annotations for mypy\n        self.train_data: Union[Path, np.ndarray] = (\n            Path(train_data) if isinstance(train_data, str) else train_data\n        )\n\n        self.val_data: Union[Path, np.ndarray] = (\n            Path(val_data) if isinstance(val_data, str) else val_data\n        )\n\n        self.train_data_target: Union[Path, np.ndarray] = (\n            Path(train_data_target)\n            if isinstance(train_data_target, str)\n            else train_data_target\n        )\n\n        self.val_data_target: Union[Path, np.ndarray] = (\n            Path(val_data_target)\n            if isinstance(val_data_target, str)\n            else val_data_target\n        )\n\n        # validation split\n        self.val_percentage = val_percentage\n        self.val_minimum_split = val_minimum_split\n\n        # read source function corresponding to the requested type\n        if data_config.data_type == SupportedData.CUSTOM:\n            # mypy check\n            assert read_source_func is not None\n\n            self.read_source_func: Callable = read_source_func\n\n        elif data_config.data_type != SupportedData.ARRAY:\n            self.read_source_func = get_read_func(data_config.data_type)\n\n        self.extension_filter: str = extension_filter\n\n        # Pytorch dataloader parameters\n        self.dataloader_params: Dict[str, Any] = (\n            data_config.dataloader_params if data_config.dataloader_params else {}\n        )\n\n    def prepare_data(self) -&gt; None:\n        \"\"\"\n        Hook used to prepare the data before calling `setup`.\n\n        Here, we only need to examine the data if it was provided as a str or a Path.\n\n        TODO: from lightning doc:\n        prepare_data is called from the main process. It is not recommended to assign\n        state here (e.g. self.x = y) since it is called on a single process and if you\n        assign states here then they won't be available for other processes.\n\n        https://lightning.ai/docs/pytorch/stable/data/datamodule.html\n        \"\"\"\n        # if the data is a Path or a str\n        if (\n            not isinstance(self.train_data, np.ndarray)\n            and not isinstance(self.val_data, np.ndarray)\n            and not isinstance(self.train_data_target, np.ndarray)\n            and not isinstance(self.val_data_target, np.ndarray)\n        ):\n            # list training files\n            self.train_files = list_files(\n                self.train_data, self.data_type, self.extension_filter\n            )\n            self.train_files_size = get_files_size(self.train_files)\n\n            # list validation files\n            if self.val_data is not None:\n                self.val_files = list_files(\n                    self.val_data, self.data_type, self.extension_filter\n                )\n\n            # same for target data\n            if self.train_data_target is not None:\n                self.train_target_files: List[Path] = list_files(\n                    self.train_data_target, self.data_type, self.extension_filter\n                )\n\n                # verify that they match the training data\n                validate_source_target_files(self.train_files, self.train_target_files)\n\n            if self.val_data_target is not None:\n                self.val_target_files = list_files(\n                    self.val_data_target, self.data_type, self.extension_filter\n                )\n\n                # verify that they match the validation data\n                validate_source_target_files(self.val_files, self.val_target_files)\n\n    def setup(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Hook called at the beginning of fit, validate, or predict.\n\n        Parameters\n        ----------\n        *args : Any\n            Unused.\n        **kwargs : Any\n            Unused.\n        \"\"\"\n        # if numpy array\n        if self.data_type == SupportedData.ARRAY:\n            # mypy checks\n            assert isinstance(self.train_data, np.ndarray)\n            if self.train_data_target is not None:\n                assert isinstance(self.train_data_target, np.ndarray)\n\n            # train dataset\n            self.train_dataset: DatasetType = InMemoryDataset(\n                data_config=self.data_config,\n                inputs=self.train_data,\n                input_target=self.train_data_target,\n            )\n\n            # validation dataset\n            if self.val_data is not None:\n                # mypy checks\n                assert isinstance(self.val_data, np.ndarray)\n                if self.val_data_target is not None:\n                    assert isinstance(self.val_data_target, np.ndarray)\n\n                # create its own dataset\n                self.val_dataset: DatasetType = InMemoryDataset(\n                    data_config=self.data_config,\n                    inputs=self.val_data,\n                    input_target=self.val_data_target,\n                )\n            else:\n                # extract validation from the training patches\n                self.val_dataset = self.train_dataset.split_dataset(\n                    percentage=self.val_percentage,\n                    minimum_patches=self.val_minimum_split,\n                )\n\n        # else we read files\n        else:\n            # Heuristics, if the file size is smaller than 80% of the RAM,\n            # we run the training in memory, otherwise we switch to iterable dataset\n            # The switch is deactivated if use_in_memory is False\n            if self.use_in_memory and self.train_files_size &lt; get_ram_size() * 0.8:\n                # train dataset\n                self.train_dataset = InMemoryDataset(\n                    data_config=self.data_config,\n                    inputs=self.train_files,\n                    input_target=(\n                        self.train_target_files if self.train_data_target else None\n                    ),\n                    read_source_func=self.read_source_func,\n                )\n\n                # validation dataset\n                if self.val_data is not None:\n                    self.val_dataset = InMemoryDataset(\n                        data_config=self.data_config,\n                        inputs=self.val_files,\n                        input_target=(\n                            self.val_target_files if self.val_data_target else None\n                        ),\n                        read_source_func=self.read_source_func,\n                    )\n                else:\n                    # split dataset\n                    self.val_dataset = self.train_dataset.split_dataset(\n                        percentage=self.val_percentage,\n                        minimum_patches=self.val_minimum_split,\n                    )\n\n            # else if the data is too large, load file by file during training\n            else:\n                # create training dataset\n                self.train_dataset = PathIterableDataset(\n                    data_config=self.data_config,\n                    src_files=self.train_files,\n                    target_files=(\n                        self.train_target_files if self.train_data_target else None\n                    ),\n                    read_source_func=self.read_source_func,\n                )\n\n                # create validation dataset\n                if self.val_files is not None:\n                    # create its own dataset\n                    self.val_dataset = PathIterableDataset(\n                        data_config=self.data_config,\n                        src_files=self.val_files,\n                        target_files=(\n                            self.val_target_files if self.val_data_target else None\n                        ),\n                        read_source_func=self.read_source_func,\n                    )\n                elif len(self.train_files) &lt;= self.val_minimum_split:\n                    raise ValueError(\n                        f\"Not enough files to split a minimum of \"\n                        f\"{self.val_minimum_split} files, got {len(self.train_files)} \"\n                        f\"files.\"\n                    )\n                else:\n                    # extract validation from the training patches\n                    self.val_dataset = self.train_dataset.split_dataset(\n                        percentage=self.val_percentage,\n                        minimum_files=self.val_minimum_split,\n                    )\n\n    def train_dataloader(self) -&gt; Any:\n        \"\"\"\n        Create a dataloader for training.\n\n        Returns\n        -------\n        Any\n            Training dataloader.\n        \"\"\"\n        return DataLoader(\n            self.train_dataset, batch_size=self.batch_size, **self.dataloader_params\n        )\n\n    def val_dataloader(self) -&gt; Any:\n        \"\"\"\n        Create a dataloader for validation.\n\n        Returns\n        -------\n        Any\n            Validation dataloader.\n        \"\"\"\n        return DataLoader(\n            self.val_dataset,\n            batch_size=self.batch_size,\n        )\n</code></pre>"},{"location":"reference/careamics/lightning_datamodule/#careamics.lightning_datamodule.CAREamicsTrainData.__init__","title":"<code>__init__(data_config, train_data, val_data=None, train_data_target=None, val_data_target=None, read_source_func=None, extension_filter='', val_percentage=0.1, val_minimum_split=5, use_in_memory=True)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>data_config</code> <code>DataModel</code> <p>Pydantic model for CAREamics data configuration.</p> required <code>train_data</code> <code>Union[Path, str, ndarray]</code> <p>Training data, can be a path to a folder, a file or a numpy array.</p> required <code>val_data</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Validation data, can be a path to a folder, a file or a numpy array, by default None.</p> <code>None</code> <code>train_data_target</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Training target data, can be a path to a folder, a file or a numpy array, by default None.</p> <code>None</code> <code>val_data_target</code> <code>Optional[Union[Path, str, ndarray]]</code> <p>Validation target data, can be a path to a folder, a file or a numpy array, by default None.</p> <code>None</code> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read the source data, by default None. Only used for <code>custom</code> data type (see DataModel).</p> <code>None</code> <code>extension_filter</code> <code>str</code> <p>Filter for file extensions, by default \"\". Only used for <code>custom</code> data types (see DataModel).</p> <code>''</code> <code>val_percentage</code> <code>float</code> <p>Percentage of the training data to use for validation, by default 0.1. Only used if <code>val_data</code> is None.</p> <code>0.1</code> <code>val_minimum_split</code> <code>int</code> <p>Minimum number of patches or files to split from the training data for validation, by default 5. Only used if <code>val_data</code> is None.</p> <code>5</code> <code>use_in_memory</code> <code>bool</code> <p>Use in memory dataset if possible, by default True.</p> <code>True</code> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>Raised if target data is provided.</p> <code>ValueError</code> <p>If the input types are mixed (e.g. Path and np.ndarray).</p> <code>ValueError</code> <p>If the data type is <code>custom</code> and no <code>read_source_func</code> is provided.</p> <code>ValueError</code> <p>If the data type is <code>array</code> and the input is not a numpy array.</p> <code>ValueError</code> <p>If the data type is <code>tiff</code> and the input is neither a Path nor a str.</p> Source code in <code>src/careamics/lightning_datamodule.py</code> <pre><code>def __init__(\n    self,\n    data_config: DataConfig,\n    train_data: Union[Path, str, np.ndarray],\n    val_data: Optional[Union[Path, str, np.ndarray]] = None,\n    train_data_target: Optional[Union[Path, str, np.ndarray]] = None,\n    val_data_target: Optional[Union[Path, str, np.ndarray]] = None,\n    read_source_func: Optional[Callable] = None,\n    extension_filter: str = \"\",\n    val_percentage: float = 0.1,\n    val_minimum_split: int = 5,\n    use_in_memory: bool = True,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    data_config : DataModel\n        Pydantic model for CAREamics data configuration.\n    train_data : Union[Path, str, np.ndarray]\n        Training data, can be a path to a folder, a file or a numpy array.\n    val_data : Optional[Union[Path, str, np.ndarray]], optional\n        Validation data, can be a path to a folder, a file or a numpy array, by\n        default None.\n    train_data_target : Optional[Union[Path, str, np.ndarray]], optional\n        Training target data, can be a path to a folder, a file or a numpy array, by\n        default None.\n    val_data_target : Optional[Union[Path, str, np.ndarray]], optional\n        Validation target data, can be a path to a folder, a file or a numpy array,\n        by default None.\n    read_source_func : Optional[Callable], optional\n        Function to read the source data, by default None. Only used for `custom`\n        data type (see DataModel).\n    extension_filter : str, optional\n        Filter for file extensions, by default \"\". Only used for `custom` data types\n        (see DataModel).\n    val_percentage : float, optional\n        Percentage of the training data to use for validation, by default 0.1. Only\n        used if `val_data` is None.\n    val_minimum_split : int, optional\n        Minimum number of patches or files to split from the training data for\n        validation, by default 5. Only used if `val_data` is None.\n    use_in_memory : bool, optional\n        Use in memory dataset if possible, by default True.\n\n    Raises\n    ------\n    NotImplementedError\n        Raised if target data is provided.\n    ValueError\n        If the input types are mixed (e.g. Path and np.ndarray).\n    ValueError\n        If the data type is `custom` and no `read_source_func` is provided.\n    ValueError\n        If the data type is `array` and the input is not a numpy array.\n    ValueError\n        If the data type is `tiff` and the input is neither a Path nor a str.\n    \"\"\"\n    super().__init__()\n\n    # check input types coherence (no mixed types)\n    inputs = [train_data, val_data, train_data_target, val_data_target]\n    types_set = {type(i) for i in inputs}\n    if len(types_set) &gt; 2:  # None + expected type\n        raise ValueError(\n            f\"Inputs for `train_data`, `val_data`, `train_data_target` and \"\n            f\"`val_data_target` must be of the same type or None. Got \"\n            f\"{types_set}.\"\n        )\n\n    # check that a read source function is provided for custom types\n    if data_config.data_type == SupportedData.CUSTOM and read_source_func is None:\n        raise ValueError(\n            f\"Data type {SupportedData.CUSTOM} is not allowed without \"\n            f\"specifying a `read_source_func` and an `extension_filer`.\"\n        )\n\n    # check correct input type\n    if (\n        isinstance(train_data, np.ndarray)\n        and data_config.data_type != SupportedData.ARRAY\n    ):\n        raise ValueError(\n            f\"Received a numpy array as input, but the data type was set to \"\n            f\"{data_config.data_type}. Set the data type in the configuration \"\n            f\"to {SupportedData.ARRAY} to train on numpy arrays.\"\n        )\n\n    # and that Path or str are passed, if tiff file type specified\n    elif (isinstance(train_data, Path) or isinstance(train_data, str)) and (\n        data_config.data_type != SupportedData.TIFF\n        and data_config.data_type != SupportedData.CUSTOM\n    ):\n        raise ValueError(\n            f\"Received a path as input, but the data type was neither set to \"\n            f\"{SupportedData.TIFF} nor {SupportedData.CUSTOM}. Set the data type \"\n            f\"in the configuration to {SupportedData.TIFF} or \"\n            f\"{SupportedData.CUSTOM} to train on files.\"\n        )\n\n    # configuration\n    self.data_config: DataConfig = data_config\n    self.data_type: str = data_config.data_type\n    self.batch_size: int = data_config.batch_size\n    self.use_in_memory: bool = use_in_memory\n\n    # data: make data Path or np.ndarray, use type annotations for mypy\n    self.train_data: Union[Path, np.ndarray] = (\n        Path(train_data) if isinstance(train_data, str) else train_data\n    )\n\n    self.val_data: Union[Path, np.ndarray] = (\n        Path(val_data) if isinstance(val_data, str) else val_data\n    )\n\n    self.train_data_target: Union[Path, np.ndarray] = (\n        Path(train_data_target)\n        if isinstance(train_data_target, str)\n        else train_data_target\n    )\n\n    self.val_data_target: Union[Path, np.ndarray] = (\n        Path(val_data_target)\n        if isinstance(val_data_target, str)\n        else val_data_target\n    )\n\n    # validation split\n    self.val_percentage = val_percentage\n    self.val_minimum_split = val_minimum_split\n\n    # read source function corresponding to the requested type\n    if data_config.data_type == SupportedData.CUSTOM:\n        # mypy check\n        assert read_source_func is not None\n\n        self.read_source_func: Callable = read_source_func\n\n    elif data_config.data_type != SupportedData.ARRAY:\n        self.read_source_func = get_read_func(data_config.data_type)\n\n    self.extension_filter: str = extension_filter\n\n    # Pytorch dataloader parameters\n    self.dataloader_params: Dict[str, Any] = (\n        data_config.dataloader_params if data_config.dataloader_params else {}\n    )\n</code></pre>"},{"location":"reference/careamics/lightning_datamodule/#careamics.lightning_datamodule.CAREamicsTrainData.prepare_data","title":"<code>prepare_data()</code>","text":"<p>Hook used to prepare the data before calling <code>setup</code>.</p> <p>Here, we only need to examine the data if it was provided as a str or a Path.</p> <p>TODO: from lightning doc: prepare_data is called from the main process. It is not recommended to assign state here (e.g. self.x = y) since it is called on a single process and if you assign states here then they won't be available for other processes.</p> <p>https://lightning.ai/docs/pytorch/stable/data/datamodule.html</p> Source code in <code>src/careamics/lightning_datamodule.py</code> <pre><code>def prepare_data(self) -&gt; None:\n    \"\"\"\n    Hook used to prepare the data before calling `setup`.\n\n    Here, we only need to examine the data if it was provided as a str or a Path.\n\n    TODO: from lightning doc:\n    prepare_data is called from the main process. It is not recommended to assign\n    state here (e.g. self.x = y) since it is called on a single process and if you\n    assign states here then they won't be available for other processes.\n\n    https://lightning.ai/docs/pytorch/stable/data/datamodule.html\n    \"\"\"\n    # if the data is a Path or a str\n    if (\n        not isinstance(self.train_data, np.ndarray)\n        and not isinstance(self.val_data, np.ndarray)\n        and not isinstance(self.train_data_target, np.ndarray)\n        and not isinstance(self.val_data_target, np.ndarray)\n    ):\n        # list training files\n        self.train_files = list_files(\n            self.train_data, self.data_type, self.extension_filter\n        )\n        self.train_files_size = get_files_size(self.train_files)\n\n        # list validation files\n        if self.val_data is not None:\n            self.val_files = list_files(\n                self.val_data, self.data_type, self.extension_filter\n            )\n\n        # same for target data\n        if self.train_data_target is not None:\n            self.train_target_files: List[Path] = list_files(\n                self.train_data_target, self.data_type, self.extension_filter\n            )\n\n            # verify that they match the training data\n            validate_source_target_files(self.train_files, self.train_target_files)\n\n        if self.val_data_target is not None:\n            self.val_target_files = list_files(\n                self.val_data_target, self.data_type, self.extension_filter\n            )\n\n            # verify that they match the validation data\n            validate_source_target_files(self.val_files, self.val_target_files)\n</code></pre>"},{"location":"reference/careamics/lightning_datamodule/#careamics.lightning_datamodule.CAREamicsTrainData.setup","title":"<code>setup(*args, **kwargs)</code>","text":"<p>Hook called at the beginning of fit, validate, or predict.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Unused.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Unused.</p> <code>{}</code> Source code in <code>src/careamics/lightning_datamodule.py</code> <pre><code>def setup(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Hook called at the beginning of fit, validate, or predict.\n\n    Parameters\n    ----------\n    *args : Any\n        Unused.\n    **kwargs : Any\n        Unused.\n    \"\"\"\n    # if numpy array\n    if self.data_type == SupportedData.ARRAY:\n        # mypy checks\n        assert isinstance(self.train_data, np.ndarray)\n        if self.train_data_target is not None:\n            assert isinstance(self.train_data_target, np.ndarray)\n\n        # train dataset\n        self.train_dataset: DatasetType = InMemoryDataset(\n            data_config=self.data_config,\n            inputs=self.train_data,\n            input_target=self.train_data_target,\n        )\n\n        # validation dataset\n        if self.val_data is not None:\n            # mypy checks\n            assert isinstance(self.val_data, np.ndarray)\n            if self.val_data_target is not None:\n                assert isinstance(self.val_data_target, np.ndarray)\n\n            # create its own dataset\n            self.val_dataset: DatasetType = InMemoryDataset(\n                data_config=self.data_config,\n                inputs=self.val_data,\n                input_target=self.val_data_target,\n            )\n        else:\n            # extract validation from the training patches\n            self.val_dataset = self.train_dataset.split_dataset(\n                percentage=self.val_percentage,\n                minimum_patches=self.val_minimum_split,\n            )\n\n    # else we read files\n    else:\n        # Heuristics, if the file size is smaller than 80% of the RAM,\n        # we run the training in memory, otherwise we switch to iterable dataset\n        # The switch is deactivated if use_in_memory is False\n        if self.use_in_memory and self.train_files_size &lt; get_ram_size() * 0.8:\n            # train dataset\n            self.train_dataset = InMemoryDataset(\n                data_config=self.data_config,\n                inputs=self.train_files,\n                input_target=(\n                    self.train_target_files if self.train_data_target else None\n                ),\n                read_source_func=self.read_source_func,\n            )\n\n            # validation dataset\n            if self.val_data is not None:\n                self.val_dataset = InMemoryDataset(\n                    data_config=self.data_config,\n                    inputs=self.val_files,\n                    input_target=(\n                        self.val_target_files if self.val_data_target else None\n                    ),\n                    read_source_func=self.read_source_func,\n                )\n            else:\n                # split dataset\n                self.val_dataset = self.train_dataset.split_dataset(\n                    percentage=self.val_percentage,\n                    minimum_patches=self.val_minimum_split,\n                )\n\n        # else if the data is too large, load file by file during training\n        else:\n            # create training dataset\n            self.train_dataset = PathIterableDataset(\n                data_config=self.data_config,\n                src_files=self.train_files,\n                target_files=(\n                    self.train_target_files if self.train_data_target else None\n                ),\n                read_source_func=self.read_source_func,\n            )\n\n            # create validation dataset\n            if self.val_files is not None:\n                # create its own dataset\n                self.val_dataset = PathIterableDataset(\n                    data_config=self.data_config,\n                    src_files=self.val_files,\n                    target_files=(\n                        self.val_target_files if self.val_data_target else None\n                    ),\n                    read_source_func=self.read_source_func,\n                )\n            elif len(self.train_files) &lt;= self.val_minimum_split:\n                raise ValueError(\n                    f\"Not enough files to split a minimum of \"\n                    f\"{self.val_minimum_split} files, got {len(self.train_files)} \"\n                    f\"files.\"\n                )\n            else:\n                # extract validation from the training patches\n                self.val_dataset = self.train_dataset.split_dataset(\n                    percentage=self.val_percentage,\n                    minimum_files=self.val_minimum_split,\n                )\n</code></pre>"},{"location":"reference/careamics/lightning_datamodule/#careamics.lightning_datamodule.CAREamicsTrainData.train_dataloader","title":"<code>train_dataloader()</code>","text":"<p>Create a dataloader for training.</p> <p>Returns:</p> Type Description <code>Any</code> <p>Training dataloader.</p> Source code in <code>src/careamics/lightning_datamodule.py</code> <pre><code>def train_dataloader(self) -&gt; Any:\n    \"\"\"\n    Create a dataloader for training.\n\n    Returns\n    -------\n    Any\n        Training dataloader.\n    \"\"\"\n    return DataLoader(\n        self.train_dataset, batch_size=self.batch_size, **self.dataloader_params\n    )\n</code></pre>"},{"location":"reference/careamics/lightning_datamodule/#careamics.lightning_datamodule.CAREamicsTrainData.val_dataloader","title":"<code>val_dataloader()</code>","text":"<p>Create a dataloader for validation.</p> <p>Returns:</p> Type Description <code>Any</code> <p>Validation dataloader.</p> Source code in <code>src/careamics/lightning_datamodule.py</code> <pre><code>def val_dataloader(self) -&gt; Any:\n    \"\"\"\n    Create a dataloader for validation.\n\n    Returns\n    -------\n    Any\n        Validation dataloader.\n    \"\"\"\n    return DataLoader(\n        self.val_dataset,\n        batch_size=self.batch_size,\n    )\n</code></pre>"},{"location":"reference/careamics/lightning_datamodule/#careamics.lightning_datamodule.TrainingDataWrapper","title":"<code>TrainingDataWrapper</code>","text":"<p>               Bases: <code>CAREamicsTrainData</code></p> <p>Wrapper around the CAREamics Lightning training data module.</p> <p>This class is used to explicitely pass the parameters usually contained in a <code>data_model</code> configuration.</p> <p>Since the lightning datamodule has no access to the model, make sure that the parameters passed to the datamodule are consistent with the model's requirements and are coherent.</p> <p>The data module can be used with Path, str or numpy arrays. In the case of numpy arrays, it loads and computes all the patches in memory. For Path and str inputs, it calculates the total file size and estimate whether it can fit in memory. If it does not, it iterates through the files. This behaviour can be deactivated by setting <code>use_in_memory</code> to False, in which case it will always use the iterating dataset to train on a Path or str.</p> <p>To use array data, set <code>data_type</code> to <code>array</code> and pass a numpy array to <code>train_data</code>.</p> <p>In particular, N2V requires a specific transformation (N2V manipulates), which is not compatible with supervised training. The default transformations applied to the training patches are defined in <code>careamics.config.data_model</code>. To use different transformations, pass a list of transforms. See examples for more details.</p> <p>By default, CAREamics only supports types defined in <code>careamics.config.support.SupportedData</code>. To read custom data types, you can set <code>data_type</code> to <code>custom</code> and provide a function that returns a numpy array from a path. Additionally, pass a <code>fnmatch</code> and <code>Path.rglob</code> compatible expression (e.g. \"*.jpeg\") to filter the files extension using <code>extension_filter</code>.</p> <p>In the absence of validation data, the validation data is extracted from the training data. The percentage of the training data to use for validation, as well as the minimum number of patches to split from the training data for validation can be set using <code>val_percentage</code> and <code>val_minimum_patches</code>, respectively.</p> <p>In <code>dataloader_params</code>, you can pass any parameter accepted by PyTorch dataloaders, except for <code>batch_size</code>, which is set by the <code>batch_size</code> parameter.</p> <p>Finally, if you intend to use N2V family of algorithms, you can set <code>use_n2v2</code> to use N2V2, and set the <code>struct_n2v_axis</code> and <code>struct_n2v_span</code> parameters to define the axis and span of the structN2V mask. These parameters are without effect if a <code>train_target_data</code> or if <code>transforms</code> are provided.</p> <p>Parameters:</p> Name Type Description Default <code>train_data</code> <code>Union[str, Path, ndarray]</code> <p>Training data.</p> required <code>data_type</code> <code>Union[str, SupportedData]</code> <p>Data type, see <code>SupportedData</code> for available options.</p> required <code>patch_size</code> <code>List[int]</code> <p>Patch size, 2D or 3D patch size.</p> required <code>axes</code> <code>str</code> <p>Axes of the data, choosen amongst SCZYX.</p> required <code>batch_size</code> <code>int</code> <p>Batch size.</p> required <code>val_data</code> <code>Optional[Union[str, Path]]</code> <p>Validation data, by default None.</p> <code>None</code> <code>transforms</code> <code>List[TRANSFORMS_UNION]</code> <p>List of transforms to apply to training patches. If None, default transforms are applied.</p> <code>None</code> <code>train_target_data</code> <code>Optional[Union[str, Path]]</code> <p>Training target data, by default None.</p> <code>None</code> <code>val_target_data</code> <code>Optional[Union[str, Path]]</code> <p>Validation target data, by default None.</p> <code>None</code> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read the source data, used if <code>data_type</code> is <code>custom</code>, by default None.</p> <code>None</code> <code>extension_filter</code> <code>str</code> <p>Filter for file extensions, used if <code>data_type</code> is <code>custom</code>, by default \"\".</p> <code>''</code> <code>val_percentage</code> <code>float</code> <p>Percentage of the training data to use for validation if no validation data is given, by default 0.1.</p> <code>0.1</code> <code>val_minimum_patches</code> <code>int</code> <p>Minimum number of patches to split from the training data for validation if no validation data is given, by default 5.</p> <code>5</code> <code>dataloader_params</code> <code>dict</code> <p>Pytorch dataloader parameters, by default {}.</p> <code>None</code> <code>use_in_memory</code> <code>bool</code> <p>Use in memory dataset if possible, by default True.</p> <code>True</code> <code>use_n2v2</code> <code>bool</code> <p>Use N2V2 transformation during training, by default False.</p> <code>False</code> <code>struct_n2v_axis</code> <code>Literal['horizontal', 'vertical', 'none']</code> <p>Axis for the structN2V mask, only applied if <code>struct_n2v_axis</code> is <code>none</code>, by default \"none\".</p> <code>'none'</code> <code>struct_n2v_span</code> <code>int</code> <p>Span for the structN2V mask, by default 5.</p> <code>5</code> <p>Examples:</p> <p>Create a TrainingDataWrapper with default transforms with a numpy array:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from careamics import TrainingDataWrapper\n&gt;&gt;&gt; my_array = np.arange(256).reshape(16, 16)\n&gt;&gt;&gt; data_module = TrainingDataWrapper(\n...     train_data=my_array,\n...     data_type=\"array\",\n...     patch_size=(8, 8),\n...     axes='YX',\n...     batch_size=2,\n... )\n</code></pre> <p>For custom data types (those not supported by CAREamics), then one can pass a read function and a filter for the files extension:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from careamics import TrainingDataWrapper\n&gt;&gt;&gt;\n&gt;&gt;&gt; def read_npy(path):\n...     return np.load(path)\n&gt;&gt;&gt;\n&gt;&gt;&gt; data_module = TrainingDataWrapper(\n...     train_data=\"path/to/data\",\n...     data_type=\"custom\",\n...     patch_size=(8, 8),\n...     axes='YX',\n...     batch_size=2,\n...     read_source_func=read_npy,\n...     extension_filter=\"*.npy\",\n... )\n</code></pre> <p>If you want to use a different set of transformations, you can pass a list of transforms:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from careamics import TrainingDataWrapper\n&gt;&gt;&gt; from careamics.config.support import SupportedTransform\n&gt;&gt;&gt; my_array = np.arange(256).reshape(16, 16)\n&gt;&gt;&gt; my_transforms = [\n...     {\n...         \"name\": SupportedTransform.NORMALIZE.value,\n...         \"mean\": 0,\n...         \"std\": 1,\n...     },\n...     {\n...         \"name\": SupportedTransform.N2V_MANIPULATE.value,\n...     }\n... ]\n&gt;&gt;&gt; data_module = TrainingDataWrapper(\n...     train_data=my_array,\n...     data_type=\"array\",\n...     patch_size=(8, 8),\n...     axes='YX',\n...     batch_size=2,\n...     transforms=my_transforms,\n... )\n</code></pre> Source code in <code>src/careamics/lightning_datamodule.py</code> <pre><code>class TrainingDataWrapper(CAREamicsTrainData):\n    \"\"\"\n    Wrapper around the CAREamics Lightning training data module.\n\n    This class is used to explicitely pass the parameters usually contained in a\n    `data_model` configuration.\n\n    Since the lightning datamodule has no access to the model, make sure that the\n    parameters passed to the datamodule are consistent with the model's requirements and\n    are coherent.\n\n    The data module can be used with Path, str or numpy arrays. In the case of\n    numpy arrays, it loads and computes all the patches in memory. For Path and str\n    inputs, it calculates the total file size and estimate whether it can fit in\n    memory. If it does not, it iterates through the files. This behaviour can be\n    deactivated by setting `use_in_memory` to False, in which case it will\n    always use the iterating dataset to train on a Path or str.\n\n    To use array data, set `data_type` to `array` and pass a numpy array to\n    `train_data`.\n\n    In particular, N2V requires a specific transformation (N2V manipulates), which is\n    not compatible with supervised training. The default transformations applied to the\n    training patches are defined in `careamics.config.data_model`. To use different\n    transformations, pass a list of transforms. See examples for more details.\n\n    By default, CAREamics only supports types defined in\n    `careamics.config.support.SupportedData`. To read custom data types, you can set\n    `data_type` to `custom` and provide a function that returns a numpy array from a\n    path. Additionally, pass a `fnmatch` and `Path.rglob` compatible expression (e.g.\n    \"*.jpeg\") to filter the files extension using `extension_filter`.\n\n    In the absence of validation data, the validation data is extracted from the\n    training data. The percentage of the training data to use for validation, as well as\n    the minimum number of patches to split from the training data for validation can be\n    set using `val_percentage` and `val_minimum_patches`, respectively.\n\n    In `dataloader_params`, you can pass any parameter accepted by PyTorch dataloaders,\n    except for `batch_size`, which is set by the `batch_size` parameter.\n\n    Finally, if you intend to use N2V family of algorithms, you can set `use_n2v2` to\n    use N2V2, and set the `struct_n2v_axis` and `struct_n2v_span` parameters to define\n    the axis and span of the structN2V mask. These parameters are without effect if\n    a `train_target_data` or if `transforms` are provided.\n\n    Parameters\n    ----------\n    train_data : Union[str, Path, np.ndarray]\n        Training data.\n    data_type : Union[str, SupportedData]\n        Data type, see `SupportedData` for available options.\n    patch_size : List[int]\n        Patch size, 2D or 3D patch size.\n    axes : str\n        Axes of the data, choosen amongst SCZYX.\n    batch_size : int\n        Batch size.\n    val_data : Optional[Union[str, Path]], optional\n        Validation data, by default None.\n    transforms : List[TRANSFORMS_UNION], optional\n        List of transforms to apply to training patches. If None, default transforms\n        are applied.\n    train_target_data : Optional[Union[str, Path]], optional\n        Training target data, by default None.\n    val_target_data : Optional[Union[str, Path]], optional\n        Validation target data, by default None.\n    read_source_func : Optional[Callable], optional\n        Function to read the source data, used if `data_type` is `custom`, by\n        default None.\n    extension_filter : str, optional\n        Filter for file extensions, used if `data_type` is `custom`, by default \"\".\n    val_percentage : float, optional\n        Percentage of the training data to use for validation if no validation data\n        is given, by default 0.1.\n    val_minimum_patches : int, optional\n        Minimum number of patches to split from the training data for validation if\n        no validation data is given, by default 5.\n    dataloader_params : dict, optional\n        Pytorch dataloader parameters, by default {}.\n    use_in_memory : bool, optional\n        Use in memory dataset if possible, by default True.\n    use_n2v2 : bool, optional\n        Use N2V2 transformation during training, by default False.\n    struct_n2v_axis : Literal[\"horizontal\", \"vertical\", \"none\"], optional\n        Axis for the structN2V mask, only applied if `struct_n2v_axis` is `none`, by\n        default \"none\".\n    struct_n2v_span : int, optional\n        Span for the structN2V mask, by default 5.\n\n    Examples\n    --------\n    Create a TrainingDataWrapper with default transforms with a numpy array:\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from careamics import TrainingDataWrapper\n    &gt;&gt;&gt; my_array = np.arange(256).reshape(16, 16)\n    &gt;&gt;&gt; data_module = TrainingDataWrapper(\n    ...     train_data=my_array,\n    ...     data_type=\"array\",\n    ...     patch_size=(8, 8),\n    ...     axes='YX',\n    ...     batch_size=2,\n    ... )\n\n    For custom data types (those not supported by CAREamics), then one can pass a read\n    function and a filter for the files extension:\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from careamics import TrainingDataWrapper\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; def read_npy(path):\n    ...     return np.load(path)\n    &gt;&gt;&gt;\n    &gt;&gt;&gt; data_module = TrainingDataWrapper(\n    ...     train_data=\"path/to/data\",\n    ...     data_type=\"custom\",\n    ...     patch_size=(8, 8),\n    ...     axes='YX',\n    ...     batch_size=2,\n    ...     read_source_func=read_npy,\n    ...     extension_filter=\"*.npy\",\n    ... )\n\n    If you want to use a different set of transformations, you can pass a list of\n    transforms:\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from careamics import TrainingDataWrapper\n    &gt;&gt;&gt; from careamics.config.support import SupportedTransform\n    &gt;&gt;&gt; my_array = np.arange(256).reshape(16, 16)\n    &gt;&gt;&gt; my_transforms = [\n    ...     {\n    ...         \"name\": SupportedTransform.NORMALIZE.value,\n    ...         \"mean\": 0,\n    ...         \"std\": 1,\n    ...     },\n    ...     {\n    ...         \"name\": SupportedTransform.N2V_MANIPULATE.value,\n    ...     }\n    ... ]\n    &gt;&gt;&gt; data_module = TrainingDataWrapper(\n    ...     train_data=my_array,\n    ...     data_type=\"array\",\n    ...     patch_size=(8, 8),\n    ...     axes='YX',\n    ...     batch_size=2,\n    ...     transforms=my_transforms,\n    ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        train_data: Union[str, Path, np.ndarray],\n        data_type: Union[Literal[\"array\", \"tiff\", \"custom\"], SupportedData],\n        patch_size: List[int],\n        axes: str,\n        batch_size: int,\n        val_data: Optional[Union[str, Path]] = None,\n        transforms: Optional[List[TRANSFORMS_UNION]] = None,\n        train_target_data: Optional[Union[str, Path]] = None,\n        val_target_data: Optional[Union[str, Path]] = None,\n        read_source_func: Optional[Callable] = None,\n        extension_filter: str = \"\",\n        val_percentage: float = 0.1,\n        val_minimum_patches: int = 5,\n        dataloader_params: Optional[dict] = None,\n        use_in_memory: bool = True,\n        use_n2v2: bool = False,\n        struct_n2v_axis: Literal[\"horizontal\", \"vertical\", \"none\"] = \"none\",\n        struct_n2v_span: int = 5,\n    ) -&gt; None:\n        \"\"\"\n        LightningDataModule wrapper for training and validation datasets.\n\n        Since the lightning datamodule has no access to the model, make sure that the\n        parameters passed to the datamodule are consistent with the model's requirements\n        and are coherent.\n\n        The data module can be used with Path, str or numpy arrays. In the case of\n        numpy arrays, it loads and computes all the patches in memory. For Path and str\n        inputs, it calculates the total file size and estimate whether it can fit in\n        memory. If it does not, it iterates through the files. This behaviour can be\n        deactivated by setting `use_in_memory` to False, in which case it will\n        always use the iterating dataset to train on a Path or str.\n\n        To use array data, set `data_type` to `array` and pass a numpy array to\n        `train_data`.\n\n        In particular, N2V requires a specific transformation (N2V manipulates), which\n        is not compatible with supervised training. The default transformations applied\n        to the training patches are defined in `careamics.config.data_model`. To use\n        different transformations, pass a list of transforms. See examples for more\n        details.\n\n        By default, CAREamics only supports types defined in\n        `careamics.config.support.SupportedData`. To read custom data types, you can set\n        `data_type` to `custom` and provide a function that returns a numpy array from a\n        path. Additionally, pass a `fnmatch` and `Path.rglob` compatible expression\n        (e.g. \"*.jpeg\") to filter the files extension using `extension_filter`.\n\n        In the absence of validation data, the validation data is extracted from the\n        training data. The percentage of the training data to use for validation, as\n        well as the minimum number of patches to split from the training data for\n        validation can be set using `val_percentage` and `val_minimum_patches`,\n        respectively.\n\n        In `dataloader_params`, you can pass any parameter accepted by PyTorch\n        dataloaders, except for `batch_size`, which is set by the `batch_size`\n        parameter.\n\n        Finally, if you intend to use N2V family of algorithms, you can set `use_n2v2`\n        to use N2V2, and set the `struct_n2v_axis` and `struct_n2v_span` parameters to\n        define the axis and span of the structN2V mask. These parameters are without\n        effect if a `train_target_data` or if `transforms` are provided.\n\n        Parameters\n        ----------\n        train_data : Union[str, Path, np.ndarray]\n            Training data.\n        data_type : Union[str, SupportedData]\n            Data type, see `SupportedData` for available options.\n        patch_size : List[int]\n            Patch size, 2D or 3D patch size.\n        axes : str\n            Axes of the data, choosen amongst SCZYX.\n        batch_size : int\n            Batch size.\n        val_data : Optional[Union[str, Path]], optional\n            Validation data, by default None.\n        transforms : Optional[List[TRANSFORMS_UNION]], optional\n            List of transforms to apply to training patches. If None, default transforms\n            are applied.\n        train_target_data : Optional[Union[str, Path]], optional\n            Training target data, by default None.\n        val_target_data : Optional[Union[str, Path]], optional\n            Validation target data, by default None.\n        read_source_func : Optional[Callable], optional\n            Function to read the source data, used if `data_type` is `custom`, by\n            default None.\n        extension_filter : str, optional\n            Filter for file extensions, used if `data_type` is `custom`, by default \"\".\n        val_percentage : float, optional\n            Percentage of the training data to use for validation if no validation data\n            is given, by default 0.1.\n        val_minimum_patches : int, optional\n            Minimum number of patches to split from the training data for validation if\n            no validation data is given, by default 5.\n        dataloader_params : dict, optional\n            Pytorch dataloader parameters, by default {}.\n        use_in_memory : bool, optional\n            Use in memory dataset if possible, by default True.\n        use_n2v2 : bool, optional\n            Use N2V2 transformation during training, by default False.\n        struct_n2v_axis : Literal[\"horizontal\", \"vertical\", \"none\"], optional\n            Axis for the structN2V mask, only applied if `struct_n2v_axis` is `none`, by\n            default \"none\".\n        struct_n2v_span : int, optional\n            Span for the structN2V mask, by default 5.\n\n        Raises\n        ------\n        ValueError\n            If a target is set and N2V manipulation is present in the transforms.\n        \"\"\"\n        if dataloader_params is None:\n            dataloader_params = {}\n        data_dict: Dict[str, Any] = {\n            \"mode\": \"train\",\n            \"data_type\": data_type,\n            \"patch_size\": patch_size,\n            \"axes\": axes,\n            \"batch_size\": batch_size,\n            \"dataloader_params\": dataloader_params,\n        }\n\n        # if transforms are passed (otherwise it will use the default ones)\n        if transforms is not None:\n            data_dict[\"transforms\"] = transforms\n\n        # validate configuration\n        self.data_config = DataConfig(**data_dict)\n\n        # N2V specific checks, N2V, structN2V, and transforms\n        if self.data_config.has_n2v_manipulate():\n            # there is not target, n2v2 and structN2V can be changed\n            if train_target_data is None:\n                self.data_config.set_N2V2(use_n2v2)\n                self.data_config.set_structN2V_mask(struct_n2v_axis, struct_n2v_span)\n            else:\n                raise ValueError(\n                    \"Cannot have both supervised training (target data) and \"\n                    \"N2V manipulation in the transforms. Pass a list of transforms \"\n                    \"that is compatible with your supervised training.\"\n                )\n\n        # sanity check on the dataloader parameters\n        if \"batch_size\" in dataloader_params:\n            # remove it\n            del dataloader_params[\"batch_size\"]\n\n        super().__init__(\n            data_config=self.data_config,\n            train_data=train_data,\n            val_data=val_data,\n            train_data_target=train_target_data,\n            val_data_target=val_target_data,\n            read_source_func=read_source_func,\n            extension_filter=extension_filter,\n            val_percentage=val_percentage,\n            val_minimum_split=val_minimum_patches,\n            use_in_memory=use_in_memory,\n        )\n</code></pre>"},{"location":"reference/careamics/lightning_datamodule/#careamics.lightning_datamodule.TrainingDataWrapper.__init__","title":"<code>__init__(train_data, data_type, patch_size, axes, batch_size, val_data=None, transforms=None, train_target_data=None, val_target_data=None, read_source_func=None, extension_filter='', val_percentage=0.1, val_minimum_patches=5, dataloader_params=None, use_in_memory=True, use_n2v2=False, struct_n2v_axis='none', struct_n2v_span=5)</code>","text":"<p>LightningDataModule wrapper for training and validation datasets.</p> <p>Since the lightning datamodule has no access to the model, make sure that the parameters passed to the datamodule are consistent with the model's requirements and are coherent.</p> <p>The data module can be used with Path, str or numpy arrays. In the case of numpy arrays, it loads and computes all the patches in memory. For Path and str inputs, it calculates the total file size and estimate whether it can fit in memory. If it does not, it iterates through the files. This behaviour can be deactivated by setting <code>use_in_memory</code> to False, in which case it will always use the iterating dataset to train on a Path or str.</p> <p>To use array data, set <code>data_type</code> to <code>array</code> and pass a numpy array to <code>train_data</code>.</p> <p>In particular, N2V requires a specific transformation (N2V manipulates), which is not compatible with supervised training. The default transformations applied to the training patches are defined in <code>careamics.config.data_model</code>. To use different transformations, pass a list of transforms. See examples for more details.</p> <p>By default, CAREamics only supports types defined in <code>careamics.config.support.SupportedData</code>. To read custom data types, you can set <code>data_type</code> to <code>custom</code> and provide a function that returns a numpy array from a path. Additionally, pass a <code>fnmatch</code> and <code>Path.rglob</code> compatible expression (e.g. \"*.jpeg\") to filter the files extension using <code>extension_filter</code>.</p> <p>In the absence of validation data, the validation data is extracted from the training data. The percentage of the training data to use for validation, as well as the minimum number of patches to split from the training data for validation can be set using <code>val_percentage</code> and <code>val_minimum_patches</code>, respectively.</p> <p>In <code>dataloader_params</code>, you can pass any parameter accepted by PyTorch dataloaders, except for <code>batch_size</code>, which is set by the <code>batch_size</code> parameter.</p> <p>Finally, if you intend to use N2V family of algorithms, you can set <code>use_n2v2</code> to use N2V2, and set the <code>struct_n2v_axis</code> and <code>struct_n2v_span</code> parameters to define the axis and span of the structN2V mask. These parameters are without effect if a <code>train_target_data</code> or if <code>transforms</code> are provided.</p> <p>Parameters:</p> Name Type Description Default <code>train_data</code> <code>Union[str, Path, ndarray]</code> <p>Training data.</p> required <code>data_type</code> <code>Union[str, SupportedData]</code> <p>Data type, see <code>SupportedData</code> for available options.</p> required <code>patch_size</code> <code>List[int]</code> <p>Patch size, 2D or 3D patch size.</p> required <code>axes</code> <code>str</code> <p>Axes of the data, choosen amongst SCZYX.</p> required <code>batch_size</code> <code>int</code> <p>Batch size.</p> required <code>val_data</code> <code>Optional[Union[str, Path]]</code> <p>Validation data, by default None.</p> <code>None</code> <code>transforms</code> <code>Optional[List[TRANSFORMS_UNION]]</code> <p>List of transforms to apply to training patches. If None, default transforms are applied.</p> <code>None</code> <code>train_target_data</code> <code>Optional[Union[str, Path]]</code> <p>Training target data, by default None.</p> <code>None</code> <code>val_target_data</code> <code>Optional[Union[str, Path]]</code> <p>Validation target data, by default None.</p> <code>None</code> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read the source data, used if <code>data_type</code> is <code>custom</code>, by default None.</p> <code>None</code> <code>extension_filter</code> <code>str</code> <p>Filter for file extensions, used if <code>data_type</code> is <code>custom</code>, by default \"\".</p> <code>''</code> <code>val_percentage</code> <code>float</code> <p>Percentage of the training data to use for validation if no validation data is given, by default 0.1.</p> <code>0.1</code> <code>val_minimum_patches</code> <code>int</code> <p>Minimum number of patches to split from the training data for validation if no validation data is given, by default 5.</p> <code>5</code> <code>dataloader_params</code> <code>dict</code> <p>Pytorch dataloader parameters, by default {}.</p> <code>None</code> <code>use_in_memory</code> <code>bool</code> <p>Use in memory dataset if possible, by default True.</p> <code>True</code> <code>use_n2v2</code> <code>bool</code> <p>Use N2V2 transformation during training, by default False.</p> <code>False</code> <code>struct_n2v_axis</code> <code>Literal['horizontal', 'vertical', 'none']</code> <p>Axis for the structN2V mask, only applied if <code>struct_n2v_axis</code> is <code>none</code>, by default \"none\".</p> <code>'none'</code> <code>struct_n2v_span</code> <code>int</code> <p>Span for the structN2V mask, by default 5.</p> <code>5</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a target is set and N2V manipulation is present in the transforms.</p> Source code in <code>src/careamics/lightning_datamodule.py</code> <pre><code>def __init__(\n    self,\n    train_data: Union[str, Path, np.ndarray],\n    data_type: Union[Literal[\"array\", \"tiff\", \"custom\"], SupportedData],\n    patch_size: List[int],\n    axes: str,\n    batch_size: int,\n    val_data: Optional[Union[str, Path]] = None,\n    transforms: Optional[List[TRANSFORMS_UNION]] = None,\n    train_target_data: Optional[Union[str, Path]] = None,\n    val_target_data: Optional[Union[str, Path]] = None,\n    read_source_func: Optional[Callable] = None,\n    extension_filter: str = \"\",\n    val_percentage: float = 0.1,\n    val_minimum_patches: int = 5,\n    dataloader_params: Optional[dict] = None,\n    use_in_memory: bool = True,\n    use_n2v2: bool = False,\n    struct_n2v_axis: Literal[\"horizontal\", \"vertical\", \"none\"] = \"none\",\n    struct_n2v_span: int = 5,\n) -&gt; None:\n    \"\"\"\n    LightningDataModule wrapper for training and validation datasets.\n\n    Since the lightning datamodule has no access to the model, make sure that the\n    parameters passed to the datamodule are consistent with the model's requirements\n    and are coherent.\n\n    The data module can be used with Path, str or numpy arrays. In the case of\n    numpy arrays, it loads and computes all the patches in memory. For Path and str\n    inputs, it calculates the total file size and estimate whether it can fit in\n    memory. If it does not, it iterates through the files. This behaviour can be\n    deactivated by setting `use_in_memory` to False, in which case it will\n    always use the iterating dataset to train on a Path or str.\n\n    To use array data, set `data_type` to `array` and pass a numpy array to\n    `train_data`.\n\n    In particular, N2V requires a specific transformation (N2V manipulates), which\n    is not compatible with supervised training. The default transformations applied\n    to the training patches are defined in `careamics.config.data_model`. To use\n    different transformations, pass a list of transforms. See examples for more\n    details.\n\n    By default, CAREamics only supports types defined in\n    `careamics.config.support.SupportedData`. To read custom data types, you can set\n    `data_type` to `custom` and provide a function that returns a numpy array from a\n    path. Additionally, pass a `fnmatch` and `Path.rglob` compatible expression\n    (e.g. \"*.jpeg\") to filter the files extension using `extension_filter`.\n\n    In the absence of validation data, the validation data is extracted from the\n    training data. The percentage of the training data to use for validation, as\n    well as the minimum number of patches to split from the training data for\n    validation can be set using `val_percentage` and `val_minimum_patches`,\n    respectively.\n\n    In `dataloader_params`, you can pass any parameter accepted by PyTorch\n    dataloaders, except for `batch_size`, which is set by the `batch_size`\n    parameter.\n\n    Finally, if you intend to use N2V family of algorithms, you can set `use_n2v2`\n    to use N2V2, and set the `struct_n2v_axis` and `struct_n2v_span` parameters to\n    define the axis and span of the structN2V mask. These parameters are without\n    effect if a `train_target_data` or if `transforms` are provided.\n\n    Parameters\n    ----------\n    train_data : Union[str, Path, np.ndarray]\n        Training data.\n    data_type : Union[str, SupportedData]\n        Data type, see `SupportedData` for available options.\n    patch_size : List[int]\n        Patch size, 2D or 3D patch size.\n    axes : str\n        Axes of the data, choosen amongst SCZYX.\n    batch_size : int\n        Batch size.\n    val_data : Optional[Union[str, Path]], optional\n        Validation data, by default None.\n    transforms : Optional[List[TRANSFORMS_UNION]], optional\n        List of transforms to apply to training patches. If None, default transforms\n        are applied.\n    train_target_data : Optional[Union[str, Path]], optional\n        Training target data, by default None.\n    val_target_data : Optional[Union[str, Path]], optional\n        Validation target data, by default None.\n    read_source_func : Optional[Callable], optional\n        Function to read the source data, used if `data_type` is `custom`, by\n        default None.\n    extension_filter : str, optional\n        Filter for file extensions, used if `data_type` is `custom`, by default \"\".\n    val_percentage : float, optional\n        Percentage of the training data to use for validation if no validation data\n        is given, by default 0.1.\n    val_minimum_patches : int, optional\n        Minimum number of patches to split from the training data for validation if\n        no validation data is given, by default 5.\n    dataloader_params : dict, optional\n        Pytorch dataloader parameters, by default {}.\n    use_in_memory : bool, optional\n        Use in memory dataset if possible, by default True.\n    use_n2v2 : bool, optional\n        Use N2V2 transformation during training, by default False.\n    struct_n2v_axis : Literal[\"horizontal\", \"vertical\", \"none\"], optional\n        Axis for the structN2V mask, only applied if `struct_n2v_axis` is `none`, by\n        default \"none\".\n    struct_n2v_span : int, optional\n        Span for the structN2V mask, by default 5.\n\n    Raises\n    ------\n    ValueError\n        If a target is set and N2V manipulation is present in the transforms.\n    \"\"\"\n    if dataloader_params is None:\n        dataloader_params = {}\n    data_dict: Dict[str, Any] = {\n        \"mode\": \"train\",\n        \"data_type\": data_type,\n        \"patch_size\": patch_size,\n        \"axes\": axes,\n        \"batch_size\": batch_size,\n        \"dataloader_params\": dataloader_params,\n    }\n\n    # if transforms are passed (otherwise it will use the default ones)\n    if transforms is not None:\n        data_dict[\"transforms\"] = transforms\n\n    # validate configuration\n    self.data_config = DataConfig(**data_dict)\n\n    # N2V specific checks, N2V, structN2V, and transforms\n    if self.data_config.has_n2v_manipulate():\n        # there is not target, n2v2 and structN2V can be changed\n        if train_target_data is None:\n            self.data_config.set_N2V2(use_n2v2)\n            self.data_config.set_structN2V_mask(struct_n2v_axis, struct_n2v_span)\n        else:\n            raise ValueError(\n                \"Cannot have both supervised training (target data) and \"\n                \"N2V manipulation in the transforms. Pass a list of transforms \"\n                \"that is compatible with your supervised training.\"\n            )\n\n    # sanity check on the dataloader parameters\n    if \"batch_size\" in dataloader_params:\n        # remove it\n        del dataloader_params[\"batch_size\"]\n\n    super().__init__(\n        data_config=self.data_config,\n        train_data=train_data,\n        val_data=val_data,\n        train_data_target=train_target_data,\n        val_data_target=val_target_data,\n        read_source_func=read_source_func,\n        extension_filter=extension_filter,\n        val_percentage=val_percentage,\n        val_minimum_split=val_minimum_patches,\n        use_in_memory=use_in_memory,\n    )\n</code></pre>"},{"location":"reference/careamics/lightning_module/","title":"lightning_module","text":"<p>CAREamics Lightning module.</p>"},{"location":"reference/careamics/lightning_module/#careamics.lightning_module.CAREamicsModule","title":"<code>CAREamicsModule</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>CAREamics Lightning module.</p> <p>This class encapsulates the a PyTorch model along with the training, validation, and testing logic. It is configured using an <code>AlgorithmModel</code> Pydantic class.</p> <p>Parameters:</p> Name Type Description Default <code>algorithm_config</code> <code>Union[AlgorithmModel, dict]</code> <p>Algorithm configuration.</p> required <p>Attributes:</p> Name Type Description <code>model</code> <code>Module</code> <p>PyTorch model.</p> <code>loss_func</code> <code>Module</code> <p>Loss function.</p> <code>optimizer_name</code> <code>str</code> <p>Optimizer name.</p> <code>optimizer_params</code> <code>dict</code> <p>Optimizer parameters.</p> <code>lr_scheduler_name</code> <code>str</code> <p>Learning rate scheduler name.</p> Source code in <code>src/careamics/lightning_module.py</code> <pre><code>class CAREamicsModule(L.LightningModule):\n    \"\"\"\n    CAREamics Lightning module.\n\n    This class encapsulates the a PyTorch model along with the training, validation,\n    and testing logic. It is configured using an `AlgorithmModel` Pydantic class.\n\n    Parameters\n    ----------\n    algorithm_config : Union[AlgorithmModel, dict]\n        Algorithm configuration.\n\n    Attributes\n    ----------\n    model : nn.Module\n        PyTorch model.\n    loss_func : nn.Module\n        Loss function.\n    optimizer_name : str\n        Optimizer name.\n    optimizer_params : dict\n        Optimizer parameters.\n    lr_scheduler_name : str\n        Learning rate scheduler name.\n    \"\"\"\n\n    def __init__(self, algorithm_config: Union[AlgorithmConfig, dict]) -&gt; None:\n        \"\"\"Lightning module for CAREamics.\n\n        This class encapsulates the a PyTorch model along with the training, validation,\n        and testing logic. It is configured using an `AlgorithmModel` Pydantic class.\n\n        Parameters\n        ----------\n        algorithm_config : Union[AlgorithmModel, dict]\n            Algorithm configuration.\n        \"\"\"\n        super().__init__()\n        # if loading from a checkpoint, AlgorithmModel needs to be instantiated\n        if isinstance(algorithm_config, dict):\n            algorithm_config = AlgorithmConfig(**algorithm_config)\n\n        # create model and loss function\n        self.model: nn.Module = model_factory(algorithm_config.model)\n        self.loss_func = loss_factory(algorithm_config.loss)\n\n        # save optimizer and lr_scheduler names and parameters\n        self.optimizer_name = algorithm_config.optimizer.name\n        self.optimizer_params = algorithm_config.optimizer.parameters\n        self.lr_scheduler_name = algorithm_config.lr_scheduler.name\n        self.lr_scheduler_params = algorithm_config.lr_scheduler.parameters\n\n    def forward(self, x: Any) -&gt; Any:\n        \"\"\"Forward pass.\n\n        Parameters\n        ----------\n        x : Any\n            Input tensor.\n\n        Returns\n        -------\n        Any\n            Output tensor.\n        \"\"\"\n        return self.model(x)\n\n    def training_step(self, batch: Tensor, batch_idx: Any) -&gt; Any:\n        \"\"\"Training step.\n\n        Parameters\n        ----------\n        batch : Tensor\n            Input batch.\n        batch_idx : Any\n            Batch index.\n\n        Returns\n        -------\n        Any\n            Loss value.\n        \"\"\"\n        x, *aux = batch\n        out = self.model(x)\n        loss = self.loss_func(out, *aux)\n        self.log(\n            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n        )\n        return loss\n\n    def validation_step(self, batch: Tensor, batch_idx: Any) -&gt; None:\n        \"\"\"Validation step.\n\n        Parameters\n        ----------\n        batch : Tensor\n            Input batch.\n        batch_idx : Any\n            Batch index.\n        \"\"\"\n        x, *aux = batch\n        out = self.model(x)\n        val_loss = self.loss_func(out, *aux)\n\n        # log validation loss\n        self.log(\n            \"val_loss\",\n            val_loss,\n            on_step=False,\n            on_epoch=True,\n            prog_bar=True,\n            logger=True,\n        )\n\n    def predict_step(self, batch: Tensor, batch_idx: Any) -&gt; Any:\n        \"\"\"Prediction step.\n\n        Parameters\n        ----------\n        batch : Tensor\n            Input batch.\n        batch_idx : Any\n            Batch index.\n\n        Returns\n        -------\n        Any\n            Model output.\n        \"\"\"\n        x, *aux = batch\n\n        # apply test-time augmentation if available\n        # TODO: probably wont work with batch size &gt; 1\n        if self._trainer.datamodule.prediction_config.tta_transforms:\n            tta = ImageRestorationTTA()\n            augmented_batch = tta.forward(batch[0])  # list of augmented tensors\n            augmented_output = []\n            for augmented in augmented_batch:\n                augmented_pred = self.model(augmented)\n                augmented_output.append(augmented_pred)\n            output = tta.backward(augmented_output)\n        else:\n            output = self.model(x)\n\n        # Denormalize the output\n        denorm = Denormalize(\n            mean=self._trainer.datamodule.predict_dataset.mean,\n            std=self._trainer.datamodule.predict_dataset.std,\n        )\n        denormalized_output, _ = denorm(patch=output)\n\n        if len(aux) &gt; 0:\n            return denormalized_output, aux\n        else:\n            return denormalized_output\n\n    def configure_optimizers(self) -&gt; Any:\n        \"\"\"Configure optimizers and learning rate schedulers.\n\n        Returns\n        -------\n        Any\n            Optimizer and learning rate scheduler.\n        \"\"\"\n        # instantiate optimizer\n        optimizer_func = get_optimizer(self.optimizer_name)\n        optimizer = optimizer_func(self.model.parameters(), **self.optimizer_params)\n\n        # and scheduler\n        scheduler_func = get_scheduler(self.lr_scheduler_name)\n        scheduler = scheduler_func(optimizer, **self.lr_scheduler_params)\n\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": scheduler,\n            \"monitor\": \"val_loss\",  # otherwise triggers MisconfigurationException\n        }\n</code></pre>"},{"location":"reference/careamics/lightning_module/#careamics.lightning_module.CAREamicsModule.__init__","title":"<code>__init__(algorithm_config)</code>","text":"<p>Lightning module for CAREamics.</p> <p>This class encapsulates the a PyTorch model along with the training, validation, and testing logic. It is configured using an <code>AlgorithmModel</code> Pydantic class.</p> <p>Parameters:</p> Name Type Description Default <code>algorithm_config</code> <code>Union[AlgorithmModel, dict]</code> <p>Algorithm configuration.</p> required Source code in <code>src/careamics/lightning_module.py</code> <pre><code>def __init__(self, algorithm_config: Union[AlgorithmConfig, dict]) -&gt; None:\n    \"\"\"Lightning module for CAREamics.\n\n    This class encapsulates the a PyTorch model along with the training, validation,\n    and testing logic. It is configured using an `AlgorithmModel` Pydantic class.\n\n    Parameters\n    ----------\n    algorithm_config : Union[AlgorithmModel, dict]\n        Algorithm configuration.\n    \"\"\"\n    super().__init__()\n    # if loading from a checkpoint, AlgorithmModel needs to be instantiated\n    if isinstance(algorithm_config, dict):\n        algorithm_config = AlgorithmConfig(**algorithm_config)\n\n    # create model and loss function\n    self.model: nn.Module = model_factory(algorithm_config.model)\n    self.loss_func = loss_factory(algorithm_config.loss)\n\n    # save optimizer and lr_scheduler names and parameters\n    self.optimizer_name = algorithm_config.optimizer.name\n    self.optimizer_params = algorithm_config.optimizer.parameters\n    self.lr_scheduler_name = algorithm_config.lr_scheduler.name\n    self.lr_scheduler_params = algorithm_config.lr_scheduler.parameters\n</code></pre>"},{"location":"reference/careamics/lightning_module/#careamics.lightning_module.CAREamicsModule.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configure optimizers and learning rate schedulers.</p> <p>Returns:</p> Type Description <code>Any</code> <p>Optimizer and learning rate scheduler.</p> Source code in <code>src/careamics/lightning_module.py</code> <pre><code>def configure_optimizers(self) -&gt; Any:\n    \"\"\"Configure optimizers and learning rate schedulers.\n\n    Returns\n    -------\n    Any\n        Optimizer and learning rate scheduler.\n    \"\"\"\n    # instantiate optimizer\n    optimizer_func = get_optimizer(self.optimizer_name)\n    optimizer = optimizer_func(self.model.parameters(), **self.optimizer_params)\n\n    # and scheduler\n    scheduler_func = get_scheduler(self.lr_scheduler_name)\n    scheduler = scheduler_func(optimizer, **self.lr_scheduler_params)\n\n    return {\n        \"optimizer\": optimizer,\n        \"lr_scheduler\": scheduler,\n        \"monitor\": \"val_loss\",  # otherwise triggers MisconfigurationException\n    }\n</code></pre>"},{"location":"reference/careamics/lightning_module/#careamics.lightning_module.CAREamicsModule.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Any</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Output tensor.</p> Source code in <code>src/careamics/lightning_module.py</code> <pre><code>def forward(self, x: Any) -&gt; Any:\n    \"\"\"Forward pass.\n\n    Parameters\n    ----------\n    x : Any\n        Input tensor.\n\n    Returns\n    -------\n    Any\n        Output tensor.\n    \"\"\"\n    return self.model(x)\n</code></pre>"},{"location":"reference/careamics/lightning_module/#careamics.lightning_module.CAREamicsModule.predict_step","title":"<code>predict_step(batch, batch_idx)</code>","text":"<p>Prediction step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tensor</code> <p>Input batch.</p> required <code>batch_idx</code> <code>Any</code> <p>Batch index.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Model output.</p> Source code in <code>src/careamics/lightning_module.py</code> <pre><code>def predict_step(self, batch: Tensor, batch_idx: Any) -&gt; Any:\n    \"\"\"Prediction step.\n\n    Parameters\n    ----------\n    batch : Tensor\n        Input batch.\n    batch_idx : Any\n        Batch index.\n\n    Returns\n    -------\n    Any\n        Model output.\n    \"\"\"\n    x, *aux = batch\n\n    # apply test-time augmentation if available\n    # TODO: probably wont work with batch size &gt; 1\n    if self._trainer.datamodule.prediction_config.tta_transforms:\n        tta = ImageRestorationTTA()\n        augmented_batch = tta.forward(batch[0])  # list of augmented tensors\n        augmented_output = []\n        for augmented in augmented_batch:\n            augmented_pred = self.model(augmented)\n            augmented_output.append(augmented_pred)\n        output = tta.backward(augmented_output)\n    else:\n        output = self.model(x)\n\n    # Denormalize the output\n    denorm = Denormalize(\n        mean=self._trainer.datamodule.predict_dataset.mean,\n        std=self._trainer.datamodule.predict_dataset.std,\n    )\n    denormalized_output, _ = denorm(patch=output)\n\n    if len(aux) &gt; 0:\n        return denormalized_output, aux\n    else:\n        return denormalized_output\n</code></pre>"},{"location":"reference/careamics/lightning_module/#careamics.lightning_module.CAREamicsModule.training_step","title":"<code>training_step(batch, batch_idx)</code>","text":"<p>Training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tensor</code> <p>Input batch.</p> required <code>batch_idx</code> <code>Any</code> <p>Batch index.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Loss value.</p> Source code in <code>src/careamics/lightning_module.py</code> <pre><code>def training_step(self, batch: Tensor, batch_idx: Any) -&gt; Any:\n    \"\"\"Training step.\n\n    Parameters\n    ----------\n    batch : Tensor\n        Input batch.\n    batch_idx : Any\n        Batch index.\n\n    Returns\n    -------\n    Any\n        Loss value.\n    \"\"\"\n    x, *aux = batch\n    out = self.model(x)\n    loss = self.loss_func(out, *aux)\n    self.log(\n        \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True\n    )\n    return loss\n</code></pre>"},{"location":"reference/careamics/lightning_module/#careamics.lightning_module.CAREamicsModule.validation_step","title":"<code>validation_step(batch, batch_idx)</code>","text":"<p>Validation step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tensor</code> <p>Input batch.</p> required <code>batch_idx</code> <code>Any</code> <p>Batch index.</p> required Source code in <code>src/careamics/lightning_module.py</code> <pre><code>def validation_step(self, batch: Tensor, batch_idx: Any) -&gt; None:\n    \"\"\"Validation step.\n\n    Parameters\n    ----------\n    batch : Tensor\n        Input batch.\n    batch_idx : Any\n        Batch index.\n    \"\"\"\n    x, *aux = batch\n    out = self.model(x)\n    val_loss = self.loss_func(out, *aux)\n\n    # log validation loss\n    self.log(\n        \"val_loss\",\n        val_loss,\n        on_step=False,\n        on_epoch=True,\n        prog_bar=True,\n        logger=True,\n    )\n</code></pre>"},{"location":"reference/careamics/lightning_module/#careamics.lightning_module.CAREamicsModuleWrapper","title":"<code>CAREamicsModuleWrapper</code>","text":"<p>               Bases: <code>CAREamicsModule</code></p> <p>Class defining the API for CAREamics Lightning layer.</p> <p>This class exposes parameters used to create an AlgorithmModel instance, triggering parameters validation.</p> <p>Parameters:</p> Name Type Description Default <code>algorithm</code> <code>Union[SupportedAlgorithm, str]</code> <p>Algorithm to use for training (see SupportedAlgorithm).</p> required <code>loss</code> <code>Union[SupportedLoss, str]</code> <p>Loss function to use for training (see SupportedLoss).</p> required <code>architecture</code> <code>Union[SupportedArchitecture, str]</code> <p>Model architecture to use for training (see SupportedArchitecture).</p> required <code>model_parameters</code> <code>dict</code> <p>Model parameters to use for training, by default {}. Model parameters are defined in the relevant <code>torch.nn.Module</code> class, or Pyddantic model (see <code>careamics.config.architectures</code>).</p> <code>None</code> <code>optimizer</code> <code>Union[SupportedOptimizer, str]</code> <p>Optimizer to use for training, by default \"Adam\" (see SupportedOptimizer).</p> <code>'Adam'</code> <code>optimizer_parameters</code> <code>dict</code> <p>Optimizer parameters to use for training, as defined in <code>torch.optim</code>, by default {}.</p> <code>None</code> <code>lr_scheduler</code> <code>Union[SupportedScheduler, str]</code> <p>Learning rate scheduler to use for training, by default \"ReduceLROnPlateau\" (see SupportedScheduler).</p> <code>'ReduceLROnPlateau'</code> <code>lr_scheduler_parameters</code> <code>dict</code> <p>Learning rate scheduler parameters to use for training, as defined in <code>torch.optim</code>, by default {}.</p> <code>None</code> Source code in <code>src/careamics/lightning_module.py</code> <pre><code>class CAREamicsModuleWrapper(CAREamicsModule):\n    \"\"\"Class defining the API for CAREamics Lightning layer.\n\n    This class exposes parameters used to create an AlgorithmModel instance, triggering\n    parameters validation.\n\n    Parameters\n    ----------\n    algorithm : Union[SupportedAlgorithm, str]\n        Algorithm to use for training (see SupportedAlgorithm).\n    loss : Union[SupportedLoss, str]\n        Loss function to use for training (see SupportedLoss).\n    architecture : Union[SupportedArchitecture, str]\n        Model architecture to use for training (see SupportedArchitecture).\n    model_parameters : dict, optional\n        Model parameters to use for training, by default {}. Model parameters are\n        defined in the relevant `torch.nn.Module` class, or Pyddantic model (see\n        `careamics.config.architectures`).\n    optimizer : Union[SupportedOptimizer, str], optional\n        Optimizer to use for training, by default \"Adam\" (see SupportedOptimizer).\n    optimizer_parameters : dict, optional\n        Optimizer parameters to use for training, as defined in `torch.optim`, by\n        default {}.\n    lr_scheduler : Union[SupportedScheduler, str], optional\n        Learning rate scheduler to use for training, by default \"ReduceLROnPlateau\"\n        (see SupportedScheduler).\n    lr_scheduler_parameters : dict, optional\n        Learning rate scheduler parameters to use for training, as defined in\n        `torch.optim`, by default {}.\n    \"\"\"\n\n    def __init__(\n        self,\n        algorithm: Union[SupportedAlgorithm, str],\n        loss: Union[SupportedLoss, str],\n        architecture: Union[SupportedArchitecture, str],\n        model_parameters: Optional[dict] = None,\n        optimizer: Union[SupportedOptimizer, str] = \"Adam\",\n        optimizer_parameters: Optional[dict] = None,\n        lr_scheduler: Union[SupportedScheduler, str] = \"ReduceLROnPlateau\",\n        lr_scheduler_parameters: Optional[dict] = None,\n    ) -&gt; None:\n        \"\"\"\n        Wrapper for the CAREamics model, exposing all algorithm configuration arguments.\n\n        Parameters\n        ----------\n        algorithm : Union[SupportedAlgorithm, str]\n            Algorithm to use for training (see SupportedAlgorithm).\n        loss : Union[SupportedLoss, str]\n            Loss function to use for training (see SupportedLoss).\n        architecture : Union[SupportedArchitecture, str]\n            Model architecture to use for training (see SupportedArchitecture).\n        model_parameters : dict, optional\n            Model parameters to use for training, by default {}. Model parameters are\n            defined in the relevant `torch.nn.Module` class, or Pyddantic model (see\n            `careamics.config.architectures`).\n        optimizer : Union[SupportedOptimizer, str], optional\n            Optimizer to use for training, by default \"Adam\" (see SupportedOptimizer).\n        optimizer_parameters : dict, optional\n            Optimizer parameters to use for training, as defined in `torch.optim`, by\n            default {}.\n        lr_scheduler : Union[SupportedScheduler, str], optional\n            Learning rate scheduler to use for training, by default \"ReduceLROnPlateau\"\n            (see SupportedScheduler).\n        lr_scheduler_parameters : dict, optional\n            Learning rate scheduler parameters to use for training, as defined in\n            `torch.optim`, by default {}.\n        \"\"\"\n        # create a AlgorithmModel compatible dictionary\n        if lr_scheduler_parameters is None:\n            lr_scheduler_parameters = {}\n        if optimizer_parameters is None:\n            optimizer_parameters = {}\n        if model_parameters is None:\n            model_parameters = {}\n        algorithm_configuration = {\n            \"algorithm\": algorithm,\n            \"loss\": loss,\n            \"optimizer\": {\n                \"name\": optimizer,\n                \"parameters\": optimizer_parameters,\n            },\n            \"lr_scheduler\": {\n                \"name\": lr_scheduler,\n                \"parameters\": lr_scheduler_parameters,\n            },\n        }\n        model_configuration = {\"architecture\": architecture}\n        model_configuration.update(model_parameters)\n\n        # add model parameters to algorithm configuration\n        algorithm_configuration[\"model\"] = model_configuration\n\n        # call the parent init using an AlgorithmModel instance\n        super().__init__(AlgorithmConfig(**algorithm_configuration))\n</code></pre>"},{"location":"reference/careamics/lightning_module/#careamics.lightning_module.CAREamicsModuleWrapper.__init__","title":"<code>__init__(algorithm, loss, architecture, model_parameters=None, optimizer='Adam', optimizer_parameters=None, lr_scheduler='ReduceLROnPlateau', lr_scheduler_parameters=None)</code>","text":"<p>Wrapper for the CAREamics model, exposing all algorithm configuration arguments.</p> <p>Parameters:</p> Name Type Description Default <code>algorithm</code> <code>Union[SupportedAlgorithm, str]</code> <p>Algorithm to use for training (see SupportedAlgorithm).</p> required <code>loss</code> <code>Union[SupportedLoss, str]</code> <p>Loss function to use for training (see SupportedLoss).</p> required <code>architecture</code> <code>Union[SupportedArchitecture, str]</code> <p>Model architecture to use for training (see SupportedArchitecture).</p> required <code>model_parameters</code> <code>dict</code> <p>Model parameters to use for training, by default {}. Model parameters are defined in the relevant <code>torch.nn.Module</code> class, or Pyddantic model (see <code>careamics.config.architectures</code>).</p> <code>None</code> <code>optimizer</code> <code>Union[SupportedOptimizer, str]</code> <p>Optimizer to use for training, by default \"Adam\" (see SupportedOptimizer).</p> <code>'Adam'</code> <code>optimizer_parameters</code> <code>dict</code> <p>Optimizer parameters to use for training, as defined in <code>torch.optim</code>, by default {}.</p> <code>None</code> <code>lr_scheduler</code> <code>Union[SupportedScheduler, str]</code> <p>Learning rate scheduler to use for training, by default \"ReduceLROnPlateau\" (see SupportedScheduler).</p> <code>'ReduceLROnPlateau'</code> <code>lr_scheduler_parameters</code> <code>dict</code> <p>Learning rate scheduler parameters to use for training, as defined in <code>torch.optim</code>, by default {}.</p> <code>None</code> Source code in <code>src/careamics/lightning_module.py</code> <pre><code>def __init__(\n    self,\n    algorithm: Union[SupportedAlgorithm, str],\n    loss: Union[SupportedLoss, str],\n    architecture: Union[SupportedArchitecture, str],\n    model_parameters: Optional[dict] = None,\n    optimizer: Union[SupportedOptimizer, str] = \"Adam\",\n    optimizer_parameters: Optional[dict] = None,\n    lr_scheduler: Union[SupportedScheduler, str] = \"ReduceLROnPlateau\",\n    lr_scheduler_parameters: Optional[dict] = None,\n) -&gt; None:\n    \"\"\"\n    Wrapper for the CAREamics model, exposing all algorithm configuration arguments.\n\n    Parameters\n    ----------\n    algorithm : Union[SupportedAlgorithm, str]\n        Algorithm to use for training (see SupportedAlgorithm).\n    loss : Union[SupportedLoss, str]\n        Loss function to use for training (see SupportedLoss).\n    architecture : Union[SupportedArchitecture, str]\n        Model architecture to use for training (see SupportedArchitecture).\n    model_parameters : dict, optional\n        Model parameters to use for training, by default {}. Model parameters are\n        defined in the relevant `torch.nn.Module` class, or Pyddantic model (see\n        `careamics.config.architectures`).\n    optimizer : Union[SupportedOptimizer, str], optional\n        Optimizer to use for training, by default \"Adam\" (see SupportedOptimizer).\n    optimizer_parameters : dict, optional\n        Optimizer parameters to use for training, as defined in `torch.optim`, by\n        default {}.\n    lr_scheduler : Union[SupportedScheduler, str], optional\n        Learning rate scheduler to use for training, by default \"ReduceLROnPlateau\"\n        (see SupportedScheduler).\n    lr_scheduler_parameters : dict, optional\n        Learning rate scheduler parameters to use for training, as defined in\n        `torch.optim`, by default {}.\n    \"\"\"\n    # create a AlgorithmModel compatible dictionary\n    if lr_scheduler_parameters is None:\n        lr_scheduler_parameters = {}\n    if optimizer_parameters is None:\n        optimizer_parameters = {}\n    if model_parameters is None:\n        model_parameters = {}\n    algorithm_configuration = {\n        \"algorithm\": algorithm,\n        \"loss\": loss,\n        \"optimizer\": {\n            \"name\": optimizer,\n            \"parameters\": optimizer_parameters,\n        },\n        \"lr_scheduler\": {\n            \"name\": lr_scheduler,\n            \"parameters\": lr_scheduler_parameters,\n        },\n    }\n    model_configuration = {\"architecture\": architecture}\n    model_configuration.update(model_parameters)\n\n    # add model parameters to algorithm configuration\n    algorithm_configuration[\"model\"] = model_configuration\n\n    # call the parent init using an AlgorithmModel instance\n    super().__init__(AlgorithmConfig(**algorithm_configuration))\n</code></pre>"},{"location":"reference/careamics/lightning_prediction_datamodule/","title":"lightning_prediction_datamodule","text":"<p>Prediction Lightning data modules.</p>"},{"location":"reference/careamics/lightning_prediction_datamodule/#careamics.lightning_prediction_datamodule.CAREamicsPredictData","title":"<code>CAREamicsPredictData</code>","text":"<p>               Bases: <code>LightningDataModule</code></p> <p>CAREamics Lightning prediction data module.</p> <p>The data module can be used with Path, str or numpy arrays. The data can be either a folder containing images or a single file.</p> <p>To read custom data types, you can set <code>data_type</code> to <code>custom</code> in <code>data_config</code> and provide a function that returns a numpy array from a path as <code>read_source_func</code> parameter. The function will receive a Path object and an axies string as arguments, the axes being derived from the <code>data_config</code>.</p> <p>You can also provide a <code>fnmatch</code> and <code>Path.rglob</code> compatible expression (e.g. \"*.czi\") to filter the files extension using <code>extension_filter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pred_config</code> <code>InferenceModel</code> <p>Pydantic model for CAREamics prediction configuration.</p> required <code>pred_data</code> <code>Union[Path, str, ndarray]</code> <p>Prediction data, can be a path to a folder, a file or a numpy array.</p> required <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read custom types, by default None.</p> <code>None</code> <code>extension_filter</code> <code>str</code> <p>Filter to filter file extensions for custom types, by default \"\".</p> <code>''</code> <code>dataloader_params</code> <code>dict</code> <p>Dataloader parameters, by default {}.</p> <code>None</code> Source code in <code>src/careamics/lightning_prediction_datamodule.py</code> <pre><code>class CAREamicsPredictData(L.LightningDataModule):\n    \"\"\"\n    CAREamics Lightning prediction data module.\n\n    The data module can be used with Path, str or numpy arrays. The data can be either\n    a folder containing images or a single file.\n\n    To read custom data types, you can set `data_type` to `custom` in `data_config`\n    and provide a function that returns a numpy array from a path as\n    `read_source_func` parameter. The function will receive a Path object and\n    an axies string as arguments, the axes being derived from the `data_config`.\n\n    You can also provide a `fnmatch` and `Path.rglob` compatible expression (e.g.\n    \"*.czi\") to filter the files extension using `extension_filter`.\n\n    Parameters\n    ----------\n    pred_config : InferenceModel\n        Pydantic model for CAREamics prediction configuration.\n    pred_data : Union[Path, str, np.ndarray]\n        Prediction data, can be a path to a folder, a file or a numpy array.\n    read_source_func : Optional[Callable], optional\n        Function to read custom types, by default None.\n    extension_filter : str, optional\n        Filter to filter file extensions for custom types, by default \"\".\n    dataloader_params : dict, optional\n        Dataloader parameters, by default {}.\n    \"\"\"\n\n    def __init__(\n        self,\n        pred_config: InferenceConfig,\n        pred_data: Union[Path, str, np.ndarray],\n        read_source_func: Optional[Callable] = None,\n        extension_filter: str = \"\",\n        dataloader_params: Optional[dict] = None,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        The data module can be used with Path, str or numpy arrays. The data can be\n        either a folder containing images or a single file.\n\n        To read custom data types, you can set `data_type` to `custom` in `data_config`\n        and provide a function that returns a numpy array from a path as\n        `read_source_func` parameter. The function will receive a Path object and\n        an axies string as arguments, the axes being derived from the `data_config`.\n\n        You can also provide a `fnmatch` and `Path.rglob` compatible expression (e.g.\n        \"*.czi\") to filter the files extension using `extension_filter`.\n\n        Parameters\n        ----------\n        pred_config : InferenceModel\n            Pydantic model for CAREamics prediction configuration.\n        pred_data : Union[Path, str, np.ndarray]\n            Prediction data, can be a path to a folder, a file or a numpy array.\n        read_source_func : Optional[Callable], optional\n            Function to read custom types, by default None.\n        extension_filter : str, optional\n            Filter to filter file extensions for custom types, by default \"\".\n        dataloader_params : dict, optional\n            Dataloader parameters, by default {}.\n\n        Raises\n        ------\n        ValueError\n            If the data type is `custom` and no `read_source_func` is provided.\n        ValueError\n            If the data type is `array` and the input is not a numpy array.\n        ValueError\n            If the data type is `tiff` and the input is neither a Path nor a str.\n        \"\"\"\n        if dataloader_params is None:\n            dataloader_params = {}\n        if dataloader_params is None:\n            dataloader_params = {}\n        super().__init__()\n\n        # check that a read source function is provided for custom types\n        if pred_config.data_type == SupportedData.CUSTOM and read_source_func is None:\n            raise ValueError(\n                f\"Data type {SupportedData.CUSTOM} is not allowed without \"\n                f\"specifying a `read_source_func` and an `extension_filer`.\"\n            )\n\n        # check correct input type\n        if (\n            isinstance(pred_data, np.ndarray)\n            and pred_config.data_type != SupportedData.ARRAY\n        ):\n            raise ValueError(\n                f\"Received a numpy array as input, but the data type was set to \"\n                f\"{pred_config.data_type}. Set the data type \"\n                f\"to {SupportedData.ARRAY} to predict on numpy arrays.\"\n            )\n\n        # and that Path or str are passed, if tiff file type specified\n        elif (isinstance(pred_data, Path) or isinstance(pred_config, str)) and (\n            pred_config.data_type != SupportedData.TIFF\n            and pred_config.data_type != SupportedData.CUSTOM\n        ):\n            raise ValueError(\n                f\"Received a path as input, but the data type was neither set to \"\n                f\"{SupportedData.TIFF} nor {SupportedData.CUSTOM}. Set the data type \"\n                f\" to {SupportedData.TIFF} or \"\n                f\"{SupportedData.CUSTOM} to predict on files.\"\n            )\n\n        # configuration data\n        self.prediction_config = pred_config\n        self.data_type = pred_config.data_type\n        self.batch_size = pred_config.batch_size\n        self.dataloader_params = dataloader_params\n\n        self.pred_data = pred_data\n        self.tile_size = pred_config.tile_size\n        self.tile_overlap = pred_config.tile_overlap\n\n        # read source function\n        if pred_config.data_type == SupportedData.CUSTOM:\n            # mypy check\n            assert read_source_func is not None\n\n            self.read_source_func: Callable = read_source_func\n        elif pred_config.data_type != SupportedData.ARRAY:\n            self.read_source_func = get_read_func(pred_config.data_type)\n\n        self.extension_filter = extension_filter\n\n    def prepare_data(self) -&gt; None:\n        \"\"\"Hook used to prepare the data before calling `setup`.\"\"\"\n        # if the data is a Path or a str\n        if not isinstance(self.pred_data, np.ndarray):\n            self.pred_files = list_files(\n                self.pred_data, self.data_type, self.extension_filter\n            )\n\n    def setup(self, stage: Optional[str] = None) -&gt; None:\n        \"\"\"\n        Hook called at the beginning of predict.\n\n        Parameters\n        ----------\n        stage : Optional[str], optional\n            Stage, by default None.\n        \"\"\"\n        # if numpy array\n        if self.data_type == SupportedData.ARRAY:\n            # prediction dataset\n            self.predict_dataset: PredictDatasetType = InMemoryPredictionDataset(\n                prediction_config=self.prediction_config,\n                inputs=self.pred_data,\n            )\n        else:\n            self.predict_dataset = IterablePredictionDataset(\n                prediction_config=self.prediction_config,\n                src_files=self.pred_files,\n                read_source_func=self.read_source_func,\n            )\n\n    def predict_dataloader(self) -&gt; DataLoader:\n        \"\"\"\n        Create a dataloader for prediction.\n\n        Returns\n        -------\n        DataLoader\n            Prediction dataloader.\n        \"\"\"\n        return DataLoader(\n            self.predict_dataset,\n            batch_size=self.batch_size,\n            collate_fn=_collate_tiles,\n            **self.dataloader_params,\n        )  # TODO check workers are used\n</code></pre>"},{"location":"reference/careamics/lightning_prediction_datamodule/#careamics.lightning_prediction_datamodule.CAREamicsPredictData.__init__","title":"<code>__init__(pred_config, pred_data, read_source_func=None, extension_filter='', dataloader_params=None)</code>","text":"<p>Constructor.</p> <p>The data module can be used with Path, str or numpy arrays. The data can be either a folder containing images or a single file.</p> <p>To read custom data types, you can set <code>data_type</code> to <code>custom</code> in <code>data_config</code> and provide a function that returns a numpy array from a path as <code>read_source_func</code> parameter. The function will receive a Path object and an axies string as arguments, the axes being derived from the <code>data_config</code>.</p> <p>You can also provide a <code>fnmatch</code> and <code>Path.rglob</code> compatible expression (e.g. \"*.czi\") to filter the files extension using <code>extension_filter</code>.</p> <p>Parameters:</p> Name Type Description Default <code>pred_config</code> <code>InferenceModel</code> <p>Pydantic model for CAREamics prediction configuration.</p> required <code>pred_data</code> <code>Union[Path, str, ndarray]</code> <p>Prediction data, can be a path to a folder, a file or a numpy array.</p> required <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read custom types, by default None.</p> <code>None</code> <code>extension_filter</code> <code>str</code> <p>Filter to filter file extensions for custom types, by default \"\".</p> <code>''</code> <code>dataloader_params</code> <code>dict</code> <p>Dataloader parameters, by default {}.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the data type is <code>custom</code> and no <code>read_source_func</code> is provided.</p> <code>ValueError</code> <p>If the data type is <code>array</code> and the input is not a numpy array.</p> <code>ValueError</code> <p>If the data type is <code>tiff</code> and the input is neither a Path nor a str.</p> Source code in <code>src/careamics/lightning_prediction_datamodule.py</code> <pre><code>def __init__(\n    self,\n    pred_config: InferenceConfig,\n    pred_data: Union[Path, str, np.ndarray],\n    read_source_func: Optional[Callable] = None,\n    extension_filter: str = \"\",\n    dataloader_params: Optional[dict] = None,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    The data module can be used with Path, str or numpy arrays. The data can be\n    either a folder containing images or a single file.\n\n    To read custom data types, you can set `data_type` to `custom` in `data_config`\n    and provide a function that returns a numpy array from a path as\n    `read_source_func` parameter. The function will receive a Path object and\n    an axies string as arguments, the axes being derived from the `data_config`.\n\n    You can also provide a `fnmatch` and `Path.rglob` compatible expression (e.g.\n    \"*.czi\") to filter the files extension using `extension_filter`.\n\n    Parameters\n    ----------\n    pred_config : InferenceModel\n        Pydantic model for CAREamics prediction configuration.\n    pred_data : Union[Path, str, np.ndarray]\n        Prediction data, can be a path to a folder, a file or a numpy array.\n    read_source_func : Optional[Callable], optional\n        Function to read custom types, by default None.\n    extension_filter : str, optional\n        Filter to filter file extensions for custom types, by default \"\".\n    dataloader_params : dict, optional\n        Dataloader parameters, by default {}.\n\n    Raises\n    ------\n    ValueError\n        If the data type is `custom` and no `read_source_func` is provided.\n    ValueError\n        If the data type is `array` and the input is not a numpy array.\n    ValueError\n        If the data type is `tiff` and the input is neither a Path nor a str.\n    \"\"\"\n    if dataloader_params is None:\n        dataloader_params = {}\n    if dataloader_params is None:\n        dataloader_params = {}\n    super().__init__()\n\n    # check that a read source function is provided for custom types\n    if pred_config.data_type == SupportedData.CUSTOM and read_source_func is None:\n        raise ValueError(\n            f\"Data type {SupportedData.CUSTOM} is not allowed without \"\n            f\"specifying a `read_source_func` and an `extension_filer`.\"\n        )\n\n    # check correct input type\n    if (\n        isinstance(pred_data, np.ndarray)\n        and pred_config.data_type != SupportedData.ARRAY\n    ):\n        raise ValueError(\n            f\"Received a numpy array as input, but the data type was set to \"\n            f\"{pred_config.data_type}. Set the data type \"\n            f\"to {SupportedData.ARRAY} to predict on numpy arrays.\"\n        )\n\n    # and that Path or str are passed, if tiff file type specified\n    elif (isinstance(pred_data, Path) or isinstance(pred_config, str)) and (\n        pred_config.data_type != SupportedData.TIFF\n        and pred_config.data_type != SupportedData.CUSTOM\n    ):\n        raise ValueError(\n            f\"Received a path as input, but the data type was neither set to \"\n            f\"{SupportedData.TIFF} nor {SupportedData.CUSTOM}. Set the data type \"\n            f\" to {SupportedData.TIFF} or \"\n            f\"{SupportedData.CUSTOM} to predict on files.\"\n        )\n\n    # configuration data\n    self.prediction_config = pred_config\n    self.data_type = pred_config.data_type\n    self.batch_size = pred_config.batch_size\n    self.dataloader_params = dataloader_params\n\n    self.pred_data = pred_data\n    self.tile_size = pred_config.tile_size\n    self.tile_overlap = pred_config.tile_overlap\n\n    # read source function\n    if pred_config.data_type == SupportedData.CUSTOM:\n        # mypy check\n        assert read_source_func is not None\n\n        self.read_source_func: Callable = read_source_func\n    elif pred_config.data_type != SupportedData.ARRAY:\n        self.read_source_func = get_read_func(pred_config.data_type)\n\n    self.extension_filter = extension_filter\n</code></pre>"},{"location":"reference/careamics/lightning_prediction_datamodule/#careamics.lightning_prediction_datamodule.CAREamicsPredictData.predict_dataloader","title":"<code>predict_dataloader()</code>","text":"<p>Create a dataloader for prediction.</p> <p>Returns:</p> Type Description <code>DataLoader</code> <p>Prediction dataloader.</p> Source code in <code>src/careamics/lightning_prediction_datamodule.py</code> <pre><code>def predict_dataloader(self) -&gt; DataLoader:\n    \"\"\"\n    Create a dataloader for prediction.\n\n    Returns\n    -------\n    DataLoader\n        Prediction dataloader.\n    \"\"\"\n    return DataLoader(\n        self.predict_dataset,\n        batch_size=self.batch_size,\n        collate_fn=_collate_tiles,\n        **self.dataloader_params,\n    )  # TODO check workers are used\n</code></pre>"},{"location":"reference/careamics/lightning_prediction_datamodule/#careamics.lightning_prediction_datamodule.CAREamicsPredictData.prepare_data","title":"<code>prepare_data()</code>","text":"<p>Hook used to prepare the data before calling <code>setup</code>.</p> Source code in <code>src/careamics/lightning_prediction_datamodule.py</code> <pre><code>def prepare_data(self) -&gt; None:\n    \"\"\"Hook used to prepare the data before calling `setup`.\"\"\"\n    # if the data is a Path or a str\n    if not isinstance(self.pred_data, np.ndarray):\n        self.pred_files = list_files(\n            self.pred_data, self.data_type, self.extension_filter\n        )\n</code></pre>"},{"location":"reference/careamics/lightning_prediction_datamodule/#careamics.lightning_prediction_datamodule.CAREamicsPredictData.setup","title":"<code>setup(stage=None)</code>","text":"<p>Hook called at the beginning of predict.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>Optional[str]</code> <p>Stage, by default None.</p> <code>None</code> Source code in <code>src/careamics/lightning_prediction_datamodule.py</code> <pre><code>def setup(self, stage: Optional[str] = None) -&gt; None:\n    \"\"\"\n    Hook called at the beginning of predict.\n\n    Parameters\n    ----------\n    stage : Optional[str], optional\n        Stage, by default None.\n    \"\"\"\n    # if numpy array\n    if self.data_type == SupportedData.ARRAY:\n        # prediction dataset\n        self.predict_dataset: PredictDatasetType = InMemoryPredictionDataset(\n            prediction_config=self.prediction_config,\n            inputs=self.pred_data,\n        )\n    else:\n        self.predict_dataset = IterablePredictionDataset(\n            prediction_config=self.prediction_config,\n            src_files=self.pred_files,\n            read_source_func=self.read_source_func,\n        )\n</code></pre>"},{"location":"reference/careamics/lightning_prediction_datamodule/#careamics.lightning_prediction_datamodule.PredictDataWrapper","title":"<code>PredictDataWrapper</code>","text":"<p>               Bases: <code>CAREamicsPredictData</code></p> <p>Wrapper around the CAREamics inference Lightning data module.</p> <p>This class is used to explicitely pass the parameters usually contained in a <code>inference_model</code> configuration.</p> <p>Since the lightning datamodule has no access to the model, make sure that the parameters passed to the datamodule are consistent with the model's requirements and are coherent.</p> <p>The data module can be used with Path, str or numpy arrays. To use array data, set <code>data_type</code> to <code>array</code> and pass a numpy array to <code>train_data</code>.</p> <p>The default transformations applied to the images are defined in <code>careamics.config.inference_model</code>. To use different transformations, pass a list of transforms. See examples for more details.</p> <p>The <code>mean</code> and <code>std</code> parameters are only used if Normalization is defined either in the default transformations or in the <code>transforms</code> parameter. If you pass a <code>Normalization</code> transform in a list as <code>transforms</code>, then the mean and std parameters will be overwritten by those passed to this method.</p> <p>By default, CAREamics only supports types defined in <code>careamics.config.support.SupportedData</code>. To read custom data types, you can set <code>data_type</code> to <code>custom</code> and provide a function that returns a numpy array from a path. Additionally, pass a <code>fnmatch</code> and <code>Path.rglob</code> compatible expression (e.g. \"*.jpeg\") to filter the files extension using <code>extension_filter</code>.</p> <p>In <code>dataloader_params</code>, you can pass any parameter accepted by PyTorch dataloaders, except for <code>batch_size</code>, which is set by the <code>batch_size</code> parameter.</p> <p>Note that if you are using a UNet model and tiling, the tile size must be divisible in every dimension by 2**d, where d is the depth of the model. This avoids artefacts arising from the broken shift invariance induced by the pooling layers of the UNet. If your image has less dimensions, as it may happen in the Z dimension, consider padding your image.</p> <p>Parameters:</p> Name Type Description Default <code>pred_data</code> <code>Union[str, Path, ndarray]</code> <p>Prediction data.</p> required <code>data_type</code> <code>Union[Literal['array', 'tiff', 'custom'], SupportedData]</code> <p>Data type, see <code>SupportedData</code> for available options.</p> required <code>mean</code> <code>float</code> <p>Mean value for normalization, only used if Normalization is defined in the transforms.</p> required <code>std</code> <code>float</code> <p>Standard deviation value for normalization, only used if Normalization is defined in the transform.</p> required <code>tile_size</code> <code>Tuple[int, ...]</code> <p>Tile size, 2D or 3D tile size.</p> <code>None</code> <code>tile_overlap</code> <code>Tuple[int, ...]</code> <p>Tile overlap, 2D or 3D tile overlap.</p> <code>None</code> <code>axes</code> <code>str</code> <p>Axes of the data, choosen amongst SCZYX.</p> <code>'YX'</code> <code>batch_size</code> <code>int</code> <p>Batch size.</p> <code>1</code> <code>tta_transforms</code> <code>bool</code> <p>Use test time augmentation, by default True.</p> <code>True</code> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read the source data, used if <code>data_type</code> is <code>custom</code>, by default None.</p> <code>None</code> <code>extension_filter</code> <code>str</code> <p>Filter for file extensions, used if <code>data_type</code> is <code>custom</code>, by default \"\".</p> <code>''</code> <code>dataloader_params</code> <code>dict</code> <p>Pytorch dataloader parameters, by default {}.</p> <code>None</code> Source code in <code>src/careamics/lightning_prediction_datamodule.py</code> <pre><code>class PredictDataWrapper(CAREamicsPredictData):\n    \"\"\"\n    Wrapper around the CAREamics inference Lightning data module.\n\n    This class is used to explicitely pass the parameters usually contained in a\n    `inference_model` configuration.\n\n    Since the lightning datamodule has no access to the model, make sure that the\n    parameters passed to the datamodule are consistent with the model's requirements\n    and are coherent.\n\n    The data module can be used with Path, str or numpy arrays. To use array data, set\n    `data_type` to `array` and pass a numpy array to `train_data`.\n\n    The default transformations applied to the images are defined in\n    `careamics.config.inference_model`. To use different transformations, pass a list\n    of transforms. See examples\n    for more details.\n\n    The `mean` and `std` parameters are only used if Normalization is defined either\n    in the default transformations or in the `transforms` parameter. If you pass a\n    `Normalization` transform in a list as `transforms`, then the mean and std\n    parameters will be overwritten by those passed to this method.\n\n    By default, CAREamics only supports types defined in\n    `careamics.config.support.SupportedData`. To read custom data types, you can set\n    `data_type` to `custom` and provide a function that returns a numpy array from a\n    path. Additionally, pass a `fnmatch` and `Path.rglob` compatible expression\n    (e.g. \"*.jpeg\") to filter the files extension using `extension_filter`.\n\n    In `dataloader_params`, you can pass any parameter accepted by PyTorch\n    dataloaders, except for `batch_size`, which is set by the `batch_size`\n    parameter.\n\n    Note that if you are using a UNet model and tiling, the tile size must be\n    divisible in every dimension by 2**d, where d is the depth of the model. This\n    avoids artefacts arising from the broken shift invariance induced by the\n    pooling layers of the UNet. If your image has less dimensions, as it may\n    happen in the Z dimension, consider padding your image.\n\n    Parameters\n    ----------\n    pred_data : Union[str, Path, np.ndarray]\n        Prediction data.\n    data_type : Union[Literal[\"array\", \"tiff\", \"custom\"], SupportedData]\n        Data type, see `SupportedData` for available options.\n    mean : float\n        Mean value for normalization, only used if Normalization is defined in the\n        transforms.\n    std : float\n        Standard deviation value for normalization, only used if Normalization is\n        defined in the transform.\n    tile_size : Tuple[int, ...]\n        Tile size, 2D or 3D tile size.\n    tile_overlap : Tuple[int, ...]\n        Tile overlap, 2D or 3D tile overlap.\n    axes : str\n        Axes of the data, choosen amongst SCZYX.\n    batch_size : int\n        Batch size.\n    tta_transforms : bool, optional\n        Use test time augmentation, by default True.\n    read_source_func : Optional[Callable], optional\n        Function to read the source data, used if `data_type` is `custom`, by\n        default None.\n    extension_filter : str, optional\n        Filter for file extensions, used if `data_type` is `custom`, by default \"\".\n    dataloader_params : dict, optional\n        Pytorch dataloader parameters, by default {}.\n    \"\"\"\n\n    def __init__(\n        self,\n        pred_data: Union[str, Path, np.ndarray],\n        data_type: Union[Literal[\"array\", \"tiff\", \"custom\"], SupportedData],\n        mean: float,\n        std: float,\n        tile_size: Optional[Tuple[int, ...]] = None,\n        tile_overlap: Optional[Tuple[int, ...]] = None,\n        axes: str = \"YX\",\n        batch_size: int = 1,\n        tta_transforms: bool = True,\n        read_source_func: Optional[Callable] = None,\n        extension_filter: str = \"\",\n        dataloader_params: Optional[dict] = None,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        pred_data : Union[str, Path, np.ndarray]\n            Prediction data.\n        data_type : Union[Literal[\"array\", \"tiff\", \"custom\"], SupportedData]\n            Data type, see `SupportedData` for available options.\n        mean : float\n            Mean value for normalization, only used if Normalization is defined in the\n            transforms.\n        std : float\n            Standard deviation value for normalization, only used if Normalization is\n            defined in the transform.\n        tile_size : List[int]\n            Tile size, 2D or 3D tile size.\n        tile_overlap : List[int]\n            Tile overlap, 2D or 3D tile overlap.\n        axes : str\n            Axes of the data, choosen amongst SCZYX.\n        batch_size : int\n            Batch size.\n        tta_transforms : bool, optional\n            Use test time augmentation, by default True.\n        read_source_func : Optional[Callable], optional\n            Function to read the source data, used if `data_type` is `custom`, by\n            default None.\n        extension_filter : str, optional\n            Filter for file extensions, used if `data_type` is `custom`, by default \"\".\n        dataloader_params : dict, optional\n            Pytorch dataloader parameters, by default {}.\n        \"\"\"\n        if dataloader_params is None:\n            dataloader_params = {}\n        prediction_dict: Dict[str, Any] = {\n            \"data_type\": data_type,\n            \"tile_size\": tile_size,\n            \"tile_overlap\": tile_overlap,\n            \"axes\": axes,\n            \"mean\": mean,\n            \"std\": std,\n            \"tta\": tta_transforms,\n            \"batch_size\": batch_size,\n            \"transforms\": [],\n        }\n\n        # validate configuration\n        self.prediction_config = InferenceConfig(**prediction_dict)\n\n        # sanity check on the dataloader parameters\n        if \"batch_size\" in dataloader_params:\n            # remove it\n            del dataloader_params[\"batch_size\"]\n\n        super().__init__(\n            pred_config=self.prediction_config,\n            pred_data=pred_data,\n            read_source_func=read_source_func,\n            extension_filter=extension_filter,\n            dataloader_params=dataloader_params,\n        )\n</code></pre>"},{"location":"reference/careamics/lightning_prediction_datamodule/#careamics.lightning_prediction_datamodule.PredictDataWrapper.__init__","title":"<code>__init__(pred_data, data_type, mean, std, tile_size=None, tile_overlap=None, axes='YX', batch_size=1, tta_transforms=True, read_source_func=None, extension_filter='', dataloader_params=None)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>pred_data</code> <code>Union[str, Path, ndarray]</code> <p>Prediction data.</p> required <code>data_type</code> <code>Union[Literal['array', 'tiff', 'custom'], SupportedData]</code> <p>Data type, see <code>SupportedData</code> for available options.</p> required <code>mean</code> <code>float</code> <p>Mean value for normalization, only used if Normalization is defined in the transforms.</p> required <code>std</code> <code>float</code> <p>Standard deviation value for normalization, only used if Normalization is defined in the transform.</p> required <code>tile_size</code> <code>List[int]</code> <p>Tile size, 2D or 3D tile size.</p> <code>None</code> <code>tile_overlap</code> <code>List[int]</code> <p>Tile overlap, 2D or 3D tile overlap.</p> <code>None</code> <code>axes</code> <code>str</code> <p>Axes of the data, choosen amongst SCZYX.</p> <code>'YX'</code> <code>batch_size</code> <code>int</code> <p>Batch size.</p> <code>1</code> <code>tta_transforms</code> <code>bool</code> <p>Use test time augmentation, by default True.</p> <code>True</code> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Function to read the source data, used if <code>data_type</code> is <code>custom</code>, by default None.</p> <code>None</code> <code>extension_filter</code> <code>str</code> <p>Filter for file extensions, used if <code>data_type</code> is <code>custom</code>, by default \"\".</p> <code>''</code> <code>dataloader_params</code> <code>dict</code> <p>Pytorch dataloader parameters, by default {}.</p> <code>None</code> Source code in <code>src/careamics/lightning_prediction_datamodule.py</code> <pre><code>def __init__(\n    self,\n    pred_data: Union[str, Path, np.ndarray],\n    data_type: Union[Literal[\"array\", \"tiff\", \"custom\"], SupportedData],\n    mean: float,\n    std: float,\n    tile_size: Optional[Tuple[int, ...]] = None,\n    tile_overlap: Optional[Tuple[int, ...]] = None,\n    axes: str = \"YX\",\n    batch_size: int = 1,\n    tta_transforms: bool = True,\n    read_source_func: Optional[Callable] = None,\n    extension_filter: str = \"\",\n    dataloader_params: Optional[dict] = None,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    pred_data : Union[str, Path, np.ndarray]\n        Prediction data.\n    data_type : Union[Literal[\"array\", \"tiff\", \"custom\"], SupportedData]\n        Data type, see `SupportedData` for available options.\n    mean : float\n        Mean value for normalization, only used if Normalization is defined in the\n        transforms.\n    std : float\n        Standard deviation value for normalization, only used if Normalization is\n        defined in the transform.\n    tile_size : List[int]\n        Tile size, 2D or 3D tile size.\n    tile_overlap : List[int]\n        Tile overlap, 2D or 3D tile overlap.\n    axes : str\n        Axes of the data, choosen amongst SCZYX.\n    batch_size : int\n        Batch size.\n    tta_transforms : bool, optional\n        Use test time augmentation, by default True.\n    read_source_func : Optional[Callable], optional\n        Function to read the source data, used if `data_type` is `custom`, by\n        default None.\n    extension_filter : str, optional\n        Filter for file extensions, used if `data_type` is `custom`, by default \"\".\n    dataloader_params : dict, optional\n        Pytorch dataloader parameters, by default {}.\n    \"\"\"\n    if dataloader_params is None:\n        dataloader_params = {}\n    prediction_dict: Dict[str, Any] = {\n        \"data_type\": data_type,\n        \"tile_size\": tile_size,\n        \"tile_overlap\": tile_overlap,\n        \"axes\": axes,\n        \"mean\": mean,\n        \"std\": std,\n        \"tta\": tta_transforms,\n        \"batch_size\": batch_size,\n        \"transforms\": [],\n    }\n\n    # validate configuration\n    self.prediction_config = InferenceConfig(**prediction_dict)\n\n    # sanity check on the dataloader parameters\n    if \"batch_size\" in dataloader_params:\n        # remove it\n        del dataloader_params[\"batch_size\"]\n\n    super().__init__(\n        pred_config=self.prediction_config,\n        pred_data=pred_data,\n        read_source_func=read_source_func,\n        extension_filter=extension_filter,\n        dataloader_params=dataloader_params,\n    )\n</code></pre>"},{"location":"reference/careamics/lightning_prediction_loop/","title":"lightning_prediction_loop","text":"<p>Lithning prediction loop allowing tiling.</p>"},{"location":"reference/careamics/lightning_prediction_loop/#careamics.lightning_prediction_loop.CAREamicsPredictionLoop","title":"<code>CAREamicsPredictionLoop</code>","text":"<p>               Bases: <code>_PredictionLoop</code></p> <p>CAREamics prediction loop.</p> <p>This class extends the PyTorch Lightning <code>_PredictionLoop</code> class to include the stitching of the tiles into a single prediction result.</p> Source code in <code>src/careamics/lightning_prediction_loop.py</code> <pre><code>class CAREamicsPredictionLoop(L.loops._PredictionLoop):\n    \"\"\"\n    CAREamics prediction loop.\n\n    This class extends the PyTorch Lightning `_PredictionLoop` class to include\n    the stitching of the tiles into a single prediction result.\n    \"\"\"\n\n    def _on_predict_epoch_end(self) -&gt; Optional[_PREDICT_OUTPUT]:\n        \"\"\"Call `on_predict_epoch_end` hook.\n\n        Adapted from the parent method.\n\n        Returns\n        -------\n        Optional[_PREDICT_OUTPUT]\n            Prediction output.\n        \"\"\"\n        trainer = self.trainer\n        call._call_callback_hooks(trainer, \"on_predict_epoch_end\")\n        call._call_lightning_module_hook(trainer, \"on_predict_epoch_end\")\n\n        if self.return_predictions:\n            ########################################################\n            ################ CAREamics specific code ###############\n            if len(self.predicted_array) == 1:\n                # TODO does this make sense to here? (force numpy array)\n                return self.predicted_array[0].numpy()\n            else:\n                # TODO revisit logic\n                return [element.numpy() for element in self.predicted_array]\n            ########################################################\n        return None\n\n    @_no_grad_context\n    def run(self) -&gt; Optional[_PREDICT_OUTPUT]:\n        \"\"\"Run the prediction loop.\n\n        Adapted from the parent method in order to stitch the predictions.\n\n        Returns\n        -------\n        Optional[_PREDICT_OUTPUT]\n            Prediction output.\n        \"\"\"\n        self.setup_data()\n        if self.skip:\n            return None\n        self.reset()\n        self.on_run_start()\n        data_fetcher = self._data_fetcher\n        assert data_fetcher is not None\n\n        self.predicted_array = []\n        self.tiles = []\n        self.stitching_data = []\n\n        while True:\n            try:\n                if isinstance(data_fetcher, _DataLoaderIterDataFetcher):\n                    dataloader_iter = next(data_fetcher)\n                    # hook's batch_idx and dataloader_idx arguments correctness cannot\n                    # be guaranteed in this setting\n                    batch = data_fetcher._batch\n                    batch_idx = data_fetcher._batch_idx\n                    dataloader_idx = data_fetcher._dataloader_idx\n                else:\n                    dataloader_iter = None\n                    batch, batch_idx, dataloader_idx = next(data_fetcher)\n                self.batch_progress.is_last_batch = data_fetcher.done\n\n                # run step hooks\n                self._predict_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\n                ########################################################\n                ################ CAREamics specific code ###############\n                is_tiled = len(self.predictions[batch_idx]) == 2\n                if is_tiled:\n                    # extract the last tile flag and the coordinates (crop and stitch)\n                    last_tile, *stitch_data = self.predictions[batch_idx][1]\n\n                    # append the tile and the coordinates to the lists\n                    self.tiles.append(self.predictions[batch_idx][0])\n                    self.stitching_data.append(stitch_data)\n\n                    # if last tile, stitch the tiles and add array to the prediction\n                    if any(last_tile):\n                        predicted_batches = stitch_prediction(\n                            self.tiles, self.stitching_data\n                        )\n                        self.predicted_array.append(predicted_batches)\n                        self.tiles.clear()\n                        self.stitching_data.clear()\n                else:\n                    # simply add the prediction to the list\n                    self.predicted_array.append(self.predictions[batch_idx])\n                ########################################################\n            except StopIteration:\n                break\n            finally:\n                self._restarting = False\n        return self.on_run_end()\n</code></pre>"},{"location":"reference/careamics/lightning_prediction_loop/#careamics.lightning_prediction_loop.CAREamicsPredictionLoop.run","title":"<code>run()</code>","text":"<p>Run the prediction loop.</p> <p>Adapted from the parent method in order to stitch the predictions.</p> <p>Returns:</p> Type Description <code>Optional[_PREDICT_OUTPUT]</code> <p>Prediction output.</p> Source code in <code>src/careamics/lightning_prediction_loop.py</code> <pre><code>@_no_grad_context\ndef run(self) -&gt; Optional[_PREDICT_OUTPUT]:\n    \"\"\"Run the prediction loop.\n\n    Adapted from the parent method in order to stitch the predictions.\n\n    Returns\n    -------\n    Optional[_PREDICT_OUTPUT]\n        Prediction output.\n    \"\"\"\n    self.setup_data()\n    if self.skip:\n        return None\n    self.reset()\n    self.on_run_start()\n    data_fetcher = self._data_fetcher\n    assert data_fetcher is not None\n\n    self.predicted_array = []\n    self.tiles = []\n    self.stitching_data = []\n\n    while True:\n        try:\n            if isinstance(data_fetcher, _DataLoaderIterDataFetcher):\n                dataloader_iter = next(data_fetcher)\n                # hook's batch_idx and dataloader_idx arguments correctness cannot\n                # be guaranteed in this setting\n                batch = data_fetcher._batch\n                batch_idx = data_fetcher._batch_idx\n                dataloader_idx = data_fetcher._dataloader_idx\n            else:\n                dataloader_iter = None\n                batch, batch_idx, dataloader_idx = next(data_fetcher)\n            self.batch_progress.is_last_batch = data_fetcher.done\n\n            # run step hooks\n            self._predict_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\n            ########################################################\n            ################ CAREamics specific code ###############\n            is_tiled = len(self.predictions[batch_idx]) == 2\n            if is_tiled:\n                # extract the last tile flag and the coordinates (crop and stitch)\n                last_tile, *stitch_data = self.predictions[batch_idx][1]\n\n                # append the tile and the coordinates to the lists\n                self.tiles.append(self.predictions[batch_idx][0])\n                self.stitching_data.append(stitch_data)\n\n                # if last tile, stitch the tiles and add array to the prediction\n                if any(last_tile):\n                    predicted_batches = stitch_prediction(\n                        self.tiles, self.stitching_data\n                    )\n                    self.predicted_array.append(predicted_batches)\n                    self.tiles.clear()\n                    self.stitching_data.clear()\n            else:\n                # simply add the prediction to the list\n                self.predicted_array.append(self.predictions[batch_idx])\n            ########################################################\n        except StopIteration:\n            break\n        finally:\n            self._restarting = False\n    return self.on_run_end()\n</code></pre>"},{"location":"reference/careamics/callbacks/hyperparameters_callback/","title":"hyperparameters_callback","text":"<p>Callback saving CAREamics configuration as hyperparameters in the model.</p>"},{"location":"reference/careamics/callbacks/hyperparameters_callback/#careamics.callbacks.hyperparameters_callback.HyperParametersCallback","title":"<code>HyperParametersCallback</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback allowing saving CAREamics configuration as hyperparameters in the model.</p> <p>This allows saving the configuration as dictionnary in the checkpoints, and loading it subsequently in a CAREamist instance.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>CAREamics configuration to be saved as hyperparameter in the model.</p> required <p>Attributes:</p> Name Type Description <code>config</code> <code>Configuration</code> <p>CAREamics configuration to be saved as hyperparameter in the model.</p> Source code in <code>src/careamics/callbacks/hyperparameters_callback.py</code> <pre><code>class HyperParametersCallback(Callback):\n    \"\"\"\n    Callback allowing saving CAREamics configuration as hyperparameters in the model.\n\n    This allows saving the configuration as dictionnary in the checkpoints, and\n    loading it subsequently in a CAREamist instance.\n\n    Parameters\n    ----------\n    config : Configuration\n        CAREamics configuration to be saved as hyperparameter in the model.\n\n    Attributes\n    ----------\n    config : Configuration\n        CAREamics configuration to be saved as hyperparameter in the model.\n    \"\"\"\n\n    def __init__(self, config: Configuration) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        config : Configuration\n            CAREamics configuration to be saved as hyperparameter in the model.\n        \"\"\"\n        self.config = config\n\n    def on_train_start(self, trainer: Trainer, pl_module: LightningModule) -&gt; None:\n        \"\"\"\n        Update the hyperparameters of the model with the configuration on train start.\n\n        Parameters\n        ----------\n        trainer : Trainer\n            PyTorch Lightning trainer, unused.\n        pl_module : LightningModule\n            PyTorch Lightning module.\n        \"\"\"\n        pl_module.hparams.update(self.config.model_dump())\n</code></pre>"},{"location":"reference/careamics/callbacks/hyperparameters_callback/#careamics.callbacks.hyperparameters_callback.HyperParametersCallback.__init__","title":"<code>__init__(config)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>CAREamics configuration to be saved as hyperparameter in the model.</p> required Source code in <code>src/careamics/callbacks/hyperparameters_callback.py</code> <pre><code>def __init__(self, config: Configuration) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    config : Configuration\n        CAREamics configuration to be saved as hyperparameter in the model.\n    \"\"\"\n    self.config = config\n</code></pre>"},{"location":"reference/careamics/callbacks/hyperparameters_callback/#careamics.callbacks.hyperparameters_callback.HyperParametersCallback.on_train_start","title":"<code>on_train_start(trainer, pl_module)</code>","text":"<p>Update the hyperparameters of the model with the configuration on train start.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>PyTorch Lightning trainer, unused.</p> required <code>pl_module</code> <code>LightningModule</code> <p>PyTorch Lightning module.</p> required Source code in <code>src/careamics/callbacks/hyperparameters_callback.py</code> <pre><code>def on_train_start(self, trainer: Trainer, pl_module: LightningModule) -&gt; None:\n    \"\"\"\n    Update the hyperparameters of the model with the configuration on train start.\n\n    Parameters\n    ----------\n    trainer : Trainer\n        PyTorch Lightning trainer, unused.\n    pl_module : LightningModule\n        PyTorch Lightning module.\n    \"\"\"\n    pl_module.hparams.update(self.config.model_dump())\n</code></pre>"},{"location":"reference/careamics/callbacks/progress_bar_callback/","title":"progress_bar_callback","text":"<p>Progressbar callback.</p>"},{"location":"reference/careamics/callbacks/progress_bar_callback/#careamics.callbacks.progress_bar_callback.ProgressBarCallback","title":"<code>ProgressBarCallback</code>","text":"<p>               Bases: <code>TQDMProgressBar</code></p> <p>Progress bar for training and validation steps.</p> Source code in <code>src/careamics/callbacks/progress_bar_callback.py</code> <pre><code>class ProgressBarCallback(TQDMProgressBar):\n    \"\"\"Progress bar for training and validation steps.\"\"\"\n\n    def init_train_tqdm(self) -&gt; tqdm:\n        \"\"\"Override this to customize the tqdm bar for training.\n\n        Returns\n        -------\n        tqdm\n            A tqdm bar.\n        \"\"\"\n        bar = tqdm(\n            desc=\"Training\",\n            position=(2 * self.process_position),\n            disable=self.is_disabled,\n            leave=True,\n            dynamic_ncols=True,\n            file=sys.stdout,\n            smoothing=0,\n        )\n        return bar\n\n    def init_validation_tqdm(self) -&gt; tqdm:\n        \"\"\"Override this to customize the tqdm bar for validation.\n\n        Returns\n        -------\n        tqdm\n            A tqdm bar.\n        \"\"\"\n        # The main progress bar doesn't exist in `trainer.validate()`\n        has_main_bar = self.train_progress_bar is not None\n        bar = tqdm(\n            desc=\"Validating\",\n            position=(2 * self.process_position + has_main_bar),\n            disable=self.is_disabled,\n            leave=False,\n            dynamic_ncols=True,\n            file=sys.stdout,\n        )\n        return bar\n\n    def init_test_tqdm(self) -&gt; tqdm:\n        \"\"\"Override this to customize the tqdm bar for testing.\n\n        Returns\n        -------\n        tqdm\n            A tqdm bar.\n        \"\"\"\n        bar = tqdm(\n            desc=\"Testing\",\n            position=(2 * self.process_position),\n            disable=self.is_disabled,\n            leave=True,\n            dynamic_ncols=False,\n            ncols=100,\n            file=sys.stdout,\n        )\n        return bar\n\n    def get_metrics(\n        self, trainer: Trainer, pl_module: LightningModule\n    ) -&gt; Dict[str, Union[int, str, float, Dict[str, float]]]:\n        \"\"\"Override this to customize the metrics displayed in the progress bar.\n\n        Parameters\n        ----------\n        trainer : Trainer\n            The trainer object.\n        pl_module : LightningModule\n            The LightningModule object, unused.\n\n        Returns\n        -------\n        dict\n            A dictionary with the metrics to display in the progress bar.\n        \"\"\"\n        pbar_metrics = trainer.progress_bar_metrics\n        return {**pbar_metrics}\n</code></pre>"},{"location":"reference/careamics/callbacks/progress_bar_callback/#careamics.callbacks.progress_bar_callback.ProgressBarCallback.get_metrics","title":"<code>get_metrics(trainer, pl_module)</code>","text":"<p>Override this to customize the metrics displayed in the progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The trainer object.</p> required <code>pl_module</code> <code>LightningModule</code> <p>The LightningModule object, unused.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with the metrics to display in the progress bar.</p> Source code in <code>src/careamics/callbacks/progress_bar_callback.py</code> <pre><code>def get_metrics(\n    self, trainer: Trainer, pl_module: LightningModule\n) -&gt; Dict[str, Union[int, str, float, Dict[str, float]]]:\n    \"\"\"Override this to customize the metrics displayed in the progress bar.\n\n    Parameters\n    ----------\n    trainer : Trainer\n        The trainer object.\n    pl_module : LightningModule\n        The LightningModule object, unused.\n\n    Returns\n    -------\n    dict\n        A dictionary with the metrics to display in the progress bar.\n    \"\"\"\n    pbar_metrics = trainer.progress_bar_metrics\n    return {**pbar_metrics}\n</code></pre>"},{"location":"reference/careamics/callbacks/progress_bar_callback/#careamics.callbacks.progress_bar_callback.ProgressBarCallback.init_test_tqdm","title":"<code>init_test_tqdm()</code>","text":"<p>Override this to customize the tqdm bar for testing.</p> <p>Returns:</p> Type Description <code>tqdm</code> <p>A tqdm bar.</p> Source code in <code>src/careamics/callbacks/progress_bar_callback.py</code> <pre><code>def init_test_tqdm(self) -&gt; tqdm:\n    \"\"\"Override this to customize the tqdm bar for testing.\n\n    Returns\n    -------\n    tqdm\n        A tqdm bar.\n    \"\"\"\n    bar = tqdm(\n        desc=\"Testing\",\n        position=(2 * self.process_position),\n        disable=self.is_disabled,\n        leave=True,\n        dynamic_ncols=False,\n        ncols=100,\n        file=sys.stdout,\n    )\n    return bar\n</code></pre>"},{"location":"reference/careamics/callbacks/progress_bar_callback/#careamics.callbacks.progress_bar_callback.ProgressBarCallback.init_train_tqdm","title":"<code>init_train_tqdm()</code>","text":"<p>Override this to customize the tqdm bar for training.</p> <p>Returns:</p> Type Description <code>tqdm</code> <p>A tqdm bar.</p> Source code in <code>src/careamics/callbacks/progress_bar_callback.py</code> <pre><code>def init_train_tqdm(self) -&gt; tqdm:\n    \"\"\"Override this to customize the tqdm bar for training.\n\n    Returns\n    -------\n    tqdm\n        A tqdm bar.\n    \"\"\"\n    bar = tqdm(\n        desc=\"Training\",\n        position=(2 * self.process_position),\n        disable=self.is_disabled,\n        leave=True,\n        dynamic_ncols=True,\n        file=sys.stdout,\n        smoothing=0,\n    )\n    return bar\n</code></pre>"},{"location":"reference/careamics/callbacks/progress_bar_callback/#careamics.callbacks.progress_bar_callback.ProgressBarCallback.init_validation_tqdm","title":"<code>init_validation_tqdm()</code>","text":"<p>Override this to customize the tqdm bar for validation.</p> <p>Returns:</p> Type Description <code>tqdm</code> <p>A tqdm bar.</p> Source code in <code>src/careamics/callbacks/progress_bar_callback.py</code> <pre><code>def init_validation_tqdm(self) -&gt; tqdm:\n    \"\"\"Override this to customize the tqdm bar for validation.\n\n    Returns\n    -------\n    tqdm\n        A tqdm bar.\n    \"\"\"\n    # The main progress bar doesn't exist in `trainer.validate()`\n    has_main_bar = self.train_progress_bar is not None\n    bar = tqdm(\n        desc=\"Validating\",\n        position=(2 * self.process_position + has_main_bar),\n        disable=self.is_disabled,\n        leave=False,\n        dynamic_ncols=True,\n        file=sys.stdout,\n    )\n    return bar\n</code></pre>"},{"location":"reference/careamics/config/algorithm_model/","title":"algorithm_model","text":"<p>Algorithm configuration.</p>"},{"location":"reference/careamics/config/algorithm_model/#careamics.config.algorithm_model.AlgorithmConfig","title":"<code>AlgorithmConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Algorithm configuration.</p> <p>This Pydantic model validates the parameters governing the components of the training algorithm: which algorithm, loss function, model architecture, optimizer, and learning rate scheduler to use.</p> <p>Currently, we only support N2V, CARE, N2N and custom models. The <code>n2v</code> algorithm is only compatible with <code>n2v</code> loss and <code>UNet</code> architecture. The <code>custom</code> algorithm allows you to register your own architecture and select it using its name as <code>name</code> in the custom pydantic model.</p> <p>Attributes:</p> Name Type Description <code>algorithm</code> <code>Literal['n2v', 'custom']</code> <p>Algorithm to use.</p> <code>loss</code> <code>Literal['n2v', 'mae', 'mse']</code> <p>Loss function to use.</p> <code>model</code> <code>Union[UNetModel, VAEModel, CustomModel]</code> <p>Model architecture to use.</p> <code>optimizer</code> <code>(OptimizerModel, optional)</code> <p>Optimizer to use.</p> <code>lr_scheduler</code> <code>(LrSchedulerModel, optional)</code> <p>Learning rate scheduler to use.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Algorithm parameter type validation errors.</p> <code>ValueError</code> <p>If the algorithm, loss and model are not compatible.</p> <p>Examples:</p> <p>Minimum example:</p> <pre><code>&gt;&gt;&gt; from careamics.config import AlgorithmConfig\n&gt;&gt;&gt; config_dict = {\n...     \"algorithm\": \"n2v\",\n...     \"loss\": \"n2v\",\n...     \"model\": {\n...         \"architecture\": \"UNet\",\n...     }\n... }\n&gt;&gt;&gt; config = AlgorithmConfig(**config_dict)\n</code></pre> <p>Using a custom model:</p> <pre><code>&gt;&gt;&gt; from torch import nn, ones\n&gt;&gt;&gt; from careamics.config import AlgorithmConfig, register_model\n...\n&gt;&gt;&gt; @register_model(name=\"linear_model\")\n... class LinearModel(nn.Module):\n...    def __init__(self, in_features, out_features, *args, **kwargs):\n...        super().__init__()\n...        self.in_features = in_features\n...        self.out_features = out_features\n...        self.weight = nn.Parameter(ones(in_features, out_features))\n...        self.bias = nn.Parameter(ones(out_features))\n...    def forward(self, input):\n...        return (input @ self.weight) + self.bias\n...\n&gt;&gt;&gt; config_dict = {\n...     \"algorithm\": \"custom\",\n...     \"loss\": \"mse\",\n...     \"model\": {\n...         \"architecture\": \"Custom\",\n...         \"name\": \"linear_model\",\n...         \"in_features\": 10,\n...         \"out_features\": 5,\n...     }\n... }\n&gt;&gt;&gt; config = AlgorithmConfig(**config_dict)\n</code></pre> Source code in <code>src/careamics/config/algorithm_model.py</code> <pre><code>class AlgorithmConfig(BaseModel):\n    \"\"\"Algorithm configuration.\n\n    This Pydantic model validates the parameters governing the components of the\n    training algorithm: which algorithm, loss function, model architecture, optimizer,\n    and learning rate scheduler to use.\n\n    Currently, we only support N2V, CARE, N2N and custom models. The `n2v` algorithm is\n    only compatible with `n2v` loss and `UNet` architecture. The `custom` algorithm\n    allows you to register your own architecture and select it using its name as\n    `name` in the custom pydantic model.\n\n    Attributes\n    ----------\n    algorithm : Literal[\"n2v\", \"custom\"]\n        Algorithm to use.\n    loss : Literal[\"n2v\", \"mae\", \"mse\"]\n        Loss function to use.\n    model : Union[UNetModel, VAEModel, CustomModel]\n        Model architecture to use.\n    optimizer : OptimizerModel, optional\n        Optimizer to use.\n    lr_scheduler : LrSchedulerModel, optional\n        Learning rate scheduler to use.\n\n    Raises\n    ------\n    ValueError\n        Algorithm parameter type validation errors.\n    ValueError\n        If the algorithm, loss and model are not compatible.\n\n    Examples\n    --------\n    Minimum example:\n    &gt;&gt;&gt; from careamics.config import AlgorithmConfig\n    &gt;&gt;&gt; config_dict = {\n    ...     \"algorithm\": \"n2v\",\n    ...     \"loss\": \"n2v\",\n    ...     \"model\": {\n    ...         \"architecture\": \"UNet\",\n    ...     }\n    ... }\n    &gt;&gt;&gt; config = AlgorithmConfig(**config_dict)\n\n    Using a custom model:\n    &gt;&gt;&gt; from torch import nn, ones\n    &gt;&gt;&gt; from careamics.config import AlgorithmConfig, register_model\n    ...\n    &gt;&gt;&gt; @register_model(name=\"linear_model\")\n    ... class LinearModel(nn.Module):\n    ...    def __init__(self, in_features, out_features, *args, **kwargs):\n    ...        super().__init__()\n    ...        self.in_features = in_features\n    ...        self.out_features = out_features\n    ...        self.weight = nn.Parameter(ones(in_features, out_features))\n    ...        self.bias = nn.Parameter(ones(out_features))\n    ...    def forward(self, input):\n    ...        return (input @ self.weight) + self.bias\n    ...\n    &gt;&gt;&gt; config_dict = {\n    ...     \"algorithm\": \"custom\",\n    ...     \"loss\": \"mse\",\n    ...     \"model\": {\n    ...         \"architecture\": \"Custom\",\n    ...         \"name\": \"linear_model\",\n    ...         \"in_features\": 10,\n    ...         \"out_features\": 5,\n    ...     }\n    ... }\n    &gt;&gt;&gt; config = AlgorithmConfig(**config_dict)\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        protected_namespaces=(),  # allows to use model_* as a field name\n        validate_assignment=True,\n    )\n\n    # Mandatory fields\n    algorithm: Literal[\"n2v\", \"care\", \"n2n\", \"custom\"]  # defined in SupportedAlgorithm\n    loss: Literal[\"n2v\", \"mae\", \"mse\"]\n    model: Union[UNetModel, VAEModel, CustomModel] = Field(discriminator=\"architecture\")\n\n    # Optional fields\n    optimizer: OptimizerModel = OptimizerModel()\n    lr_scheduler: LrSchedulerModel = LrSchedulerModel()\n\n    @model_validator(mode=\"after\")\n    def algorithm_cross_validation(self: Self) -&gt; Self:\n        \"\"\"Validate the algorithm model based on `algorithm`.\n\n        N2V:\n        - loss must be n2v\n        - model must be a `UNetModel`\n\n        Returns\n        -------\n        Self\n            The validated model.\n        \"\"\"\n        # N2V\n        if self.algorithm == \"n2v\":\n            # n2v is only compatible with the n2v loss\n            if self.loss != \"n2v\":\n                raise ValueError(\n                    f\"Algorithm {self.algorithm} only supports loss `n2v`.\"\n                )\n\n            # n2v is only compatible with the UNet model\n            if not isinstance(self.model, UNetModel):\n                raise ValueError(\n                    f\"Model for algorithm {self.algorithm} must be a `UNetModel`.\"\n                )\n\n            # n2v requires the number of input and output channels to be the same\n            if self.model.in_channels != self.model.num_classes:\n                raise ValueError(\n                    \"N2V requires the same number of input and output channels. Make \"\n                    \"sure that `in_channels` and `num_classes` are the same.\"\n                )\n\n        # N2N\n        if self.algorithm == \"n2n\":\n            # n2n is only compatible with the UNet model\n            if not isinstance(self.model, UNetModel):\n                raise ValueError(\n                    f\"Model for algorithm {self.algorithm} must be a `UNetModel`.\"\n                )\n\n            # n2n requires the number of input and output channels to be the same\n            if self.model.in_channels != self.model.num_classes:\n                raise ValueError(\n                    \"N2N requires the same number of input and output channels. Make \"\n                    \"sure that `in_channels` and `num_classes` are the same.\"\n                )\n\n        if self.algorithm == \"care\" or self.algorithm == \"n2n\":\n            if self.loss == \"n2v\":\n                raise ValueError(\"Supervised algorithms do not support loss `n2v`.\")\n\n        if isinstance(self.model, VAEModel):\n            raise ValueError(\"VAE are currently not implemented.\")\n\n        return self\n\n    def __str__(self) -&gt; str:\n        \"\"\"Pretty string representing the configuration.\n\n        Returns\n        -------\n        str\n            Pretty string.\n        \"\"\"\n        return pformat(self.model_dump())\n</code></pre>"},{"location":"reference/careamics/config/algorithm_model/#careamics.config.algorithm_model.AlgorithmConfig.__str__","title":"<code>__str__()</code>","text":"<p>Pretty string representing the configuration.</p> <p>Returns:</p> Type Description <code>str</code> <p>Pretty string.</p> Source code in <code>src/careamics/config/algorithm_model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Pretty string representing the configuration.\n\n    Returns\n    -------\n    str\n        Pretty string.\n    \"\"\"\n    return pformat(self.model_dump())\n</code></pre>"},{"location":"reference/careamics/config/algorithm_model/#careamics.config.algorithm_model.AlgorithmConfig.algorithm_cross_validation","title":"<code>algorithm_cross_validation()</code>","text":"<p>Validate the algorithm model based on <code>algorithm</code>.</p> <p>N2V: - loss must be n2v - model must be a <code>UNetModel</code></p> <p>Returns:</p> Type Description <code>Self</code> <p>The validated model.</p> Source code in <code>src/careamics/config/algorithm_model.py</code> <pre><code>@model_validator(mode=\"after\")\ndef algorithm_cross_validation(self: Self) -&gt; Self:\n    \"\"\"Validate the algorithm model based on `algorithm`.\n\n    N2V:\n    - loss must be n2v\n    - model must be a `UNetModel`\n\n    Returns\n    -------\n    Self\n        The validated model.\n    \"\"\"\n    # N2V\n    if self.algorithm == \"n2v\":\n        # n2v is only compatible with the n2v loss\n        if self.loss != \"n2v\":\n            raise ValueError(\n                f\"Algorithm {self.algorithm} only supports loss `n2v`.\"\n            )\n\n        # n2v is only compatible with the UNet model\n        if not isinstance(self.model, UNetModel):\n            raise ValueError(\n                f\"Model for algorithm {self.algorithm} must be a `UNetModel`.\"\n            )\n\n        # n2v requires the number of input and output channels to be the same\n        if self.model.in_channels != self.model.num_classes:\n            raise ValueError(\n                \"N2V requires the same number of input and output channels. Make \"\n                \"sure that `in_channels` and `num_classes` are the same.\"\n            )\n\n    # N2N\n    if self.algorithm == \"n2n\":\n        # n2n is only compatible with the UNet model\n        if not isinstance(self.model, UNetModel):\n            raise ValueError(\n                f\"Model for algorithm {self.algorithm} must be a `UNetModel`.\"\n            )\n\n        # n2n requires the number of input and output channels to be the same\n        if self.model.in_channels != self.model.num_classes:\n            raise ValueError(\n                \"N2N requires the same number of input and output channels. Make \"\n                \"sure that `in_channels` and `num_classes` are the same.\"\n            )\n\n    if self.algorithm == \"care\" or self.algorithm == \"n2n\":\n        if self.loss == \"n2v\":\n            raise ValueError(\"Supervised algorithms do not support loss `n2v`.\")\n\n    if isinstance(self.model, VAEModel):\n        raise ValueError(\"VAE are currently not implemented.\")\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/callback_model/","title":"callback_model","text":"<p>Callback Pydantic models.</p>"},{"location":"reference/careamics/config/callback_model/#careamics.config.callback_model.CheckpointModel","title":"<code>CheckpointModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Checkpoint saving callback Pydantic model.</p> Source code in <code>src/careamics/config/callback_model.py</code> <pre><code>class CheckpointModel(BaseModel):\n    \"\"\"Checkpoint saving callback Pydantic model.\"\"\"\n\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    monitor: Literal[\"val_loss\"] = Field(default=\"val_loss\", validate_default=True)\n    verbose: bool = Field(default=False, validate_default=True)\n    save_weights_only: bool = Field(default=False, validate_default=True)\n    mode: Literal[\"min\", \"max\"] = Field(default=\"min\", validate_default=True)\n    auto_insert_metric_name: bool = Field(default=False, validate_default=True)\n    every_n_train_steps: Optional[int] = Field(\n        default=None, ge=1, le=10, validate_default=True\n    )\n    train_time_interval: Optional[timedelta] = Field(\n        default=None, validate_default=True\n    )\n    every_n_epochs: Optional[int] = Field(\n        default=None, ge=1, le=10, validate_default=True\n    )\n    save_last: Optional[Literal[True, False, \"link\"]] = Field(\n        default=True, validate_default=True\n    )\n    save_top_k: int = Field(default=3, ge=1, le=10, validate_default=True)\n</code></pre>"},{"location":"reference/careamics/config/callback_model/#careamics.config.callback_model.EarlyStoppingModel","title":"<code>EarlyStoppingModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Early stopping callback Pydantic model.</p> Source code in <code>src/careamics/config/callback_model.py</code> <pre><code>class EarlyStoppingModel(BaseModel):\n    \"\"\"Early stopping callback Pydantic model.\"\"\"\n\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    monitor: Literal[\"val_loss\"] = Field(default=\"val_loss\", validate_default=True)\n    patience: int = Field(default=3, ge=1, le=10, validate_default=True)\n    mode: Literal[\"min\", \"max\", \"auto\"] = Field(default=\"min\", validate_default=True)\n    min_delta: float = Field(default=0.0, ge=0.0, le=1.0, validate_default=True)\n    check_finite: bool = Field(default=True, validate_default=True)\n    stop_on_nan: bool = Field(default=True, validate_default=True)\n    verbose: bool = Field(default=False, validate_default=True)\n    restore_best_weights: bool = Field(default=True, validate_default=True)\n    auto_lr_find: bool = Field(default=False, validate_default=True)\n    auto_lr_find_patience: int = Field(default=3, ge=1, le=10, validate_default=True)\n    auto_lr_find_mode: Literal[\"min\", \"max\", \"auto\"] = Field(\n        default=\"min\", validate_default=True\n    )\n    auto_lr_find_direction: Literal[\"forward\", \"backward\"] = Field(\n        default=\"backward\", validate_default=True\n    )\n    auto_lr_find_max_lr: float = Field(\n        default=10.0, ge=0.0, le=1e6, validate_default=True\n    )\n    auto_lr_find_min_lr: float = Field(\n        default=1e-8, ge=0.0, le=1e6, validate_default=True\n    )\n    auto_lr_find_num_training: int = Field(\n        default=100, ge=1, le=1e6, validate_default=True\n    )\n    auto_lr_find_divergence_threshold: float = Field(\n        default=5.0, ge=0.0, le=1e6, validate_default=True\n    )\n    auto_lr_find_accumulate_grad_batches: int = Field(\n        default=1, ge=1, le=1e6, validate_default=True\n    )\n    auto_lr_find_stop_divergence: bool = Field(default=True, validate_default=True)\n    auto_lr_find_step_scale: float = Field(default=0.1, ge=0.0, le=10)\n</code></pre>"},{"location":"reference/careamics/config/configuration_example/","title":"configuration_example","text":"<p>Example of configurations.</p>"},{"location":"reference/careamics/config/configuration_example/#careamics.config.configuration_example.full_configuration_example","title":"<code>full_configuration_example()</code>","text":"<p>Return a dictionnary representing a full configuration example.</p> <p>Returns:</p> Type Description <code>Configuration</code> <p>Full configuration example.</p> Source code in <code>src/careamics/config/configuration_example.py</code> <pre><code>def full_configuration_example() -&gt; Configuration:\n    \"\"\"Return a dictionnary representing a full configuration example.\n\n    Returns\n    -------\n    Configuration\n        Full configuration example.\n    \"\"\"\n    experiment_name = \"Full example\"\n    algorithm_model = AlgorithmConfig(\n        algorithm=SupportedAlgorithm.N2V.value,\n        loss=SupportedLoss.N2V.value,\n        model=UNetModel(\n            architecture=SupportedArchitecture.UNET.value,\n            in_channels=1,\n            num_classes=1,\n            depth=2,\n            num_channels_init=32,\n            final_activation=SupportedActivation.NONE.value,\n            n2v2=True,\n        ),\n        optimizer=OptimizerModel(\n            name=SupportedOptimizer.ADAM.value, parameters={\"lr\": 0.0001}\n        ),\n        lr_scheduler=LrSchedulerModel(\n            name=SupportedScheduler.REDUCE_LR_ON_PLATEAU.value,\n        ),\n    )\n    data_model = DataConfig(\n        data_type=SupportedData.ARRAY.value,\n        patch_size=(256, 256),\n        batch_size=8,\n        axes=\"YX\",\n        transforms=[\n            {\n                \"name\": SupportedTransform.NORMALIZE.value,\n            },\n            {\n                \"name\": SupportedTransform.XY_FLIP.value,\n            },\n            {\n                \"name\": SupportedTransform.XY_RANDOM_ROTATE90.value,\n            },\n            {\n                \"name\": SupportedTransform.N2V_MANIPULATE.value,\n                \"roi_size\": 11,\n                \"masked_pixel_percentage\": 0.2,\n                \"strategy\": SupportedPixelManipulation.MEDIAN.value,\n            },\n        ],\n        mean=0.485,\n        std=0.229,\n        dataloader_params={\n            \"num_workers\": 4,\n        },\n    )\n    training_model = TrainingConfig(\n        num_epochs=30,\n        logger=SupportedLogger.WANDB.value,\n    )\n\n    return Configuration(\n        experiment_name=experiment_name,\n        algorithm_config=algorithm_model,\n        data_config=data_model,\n        training_config=training_model,\n    )\n</code></pre>"},{"location":"reference/careamics/config/configuration_factory/","title":"configuration_factory","text":"<p>Convenience functions to create configurations for training and inference.</p>"},{"location":"reference/careamics/config/configuration_factory/#careamics.config.configuration_factory.create_care_configuration","title":"<code>create_care_configuration(experiment_name, data_type, axes, patch_size, batch_size, num_epochs, use_augmentations=True, independent_channels=False, loss='mae', n_channels_in=1, n_channels_out=-1, logger='none', model_kwargs=None)</code>","text":"<p>Create a configuration for training CARE.</p> <p>If \"Z\" is present in <code>axes</code>, then <code>path_size</code> must be a list of length 3, otherwise 2.</p> <p>If \"C\" is present in <code>axes</code>, then you need to set <code>n_channels_in</code> to the number of channels. Likewise, if you set the number of channels, then \"C\" must be present in <code>axes</code>.</p> <p>To set the number of output channels, use the <code>n_channels_out</code> parameter. If it is not specified, it will be assumed to be equal to <code>n_channels_in</code>.</p> <p>By default, all channels are trained together. To train all channels independently, set <code>independent_channels</code> to True.</p> <p>By setting <code>use_augmentations</code> to False, the only transformation applied will be normalization.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name</code> <code>str</code> <p>Name of the experiment.</p> required <code>data_type</code> <code>Literal['array', 'tiff', 'custom']</code> <p>Type of the data.</p> required <code>axes</code> <code>str</code> <p>Axes of the data (e.g. SYX).</p> required <code>patch_size</code> <code>List[int]</code> <p>Size of the patches along the spatial dimensions (e.g. [64, 64]).</p> required <code>batch_size</code> <code>int</code> <p>Batch size.</p> required <code>num_epochs</code> <code>int</code> <p>Number of epochs.</p> required <code>use_augmentations</code> <code>bool</code> <p>Whether to use augmentations, by default True.</p> <code>True</code> <code>independent_channels</code> <code>bool</code> <p>Whether to train all channels independently, by default False.</p> <code>False</code> <code>loss</code> <code>Literal['mae', 'mse']</code> <p>Loss function to use, by default \"mae\".</p> <code>'mae'</code> <code>n_channels_in</code> <code>int</code> <p>Number of channels in, by default 1.</p> <code>1</code> <code>n_channels_out</code> <code>int</code> <p>Number of channels out, by default -1.</p> <code>-1</code> <code>logger</code> <code>Literal['wandb', 'tensorboard', 'none']</code> <p>Logger to use, by default \"none\".</p> <code>'none'</code> <code>model_kwargs</code> <code>dict</code> <p>UNetModel parameters, by default {}.</p> <code>None</code> <p>Returns:</p> Type Description <code>Configuration</code> <p>Configuration for training CARE.</p> Source code in <code>src/careamics/config/configuration_factory.py</code> <pre><code>def create_care_configuration(\n    experiment_name: str,\n    data_type: Literal[\"array\", \"tiff\", \"custom\"],\n    axes: str,\n    patch_size: List[int],\n    batch_size: int,\n    num_epochs: int,\n    use_augmentations: bool = True,\n    independent_channels: bool = False,\n    loss: Literal[\"mae\", \"mse\"] = \"mae\",\n    n_channels_in: int = 1,\n    n_channels_out: int = -1,\n    logger: Literal[\"wandb\", \"tensorboard\", \"none\"] = \"none\",\n    model_kwargs: Optional[dict] = None,\n) -&gt; Configuration:\n    \"\"\"\n    Create a configuration for training CARE.\n\n    If \"Z\" is present in `axes`, then `path_size` must be a list of length 3, otherwise\n    2.\n\n    If \"C\" is present in `axes`, then you need to set `n_channels_in` to the number of\n    channels. Likewise, if you set the number of channels, then \"C\" must be present in\n    `axes`.\n\n    To set the number of output channels, use the `n_channels_out` parameter. If it is\n    not specified, it will be assumed to be equal to `n_channels_in`.\n\n    By default, all channels are trained together. To train all channels independently,\n    set `independent_channels` to True.\n\n    By setting `use_augmentations` to False, the only transformation applied will be\n    normalization.\n\n    Parameters\n    ----------\n    experiment_name : str\n        Name of the experiment.\n    data_type : Literal[\"array\", \"tiff\", \"custom\"]\n        Type of the data.\n    axes : str\n        Axes of the data (e.g. SYX).\n    patch_size : List[int]\n        Size of the patches along the spatial dimensions (e.g. [64, 64]).\n    batch_size : int\n        Batch size.\n    num_epochs : int\n        Number of epochs.\n    use_augmentations : bool, optional\n        Whether to use augmentations, by default True.\n    independent_channels : bool, optional\n        Whether to train all channels independently, by default False.\n    loss : Literal[\"mae\", \"mse\"], optional\n        Loss function to use, by default \"mae\".\n    n_channels_in : int, optional\n        Number of channels in, by default 1.\n    n_channels_out : int, optional\n        Number of channels out, by default -1.\n    logger : Literal[\"wandb\", \"tensorboard\", \"none\"], optional\n        Logger to use, by default \"none\".\n    model_kwargs : dict, optional\n        UNetModel parameters, by default {}.\n\n    Returns\n    -------\n    Configuration\n        Configuration for training CARE.\n    \"\"\"\n    if n_channels_out == -1:\n        n_channels_out = n_channels_in\n\n    return _create_supervised_configuration(\n        algorithm=\"care\",\n        experiment_name=experiment_name,\n        data_type=data_type,\n        axes=axes,\n        patch_size=patch_size,\n        batch_size=batch_size,\n        num_epochs=num_epochs,\n        use_augmentations=use_augmentations,\n        independent_channels=independent_channels,\n        loss=loss,\n        n_channels_in=n_channels_in,\n        n_channels_out=n_channels_out,\n        logger=logger,\n        model_kwargs=model_kwargs,\n    )\n</code></pre>"},{"location":"reference/careamics/config/configuration_factory/#careamics.config.configuration_factory.create_inference_configuration","title":"<code>create_inference_configuration(configuration, tile_size=None, tile_overlap=None, data_type=None, axes=None, tta_transforms=True, batch_size=1)</code>","text":"<p>Create a configuration for inference with N2V.</p> <p>If not provided, <code>data_type</code> and <code>axes</code> are taken from the training configuration.</p> <p>Parameters:</p> Name Type Description Default <code>configuration</code> <code>Configuration</code> <p>Global configuration.</p> required <code>tile_size</code> <code>Tuple[int, ...]</code> <p>Size of the tiles.</p> <code>None</code> <code>tile_overlap</code> <code>Tuple[int, ...]</code> <p>Overlap of the tiles.</p> <code>None</code> <code>data_type</code> <code>str</code> <p>Type of the data, by default \"tiff\".</p> <code>None</code> <code>axes</code> <code>str</code> <p>Axes of the data, by default \"YX\".</p> <code>None</code> <code>tta_transforms</code> <code>bool</code> <p>Whether to apply test-time augmentations, by default True.</p> <code>True</code> <code>batch_size</code> <code>int</code> <p>Batch size, by default 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>InferenceConfiguration</code> <p>Configuration used to configure CAREamicsPredictData.</p> Source code in <code>src/careamics/config/configuration_factory.py</code> <pre><code>def create_inference_configuration(\n    configuration: Configuration,\n    tile_size: Optional[Tuple[int, ...]] = None,\n    tile_overlap: Optional[Tuple[int, ...]] = None,\n    data_type: Optional[Literal[\"array\", \"tiff\", \"custom\"]] = None,\n    axes: Optional[str] = None,\n    tta_transforms: bool = True,\n    batch_size: Optional[int] = 1,\n) -&gt; InferenceConfig:\n    \"\"\"\n    Create a configuration for inference with N2V.\n\n    If not provided, `data_type` and `axes` are taken from the training\n    configuration.\n\n    Parameters\n    ----------\n    configuration : Configuration\n        Global configuration.\n    tile_size : Tuple[int, ...], optional\n        Size of the tiles.\n    tile_overlap : Tuple[int, ...], optional\n        Overlap of the tiles.\n    data_type : str, optional\n        Type of the data, by default \"tiff\".\n    axes : str, optional\n        Axes of the data, by default \"YX\".\n    tta_transforms : bool, optional\n        Whether to apply test-time augmentations, by default True.\n    batch_size : int, optional\n        Batch size, by default 1.\n\n    Returns\n    -------\n    InferenceConfiguration\n        Configuration used to configure CAREamicsPredictData.\n    \"\"\"\n    if configuration.data_config.mean is None or configuration.data_config.std is None:\n        raise ValueError(\"Mean and std must be provided in the configuration.\")\n\n    # tile size for UNets\n    if tile_size is not None:\n        model = configuration.algorithm_config.model\n\n        if model.architecture == SupportedArchitecture.UNET.value:\n            # tile size must be equal to k*2^n, where n is the number of pooling layers\n            # (equal to the depth) and k is an integer\n            depth = model.depth\n            tile_increment = 2**depth\n\n            for i, t in enumerate(tile_size):\n                if t % tile_increment != 0:\n                    raise ValueError(\n                        f\"Tile size must be divisible by {tile_increment} along all \"\n                        f\"axes (got {t} for axis {i}). If your image size is smaller \"\n                        f\"along one axis (e.g. Z), consider padding the image.\"\n                    )\n\n        # tile overlaps must be specified\n        if tile_overlap is None:\n            raise ValueError(\"Tile overlap must be specified.\")\n\n    return InferenceConfig(\n        data_type=data_type or configuration.data_config.data_type,\n        tile_size=tile_size,\n        tile_overlap=tile_overlap,\n        axes=axes or configuration.data_config.axes,\n        mean=configuration.data_config.mean,\n        std=configuration.data_config.std,\n        tta_transforms=tta_transforms,\n        batch_size=batch_size,\n    )\n</code></pre>"},{"location":"reference/careamics/config/configuration_factory/#careamics.config.configuration_factory.create_n2n_configuration","title":"<code>create_n2n_configuration(experiment_name, data_type, axes, patch_size, batch_size, num_epochs, use_augmentations=True, independent_channels=False, loss='mae', n_channels=1, logger='none', model_kwargs=None)</code>","text":"<p>Create a configuration for training Noise2Noise.</p> <p>If \"Z\" is present in <code>axes</code>, then <code>path_size</code> must be a list of length 3, otherwise 2.</p> <p>If \"C\" is present in <code>axes</code>, then you need to set <code>n_channels</code> to the number of channels. Likewise, if you set the number of channels, then \"C\" must be present in <code>axes</code>.</p> <p>By default, all channels are trained together. To train all channels independently, set <code>independent_channels</code> to True.</p> <p>By setting <code>use_augmentations</code> to False, the only transformation applied will be normalization.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name</code> <code>str</code> <p>Name of the experiment.</p> required <code>data_type</code> <code>Literal['array', 'tiff', 'custom']</code> <p>Type of the data.</p> required <code>axes</code> <code>str</code> <p>Axes of the data (e.g. SYX).</p> required <code>patch_size</code> <code>List[int]</code> <p>Size of the patches along the spatial dimensions (e.g. [64, 64]).</p> required <code>batch_size</code> <code>int</code> <p>Batch size.</p> required <code>num_epochs</code> <code>int</code> <p>Number of epochs.</p> required <code>use_augmentations</code> <code>bool</code> <p>Whether to use augmentations, by default True.</p> <code>True</code> <code>independent_channels</code> <code>bool</code> <p>Whether to train all channels independently, by default False.</p> <code>False</code> <code>loss</code> <code>Literal['mae', 'mse']</code> <p>Loss function to use, by default \"mae\".</p> <code>'mae'</code> <code>n_channels</code> <code>int</code> <p>Number of channels (in and out), by default 1.</p> <code>1</code> <code>logger</code> <code>Literal['wandb', 'tensorboard', 'none']</code> <p>Logger to use, by default \"none\".</p> <code>'none'</code> <code>model_kwargs</code> <code>dict</code> <p>UNetModel parameters, by default {}.</p> <code>None</code> <p>Returns:</p> Type Description <code>Configuration</code> <p>Configuration for training Noise2Noise.</p> Source code in <code>src/careamics/config/configuration_factory.py</code> <pre><code>def create_n2n_configuration(\n    experiment_name: str,\n    data_type: Literal[\"array\", \"tiff\", \"custom\"],\n    axes: str,\n    patch_size: List[int],\n    batch_size: int,\n    num_epochs: int,\n    use_augmentations: bool = True,\n    independent_channels: bool = False,\n    loss: Literal[\"mae\", \"mse\"] = \"mae\",\n    n_channels: int = 1,\n    logger: Literal[\"wandb\", \"tensorboard\", \"none\"] = \"none\",\n    model_kwargs: Optional[dict] = None,\n) -&gt; Configuration:\n    \"\"\"\n    Create a configuration for training Noise2Noise.\n\n    If \"Z\" is present in `axes`, then `path_size` must be a list of length 3, otherwise\n    2.\n\n    If \"C\" is present in `axes`, then you need to set `n_channels` to the number of\n    channels. Likewise, if you set the number of channels, then \"C\" must be present in\n    `axes`.\n\n    By default, all channels are trained together. To train all channels independently,\n    set `independent_channels` to True.\n\n    By setting `use_augmentations` to False, the only transformation applied will be\n    normalization.\n\n    Parameters\n    ----------\n    experiment_name : str\n        Name of the experiment.\n    data_type : Literal[\"array\", \"tiff\", \"custom\"]\n        Type of the data.\n    axes : str\n        Axes of the data (e.g. SYX).\n    patch_size : List[int]\n        Size of the patches along the spatial dimensions (e.g. [64, 64]).\n    batch_size : int\n        Batch size.\n    num_epochs : int\n        Number of epochs.\n    use_augmentations : bool, optional\n        Whether to use augmentations, by default True.\n    independent_channels : bool, optional\n        Whether to train all channels independently, by default False.\n    loss : Literal[\"mae\", \"mse\"], optional\n        Loss function to use, by default \"mae\".\n    n_channels : int, optional\n        Number of channels (in and out), by default 1.\n    logger : Literal[\"wandb\", \"tensorboard\", \"none\"], optional\n        Logger to use, by default \"none\".\n    model_kwargs : dict, optional\n        UNetModel parameters, by default {}.\n\n    Returns\n    -------\n    Configuration\n        Configuration for training Noise2Noise.\n    \"\"\"\n    return _create_supervised_configuration(\n        algorithm=\"n2n\",\n        experiment_name=experiment_name,\n        data_type=data_type,\n        axes=axes,\n        patch_size=patch_size,\n        batch_size=batch_size,\n        num_epochs=num_epochs,\n        use_augmentations=use_augmentations,\n        independent_channels=independent_channels,\n        loss=loss,\n        n_channels_in=n_channels,\n        n_channels_out=n_channels,\n        logger=logger,\n        model_kwargs=model_kwargs,\n    )\n</code></pre>"},{"location":"reference/careamics/config/configuration_factory/#careamics.config.configuration_factory.create_n2v_configuration","title":"<code>create_n2v_configuration(experiment_name, data_type, axes, patch_size, batch_size, num_epochs, use_augmentations=True, independent_channels=True, use_n2v2=False, n_channels=1, roi_size=11, masked_pixel_percentage=0.2, struct_n2v_axis='none', struct_n2v_span=5, logger='none', model_kwargs=None)</code>","text":"<p>Create a configuration for training Noise2Void.</p> <p>N2V uses a UNet model to denoise images in a self-supervised manner. To use its variants structN2V and N2V2, set the <code>struct_n2v_axis</code> and <code>struct_n2v_span</code> (structN2V) parameters, or set <code>use_n2v2</code> to True (N2V2).</p> <p>N2V2 modifies the UNet architecture by adding blur pool layers and removes the skip connections, thus removing checkboard artefacts. StructN2V is used when vertical or horizontal correlations are present in the noise; it applies an additional mask to the manipulated pixel neighbors.</p> <p>If \"Z\" is present in <code>axes</code>, then <code>path_size</code> must be a list of length 3, otherwise 2.</p> <p>If \"C\" is present in <code>axes</code>, then you need to set <code>n_channels</code> to the number of channels.</p> <p>By default, all channels are trained independently. To train all channels together, set <code>independent_channels</code> to False.</p> <p>By setting <code>use_augmentations</code> to False, the only transformations applied will be normalization and N2V manipulation.</p> <p>The <code>roi_size</code> parameter specifies the size of the area around each pixel that will be manipulated by N2V. The <code>masked_pixel_percentage</code> parameter specifies how many pixels per patch will be manipulated.</p> <p>The parameters of the UNet can be specified in the <code>model_kwargs</code> (passed as a parameter-value dictionary). Note that <code>use_n2v2</code> and 'n_channels' override the corresponding parameters passed in <code>model_kwargs</code>.</p> <p>If you pass \"horizontal\" or \"vertical\" to <code>struct_n2v_axis</code>, then structN2V mask will be applied to each manipulated pixel.</p> <p>Parameters:</p> Name Type Description Default <code>experiment_name</code> <code>str</code> <p>Name of the experiment.</p> required <code>data_type</code> <code>Literal['array', 'tiff', 'custom']</code> <p>Type of the data.</p> required <code>axes</code> <code>str</code> <p>Axes of the data (e.g. SYX).</p> required <code>patch_size</code> <code>List[int]</code> <p>Size of the patches along the spatial dimensions (e.g. [64, 64]).</p> required <code>batch_size</code> <code>int</code> <p>Batch size.</p> required <code>num_epochs</code> <code>int</code> <p>Number of epochs.</p> required <code>use_augmentations</code> <code>bool</code> <p>Whether to use augmentations, by default True.</p> <code>True</code> <code>independent_channels</code> <code>bool</code> <p>Whether to train all channels together, by default True.</p> <code>True</code> <code>use_n2v2</code> <code>bool</code> <p>Whether to use N2V2, by default False.</p> <code>False</code> <code>n_channels</code> <code>int</code> <p>Number of channels (in and out), by default 1.</p> <code>1</code> <code>roi_size</code> <code>int</code> <p>N2V pixel manipulation area, by default 11.</p> <code>11</code> <code>masked_pixel_percentage</code> <code>float</code> <p>Percentage of pixels masked in each patch, by default 0.2.</p> <code>0.2</code> <code>struct_n2v_axis</code> <code>Literal['horizontal', 'vertical', 'none']</code> <p>Axis along which to apply structN2V mask, by default \"none\".</p> <code>'none'</code> <code>struct_n2v_span</code> <code>int</code> <p>Span of the structN2V mask, by default 5.</p> <code>5</code> <code>logger</code> <code>Literal['wandb', 'tensorboard', 'none']</code> <p>Logger to use, by default \"none\".</p> <code>'none'</code> <code>model_kwargs</code> <code>dict</code> <p>UNetModel parameters, by default {}.</p> <code>None</code> <p>Returns:</p> Type Description <code>Configuration</code> <p>Configuration for training N2V.</p> <p>Examples:</p> <p>Minimum example:</p> <pre><code>&gt;&gt;&gt; config = create_n2v_configuration(\n...     experiment_name=\"n2v_experiment\",\n...     data_type=\"array\",\n...     axes=\"YX\",\n...     patch_size=[64, 64],\n...     batch_size=32,\n...     num_epochs=100\n... )\n</code></pre> <p>To use N2V2, simply pass the <code>use_n2v2</code> parameter:</p> <pre><code>&gt;&gt;&gt; config = create_n2v_configuration(\n...     experiment_name=\"n2v2_experiment\",\n...     data_type=\"tiff\",\n...     axes=\"YX\",\n...     patch_size=[64, 64],\n...     batch_size=32,\n...     num_epochs=100,\n...     use_n2v2=True\n... )\n</code></pre> <p>For structN2V, there are two parameters to set, <code>struct_n2v_axis</code> and <code>struct_n2v_span</code>:</p> <pre><code>&gt;&gt;&gt; config = create_n2v_configuration(\n...     experiment_name=\"structn2v_experiment\",\n...     data_type=\"tiff\",\n...     axes=\"YX\",\n...     patch_size=[64, 64],\n...     batch_size=32,\n...     num_epochs=100,\n...     struct_n2v_axis=\"horizontal\",\n...     struct_n2v_span=7\n... )\n</code></pre> <p>If you are training multiple channels independently, then you need to specify the number of channels:</p> <pre><code>&gt;&gt;&gt; config = create_n2v_configuration(\n...     experiment_name=\"n2v_experiment\",\n...     data_type=\"array\",\n...     axes=\"YXC\",\n...     patch_size=[64, 64],\n...     batch_size=32,\n...     num_epochs=100,\n...     n_channels=3\n... )\n</code></pre> <p>If instead you want to train multiple channels together, you need to turn off the <code>independent_channels</code> parameter:</p> <pre><code>&gt;&gt;&gt; config = create_n2v_configuration(\n...     experiment_name=\"n2v_experiment\",\n...     data_type=\"array\",\n...     axes=\"YXC\",\n...     patch_size=[64, 64],\n...     batch_size=32,\n...     num_epochs=100,\n...     independent_channels=False,\n...     n_channels=3\n... )\n</code></pre> <p>To turn off the augmentations, except normalization and N2V manipulation, use the relevant keyword argument:</p> <pre><code>&gt;&gt;&gt; config = create_n2v_configuration(\n...     experiment_name=\"n2v_experiment\",\n...     data_type=\"array\",\n...     axes=\"YX\",\n...     patch_size=[64, 64],\n...     batch_size=32,\n...     num_epochs=100,\n...     use_augmentations=False\n... )\n</code></pre> Source code in <code>src/careamics/config/configuration_factory.py</code> <pre><code>def create_n2v_configuration(\n    experiment_name: str,\n    data_type: Literal[\"array\", \"tiff\", \"custom\"],\n    axes: str,\n    patch_size: List[int],\n    batch_size: int,\n    num_epochs: int,\n    use_augmentations: bool = True,\n    independent_channels: bool = True,\n    use_n2v2: bool = False,\n    n_channels: int = 1,\n    roi_size: int = 11,\n    masked_pixel_percentage: float = 0.2,\n    struct_n2v_axis: Literal[\"horizontal\", \"vertical\", \"none\"] = \"none\",\n    struct_n2v_span: int = 5,\n    logger: Literal[\"wandb\", \"tensorboard\", \"none\"] = \"none\",\n    model_kwargs: Optional[dict] = None,\n) -&gt; Configuration:\n    \"\"\"\n    Create a configuration for training Noise2Void.\n\n    N2V uses a UNet model to denoise images in a self-supervised manner. To use its\n    variants structN2V and N2V2, set the `struct_n2v_axis` and `struct_n2v_span`\n    (structN2V) parameters, or set `use_n2v2` to True (N2V2).\n\n    N2V2 modifies the UNet architecture by adding blur pool layers and removes the skip\n    connections, thus removing checkboard artefacts. StructN2V is used when vertical\n    or horizontal correlations are present in the noise; it applies an additional mask\n    to the manipulated pixel neighbors.\n\n    If \"Z\" is present in `axes`, then `path_size` must be a list of length 3, otherwise\n    2.\n\n    If \"C\" is present in `axes`, then you need to set `n_channels` to the number of\n    channels.\n\n    By default, all channels are trained independently. To train all channels together,\n    set `independent_channels` to False.\n\n    By setting `use_augmentations` to False, the only transformations applied will be\n    normalization and N2V manipulation.\n\n    The `roi_size` parameter specifies the size of the area around each pixel that will\n    be manipulated by N2V. The `masked_pixel_percentage` parameter specifies how many\n    pixels per patch will be manipulated.\n\n    The parameters of the UNet can be specified in the `model_kwargs` (passed as a\n    parameter-value dictionary). Note that `use_n2v2` and 'n_channels' override the\n    corresponding parameters passed in `model_kwargs`.\n\n    If you pass \"horizontal\" or \"vertical\" to `struct_n2v_axis`, then structN2V mask\n    will be applied to each manipulated pixel.\n\n    Parameters\n    ----------\n    experiment_name : str\n        Name of the experiment.\n    data_type : Literal[\"array\", \"tiff\", \"custom\"]\n        Type of the data.\n    axes : str\n        Axes of the data (e.g. SYX).\n    patch_size : List[int]\n        Size of the patches along the spatial dimensions (e.g. [64, 64]).\n    batch_size : int\n        Batch size.\n    num_epochs : int\n        Number of epochs.\n    use_augmentations : bool, optional\n        Whether to use augmentations, by default True.\n    independent_channels : bool, optional\n        Whether to train all channels together, by default True.\n    use_n2v2 : bool, optional\n        Whether to use N2V2, by default False.\n    n_channels : int, optional\n        Number of channels (in and out), by default 1.\n    roi_size : int, optional\n        N2V pixel manipulation area, by default 11.\n    masked_pixel_percentage : float, optional\n        Percentage of pixels masked in each patch, by default 0.2.\n    struct_n2v_axis : Literal[\"horizontal\", \"vertical\", \"none\"], optional\n        Axis along which to apply structN2V mask, by default \"none\".\n    struct_n2v_span : int, optional\n        Span of the structN2V mask, by default 5.\n    logger : Literal[\"wandb\", \"tensorboard\", \"none\"], optional\n        Logger to use, by default \"none\".\n    model_kwargs : dict, optional\n        UNetModel parameters, by default {}.\n\n    Returns\n    -------\n    Configuration\n        Configuration for training N2V.\n\n    Examples\n    --------\n    Minimum example:\n    &gt;&gt;&gt; config = create_n2v_configuration(\n    ...     experiment_name=\"n2v_experiment\",\n    ...     data_type=\"array\",\n    ...     axes=\"YX\",\n    ...     patch_size=[64, 64],\n    ...     batch_size=32,\n    ...     num_epochs=100\n    ... )\n\n    To use N2V2, simply pass the `use_n2v2` parameter:\n    &gt;&gt;&gt; config = create_n2v_configuration(\n    ...     experiment_name=\"n2v2_experiment\",\n    ...     data_type=\"tiff\",\n    ...     axes=\"YX\",\n    ...     patch_size=[64, 64],\n    ...     batch_size=32,\n    ...     num_epochs=100,\n    ...     use_n2v2=True\n    ... )\n\n    For structN2V, there are two parameters to set, `struct_n2v_axis` and\n    `struct_n2v_span`:\n    &gt;&gt;&gt; config = create_n2v_configuration(\n    ...     experiment_name=\"structn2v_experiment\",\n    ...     data_type=\"tiff\",\n    ...     axes=\"YX\",\n    ...     patch_size=[64, 64],\n    ...     batch_size=32,\n    ...     num_epochs=100,\n    ...     struct_n2v_axis=\"horizontal\",\n    ...     struct_n2v_span=7\n    ... )\n\n    If you are training multiple channels independently, then you need to specify the\n    number of channels:\n    &gt;&gt;&gt; config = create_n2v_configuration(\n    ...     experiment_name=\"n2v_experiment\",\n    ...     data_type=\"array\",\n    ...     axes=\"YXC\",\n    ...     patch_size=[64, 64],\n    ...     batch_size=32,\n    ...     num_epochs=100,\n    ...     n_channels=3\n    ... )\n\n    If instead you want to train multiple channels together, you need to turn off the\n    `independent_channels` parameter:\n    &gt;&gt;&gt; config = create_n2v_configuration(\n    ...     experiment_name=\"n2v_experiment\",\n    ...     data_type=\"array\",\n    ...     axes=\"YXC\",\n    ...     patch_size=[64, 64],\n    ...     batch_size=32,\n    ...     num_epochs=100,\n    ...     independent_channels=False,\n    ...     n_channels=3\n    ... )\n\n    To turn off the augmentations, except normalization and N2V manipulation, use the\n    relevant keyword argument:\n    &gt;&gt;&gt; config = create_n2v_configuration(\n    ...     experiment_name=\"n2v_experiment\",\n    ...     data_type=\"array\",\n    ...     axes=\"YX\",\n    ...     patch_size=[64, 64],\n    ...     batch_size=32,\n    ...     num_epochs=100,\n    ...     use_augmentations=False\n    ... )\n    \"\"\"\n    # if there are channels, we need to specify their number\n    if \"C\" in axes and n_channels == 1:\n        raise ValueError(\n            f\"Number of channels must be specified when using channels \"\n            f\"(got {n_channels} channel).\"\n        )\n    elif \"C\" not in axes and n_channels &gt; 1:\n        raise ValueError(\n            f\"C is not present in the axes, but number of channels is specified \"\n            f\"(got {n_channels} channel).\"\n        )\n\n    # model\n    if model_kwargs is None:\n        model_kwargs = {}\n    model_kwargs[\"n2v2\"] = use_n2v2\n    model_kwargs[\"conv_dims\"] = 3 if \"Z\" in axes else 2\n    model_kwargs[\"in_channels\"] = n_channels\n    model_kwargs[\"num_classes\"] = n_channels\n    model_kwargs[\"independent_channels\"] = independent_channels\n\n    unet_model = UNetModel(\n        architecture=SupportedArchitecture.UNET.value,\n        **model_kwargs,\n    )\n\n    # algorithm model\n    algorithm = AlgorithmConfig(\n        algorithm=SupportedAlgorithm.N2V.value,\n        loss=SupportedLoss.N2V.value,\n        model=unet_model,\n    )\n\n    # augmentations\n    if use_augmentations:\n        transforms: List[Dict[str, Any]] = [\n            {\n                \"name\": SupportedTransform.NORMALIZE.value,\n            },\n            {\n                \"name\": SupportedTransform.XY_FLIP.value,\n            },\n            {\n                \"name\": SupportedTransform.XY_RANDOM_ROTATE90.value,\n            },\n        ]\n    else:\n        transforms = [\n            {\n                \"name\": SupportedTransform.NORMALIZE.value,\n            },\n        ]\n\n    # n2v2 and structn2v\n    nv2_transform = {\n        \"name\": SupportedTransform.N2V_MANIPULATE.value,\n        \"strategy\": (\n            SupportedPixelManipulation.MEDIAN.value\n            if use_n2v2\n            else SupportedPixelManipulation.UNIFORM.value\n        ),\n        \"roi_size\": roi_size,\n        \"masked_pixel_percentage\": masked_pixel_percentage,\n        \"struct_mask_axis\": struct_n2v_axis,\n        \"struct_mask_span\": struct_n2v_span,\n    }\n    transforms.append(nv2_transform)\n\n    # data model\n    data = DataConfig(\n        data_type=data_type,\n        axes=axes,\n        patch_size=patch_size,\n        batch_size=batch_size,\n        transforms=transforms,\n    )\n\n    # training model\n    training = TrainingConfig(\n        num_epochs=num_epochs,\n        batch_size=batch_size,\n        logger=None if logger == \"none\" else logger,\n    )\n\n    # create configuration\n    configuration = Configuration(\n        experiment_name=experiment_name,\n        algorithm_config=algorithm,\n        data_config=data,\n        training_config=training,\n    )\n\n    return configuration\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/","title":"configuration_model","text":"<p>Pydantic CAREamics configuration.</p>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration","title":"<code>Configuration</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>CAREamics configuration.</p> <p>The configuration defines all parameters used to build and train a CAREamics model. These parameters are validated to ensure that they are compatible with each other.</p> <p>It contains three sub-configurations:</p> <ul> <li>AlgorithmModel: configuration for the algorithm training, which includes the     architecture, loss function, optimizer, and other hyperparameters.</li> <li>DataModel: configuration for the dataloader, which includes the type of data,     transformations, mean/std and other parameters.</li> <li>TrainingModel: configuration for the training, which includes the number of     epochs or the callbacks.</li> </ul> <p>Attributes:</p> Name Type Description <code>experiment_name</code> <code>str</code> <p>Name of the experiment, used when saving logs and checkpoints.</p> <code>algorithm</code> <code>AlgorithmModel</code> <p>Algorithm configuration.</p> <code>data</code> <code>DataModel</code> <p>Data configuration.</p> <code>training</code> <code>TrainingModel</code> <p>Training configuration.</p> <p>Methods:</p> Name Description <code>set_3D</code> <p>Switch configuration between 2D and 3D.</p> <code>set_N2V2</code> <p>Switch N2V algorithm between N2V and N2V2.</p> <code>set_structN2V</code> <p>mask_axis: Literal[\"horizontal\", \"vertical\", \"none\"], mask_span: int) -&gt; None Set StructN2V parameters.</p> <code>model_dump</code> <p>exclude_defaults: bool = False, exclude_none: bool = True, **kwargs: Dict ) -&gt; Dict Export configuration to a dictionary.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Configuration parameter type validation errors.</p> <code>ValueError</code> <p>If the experiment name contains invalid characters or is empty.</p> <code>ValueError</code> <p>If the algorithm is 3D but there is not \"Z\" in the data axes, or 2D algorithm with \"Z\" in data axes.</p> <code>ValueError</code> <p>Algorithm, data or training validation errors.</p> Notes <p>We provide convenience methods to create standards configurations, for instance for N2V, in the <code>careamics.config.configuration_factory</code> module.</p> <p>from careamics.config.configuration_factory import create_n2v_configuration config = create_n2v_configuration( ...     experiment_name=\"n2v_experiment\", ...     data_type=\"array\", ...     axes=\"YX\", ...     patch_size=[64, 64], ...     batch_size=32, ...     num_epochs=100 ... )</p> <p>The configuration can be exported to a dictionary using the model_dump method:</p> <p>config_dict = config.model_dump()</p> <p>Configurations can also be exported or imported from yaml files:</p> <p>from careamics.config import save_configuration, load_configuration path_to_config = save_configuration(config, my_path / \"config.yml\") other_config = load_configuration(path_to_config)</p> <p>Examples:</p> <p>Minimum example:</p> <pre><code>&gt;&gt;&gt; from careamics.config import Configuration\n&gt;&gt;&gt; config_dict = {\n...         \"experiment_name\": \"N2V_experiment\",\n...         \"algorithm_config\": {\n...             \"algorithm\": \"n2v\",\n...             \"loss\": \"n2v\",\n...             \"model\": {\n...                 \"architecture\": \"UNet\",\n...             },\n...         },\n...         \"training_config\": {\n...             \"num_epochs\": 200,\n...         },\n...         \"data_config\": {\n...             \"data_type\": \"tiff\",\n...             \"patch_size\": [64, 64],\n...             \"axes\": \"SYX\",\n...         },\n...     }\n&gt;&gt;&gt; config = Configuration(**config_dict)\n</code></pre> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>class Configuration(BaseModel):\n    \"\"\"\n    CAREamics configuration.\n\n    The configuration defines all parameters used to build and train a CAREamics model.\n    These parameters are validated to ensure that they are compatible with each other.\n\n    It contains three sub-configurations:\n\n    - AlgorithmModel: configuration for the algorithm training, which includes the\n        architecture, loss function, optimizer, and other hyperparameters.\n    - DataModel: configuration for the dataloader, which includes the type of data,\n        transformations, mean/std and other parameters.\n    - TrainingModel: configuration for the training, which includes the number of\n        epochs or the callbacks.\n\n    Attributes\n    ----------\n    experiment_name : str\n        Name of the experiment, used when saving logs and checkpoints.\n    algorithm : AlgorithmModel\n        Algorithm configuration.\n    data : DataModel\n        Data configuration.\n    training : TrainingModel\n        Training configuration.\n\n    Methods\n    -------\n    set_3D(is_3D: bool, axes: str, patch_size: List[int]) -&gt; None\n        Switch configuration between 2D and 3D.\n    set_N2V2(use_n2v2: bool) -&gt; None\n        Switch N2V algorithm between N2V and N2V2.\n    set_structN2V(\n        mask_axis: Literal[\"horizontal\", \"vertical\", \"none\"], mask_span: int) -&gt; None\n        Set StructN2V parameters.\n    model_dump(\n        exclude_defaults: bool = False, exclude_none: bool = True, **kwargs: Dict\n        ) -&gt; Dict\n        Export configuration to a dictionary.\n\n    Raises\n    ------\n    ValueError\n        Configuration parameter type validation errors.\n    ValueError\n        If the experiment name contains invalid characters or is empty.\n    ValueError\n        If the algorithm is 3D but there is not \"Z\" in the data axes, or 2D algorithm\n        with \"Z\" in data axes.\n    ValueError\n        Algorithm, data or training validation errors.\n\n    Notes\n    -----\n    We provide convenience methods to create standards configurations, for instance\n    for N2V, in the `careamics.config.configuration_factory` module.\n    &gt;&gt;&gt; from careamics.config.configuration_factory import create_n2v_configuration\n    &gt;&gt;&gt; config = create_n2v_configuration(\n    ...     experiment_name=\"n2v_experiment\",\n    ...     data_type=\"array\",\n    ...     axes=\"YX\",\n    ...     patch_size=[64, 64],\n    ...     batch_size=32,\n    ...     num_epochs=100\n    ... )\n\n    The configuration can be exported to a dictionary using the model_dump method:\n    &gt;&gt;&gt; config_dict = config.model_dump()\n\n    Configurations can also be exported or imported from yaml files:\n    &gt;&gt;&gt; from careamics.config import save_configuration, load_configuration\n    &gt;&gt;&gt; path_to_config = save_configuration(config, my_path / \"config.yml\")\n    &gt;&gt;&gt; other_config = load_configuration(path_to_config)\n\n    Examples\n    --------\n    Minimum example:\n    &gt;&gt;&gt; from careamics.config import Configuration\n    &gt;&gt;&gt; config_dict = {\n    ...         \"experiment_name\": \"N2V_experiment\",\n    ...         \"algorithm_config\": {\n    ...             \"algorithm\": \"n2v\",\n    ...             \"loss\": \"n2v\",\n    ...             \"model\": {\n    ...                 \"architecture\": \"UNet\",\n    ...             },\n    ...         },\n    ...         \"training_config\": {\n    ...             \"num_epochs\": 200,\n    ...         },\n    ...         \"data_config\": {\n    ...             \"data_type\": \"tiff\",\n    ...             \"patch_size\": [64, 64],\n    ...             \"axes\": \"SYX\",\n    ...         },\n    ...     }\n    &gt;&gt;&gt; config = Configuration(**config_dict)\n    \"\"\"\n\n    model_config = ConfigDict(\n        validate_assignment=True,\n        set_arbitrary_types_allowed=True,\n    )\n\n    # version\n    version: Literal[\"0.1.0\"] = Field(\n        default=\"0.1.0\", description=\"Version of the CAREamics configuration.\"\n    )\n\n    # required parameters\n    experiment_name: str = Field(\n        ..., description=\"Name of the experiment, used to name logs and checkpoints.\"\n    )\n\n    # Sub-configurations\n    algorithm_config: AlgorithmConfig\n\n    data_config: DataConfig\n    training_config: TrainingConfig\n\n    @field_validator(\"experiment_name\")\n    @classmethod\n    def no_symbol(cls, name: str) -&gt; str:\n        \"\"\"\n        Validate experiment name.\n\n        A valid experiment name is a non-empty string with only contains letters,\n        numbers, underscores, dashes and spaces.\n\n        Parameters\n        ----------\n        name : str\n            Name to validate.\n\n        Returns\n        -------\n        str\n            Validated name.\n\n        Raises\n        ------\n        ValueError\n            If the name is empty or contains invalid characters.\n        \"\"\"\n        if len(name) == 0 or name.isspace():\n            raise ValueError(\"Experiment name is empty.\")\n\n        # Validate using a regex that it contains only letters, numbers, underscores,\n        # dashes and spaces\n        if not re.match(r\"^[a-zA-Z0-9_\\- ]*$\", name):\n            raise ValueError(\n                f\"Experiment name contains invalid characters (got {name}). \"\n                f\"Only letters, numbers, underscores, dashes and spaces are allowed.\"\n            )\n\n        return name\n\n    @model_validator(mode=\"after\")\n    def validate_3D(self: Self) -&gt; Self:\n        \"\"\"\n        Change algorithm dimensions to match data.axes.\n\n        Only for non-custom algorithms.\n\n        Returns\n        -------\n        Self\n            Validated configuration.\n        \"\"\"\n        if self.algorithm_config.algorithm != SupportedAlgorithm.CUSTOM:\n            if \"Z\" in self.data_config.axes and not self.algorithm_config.model.is_3D():\n                # change algorithm to 3D\n                self.algorithm_config.model.set_3D(True)\n            elif (\n                \"Z\" not in self.data_config.axes and self.algorithm_config.model.is_3D()\n            ):\n                # change algorithm to 2D\n                self.algorithm_config.model.set_3D(False)\n\n        return self\n\n    @model_validator(mode=\"after\")\n    def validate_algorithm_and_data(self: Self) -&gt; Self:\n        \"\"\"\n        Validate algorithm and data compatibility.\n\n        In particular, the validation does the following:\n\n        - If N2V is used, it enforces the presence of N2V_Maniuplate in the transforms\n        - If N2V2 is used, it enforces the correct manipulation strategy\n\n        Returns\n        -------\n        Self\n            Validated configuration.\n        \"\"\"\n        if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n            # missing N2V_MANIPULATE\n            if not self.data_config.has_n2v_manipulate():\n                self.data_config.transforms.append(\n                    N2VManipulateModel(\n                        name=SupportedTransform.N2V_MANIPULATE.value,\n                    )\n                )\n\n            median = SupportedPixelManipulation.MEDIAN.value\n            uniform = SupportedPixelManipulation.UNIFORM.value\n            strategy = median if self.algorithm_config.model.n2v2 else uniform\n            self.data_config.set_N2V2_strategy(strategy)\n        else:\n            # remove N2V manipulate if present\n            if self.data_config.has_n2v_manipulate():\n                self.data_config.remove_n2v_manipulate()\n\n        return self\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Pretty string reprensenting the configuration.\n\n        Returns\n        -------\n        str\n            Pretty string.\n        \"\"\"\n        return pformat(self.model_dump())\n\n    def set_3D(self, is_3D: bool, axes: str, patch_size: List[int]) -&gt; None:\n        \"\"\"\n        Set 3D flag and axes.\n\n        Parameters\n        ----------\n        is_3D : bool\n            Whether the algorithm is 3D or not.\n        axes : str\n            Axes of the data.\n        patch_size : List[int]\n            Patch size.\n        \"\"\"\n        # set the flag and axes (this will not trigger validation at the config level)\n        self.algorithm_config.model.set_3D(is_3D)\n        self.data_config.set_3D(axes, patch_size)\n\n        # cheap hack: trigger validation\n        self.algorithm_config = self.algorithm_config\n\n    def set_N2V2(self, use_n2v2: bool) -&gt; None:\n        \"\"\"\n        Switch N2V algorithm between N2V and N2V2.\n\n        Parameters\n        ----------\n        use_n2v2 : bool\n            Whether to use N2V2 or not.\n\n        Raises\n        ------\n        ValueError\n            If the algorithm is not N2V.\n        \"\"\"\n        if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n            self.algorithm_config.model.n2v2 = use_n2v2\n            strategy = (\n                SupportedPixelManipulation.MEDIAN.value\n                if use_n2v2\n                else SupportedPixelManipulation.UNIFORM.value\n            )\n            self.data_config.set_N2V2_strategy(strategy)\n        else:\n            raise ValueError(\"N2V2 can only be set for N2V algorithm.\")\n\n    def set_structN2V(\n        self, mask_axis: Literal[\"horizontal\", \"vertical\", \"none\"], mask_span: int\n    ) -&gt; None:\n        \"\"\"\n        Set StructN2V parameters.\n\n        Parameters\n        ----------\n        mask_axis : Literal[\"horizontal\", \"vertical\", \"none\"]\n            Axis of the structural mask.\n        mask_span : int\n            Span of the structural mask.\n        \"\"\"\n        self.data_config.set_structN2V_mask(mask_axis, mask_span)\n\n    def get_algorithm_flavour(self) -&gt; str:\n        \"\"\"\n        Get the algorithm name.\n\n        Returns\n        -------\n        str\n            Algorithm name.\n        \"\"\"\n        if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n            use_n2v2 = self.algorithm_config.model.n2v2\n            use_structN2V = self.data_config.transforms[-1].struct_mask_axis != \"none\"\n\n            # return the n2v flavour\n            if use_n2v2 and use_structN2V:\n                return STRUCT_N2V2\n            elif use_n2v2:\n                return N2V2\n            elif use_structN2V:\n                return STRUCT_N2V\n            else:\n                return N2V\n        elif self.algorithm_config.algorithm == SupportedAlgorithm.N2N:\n            return N2N\n        elif self.algorithm_config.algorithm == SupportedAlgorithm.CARE:\n            return CARE\n        else:\n            return CUSTOM\n\n    def get_algorithm_description(self) -&gt; str:\n        \"\"\"\n        Return a description of the algorithm.\n\n        This method is used to generate the README of the BioImage Model Zoo export.\n\n        Returns\n        -------\n        str\n            Description of the algorithm.\n        \"\"\"\n        algorithm_flavour = self.get_algorithm_flavour()\n\n        if algorithm_flavour == CUSTOM:\n            return f\"Custom algorithm, named {self.algorithm_config.model.name}\"\n        else:  # currently only N2V flavours\n            if algorithm_flavour == N2V:\n                return N2VDescription().description\n            elif algorithm_flavour == N2V2:\n                return N2V2Description().description\n            elif algorithm_flavour == STRUCT_N2V:\n                return StructN2VDescription().description\n            elif algorithm_flavour == STRUCT_N2V2:\n                return StructN2V2Description().description\n            elif algorithm_flavour == N2N:\n                return N2NDescription().description\n            elif algorithm_flavour == CARE:\n                return CAREDescription().description\n\n        return \"\"\n\n    def get_algorithm_citations(self) -&gt; List[CiteEntry]:\n        \"\"\"\n        Return a list of citation entries of the current algorithm.\n\n        This is used to generate the model description for the BioImage Model Zoo.\n\n        Returns\n        -------\n        List[CiteEntry]\n            List of citation entries.\n        \"\"\"\n        if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n            use_n2v2 = self.algorithm_config.model.n2v2\n            use_structN2V = self.data_config.transforms[-1].struct_mask_axis != \"none\"\n\n            # return the (struct)N2V(2) references\n            if use_n2v2 and use_structN2V:\n                return [N2VRef, N2V2Ref, StructN2VRef]\n            elif use_n2v2:\n                return [N2VRef, N2V2Ref]\n            elif use_structN2V:\n                return [N2VRef, StructN2VRef]\n            else:\n                return [N2VRef]\n        elif self.algorithm_config.algorithm == SupportedAlgorithm.N2N:\n            return [N2NRef]\n        elif self.algorithm_config.algorithm == SupportedAlgorithm.CARE:\n            return [CARERef]\n\n        raise ValueError(\"Citation not available for custom algorithm.\")\n\n    def get_algorithm_references(self) -&gt; str:\n        \"\"\"\n        Get the algorithm references.\n\n        This is used to generate the README of the BioImage Model Zoo export.\n\n        Returns\n        -------\n        str\n            Algorithm references.\n        \"\"\"\n        if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n            use_n2v2 = self.algorithm_config.model.n2v2\n            use_structN2V = self.data_config.transforms[-1].struct_mask_axis != \"none\"\n\n            references = [\n                N2VRef.text + \" doi: \" + N2VRef.doi,\n                N2V2Ref.text + \" doi: \" + N2V2Ref.doi,\n                StructN2VRef.text + \" doi: \" + StructN2VRef.doi,\n            ]\n\n            # return the (struct)N2V(2) references\n            if use_n2v2 and use_structN2V:\n                return \"\".join(references)\n            elif use_n2v2:\n                references.pop(-1)\n                return \"\".join(references)\n            elif use_structN2V:\n                references.pop(-2)\n                return \"\".join(references)\n            else:\n                return references[0]\n\n        return \"\"\n\n    def get_algorithm_keywords(self) -&gt; List[str]:\n        \"\"\"\n        Get algorithm keywords.\n\n        Returns\n        -------\n        List[str]\n            List of keywords.\n        \"\"\"\n        if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n            use_n2v2 = self.algorithm_config.model.n2v2\n            use_structN2V = self.data_config.transforms[-1].struct_mask_axis != \"none\"\n\n            keywords = [\n                \"denoising\",\n                \"restoration\",\n                \"UNet\",\n                \"3D\" if \"Z\" in self.data_config.axes else \"2D\",\n                \"CAREamics\",\n                \"pytorch\",\n                N2V,\n            ]\n\n            if use_n2v2:\n                keywords.append(N2V2)\n            if use_structN2V:\n                keywords.append(STRUCT_N2V)\n        else:\n            keywords = [\"CAREamics\"]\n\n        return keywords\n\n    def model_dump(\n        self,\n        exclude_defaults: bool = False,\n        exclude_none: bool = True,\n        **kwargs: Dict,\n    ) -&gt; Dict:\n        \"\"\"\n        Override model_dump method in order to set default values.\n\n        Parameters\n        ----------\n        exclude_defaults : bool, optional\n            Whether to exclude fields with default values or not, by default\n            True.\n        exclude_none : bool, optional\n            Whether to exclude fields with None values or not, by default True.\n        **kwargs : Dict\n            Keyword arguments.\n\n        Returns\n        -------\n        dict\n            Dictionary containing the model parameters.\n        \"\"\"\n        dictionary = super().model_dump(\n            exclude_none=exclude_none, exclude_defaults=exclude_defaults, **kwargs\n        )\n\n        return dictionary\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.__str__","title":"<code>__str__()</code>","text":"<p>Pretty string reprensenting the configuration.</p> <p>Returns:</p> Type Description <code>str</code> <p>Pretty string.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Pretty string reprensenting the configuration.\n\n    Returns\n    -------\n    str\n        Pretty string.\n    \"\"\"\n    return pformat(self.model_dump())\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.get_algorithm_citations","title":"<code>get_algorithm_citations()</code>","text":"<p>Return a list of citation entries of the current algorithm.</p> <p>This is used to generate the model description for the BioImage Model Zoo.</p> <p>Returns:</p> Type Description <code>List[CiteEntry]</code> <p>List of citation entries.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def get_algorithm_citations(self) -&gt; List[CiteEntry]:\n    \"\"\"\n    Return a list of citation entries of the current algorithm.\n\n    This is used to generate the model description for the BioImage Model Zoo.\n\n    Returns\n    -------\n    List[CiteEntry]\n        List of citation entries.\n    \"\"\"\n    if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n        use_n2v2 = self.algorithm_config.model.n2v2\n        use_structN2V = self.data_config.transforms[-1].struct_mask_axis != \"none\"\n\n        # return the (struct)N2V(2) references\n        if use_n2v2 and use_structN2V:\n            return [N2VRef, N2V2Ref, StructN2VRef]\n        elif use_n2v2:\n            return [N2VRef, N2V2Ref]\n        elif use_structN2V:\n            return [N2VRef, StructN2VRef]\n        else:\n            return [N2VRef]\n    elif self.algorithm_config.algorithm == SupportedAlgorithm.N2N:\n        return [N2NRef]\n    elif self.algorithm_config.algorithm == SupportedAlgorithm.CARE:\n        return [CARERef]\n\n    raise ValueError(\"Citation not available for custom algorithm.\")\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.get_algorithm_description","title":"<code>get_algorithm_description()</code>","text":"<p>Return a description of the algorithm.</p> <p>This method is used to generate the README of the BioImage Model Zoo export.</p> <p>Returns:</p> Type Description <code>str</code> <p>Description of the algorithm.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def get_algorithm_description(self) -&gt; str:\n    \"\"\"\n    Return a description of the algorithm.\n\n    This method is used to generate the README of the BioImage Model Zoo export.\n\n    Returns\n    -------\n    str\n        Description of the algorithm.\n    \"\"\"\n    algorithm_flavour = self.get_algorithm_flavour()\n\n    if algorithm_flavour == CUSTOM:\n        return f\"Custom algorithm, named {self.algorithm_config.model.name}\"\n    else:  # currently only N2V flavours\n        if algorithm_flavour == N2V:\n            return N2VDescription().description\n        elif algorithm_flavour == N2V2:\n            return N2V2Description().description\n        elif algorithm_flavour == STRUCT_N2V:\n            return StructN2VDescription().description\n        elif algorithm_flavour == STRUCT_N2V2:\n            return StructN2V2Description().description\n        elif algorithm_flavour == N2N:\n            return N2NDescription().description\n        elif algorithm_flavour == CARE:\n            return CAREDescription().description\n\n    return \"\"\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.get_algorithm_flavour","title":"<code>get_algorithm_flavour()</code>","text":"<p>Get the algorithm name.</p> <p>Returns:</p> Type Description <code>str</code> <p>Algorithm name.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def get_algorithm_flavour(self) -&gt; str:\n    \"\"\"\n    Get the algorithm name.\n\n    Returns\n    -------\n    str\n        Algorithm name.\n    \"\"\"\n    if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n        use_n2v2 = self.algorithm_config.model.n2v2\n        use_structN2V = self.data_config.transforms[-1].struct_mask_axis != \"none\"\n\n        # return the n2v flavour\n        if use_n2v2 and use_structN2V:\n            return STRUCT_N2V2\n        elif use_n2v2:\n            return N2V2\n        elif use_structN2V:\n            return STRUCT_N2V\n        else:\n            return N2V\n    elif self.algorithm_config.algorithm == SupportedAlgorithm.N2N:\n        return N2N\n    elif self.algorithm_config.algorithm == SupportedAlgorithm.CARE:\n        return CARE\n    else:\n        return CUSTOM\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.get_algorithm_keywords","title":"<code>get_algorithm_keywords()</code>","text":"<p>Get algorithm keywords.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of keywords.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def get_algorithm_keywords(self) -&gt; List[str]:\n    \"\"\"\n    Get algorithm keywords.\n\n    Returns\n    -------\n    List[str]\n        List of keywords.\n    \"\"\"\n    if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n        use_n2v2 = self.algorithm_config.model.n2v2\n        use_structN2V = self.data_config.transforms[-1].struct_mask_axis != \"none\"\n\n        keywords = [\n            \"denoising\",\n            \"restoration\",\n            \"UNet\",\n            \"3D\" if \"Z\" in self.data_config.axes else \"2D\",\n            \"CAREamics\",\n            \"pytorch\",\n            N2V,\n        ]\n\n        if use_n2v2:\n            keywords.append(N2V2)\n        if use_structN2V:\n            keywords.append(STRUCT_N2V)\n    else:\n        keywords = [\"CAREamics\"]\n\n    return keywords\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.get_algorithm_references","title":"<code>get_algorithm_references()</code>","text":"<p>Get the algorithm references.</p> <p>This is used to generate the README of the BioImage Model Zoo export.</p> <p>Returns:</p> Type Description <code>str</code> <p>Algorithm references.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def get_algorithm_references(self) -&gt; str:\n    \"\"\"\n    Get the algorithm references.\n\n    This is used to generate the README of the BioImage Model Zoo export.\n\n    Returns\n    -------\n    str\n        Algorithm references.\n    \"\"\"\n    if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n        use_n2v2 = self.algorithm_config.model.n2v2\n        use_structN2V = self.data_config.transforms[-1].struct_mask_axis != \"none\"\n\n        references = [\n            N2VRef.text + \" doi: \" + N2VRef.doi,\n            N2V2Ref.text + \" doi: \" + N2V2Ref.doi,\n            StructN2VRef.text + \" doi: \" + StructN2VRef.doi,\n        ]\n\n        # return the (struct)N2V(2) references\n        if use_n2v2 and use_structN2V:\n            return \"\".join(references)\n        elif use_n2v2:\n            references.pop(-1)\n            return \"\".join(references)\n        elif use_structN2V:\n            references.pop(-2)\n            return \"\".join(references)\n        else:\n            return references[0]\n\n    return \"\"\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.model_dump","title":"<code>model_dump(exclude_defaults=False, exclude_none=True, **kwargs)</code>","text":"<p>Override model_dump method in order to set default values.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields with default values or not, by default True.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields with None values or not, by default True.</p> <code>True</code> <code>**kwargs</code> <code>Dict</code> <p>Keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary containing the model parameters.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def model_dump(\n    self,\n    exclude_defaults: bool = False,\n    exclude_none: bool = True,\n    **kwargs: Dict,\n) -&gt; Dict:\n    \"\"\"\n    Override model_dump method in order to set default values.\n\n    Parameters\n    ----------\n    exclude_defaults : bool, optional\n        Whether to exclude fields with default values or not, by default\n        True.\n    exclude_none : bool, optional\n        Whether to exclude fields with None values or not, by default True.\n    **kwargs : Dict\n        Keyword arguments.\n\n    Returns\n    -------\n    dict\n        Dictionary containing the model parameters.\n    \"\"\"\n    dictionary = super().model_dump(\n        exclude_none=exclude_none, exclude_defaults=exclude_defaults, **kwargs\n    )\n\n    return dictionary\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.no_symbol","title":"<code>no_symbol(name)</code>  <code>classmethod</code>","text":"<p>Validate experiment name.</p> <p>A valid experiment name is a non-empty string with only contains letters, numbers, underscores, dashes and spaces.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name to validate.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Validated name.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the name is empty or contains invalid characters.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>@field_validator(\"experiment_name\")\n@classmethod\ndef no_symbol(cls, name: str) -&gt; str:\n    \"\"\"\n    Validate experiment name.\n\n    A valid experiment name is a non-empty string with only contains letters,\n    numbers, underscores, dashes and spaces.\n\n    Parameters\n    ----------\n    name : str\n        Name to validate.\n\n    Returns\n    -------\n    str\n        Validated name.\n\n    Raises\n    ------\n    ValueError\n        If the name is empty or contains invalid characters.\n    \"\"\"\n    if len(name) == 0 or name.isspace():\n        raise ValueError(\"Experiment name is empty.\")\n\n    # Validate using a regex that it contains only letters, numbers, underscores,\n    # dashes and spaces\n    if not re.match(r\"^[a-zA-Z0-9_\\- ]*$\", name):\n        raise ValueError(\n            f\"Experiment name contains invalid characters (got {name}). \"\n            f\"Only letters, numbers, underscores, dashes and spaces are allowed.\"\n        )\n\n    return name\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.set_3D","title":"<code>set_3D(is_3D, axes, patch_size)</code>","text":"<p>Set 3D flag and axes.</p> <p>Parameters:</p> Name Type Description Default <code>is_3D</code> <code>bool</code> <p>Whether the algorithm is 3D or not.</p> required <code>axes</code> <code>str</code> <p>Axes of the data.</p> required <code>patch_size</code> <code>List[int]</code> <p>Patch size.</p> required Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def set_3D(self, is_3D: bool, axes: str, patch_size: List[int]) -&gt; None:\n    \"\"\"\n    Set 3D flag and axes.\n\n    Parameters\n    ----------\n    is_3D : bool\n        Whether the algorithm is 3D or not.\n    axes : str\n        Axes of the data.\n    patch_size : List[int]\n        Patch size.\n    \"\"\"\n    # set the flag and axes (this will not trigger validation at the config level)\n    self.algorithm_config.model.set_3D(is_3D)\n    self.data_config.set_3D(axes, patch_size)\n\n    # cheap hack: trigger validation\n    self.algorithm_config = self.algorithm_config\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.set_N2V2","title":"<code>set_N2V2(use_n2v2)</code>","text":"<p>Switch N2V algorithm between N2V and N2V2.</p> <p>Parameters:</p> Name Type Description Default <code>use_n2v2</code> <code>bool</code> <p>Whether to use N2V2 or not.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the algorithm is not N2V.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def set_N2V2(self, use_n2v2: bool) -&gt; None:\n    \"\"\"\n    Switch N2V algorithm between N2V and N2V2.\n\n    Parameters\n    ----------\n    use_n2v2 : bool\n        Whether to use N2V2 or not.\n\n    Raises\n    ------\n    ValueError\n        If the algorithm is not N2V.\n    \"\"\"\n    if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n        self.algorithm_config.model.n2v2 = use_n2v2\n        strategy = (\n            SupportedPixelManipulation.MEDIAN.value\n            if use_n2v2\n            else SupportedPixelManipulation.UNIFORM.value\n        )\n        self.data_config.set_N2V2_strategy(strategy)\n    else:\n        raise ValueError(\"N2V2 can only be set for N2V algorithm.\")\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.set_structN2V","title":"<code>set_structN2V(mask_axis, mask_span)</code>","text":"<p>Set StructN2V parameters.</p> <p>Parameters:</p> Name Type Description Default <code>mask_axis</code> <code>Literal['horizontal', 'vertical', 'none']</code> <p>Axis of the structural mask.</p> required <code>mask_span</code> <code>int</code> <p>Span of the structural mask.</p> required Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def set_structN2V(\n    self, mask_axis: Literal[\"horizontal\", \"vertical\", \"none\"], mask_span: int\n) -&gt; None:\n    \"\"\"\n    Set StructN2V parameters.\n\n    Parameters\n    ----------\n    mask_axis : Literal[\"horizontal\", \"vertical\", \"none\"]\n        Axis of the structural mask.\n    mask_span : int\n        Span of the structural mask.\n    \"\"\"\n    self.data_config.set_structN2V_mask(mask_axis, mask_span)\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.validate_3D","title":"<code>validate_3D()</code>","text":"<p>Change algorithm dimensions to match data.axes.</p> <p>Only for non-custom algorithms.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Validated configuration.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_3D(self: Self) -&gt; Self:\n    \"\"\"\n    Change algorithm dimensions to match data.axes.\n\n    Only for non-custom algorithms.\n\n    Returns\n    -------\n    Self\n        Validated configuration.\n    \"\"\"\n    if self.algorithm_config.algorithm != SupportedAlgorithm.CUSTOM:\n        if \"Z\" in self.data_config.axes and not self.algorithm_config.model.is_3D():\n            # change algorithm to 3D\n            self.algorithm_config.model.set_3D(True)\n        elif (\n            \"Z\" not in self.data_config.axes and self.algorithm_config.model.is_3D()\n        ):\n            # change algorithm to 2D\n            self.algorithm_config.model.set_3D(False)\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.Configuration.validate_algorithm_and_data","title":"<code>validate_algorithm_and_data()</code>","text":"<p>Validate algorithm and data compatibility.</p> <p>In particular, the validation does the following:</p> <ul> <li>If N2V is used, it enforces the presence of N2V_Maniuplate in the transforms</li> <li>If N2V2 is used, it enforces the correct manipulation strategy</li> </ul> <p>Returns:</p> Type Description <code>Self</code> <p>Validated configuration.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_algorithm_and_data(self: Self) -&gt; Self:\n    \"\"\"\n    Validate algorithm and data compatibility.\n\n    In particular, the validation does the following:\n\n    - If N2V is used, it enforces the presence of N2V_Maniuplate in the transforms\n    - If N2V2 is used, it enforces the correct manipulation strategy\n\n    Returns\n    -------\n    Self\n        Validated configuration.\n    \"\"\"\n    if self.algorithm_config.algorithm == SupportedAlgorithm.N2V:\n        # missing N2V_MANIPULATE\n        if not self.data_config.has_n2v_manipulate():\n            self.data_config.transforms.append(\n                N2VManipulateModel(\n                    name=SupportedTransform.N2V_MANIPULATE.value,\n                )\n            )\n\n        median = SupportedPixelManipulation.MEDIAN.value\n        uniform = SupportedPixelManipulation.UNIFORM.value\n        strategy = median if self.algorithm_config.model.n2v2 else uniform\n        self.data_config.set_N2V2_strategy(strategy)\n    else:\n        # remove N2V manipulate if present\n        if self.data_config.has_n2v_manipulate():\n            self.data_config.remove_n2v_manipulate()\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.load_configuration","title":"<code>load_configuration(path)</code>","text":"<p>Load configuration from a yaml file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the configuration.</p> required <p>Returns:</p> Type Description <code>Configuration</code> <p>Configuration.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the configuration file does not exist.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def load_configuration(path: Union[str, Path]) -&gt; Configuration:\n    \"\"\"\n    Load configuration from a yaml file.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to the configuration.\n\n    Returns\n    -------\n    Configuration\n        Configuration.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the configuration file does not exist.\n    \"\"\"\n    # load dictionary from yaml\n    if not Path(path).exists():\n        raise FileNotFoundError(\n            f\"Configuration file {path} does not exist in \" f\" {Path.cwd()!s}\"\n        )\n\n    dictionary = yaml.load(Path(path).open(\"r\"), Loader=yaml.SafeLoader)\n\n    return Configuration(**dictionary)\n</code></pre>"},{"location":"reference/careamics/config/configuration_model/#careamics.config.configuration_model.save_configuration","title":"<code>save_configuration(config, path)</code>","text":"<p>Save configuration to path.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>Configuration to save.</p> required <code>path</code> <code>Union[str, Path]</code> <p>Path to a existing folder in which to save the configuration or to an existing configuration file.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path object representing the configuration.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the path does not point to an existing directory or .yml file.</p> Source code in <code>src/careamics/config/configuration_model.py</code> <pre><code>def save_configuration(config: Configuration, path: Union[str, Path]) -&gt; Path:\n    \"\"\"\n    Save configuration to path.\n\n    Parameters\n    ----------\n    config : Configuration\n        Configuration to save.\n    path : Union[str, Path]\n        Path to a existing folder in which to save the configuration or to an existing\n        configuration file.\n\n    Returns\n    -------\n    Path\n        Path object representing the configuration.\n\n    Raises\n    ------\n    ValueError\n        If the path does not point to an existing directory or .yml file.\n    \"\"\"\n    # make sure path is a Path object\n    config_path = Path(path)\n\n    # check if path is pointing to an existing directory or .yml file\n    if config_path.exists():\n        if config_path.is_dir():\n            config_path = Path(config_path, \"config.yml\")\n        elif config_path.suffix != \".yml\" and config_path.suffix != \".yaml\":\n            raise ValueError(\n                f\"Path must be a directory or .yml or .yaml file (got {config_path}).\"\n            )\n    else:\n        if config_path.suffix != \".yml\" and config_path.suffix != \".yaml\":\n            raise ValueError(\n                f\"Path must be a directory or .yml or .yaml file (got {config_path}).\"\n            )\n\n    # save configuration as dictionary to yaml\n    with open(config_path, \"w\") as f:\n        # dump configuration\n        yaml.dump(config.model_dump(), f, default_flow_style=False, sort_keys=False)\n\n    return config_path\n</code></pre>"},{"location":"reference/careamics/config/data_model/","title":"data_model","text":"<p>Data configuration.</p>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig","title":"<code>DataConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Data configuration.</p> <p>If std is specified, mean must be specified as well. Note that setting the std first and then the mean (if they were both <code>None</code> before) will raise a validation error. Prefer instead <code>set_mean_and_std</code> to set both at once.</p> <p>Examples:</p> <p>Minimum example:</p> <pre><code>&gt;&gt;&gt; data = DataConfig(\n...     data_type=\"array\", # defined in SupportedData\n...     patch_size=[128, 128],\n...     batch_size=4,\n...     axes=\"YX\"\n... )\n</code></pre> <p>To change the mean and std of the data:</p> <pre><code>&gt;&gt;&gt; data.set_mean_and_std(mean=214.3, std=84.5)\n</code></pre> <p>One can pass also a list of transformations, by keyword, using the SupportedTransform or the name of an Albumentation transform:</p> <pre><code>&gt;&gt;&gt; from careamics.config.support import SupportedTransform\n&gt;&gt;&gt; data = DataConfig(\n...     data_type=\"tiff\",\n...     patch_size=[128, 128],\n...     batch_size=4,\n...     axes=\"YX\",\n...     transforms=[\n...         {\n...             \"name\": SupportedTransform.NORMALIZE.value,\n...             \"mean\": 167.6,\n...             \"std\": 47.2,\n...         },\n...         {\n...             \"name\": \"XYFlip\",\n...         }\n...     ]\n... )\n</code></pre> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>class DataConfig(BaseModel):\n    \"\"\"\n    Data configuration.\n\n    If std is specified, mean must be specified as well. Note that setting the std first\n    and then the mean (if they were both `None` before) will raise a validation error.\n    Prefer instead `set_mean_and_std` to set both at once.\n\n    Examples\n    --------\n    Minimum example:\n\n    &gt;&gt;&gt; data = DataConfig(\n    ...     data_type=\"array\", # defined in SupportedData\n    ...     patch_size=[128, 128],\n    ...     batch_size=4,\n    ...     axes=\"YX\"\n    ... )\n\n    To change the mean and std of the data:\n    &gt;&gt;&gt; data.set_mean_and_std(mean=214.3, std=84.5)\n\n    One can pass also a list of transformations, by keyword, using the\n    SupportedTransform or the name of an Albumentation transform:\n    &gt;&gt;&gt; from careamics.config.support import SupportedTransform\n    &gt;&gt;&gt; data = DataConfig(\n    ...     data_type=\"tiff\",\n    ...     patch_size=[128, 128],\n    ...     batch_size=4,\n    ...     axes=\"YX\",\n    ...     transforms=[\n    ...         {\n    ...             \"name\": SupportedTransform.NORMALIZE.value,\n    ...             \"mean\": 167.6,\n    ...             \"std\": 47.2,\n    ...         },\n    ...         {\n    ...             \"name\": \"XYFlip\",\n    ...         }\n    ...     ]\n    ... )\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    # Dataset configuration\n    data_type: Literal[\"array\", \"tiff\", \"custom\"]  # As defined in SupportedData\n    patch_size: Union[List[int]] = Field(..., min_length=2, max_length=3)\n    batch_size: int = Field(default=1, ge=1, validate_default=True)\n    axes: str\n\n    # Optional fields\n    mean: Optional[float] = None\n    std: Optional[float] = None\n\n    transforms: List[TRANSFORMS_UNION] = Field(\n        default=[\n            {\n                \"name\": SupportedTransform.NORMALIZE.value,\n            },\n            {\n                \"name\": SupportedTransform.XY_FLIP.value,\n            },\n            {\n                \"name\": SupportedTransform.XY_RANDOM_ROTATE90.value,\n            },\n            {\n                \"name\": SupportedTransform.N2V_MANIPULATE.value,\n            },\n        ],\n        validate_default=True,\n    )\n\n    dataloader_params: Optional[dict] = None\n\n    @field_validator(\"patch_size\")\n    @classmethod\n    def all_elements_power_of_2_minimum_8(\n        cls, patch_list: Union[List[int]]\n    ) -&gt; Union[List[int]]:\n        \"\"\"\n        Validate patch size.\n\n        Patch size must be powers of 2 and minimum 8.\n\n        Parameters\n        ----------\n        patch_list : Union[List[int]]\n            Patch size.\n\n        Returns\n        -------\n        Union[List[int]]\n            Validated patch size.\n\n        Raises\n        ------\n        ValueError\n            If the patch size is smaller than 8.\n        ValueError\n            If the patch size is not a power of 2.\n        \"\"\"\n        patch_size_ge_than_8_power_of_2(patch_list)\n\n        return patch_list\n\n    @field_validator(\"axes\")\n    @classmethod\n    def axes_valid(cls, axes: str) -&gt; str:\n        \"\"\"\n        Validate axes.\n\n        Axes must:\n        - be a combination of 'STCZYX'\n        - not contain duplicates\n        - contain at least 2 contiguous axes: X and Y\n        - contain at most 4 axes\n        - not contain both S and T axes\n\n        Parameters\n        ----------\n        axes : str\n            Axes to validate.\n\n        Returns\n        -------\n        str\n            Validated axes.\n\n        Raises\n        ------\n        ValueError\n            If axes are not valid.\n        \"\"\"\n        # Validate axes\n        check_axes_validity(axes)\n\n        return axes\n\n    @field_validator(\"transforms\")\n    @classmethod\n    def validate_prediction_transforms(\n        cls, transforms: List[TRANSFORMS_UNION]\n    ) -&gt; List[TRANSFORMS_UNION]:\n        \"\"\"\n        Validate N2VManipulate transform position in the transform list.\n\n        Parameters\n        ----------\n        transforms : List[Transformations_Union]\n            Transforms.\n\n        Returns\n        -------\n        List[TRANSFORMS_UNION]\n            Validated transforms.\n\n        Raises\n        ------\n        ValueError\n            If multiple instances of N2VManipulate are found.\n        \"\"\"\n        transform_list = [t.name for t in transforms]\n\n        if SupportedTransform.N2V_MANIPULATE in transform_list:\n            # multiple N2V_MANIPULATE\n            if transform_list.count(SupportedTransform.N2V_MANIPULATE.value) &gt; 1:\n                raise ValueError(\n                    f\"Multiple instances of \"\n                    f\"{SupportedTransform.N2V_MANIPULATE} transforms \"\n                    f\"are not allowed.\"\n                )\n\n            # N2V_MANIPULATE not the last transform\n            elif transform_list[-1] != SupportedTransform.N2V_MANIPULATE:\n                index = transform_list.index(SupportedTransform.N2V_MANIPULATE.value)\n                transform = transforms.pop(index)\n                transforms.append(transform)\n\n        return transforms\n\n    @model_validator(mode=\"after\")\n    def std_only_with_mean(self: Self) -&gt; Self:\n        \"\"\"\n        Check that mean and std are either both None, or both specified.\n\n        Returns\n        -------\n        Self\n            Validated data model.\n\n        Raises\n        ------\n        ValueError\n            If std is not None and mean is None.\n        \"\"\"\n        # check that mean and std are either both None, or both specified\n        if (self.mean is None) != (self.std is None):\n            raise ValueError(\n                \"Mean and std must be either both None, or both specified.\"\n            )\n\n        return self\n\n    @model_validator(mode=\"after\")\n    def add_std_and_mean_to_normalize(self: Self) -&gt; Self:\n        \"\"\"\n        Add mean and std to the Normalize transform if it is present.\n\n        Returns\n        -------\n        Self\n            Data model with mean and std added to the Normalize transform.\n        \"\"\"\n        if self.mean is not None and self.std is not None:\n            # search in the transforms for Normalize and update parameters\n            for transform in self.transforms:\n                if transform.name == SupportedTransform.NORMALIZE.value:\n                    transform.mean = self.mean\n                    transform.std = self.std\n\n        return self\n\n    @model_validator(mode=\"after\")\n    def validate_dimensions(self: Self) -&gt; Self:\n        \"\"\"\n        Validate 2D/3D dimensions between axes, patch size and transforms.\n\n        Returns\n        -------\n        Self\n            Validated data model.\n\n        Raises\n        ------\n        ValueError\n            If the transforms are not valid.\n        \"\"\"\n        if \"Z\" in self.axes:\n            if len(self.patch_size) != 3:\n                raise ValueError(\n                    f\"Patch size must have 3 dimensions if the data is 3D \"\n                    f\"({self.axes}).\"\n                )\n\n        else:\n            if len(self.patch_size) != 2:\n                raise ValueError(\n                    f\"Patch size must have 3 dimensions if the data is 3D \"\n                    f\"({self.axes}).\"\n                )\n\n        return self\n\n    def __str__(self) -&gt; str:\n        \"\"\"\n        Pretty string reprensenting the configuration.\n\n        Returns\n        -------\n        str\n            Pretty string.\n        \"\"\"\n        return pformat(self.model_dump())\n\n    def _update(self, **kwargs: Any) -&gt; None:\n        \"\"\"\n        Update multiple arguments at once.\n\n        Parameters\n        ----------\n        **kwargs : Any\n            Keyword arguments to update.\n        \"\"\"\n        self.__dict__.update(kwargs)\n        self.__class__.model_validate(self.__dict__)\n\n    def has_n2v_manipulate(self) -&gt; bool:\n        \"\"\"\n        Check if the transforms contain N2VManipulate.\n\n        Returns\n        -------\n        bool\n            True if the transforms contain N2VManipulate, False otherwise.\n        \"\"\"\n        return any(\n            transform.name == SupportedTransform.N2V_MANIPULATE.value\n            for transform in self.transforms\n        )\n\n    def add_n2v_manipulate(self) -&gt; None:\n        \"\"\"Add N2VManipulate to the transforms.\"\"\"\n        if not self.has_n2v_manipulate():\n            self.transforms.append(\n                N2VManipulateModel(name=SupportedTransform.N2V_MANIPULATE.value)\n            )\n\n    def remove_n2v_manipulate(self) -&gt; None:\n        \"\"\"Remove N2VManipulate from the transforms.\"\"\"\n        if self.has_n2v_manipulate():\n            self.transforms.pop(-1)\n\n    def set_mean_and_std(self, mean: float, std: float) -&gt; None:\n        \"\"\"\n        Set mean and standard deviation of the data.\n\n        This method should be used instead setting the fields directly, as it would\n        otherwise trigger a validation error.\n\n        Parameters\n        ----------\n        mean : float\n            Mean of the data.\n        std : float\n            Standard deviation of the data.\n        \"\"\"\n        self._update(mean=mean, std=std)\n\n    def set_3D(self, axes: str, patch_size: List[int]) -&gt; None:\n        \"\"\"\n        Set 3D parameters.\n\n        Parameters\n        ----------\n        axes : str\n            Axes.\n        patch_size : List[int]\n            Patch size.\n        \"\"\"\n        self._update(axes=axes, patch_size=patch_size)\n\n    def set_N2V2(self, use_n2v2: bool) -&gt; None:\n        \"\"\"\n        Set N2V2.\n\n        Parameters\n        ----------\n        use_n2v2 : bool\n            Whether to use N2V2.\n\n        Raises\n        ------\n        ValueError\n            If the N2V pixel manipulate transform is not found in the transforms.\n        \"\"\"\n        if use_n2v2:\n            self.set_N2V2_strategy(\"median\")\n        else:\n            self.set_N2V2_strategy(\"uniform\")\n\n    def set_N2V2_strategy(self, strategy: Literal[\"uniform\", \"median\"]) -&gt; None:\n        \"\"\"\n        Set N2V2 strategy.\n\n        Parameters\n        ----------\n        strategy : Literal[\"uniform\", \"median\"]\n            Strategy to use for N2V2.\n\n        Raises\n        ------\n        ValueError\n            If the N2V pixel manipulate transform is not found in the transforms.\n        \"\"\"\n        found_n2v = False\n\n        for transform in self.transforms:\n            if transform.name == SupportedTransform.N2V_MANIPULATE.value:\n                transform.strategy = strategy\n                found_n2v = True\n\n        if not found_n2v:\n            transforms = [t.name for t in self.transforms]\n            raise ValueError(\n                f\"N2V_Manipulate transform not found in the transforms list \"\n                f\"({transforms}).\"\n            )\n\n    def set_structN2V_mask(\n        self, mask_axis: Literal[\"horizontal\", \"vertical\", \"none\"], mask_span: int\n    ) -&gt; None:\n        \"\"\"\n        Set structN2V mask parameters.\n\n        Setting `mask_axis` to `none` will disable structN2V.\n\n        Parameters\n        ----------\n        mask_axis : Literal[\"horizontal\", \"vertical\", \"none\"]\n            Axis along which to apply the mask. `none` will disable structN2V.\n        mask_span : int\n            Total span of the mask in pixels.\n\n        Raises\n        ------\n        ValueError\n            If the N2V pixel manipulate transform is not found in the transforms.\n        \"\"\"\n        found_n2v = False\n\n        for transform in self.transforms:\n            if transform.name == SupportedTransform.N2V_MANIPULATE.value:\n                transform.struct_mask_axis = mask_axis\n                transform.struct_mask_span = mask_span\n                found_n2v = True\n\n        if not found_n2v:\n            transforms = [t.name for t in self.transforms]\n            raise ValueError(\n                f\"N2V pixel manipulate transform not found in the transforms \"\n                f\"({transforms}).\"\n            )\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.__str__","title":"<code>__str__()</code>","text":"<p>Pretty string reprensenting the configuration.</p> <p>Returns:</p> Type Description <code>str</code> <p>Pretty string.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"\n    Pretty string reprensenting the configuration.\n\n    Returns\n    -------\n    str\n        Pretty string.\n    \"\"\"\n    return pformat(self.model_dump())\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.add_n2v_manipulate","title":"<code>add_n2v_manipulate()</code>","text":"<p>Add N2VManipulate to the transforms.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>def add_n2v_manipulate(self) -&gt; None:\n    \"\"\"Add N2VManipulate to the transforms.\"\"\"\n    if not self.has_n2v_manipulate():\n        self.transforms.append(\n            N2VManipulateModel(name=SupportedTransform.N2V_MANIPULATE.value)\n        )\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.add_std_and_mean_to_normalize","title":"<code>add_std_and_mean_to_normalize()</code>","text":"<p>Add mean and std to the Normalize transform if it is present.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Data model with mean and std added to the Normalize transform.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>@model_validator(mode=\"after\")\ndef add_std_and_mean_to_normalize(self: Self) -&gt; Self:\n    \"\"\"\n    Add mean and std to the Normalize transform if it is present.\n\n    Returns\n    -------\n    Self\n        Data model with mean and std added to the Normalize transform.\n    \"\"\"\n    if self.mean is not None and self.std is not None:\n        # search in the transforms for Normalize and update parameters\n        for transform in self.transforms:\n            if transform.name == SupportedTransform.NORMALIZE.value:\n                transform.mean = self.mean\n                transform.std = self.std\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.all_elements_power_of_2_minimum_8","title":"<code>all_elements_power_of_2_minimum_8(patch_list)</code>  <code>classmethod</code>","text":"<p>Validate patch size.</p> <p>Patch size must be powers of 2 and minimum 8.</p> <p>Parameters:</p> Name Type Description Default <code>patch_list</code> <code>Union[List[int]]</code> <p>Patch size.</p> required <p>Returns:</p> Type Description <code>Union[List[int]]</code> <p>Validated patch size.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the patch size is smaller than 8.</p> <code>ValueError</code> <p>If the patch size is not a power of 2.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>@field_validator(\"patch_size\")\n@classmethod\ndef all_elements_power_of_2_minimum_8(\n    cls, patch_list: Union[List[int]]\n) -&gt; Union[List[int]]:\n    \"\"\"\n    Validate patch size.\n\n    Patch size must be powers of 2 and minimum 8.\n\n    Parameters\n    ----------\n    patch_list : Union[List[int]]\n        Patch size.\n\n    Returns\n    -------\n    Union[List[int]]\n        Validated patch size.\n\n    Raises\n    ------\n    ValueError\n        If the patch size is smaller than 8.\n    ValueError\n        If the patch size is not a power of 2.\n    \"\"\"\n    patch_size_ge_than_8_power_of_2(patch_list)\n\n    return patch_list\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.axes_valid","title":"<code>axes_valid(axes)</code>  <code>classmethod</code>","text":"<p>Validate axes.</p> <p>Axes must: - be a combination of 'STCZYX' - not contain duplicates - contain at least 2 contiguous axes: X and Y - contain at most 4 axes - not contain both S and T axes</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>str</code> <p>Axes to validate.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Validated axes.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If axes are not valid.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>@field_validator(\"axes\")\n@classmethod\ndef axes_valid(cls, axes: str) -&gt; str:\n    \"\"\"\n    Validate axes.\n\n    Axes must:\n    - be a combination of 'STCZYX'\n    - not contain duplicates\n    - contain at least 2 contiguous axes: X and Y\n    - contain at most 4 axes\n    - not contain both S and T axes\n\n    Parameters\n    ----------\n    axes : str\n        Axes to validate.\n\n    Returns\n    -------\n    str\n        Validated axes.\n\n    Raises\n    ------\n    ValueError\n        If axes are not valid.\n    \"\"\"\n    # Validate axes\n    check_axes_validity(axes)\n\n    return axes\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.has_n2v_manipulate","title":"<code>has_n2v_manipulate()</code>","text":"<p>Check if the transforms contain N2VManipulate.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the transforms contain N2VManipulate, False otherwise.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>def has_n2v_manipulate(self) -&gt; bool:\n    \"\"\"\n    Check if the transforms contain N2VManipulate.\n\n    Returns\n    -------\n    bool\n        True if the transforms contain N2VManipulate, False otherwise.\n    \"\"\"\n    return any(\n        transform.name == SupportedTransform.N2V_MANIPULATE.value\n        for transform in self.transforms\n    )\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.remove_n2v_manipulate","title":"<code>remove_n2v_manipulate()</code>","text":"<p>Remove N2VManipulate from the transforms.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>def remove_n2v_manipulate(self) -&gt; None:\n    \"\"\"Remove N2VManipulate from the transforms.\"\"\"\n    if self.has_n2v_manipulate():\n        self.transforms.pop(-1)\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.set_3D","title":"<code>set_3D(axes, patch_size)</code>","text":"<p>Set 3D parameters.</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>str</code> <p>Axes.</p> required <code>patch_size</code> <code>List[int]</code> <p>Patch size.</p> required Source code in <code>src/careamics/config/data_model.py</code> <pre><code>def set_3D(self, axes: str, patch_size: List[int]) -&gt; None:\n    \"\"\"\n    Set 3D parameters.\n\n    Parameters\n    ----------\n    axes : str\n        Axes.\n    patch_size : List[int]\n        Patch size.\n    \"\"\"\n    self._update(axes=axes, patch_size=patch_size)\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.set_N2V2","title":"<code>set_N2V2(use_n2v2)</code>","text":"<p>Set N2V2.</p> <p>Parameters:</p> Name Type Description Default <code>use_n2v2</code> <code>bool</code> <p>Whether to use N2V2.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the N2V pixel manipulate transform is not found in the transforms.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>def set_N2V2(self, use_n2v2: bool) -&gt; None:\n    \"\"\"\n    Set N2V2.\n\n    Parameters\n    ----------\n    use_n2v2 : bool\n        Whether to use N2V2.\n\n    Raises\n    ------\n    ValueError\n        If the N2V pixel manipulate transform is not found in the transforms.\n    \"\"\"\n    if use_n2v2:\n        self.set_N2V2_strategy(\"median\")\n    else:\n        self.set_N2V2_strategy(\"uniform\")\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.set_N2V2_strategy","title":"<code>set_N2V2_strategy(strategy)</code>","text":"<p>Set N2V2 strategy.</p> <p>Parameters:</p> Name Type Description Default <code>strategy</code> <code>Literal['uniform', 'median']</code> <p>Strategy to use for N2V2.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the N2V pixel manipulate transform is not found in the transforms.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>def set_N2V2_strategy(self, strategy: Literal[\"uniform\", \"median\"]) -&gt; None:\n    \"\"\"\n    Set N2V2 strategy.\n\n    Parameters\n    ----------\n    strategy : Literal[\"uniform\", \"median\"]\n        Strategy to use for N2V2.\n\n    Raises\n    ------\n    ValueError\n        If the N2V pixel manipulate transform is not found in the transforms.\n    \"\"\"\n    found_n2v = False\n\n    for transform in self.transforms:\n        if transform.name == SupportedTransform.N2V_MANIPULATE.value:\n            transform.strategy = strategy\n            found_n2v = True\n\n    if not found_n2v:\n        transforms = [t.name for t in self.transforms]\n        raise ValueError(\n            f\"N2V_Manipulate transform not found in the transforms list \"\n            f\"({transforms}).\"\n        )\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.set_mean_and_std","title":"<code>set_mean_and_std(mean, std)</code>","text":"<p>Set mean and standard deviation of the data.</p> <p>This method should be used instead setting the fields directly, as it would otherwise trigger a validation error.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>Mean of the data.</p> required <code>std</code> <code>float</code> <p>Standard deviation of the data.</p> required Source code in <code>src/careamics/config/data_model.py</code> <pre><code>def set_mean_and_std(self, mean: float, std: float) -&gt; None:\n    \"\"\"\n    Set mean and standard deviation of the data.\n\n    This method should be used instead setting the fields directly, as it would\n    otherwise trigger a validation error.\n\n    Parameters\n    ----------\n    mean : float\n        Mean of the data.\n    std : float\n        Standard deviation of the data.\n    \"\"\"\n    self._update(mean=mean, std=std)\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.set_structN2V_mask","title":"<code>set_structN2V_mask(mask_axis, mask_span)</code>","text":"<p>Set structN2V mask parameters.</p> <p>Setting <code>mask_axis</code> to <code>none</code> will disable structN2V.</p> <p>Parameters:</p> Name Type Description Default <code>mask_axis</code> <code>Literal['horizontal', 'vertical', 'none']</code> <p>Axis along which to apply the mask. <code>none</code> will disable structN2V.</p> required <code>mask_span</code> <code>int</code> <p>Total span of the mask in pixels.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the N2V pixel manipulate transform is not found in the transforms.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>def set_structN2V_mask(\n    self, mask_axis: Literal[\"horizontal\", \"vertical\", \"none\"], mask_span: int\n) -&gt; None:\n    \"\"\"\n    Set structN2V mask parameters.\n\n    Setting `mask_axis` to `none` will disable structN2V.\n\n    Parameters\n    ----------\n    mask_axis : Literal[\"horizontal\", \"vertical\", \"none\"]\n        Axis along which to apply the mask. `none` will disable structN2V.\n    mask_span : int\n        Total span of the mask in pixels.\n\n    Raises\n    ------\n    ValueError\n        If the N2V pixel manipulate transform is not found in the transforms.\n    \"\"\"\n    found_n2v = False\n\n    for transform in self.transforms:\n        if transform.name == SupportedTransform.N2V_MANIPULATE.value:\n            transform.struct_mask_axis = mask_axis\n            transform.struct_mask_span = mask_span\n            found_n2v = True\n\n    if not found_n2v:\n        transforms = [t.name for t in self.transforms]\n        raise ValueError(\n            f\"N2V pixel manipulate transform not found in the transforms \"\n            f\"({transforms}).\"\n        )\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.std_only_with_mean","title":"<code>std_only_with_mean()</code>","text":"<p>Check that mean and std are either both None, or both specified.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Validated data model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If std is not None and mean is None.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>@model_validator(mode=\"after\")\ndef std_only_with_mean(self: Self) -&gt; Self:\n    \"\"\"\n    Check that mean and std are either both None, or both specified.\n\n    Returns\n    -------\n    Self\n        Validated data model.\n\n    Raises\n    ------\n    ValueError\n        If std is not None and mean is None.\n    \"\"\"\n    # check that mean and std are either both None, or both specified\n    if (self.mean is None) != (self.std is None):\n        raise ValueError(\n            \"Mean and std must be either both None, or both specified.\"\n        )\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.validate_dimensions","title":"<code>validate_dimensions()</code>","text":"<p>Validate 2D/3D dimensions between axes, patch size and transforms.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Validated data model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the transforms are not valid.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_dimensions(self: Self) -&gt; Self:\n    \"\"\"\n    Validate 2D/3D dimensions between axes, patch size and transforms.\n\n    Returns\n    -------\n    Self\n        Validated data model.\n\n    Raises\n    ------\n    ValueError\n        If the transforms are not valid.\n    \"\"\"\n    if \"Z\" in self.axes:\n        if len(self.patch_size) != 3:\n            raise ValueError(\n                f\"Patch size must have 3 dimensions if the data is 3D \"\n                f\"({self.axes}).\"\n            )\n\n    else:\n        if len(self.patch_size) != 2:\n            raise ValueError(\n                f\"Patch size must have 3 dimensions if the data is 3D \"\n                f\"({self.axes}).\"\n            )\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/data_model/#careamics.config.data_model.DataConfig.validate_prediction_transforms","title":"<code>validate_prediction_transforms(transforms)</code>  <code>classmethod</code>","text":"<p>Validate N2VManipulate transform position in the transform list.</p> <p>Parameters:</p> Name Type Description Default <code>transforms</code> <code>List[Transformations_Union]</code> <p>Transforms.</p> required <p>Returns:</p> Type Description <code>List[TRANSFORMS_UNION]</code> <p>Validated transforms.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If multiple instances of N2VManipulate are found.</p> Source code in <code>src/careamics/config/data_model.py</code> <pre><code>@field_validator(\"transforms\")\n@classmethod\ndef validate_prediction_transforms(\n    cls, transforms: List[TRANSFORMS_UNION]\n) -&gt; List[TRANSFORMS_UNION]:\n    \"\"\"\n    Validate N2VManipulate transform position in the transform list.\n\n    Parameters\n    ----------\n    transforms : List[Transformations_Union]\n        Transforms.\n\n    Returns\n    -------\n    List[TRANSFORMS_UNION]\n        Validated transforms.\n\n    Raises\n    ------\n    ValueError\n        If multiple instances of N2VManipulate are found.\n    \"\"\"\n    transform_list = [t.name for t in transforms]\n\n    if SupportedTransform.N2V_MANIPULATE in transform_list:\n        # multiple N2V_MANIPULATE\n        if transform_list.count(SupportedTransform.N2V_MANIPULATE.value) &gt; 1:\n            raise ValueError(\n                f\"Multiple instances of \"\n                f\"{SupportedTransform.N2V_MANIPULATE} transforms \"\n                f\"are not allowed.\"\n            )\n\n        # N2V_MANIPULATE not the last transform\n        elif transform_list[-1] != SupportedTransform.N2V_MANIPULATE:\n            index = transform_list.index(SupportedTransform.N2V_MANIPULATE.value)\n            transform = transforms.pop(index)\n            transforms.append(transform)\n\n    return transforms\n</code></pre>"},{"location":"reference/careamics/config/inference_model/","title":"inference_model","text":"<p>Pydantic model representing CAREamics prediction configuration.</p>"},{"location":"reference/careamics/config/inference_model/#careamics.config.inference_model.InferenceConfig","title":"<code>InferenceConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration class for the prediction model.</p> Source code in <code>src/careamics/config/inference_model.py</code> <pre><code>class InferenceConfig(BaseModel):\n    \"\"\"Configuration class for the prediction model.\"\"\"\n\n    model_config = ConfigDict(validate_assignment=True, arbitrary_types_allowed=True)\n\n    # Mandatory fields\n    data_type: Literal[\"array\", \"tiff\", \"custom\"]  # As defined in SupportedData\n    tile_size: Optional[Union[List[int]]] = Field(\n        default=None, min_length=2, max_length=3\n    )\n    tile_overlap: Optional[Union[List[int]]] = Field(\n        default=None, min_length=2, max_length=3\n    )\n\n    axes: str\n\n    mean: float\n    std: float = Field(..., ge=0.0)\n\n    # only default TTAs are supported for now\n    tta_transforms: bool = Field(default=True)\n\n    # Dataloader parameters\n    batch_size: int = Field(default=1, ge=1)\n\n    @field_validator(\"tile_overlap\")\n    @classmethod\n    def all_elements_non_zero_even(\n        cls, tile_overlap: Optional[Union[List[int]]]\n    ) -&gt; Optional[Union[List[int]]]:\n        \"\"\"\n        Validate tile overlap.\n\n        Overlaps must be non-zero, positive and even.\n\n        Parameters\n        ----------\n        tile_overlap : Optional[Union[List[int]]]\n            Patch size.\n\n        Returns\n        -------\n        Optional[Union[List[int]]]\n            Validated tile overlap.\n\n        Raises\n        ------\n        ValueError\n            If the patch size is 0.\n        ValueError\n            If the patch size is not even.\n        \"\"\"\n        if tile_overlap is not None:\n            for dim in tile_overlap:\n                if dim &lt; 1:\n                    raise ValueError(\n                        f\"Patch size must be non-zero positive (got {dim}).\"\n                    )\n\n                if dim % 2 != 0:\n                    raise ValueError(f\"Patch size must be even (got {dim}).\")\n\n        return tile_overlap\n\n    @field_validator(\"tile_size\")\n    @classmethod\n    def tile_min_8_power_of_2(\n        cls, tile_list: Optional[Union[List[int]]]\n    ) -&gt; Optional[Union[List[int]]]:\n        \"\"\"\n        Validate that each entry is greater or equal than 8 and a power of 2.\n\n        Parameters\n        ----------\n        tile_list : List[int]\n            Patch size.\n\n        Returns\n        -------\n        List[int]\n            Validated patch size.\n\n        Raises\n        ------\n        ValueError\n            If the patch size if smaller than 8.\n        ValueError\n            If the patch size is not a power of 2.\n        \"\"\"\n        patch_size_ge_than_8_power_of_2(tile_list)\n\n        return tile_list\n\n    @field_validator(\"axes\")\n    @classmethod\n    def axes_valid(cls, axes: str) -&gt; str:\n        \"\"\"\n        Validate axes.\n\n        Axes must:\n        - be a combination of 'STCZYX'\n        - not contain duplicates\n        - contain at least 2 contiguous axes: X and Y\n        - contain at most 4 axes\n        - not contain both S and T axes\n\n        Parameters\n        ----------\n        axes : str\n            Axes to validate.\n\n        Returns\n        -------\n        str\n            Validated axes.\n\n        Raises\n        ------\n        ValueError\n            If axes are not valid.\n        \"\"\"\n        # Validate axes\n        check_axes_validity(axes)\n\n        return axes\n\n    @model_validator(mode=\"after\")\n    def validate_dimensions(self: Self) -&gt; Self:\n        \"\"\"\n        Validate 2D/3D dimensions between axes and tile size.\n\n        Returns\n        -------\n        Self\n            Validated prediction model.\n        \"\"\"\n        expected_len = 3 if \"Z\" in self.axes else 2\n\n        if self.tile_size is not None and self.tile_overlap is not None:\n            if len(self.tile_size) != expected_len:\n                raise ValueError(\n                    f\"Tile size must have {expected_len} dimensions given axes \"\n                    f\"{self.axes} (got {self.tile_size}).\"\n                )\n\n            if len(self.tile_overlap) != expected_len:\n                raise ValueError(\n                    f\"Tile overlap must have {expected_len} dimensions given axes \"\n                    f\"{self.axes} (got {self.tile_overlap}).\"\n                )\n\n            if any((i &gt;= j) for i, j in zip(self.tile_overlap, self.tile_size)):\n                raise ValueError(\"Tile overlap must be smaller than tile size.\")\n\n        return self\n\n    @model_validator(mode=\"after\")\n    def std_only_with_mean(self: Self) -&gt; Self:\n        \"\"\"\n        Check that mean and std are either both None, or both specified.\n\n        Returns\n        -------\n        Self\n            Validated prediction model.\n\n        Raises\n        ------\n        ValueError\n            If std is not None and mean is None.\n        \"\"\"\n        # check that mean and std are either both None, or both specified\n        if (self.mean is None) != (self.std is None):\n            raise ValueError(\n                \"Mean and std must be either both None, or both specified.\"\n            )\n\n        return self\n\n    def _update(self, **kwargs: Any) -&gt; None:\n        \"\"\"\n        Update multiple arguments at once.\n\n        Parameters\n        ----------\n        **kwargs : Any\n            Key-value pairs of arguments to update.\n        \"\"\"\n        self.__dict__.update(kwargs)\n        self.__class__.model_validate(self.__dict__)\n\n    def set_3D(self, axes: str, tile_size: List[int], tile_overlap: List[int]) -&gt; None:\n        \"\"\"\n        Set 3D parameters.\n\n        Parameters\n        ----------\n        axes : str\n            Axes.\n        tile_size : List[int]\n            Tile size.\n        tile_overlap : List[int]\n            Tile overlap.\n        \"\"\"\n        self._update(axes=axes, tile_size=tile_size, tile_overlap=tile_overlap)\n</code></pre>"},{"location":"reference/careamics/config/inference_model/#careamics.config.inference_model.InferenceConfig.all_elements_non_zero_even","title":"<code>all_elements_non_zero_even(tile_overlap)</code>  <code>classmethod</code>","text":"<p>Validate tile overlap.</p> <p>Overlaps must be non-zero, positive and even.</p> <p>Parameters:</p> Name Type Description Default <code>tile_overlap</code> <code>Optional[Union[List[int]]]</code> <p>Patch size.</p> required <p>Returns:</p> Type Description <code>Optional[Union[List[int]]]</code> <p>Validated tile overlap.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the patch size is 0.</p> <code>ValueError</code> <p>If the patch size is not even.</p> Source code in <code>src/careamics/config/inference_model.py</code> <pre><code>@field_validator(\"tile_overlap\")\n@classmethod\ndef all_elements_non_zero_even(\n    cls, tile_overlap: Optional[Union[List[int]]]\n) -&gt; Optional[Union[List[int]]]:\n    \"\"\"\n    Validate tile overlap.\n\n    Overlaps must be non-zero, positive and even.\n\n    Parameters\n    ----------\n    tile_overlap : Optional[Union[List[int]]]\n        Patch size.\n\n    Returns\n    -------\n    Optional[Union[List[int]]]\n        Validated tile overlap.\n\n    Raises\n    ------\n    ValueError\n        If the patch size is 0.\n    ValueError\n        If the patch size is not even.\n    \"\"\"\n    if tile_overlap is not None:\n        for dim in tile_overlap:\n            if dim &lt; 1:\n                raise ValueError(\n                    f\"Patch size must be non-zero positive (got {dim}).\"\n                )\n\n            if dim % 2 != 0:\n                raise ValueError(f\"Patch size must be even (got {dim}).\")\n\n    return tile_overlap\n</code></pre>"},{"location":"reference/careamics/config/inference_model/#careamics.config.inference_model.InferenceConfig.axes_valid","title":"<code>axes_valid(axes)</code>  <code>classmethod</code>","text":"<p>Validate axes.</p> <p>Axes must: - be a combination of 'STCZYX' - not contain duplicates - contain at least 2 contiguous axes: X and Y - contain at most 4 axes - not contain both S and T axes</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>str</code> <p>Axes to validate.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Validated axes.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If axes are not valid.</p> Source code in <code>src/careamics/config/inference_model.py</code> <pre><code>@field_validator(\"axes\")\n@classmethod\ndef axes_valid(cls, axes: str) -&gt; str:\n    \"\"\"\n    Validate axes.\n\n    Axes must:\n    - be a combination of 'STCZYX'\n    - not contain duplicates\n    - contain at least 2 contiguous axes: X and Y\n    - contain at most 4 axes\n    - not contain both S and T axes\n\n    Parameters\n    ----------\n    axes : str\n        Axes to validate.\n\n    Returns\n    -------\n    str\n        Validated axes.\n\n    Raises\n    ------\n    ValueError\n        If axes are not valid.\n    \"\"\"\n    # Validate axes\n    check_axes_validity(axes)\n\n    return axes\n</code></pre>"},{"location":"reference/careamics/config/inference_model/#careamics.config.inference_model.InferenceConfig.set_3D","title":"<code>set_3D(axes, tile_size, tile_overlap)</code>","text":"<p>Set 3D parameters.</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>str</code> <p>Axes.</p> required <code>tile_size</code> <code>List[int]</code> <p>Tile size.</p> required <code>tile_overlap</code> <code>List[int]</code> <p>Tile overlap.</p> required Source code in <code>src/careamics/config/inference_model.py</code> <pre><code>def set_3D(self, axes: str, tile_size: List[int], tile_overlap: List[int]) -&gt; None:\n    \"\"\"\n    Set 3D parameters.\n\n    Parameters\n    ----------\n    axes : str\n        Axes.\n    tile_size : List[int]\n        Tile size.\n    tile_overlap : List[int]\n        Tile overlap.\n    \"\"\"\n    self._update(axes=axes, tile_size=tile_size, tile_overlap=tile_overlap)\n</code></pre>"},{"location":"reference/careamics/config/inference_model/#careamics.config.inference_model.InferenceConfig.std_only_with_mean","title":"<code>std_only_with_mean()</code>","text":"<p>Check that mean and std are either both None, or both specified.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Validated prediction model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If std is not None and mean is None.</p> Source code in <code>src/careamics/config/inference_model.py</code> <pre><code>@model_validator(mode=\"after\")\ndef std_only_with_mean(self: Self) -&gt; Self:\n    \"\"\"\n    Check that mean and std are either both None, or both specified.\n\n    Returns\n    -------\n    Self\n        Validated prediction model.\n\n    Raises\n    ------\n    ValueError\n        If std is not None and mean is None.\n    \"\"\"\n    # check that mean and std are either both None, or both specified\n    if (self.mean is None) != (self.std is None):\n        raise ValueError(\n            \"Mean and std must be either both None, or both specified.\"\n        )\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/inference_model/#careamics.config.inference_model.InferenceConfig.tile_min_8_power_of_2","title":"<code>tile_min_8_power_of_2(tile_list)</code>  <code>classmethod</code>","text":"<p>Validate that each entry is greater or equal than 8 and a power of 2.</p> <p>Parameters:</p> Name Type Description Default <code>tile_list</code> <code>List[int]</code> <p>Patch size.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>Validated patch size.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the patch size if smaller than 8.</p> <code>ValueError</code> <p>If the patch size is not a power of 2.</p> Source code in <code>src/careamics/config/inference_model.py</code> <pre><code>@field_validator(\"tile_size\")\n@classmethod\ndef tile_min_8_power_of_2(\n    cls, tile_list: Optional[Union[List[int]]]\n) -&gt; Optional[Union[List[int]]]:\n    \"\"\"\n    Validate that each entry is greater or equal than 8 and a power of 2.\n\n    Parameters\n    ----------\n    tile_list : List[int]\n        Patch size.\n\n    Returns\n    -------\n    List[int]\n        Validated patch size.\n\n    Raises\n    ------\n    ValueError\n        If the patch size if smaller than 8.\n    ValueError\n        If the patch size is not a power of 2.\n    \"\"\"\n    patch_size_ge_than_8_power_of_2(tile_list)\n\n    return tile_list\n</code></pre>"},{"location":"reference/careamics/config/inference_model/#careamics.config.inference_model.InferenceConfig.validate_dimensions","title":"<code>validate_dimensions()</code>","text":"<p>Validate 2D/3D dimensions between axes and tile size.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Validated prediction model.</p> Source code in <code>src/careamics/config/inference_model.py</code> <pre><code>@model_validator(mode=\"after\")\ndef validate_dimensions(self: Self) -&gt; Self:\n    \"\"\"\n    Validate 2D/3D dimensions between axes and tile size.\n\n    Returns\n    -------\n    Self\n        Validated prediction model.\n    \"\"\"\n    expected_len = 3 if \"Z\" in self.axes else 2\n\n    if self.tile_size is not None and self.tile_overlap is not None:\n        if len(self.tile_size) != expected_len:\n            raise ValueError(\n                f\"Tile size must have {expected_len} dimensions given axes \"\n                f\"{self.axes} (got {self.tile_size}).\"\n            )\n\n        if len(self.tile_overlap) != expected_len:\n            raise ValueError(\n                f\"Tile overlap must have {expected_len} dimensions given axes \"\n                f\"{self.axes} (got {self.tile_overlap}).\"\n            )\n\n        if any((i &gt;= j) for i, j in zip(self.tile_overlap, self.tile_size)):\n            raise ValueError(\"Tile overlap must be smaller than tile size.\")\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/optimizer_models/","title":"optimizer_models","text":"<p>Optimizers and schedulers Pydantic models.</p>"},{"location":"reference/careamics/config/optimizer_models/#careamics.config.optimizer_models.LrSchedulerModel","title":"<code>LrSchedulerModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Torch learning rate scheduler Pydantic model.</p> <p>Only parameters supported by the corresponding torch lr scheduler will be taken into account. For more details, check: https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate</p> <p>Note that mandatory parameters (see the specific LrScheduler signature in the link above) must be provided. For example, StepLR requires <code>step_size</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>TorchLRScheduler</code> <p>Name of the learning rate scheduler.</p> <code>parameters</code> <code>dict</code> <p>Parameters of the learning rate scheduler (see torch documentation).</p> Source code in <code>src/careamics/config/optimizer_models.py</code> <pre><code>class LrSchedulerModel(BaseModel):\n    \"\"\"Torch learning rate scheduler Pydantic model.\n\n    Only parameters supported by the corresponding torch lr scheduler will be taken\n    into account. For more details, check:\n    https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n\n    Note that mandatory parameters (see the specific LrScheduler signature in the\n    link above) must be provided. For example, StepLR requires `step_size`.\n\n    Attributes\n    ----------\n    name : TorchLRScheduler\n        Name of the learning rate scheduler.\n    parameters : dict\n        Parameters of the learning rate scheduler (see torch documentation).\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    # Mandatory field\n    name: Literal[\"ReduceLROnPlateau\", \"StepLR\"] = Field(default=\"ReduceLROnPlateau\")\n\n    # Optional parameters\n    parameters: dict = Field(default={}, validate_default=True)\n\n    @field_validator(\"parameters\")\n    @classmethod\n    def filter_parameters(cls, user_params: dict, values: ValidationInfo) -&gt; Dict:\n        \"\"\"Filter parameters based on the learning rate scheduler's signature.\n\n        Parameters\n        ----------\n        user_params : dict\n            User parameters.\n        values : ValidationInfo\n            Pydantic field validation info, used to get the scheduler name.\n\n        Returns\n        -------\n        Dict\n            Filtered scheduler parameters.\n\n        Raises\n        ------\n        ValueError\n            If the scheduler is StepLR and the step_size parameter is not specified.\n        \"\"\"\n        # retrieve the corresponding scheduler class\n        scheduler_class = getattr(optim.lr_scheduler, values.data[\"name\"])\n\n        # filter the user parameters according to the scheduler's signature\n        parameters = filter_parameters(scheduler_class, user_params)\n\n        if values.data[\"name\"] == \"StepLR\" and \"step_size\" not in parameters:\n            raise ValueError(\n                \"StepLR scheduler requires `step_size` parameter, check that it has \"\n                \"correctly been specified in `parameters`.\"\n            )\n\n        return parameters\n</code></pre>"},{"location":"reference/careamics/config/optimizer_models/#careamics.config.optimizer_models.LrSchedulerModel.filter_parameters","title":"<code>filter_parameters(user_params, values)</code>  <code>classmethod</code>","text":"<p>Filter parameters based on the learning rate scheduler's signature.</p> <p>Parameters:</p> Name Type Description Default <code>user_params</code> <code>dict</code> <p>User parameters.</p> required <code>values</code> <code>ValidationInfo</code> <p>Pydantic field validation info, used to get the scheduler name.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Filtered scheduler parameters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the scheduler is StepLR and the step_size parameter is not specified.</p> Source code in <code>src/careamics/config/optimizer_models.py</code> <pre><code>@field_validator(\"parameters\")\n@classmethod\ndef filter_parameters(cls, user_params: dict, values: ValidationInfo) -&gt; Dict:\n    \"\"\"Filter parameters based on the learning rate scheduler's signature.\n\n    Parameters\n    ----------\n    user_params : dict\n        User parameters.\n    values : ValidationInfo\n        Pydantic field validation info, used to get the scheduler name.\n\n    Returns\n    -------\n    Dict\n        Filtered scheduler parameters.\n\n    Raises\n    ------\n    ValueError\n        If the scheduler is StepLR and the step_size parameter is not specified.\n    \"\"\"\n    # retrieve the corresponding scheduler class\n    scheduler_class = getattr(optim.lr_scheduler, values.data[\"name\"])\n\n    # filter the user parameters according to the scheduler's signature\n    parameters = filter_parameters(scheduler_class, user_params)\n\n    if values.data[\"name\"] == \"StepLR\" and \"step_size\" not in parameters:\n        raise ValueError(\n            \"StepLR scheduler requires `step_size` parameter, check that it has \"\n            \"correctly been specified in `parameters`.\"\n        )\n\n    return parameters\n</code></pre>"},{"location":"reference/careamics/config/optimizer_models/#careamics.config.optimizer_models.OptimizerModel","title":"<code>OptimizerModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Torch optimizer Pydantic model.</p> <p>Only parameters supported by the corresponding torch optimizer will be taken into account. For more details, check: https://pytorch.org/docs/stable/optim.html#algorithms</p> <p>Note that mandatory parameters (see the specific Optimizer signature in the link above) must be provided. For example, SGD requires <code>lr</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>TorchOptimizer</code> <p>Name of the optimizer.</p> <code>parameters</code> <code>dict</code> <p>Parameters of the optimizer (see torch documentation).</p> Source code in <code>src/careamics/config/optimizer_models.py</code> <pre><code>class OptimizerModel(BaseModel):\n    \"\"\"Torch optimizer Pydantic model.\n\n    Only parameters supported by the corresponding torch optimizer will be taken\n    into account. For more details, check:\n    https://pytorch.org/docs/stable/optim.html#algorithms\n\n    Note that mandatory parameters (see the specific Optimizer signature in the\n    link above) must be provided. For example, SGD requires `lr`.\n\n    Attributes\n    ----------\n    name : TorchOptimizer\n        Name of the optimizer.\n    parameters : dict\n        Parameters of the optimizer (see torch documentation).\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    # Mandatory field\n    name: Literal[\"Adam\", \"SGD\"] = Field(default=\"Adam\", validate_default=True)\n\n    # Optional parameters, empty dict default value to allow filtering dictionary\n    parameters: dict = Field(\n        default={\n            \"lr\": 1e-4,\n        },\n        validate_default=True,\n    )\n\n    @field_validator(\"parameters\")\n    @classmethod\n    def filter_parameters(cls, user_params: dict, values: ValidationInfo) -&gt; Dict:\n        \"\"\"\n        Validate optimizer parameters.\n\n        This method filters out unknown parameters, given the optimizer name.\n\n        Parameters\n        ----------\n        user_params : dict\n            Parameters passed on to the torch optimizer.\n        values : ValidationInfo\n            Pydantic field validation info, used to get the optimizer name.\n\n        Returns\n        -------\n        Dict\n            Filtered optimizer parameters.\n\n        Raises\n        ------\n        ValueError\n            If the optimizer name is not specified.\n        \"\"\"\n        optimizer_name = values.data[\"name\"]\n\n        # retrieve the corresponding optimizer class\n        optimizer_class = getattr(optim, optimizer_name)\n\n        # filter the user parameters according to the optimizer's signature\n        parameters = filter_parameters(optimizer_class, user_params)\n\n        return parameters\n\n    @model_validator(mode=\"after\")\n    def sgd_lr_parameter(self) -&gt; Self:\n        \"\"\"\n        Check that SGD optimizer has the mandatory `lr` parameter specified.\n\n        This is specific for PyTorch &lt; 2.2.\n\n        Returns\n        -------\n        Self\n            Validated optimizer.\n\n        Raises\n        ------\n        ValueError\n            If the optimizer is SGD and the lr parameter is not specified.\n        \"\"\"\n        if self.name == SupportedOptimizer.SGD and \"lr\" not in self.parameters:\n            raise ValueError(\n                \"SGD optimizer requires `lr` parameter, check that it has correctly \"\n                \"been specified in `parameters`.\"\n            )\n\n        return self\n</code></pre>"},{"location":"reference/careamics/config/optimizer_models/#careamics.config.optimizer_models.OptimizerModel.filter_parameters","title":"<code>filter_parameters(user_params, values)</code>  <code>classmethod</code>","text":"<p>Validate optimizer parameters.</p> <p>This method filters out unknown parameters, given the optimizer name.</p> <p>Parameters:</p> Name Type Description Default <code>user_params</code> <code>dict</code> <p>Parameters passed on to the torch optimizer.</p> required <code>values</code> <code>ValidationInfo</code> <p>Pydantic field validation info, used to get the optimizer name.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Filtered optimizer parameters.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the optimizer name is not specified.</p> Source code in <code>src/careamics/config/optimizer_models.py</code> <pre><code>@field_validator(\"parameters\")\n@classmethod\ndef filter_parameters(cls, user_params: dict, values: ValidationInfo) -&gt; Dict:\n    \"\"\"\n    Validate optimizer parameters.\n\n    This method filters out unknown parameters, given the optimizer name.\n\n    Parameters\n    ----------\n    user_params : dict\n        Parameters passed on to the torch optimizer.\n    values : ValidationInfo\n        Pydantic field validation info, used to get the optimizer name.\n\n    Returns\n    -------\n    Dict\n        Filtered optimizer parameters.\n\n    Raises\n    ------\n    ValueError\n        If the optimizer name is not specified.\n    \"\"\"\n    optimizer_name = values.data[\"name\"]\n\n    # retrieve the corresponding optimizer class\n    optimizer_class = getattr(optim, optimizer_name)\n\n    # filter the user parameters according to the optimizer's signature\n    parameters = filter_parameters(optimizer_class, user_params)\n\n    return parameters\n</code></pre>"},{"location":"reference/careamics/config/optimizer_models/#careamics.config.optimizer_models.OptimizerModel.sgd_lr_parameter","title":"<code>sgd_lr_parameter()</code>","text":"<p>Check that SGD optimizer has the mandatory <code>lr</code> parameter specified.</p> <p>This is specific for PyTorch &lt; 2.2.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Validated optimizer.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the optimizer is SGD and the lr parameter is not specified.</p> Source code in <code>src/careamics/config/optimizer_models.py</code> <pre><code>@model_validator(mode=\"after\")\ndef sgd_lr_parameter(self) -&gt; Self:\n    \"\"\"\n    Check that SGD optimizer has the mandatory `lr` parameter specified.\n\n    This is specific for PyTorch &lt; 2.2.\n\n    Returns\n    -------\n    Self\n        Validated optimizer.\n\n    Raises\n    ------\n    ValueError\n        If the optimizer is SGD and the lr parameter is not specified.\n    \"\"\"\n    if self.name == SupportedOptimizer.SGD and \"lr\" not in self.parameters:\n        raise ValueError(\n            \"SGD optimizer requires `lr` parameter, check that it has correctly \"\n            \"been specified in `parameters`.\"\n        )\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/tile_information/","title":"tile_information","text":"<p>Pydantic model representing the metadata of a prediction tile.</p>"},{"location":"reference/careamics/config/tile_information/#careamics.config.tile_information.TileInformation","title":"<code>TileInformation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pydantic model containing tile information.</p> <p>This model is used to represent the information required to stitch back a tile into a larger image. It is used throughout the prediction pipeline of CAREamics.</p> Source code in <code>src/careamics/config/tile_information.py</code> <pre><code>class TileInformation(BaseModel):\n    \"\"\"\n    Pydantic model containing tile information.\n\n    This model is used to represent the information required to stitch back a tile into\n    a larger image. It is used throughout the prediction pipeline of CAREamics.\n    \"\"\"\n\n    model_config = ConfigDict(validate_default=True)\n\n    array_shape: Tuple[int, ...]\n    tiled: bool = False\n    last_tile: bool = False\n    overlap_crop_coords: Optional[Tuple[Tuple[int, ...], ...]] = Field(default=None)\n    stitch_coords: Optional[Tuple[Tuple[int, ...], ...]] = Field(default=None)\n\n    @field_validator(\"array_shape\")\n    @classmethod\n    def no_singleton_dimensions(cls, v: Tuple[int, ...]):\n        \"\"\"\n        Check that the array shape does not have any singleton dimensions.\n\n        Parameters\n        ----------\n        v : Tuple[int, ...]\n            Array shape to check.\n\n        Returns\n        -------\n        Tuple[int, ...]\n            The array shape if it does not contain singleton dimensions.\n\n        Raises\n        ------\n        ValueError\n            If the array shape contains singleton dimensions.\n        \"\"\"\n        if any(dim == 1 for dim in v):\n            raise ValueError(\"Array shape must not contain singleton dimensions.\")\n        return v\n\n    @field_validator(\"last_tile\")\n    @classmethod\n    def only_if_tiled(cls, v: bool, values: ValidationInfo):\n        \"\"\"\n        Check that the last tile flag is only set if tiling is enabled.\n\n        Parameters\n        ----------\n        v : bool\n            Last tile flag.\n        values : ValidationInfo\n            Validation information.\n\n        Returns\n        -------\n        bool\n            The last tile flag.\n        \"\"\"\n        if not values.data[\"tiled\"]:\n            return False\n        return v\n\n    @field_validator(\"overlap_crop_coords\", \"stitch_coords\")\n    @classmethod\n    def mandatory_if_tiled(\n        cls, v: Optional[Tuple[int, ...]], values: ValidationInfo\n    ) -&gt; Optional[Tuple[int, ...]]:\n        \"\"\"\n        Check that the coordinates are not `None` if tiling is enabled.\n\n        The method also return `None` if tiling is not enabled.\n\n        Parameters\n        ----------\n        v : Optional[Tuple[int, ...]]\n            Coordinates to check.\n        values : ValidationInfo\n            Validation information.\n\n        Returns\n        -------\n        Optional[Tuple[int, ...]]\n            The coordinates if tiling is enabled, otherwise `None`.\n\n        Raises\n        ------\n        ValueError\n            If the coordinates are `None` and tiling is enabled.\n        \"\"\"\n        if values.data[\"tiled\"]:\n            if v is None:\n                raise ValueError(\"Value must be specified if tiling is enabled.\")\n\n            return v\n        else:\n            return None\n</code></pre>"},{"location":"reference/careamics/config/tile_information/#careamics.config.tile_information.TileInformation.mandatory_if_tiled","title":"<code>mandatory_if_tiled(v, values)</code>  <code>classmethod</code>","text":"<p>Check that the coordinates are not <code>None</code> if tiling is enabled.</p> <p>The method also return <code>None</code> if tiling is not enabled.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Optional[Tuple[int, ...]]</code> <p>Coordinates to check.</p> required <code>values</code> <code>ValidationInfo</code> <p>Validation information.</p> required <p>Returns:</p> Type Description <code>Optional[Tuple[int, ...]]</code> <p>The coordinates if tiling is enabled, otherwise <code>None</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the coordinates are <code>None</code> and tiling is enabled.</p> Source code in <code>src/careamics/config/tile_information.py</code> <pre><code>@field_validator(\"overlap_crop_coords\", \"stitch_coords\")\n@classmethod\ndef mandatory_if_tiled(\n    cls, v: Optional[Tuple[int, ...]], values: ValidationInfo\n) -&gt; Optional[Tuple[int, ...]]:\n    \"\"\"\n    Check that the coordinates are not `None` if tiling is enabled.\n\n    The method also return `None` if tiling is not enabled.\n\n    Parameters\n    ----------\n    v : Optional[Tuple[int, ...]]\n        Coordinates to check.\n    values : ValidationInfo\n        Validation information.\n\n    Returns\n    -------\n    Optional[Tuple[int, ...]]\n        The coordinates if tiling is enabled, otherwise `None`.\n\n    Raises\n    ------\n    ValueError\n        If the coordinates are `None` and tiling is enabled.\n    \"\"\"\n    if values.data[\"tiled\"]:\n        if v is None:\n            raise ValueError(\"Value must be specified if tiling is enabled.\")\n\n        return v\n    else:\n        return None\n</code></pre>"},{"location":"reference/careamics/config/tile_information/#careamics.config.tile_information.TileInformation.no_singleton_dimensions","title":"<code>no_singleton_dimensions(v)</code>  <code>classmethod</code>","text":"<p>Check that the array shape does not have any singleton dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>Tuple[int, ...]</code> <p>Array shape to check.</p> required <p>Returns:</p> Type Description <code>Tuple[int, ...]</code> <p>The array shape if it does not contain singleton dimensions.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the array shape contains singleton dimensions.</p> Source code in <code>src/careamics/config/tile_information.py</code> <pre><code>@field_validator(\"array_shape\")\n@classmethod\ndef no_singleton_dimensions(cls, v: Tuple[int, ...]):\n    \"\"\"\n    Check that the array shape does not have any singleton dimensions.\n\n    Parameters\n    ----------\n    v : Tuple[int, ...]\n        Array shape to check.\n\n    Returns\n    -------\n    Tuple[int, ...]\n        The array shape if it does not contain singleton dimensions.\n\n    Raises\n    ------\n    ValueError\n        If the array shape contains singleton dimensions.\n    \"\"\"\n    if any(dim == 1 for dim in v):\n        raise ValueError(\"Array shape must not contain singleton dimensions.\")\n    return v\n</code></pre>"},{"location":"reference/careamics/config/tile_information/#careamics.config.tile_information.TileInformation.only_if_tiled","title":"<code>only_if_tiled(v, values)</code>  <code>classmethod</code>","text":"<p>Check that the last tile flag is only set if tiling is enabled.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>bool</code> <p>Last tile flag.</p> required <code>values</code> <code>ValidationInfo</code> <p>Validation information.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>The last tile flag.</p> Source code in <code>src/careamics/config/tile_information.py</code> <pre><code>@field_validator(\"last_tile\")\n@classmethod\ndef only_if_tiled(cls, v: bool, values: ValidationInfo):\n    \"\"\"\n    Check that the last tile flag is only set if tiling is enabled.\n\n    Parameters\n    ----------\n    v : bool\n        Last tile flag.\n    values : ValidationInfo\n        Validation information.\n\n    Returns\n    -------\n    bool\n        The last tile flag.\n    \"\"\"\n    if not values.data[\"tiled\"]:\n        return False\n    return v\n</code></pre>"},{"location":"reference/careamics/config/training_model/","title":"training_model","text":"<p>Training configuration.</p>"},{"location":"reference/careamics/config/training_model/#careamics.config.training_model.TrainingConfig","title":"<code>TrainingConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Parameters related to the training.</p> <p>Mandatory parameters are:     - num_epochs: number of epochs, greater than 0.     - batch_size: batch size, greater than 0.     - augmentation: whether to use data augmentation or not (True or False).</p> <p>Attributes:</p> Name Type Description <code>num_epochs</code> <code>int</code> <p>Number of epochs, greater than 0.</p> Source code in <code>src/careamics/config/training_model.py</code> <pre><code>class TrainingConfig(BaseModel):\n    \"\"\"\n    Parameters related to the training.\n\n    Mandatory parameters are:\n        - num_epochs: number of epochs, greater than 0.\n        - batch_size: batch size, greater than 0.\n        - augmentation: whether to use data augmentation or not (True or False).\n\n    Attributes\n    ----------\n    num_epochs : int\n        Number of epochs, greater than 0.\n    \"\"\"\n\n    # Pydantic class configuration\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    num_epochs: int = Field(default=20, ge=1)\n\n    logger: Optional[Literal[\"wandb\", \"tensorboard\"]] = None\n\n    checkpoint_callback: CheckpointModel = CheckpointModel()\n\n    early_stopping_callback: Optional[EarlyStoppingModel] = Field(\n        default=None, validate_default=True\n    )\n    # precision: Literal[\"64\", \"32\", \"16\", \"bf16\"] = 32\n\n    def __str__(self) -&gt; str:\n        \"\"\"Pretty string reprensenting the configuration.\n\n        Returns\n        -------\n        str\n            Pretty string.\n        \"\"\"\n        return pformat(self.model_dump())\n\n    def has_logger(self) -&gt; bool:\n        \"\"\"Check if the logger is defined.\n\n        Returns\n        -------\n        bool\n            Whether the logger is defined or not.\n        \"\"\"\n        return self.logger is not None\n</code></pre>"},{"location":"reference/careamics/config/training_model/#careamics.config.training_model.TrainingConfig.__str__","title":"<code>__str__()</code>","text":"<p>Pretty string reprensenting the configuration.</p> <p>Returns:</p> Type Description <code>str</code> <p>Pretty string.</p> Source code in <code>src/careamics/config/training_model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Pretty string reprensenting the configuration.\n\n    Returns\n    -------\n    str\n        Pretty string.\n    \"\"\"\n    return pformat(self.model_dump())\n</code></pre>"},{"location":"reference/careamics/config/training_model/#careamics.config.training_model.TrainingConfig.has_logger","title":"<code>has_logger()</code>","text":"<p>Check if the logger is defined.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the logger is defined or not.</p> Source code in <code>src/careamics/config/training_model.py</code> <pre><code>def has_logger(self) -&gt; bool:\n    \"\"\"Check if the logger is defined.\n\n    Returns\n    -------\n    bool\n        Whether the logger is defined or not.\n    \"\"\"\n    return self.logger is not None\n</code></pre>"},{"location":"reference/careamics/config/architectures/architecture_model/","title":"architecture_model","text":"<p>Base model for the various CAREamics architectures.</p>"},{"location":"reference/careamics/config/architectures/architecture_model/#careamics.config.architectures.architecture_model.ArchitectureModel","title":"<code>ArchitectureModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base Pydantic model for all model architectures.</p> <p>The <code>model_dump</code> method allows removing the <code>architecture</code> key from the model.</p> Source code in <code>src/careamics/config/architectures/architecture_model.py</code> <pre><code>class ArchitectureModel(BaseModel):\n    \"\"\"\n    Base Pydantic model for all model architectures.\n\n    The `model_dump` method allows removing the `architecture` key from the model.\n    \"\"\"\n\n    architecture: str\n\n    def model_dump(self, **kwargs: Any) -&gt; Dict[str, Any]:\n        \"\"\"\n        Dump the model as a dictionary, ignoring the architecture keyword.\n\n        Parameters\n        ----------\n        **kwargs : Any\n            Additional keyword arguments from Pydantic BaseModel model_dump method.\n\n        Returns\n        -------\n        dict[str, Any]\n            Model as a dictionnary.\n        \"\"\"\n        model_dict = super().model_dump(**kwargs)\n\n        # remove the architecture key\n        model_dict.pop(\"architecture\")\n\n        return model_dict\n</code></pre>"},{"location":"reference/careamics/config/architectures/architecture_model/#careamics.config.architectures.architecture_model.ArchitectureModel.model_dump","title":"<code>model_dump(**kwargs)</code>","text":"<p>Dump the model as a dictionary, ignoring the architecture keyword.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments from Pydantic BaseModel model_dump method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Model as a dictionnary.</p> Source code in <code>src/careamics/config/architectures/architecture_model.py</code> <pre><code>def model_dump(self, **kwargs: Any) -&gt; Dict[str, Any]:\n    \"\"\"\n    Dump the model as a dictionary, ignoring the architecture keyword.\n\n    Parameters\n    ----------\n    **kwargs : Any\n        Additional keyword arguments from Pydantic BaseModel model_dump method.\n\n    Returns\n    -------\n    dict[str, Any]\n        Model as a dictionnary.\n    \"\"\"\n    model_dict = super().model_dump(**kwargs)\n\n    # remove the architecture key\n    model_dict.pop(\"architecture\")\n\n    return model_dict\n</code></pre>"},{"location":"reference/careamics/config/architectures/custom_model/","title":"custom_model","text":"<p>Custom architecture Pydantic model.</p>"},{"location":"reference/careamics/config/architectures/custom_model/#careamics.config.architectures.custom_model.CustomModel","title":"<code>CustomModel</code>","text":"<p>               Bases: <code>ArchitectureModel</code></p> <p>Custom model configuration.</p> <p>This Pydantic model allows storing parameters for a custom model. In order for the model to be valid, the specific model needs to be registered using the <code>register_model</code> decorator, and its name correctly passed to this model configuration (see Examples).</p> <p>Attributes:</p> Name Type Description <code>architecture</code> <code>Literal['Custom']</code> <p>Discriminator for the custom model, must be set to \"Custom\".</p> <code>name</code> <code>str</code> <p>Name of the custom model.</p> <code>parameters</code> <code>CustomParametersModel</code> <p>Parameters of the custom model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the custom model <code>name</code> is unknown.</p> <code>ValueError</code> <p>If the custom model is not a torch Module subclass.</p> <code>ValueError</code> <p>If the custom model parameters are not valid.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from torch import nn, ones\n&gt;&gt;&gt; from careamics.config import CustomModel, register_model\n&gt;&gt;&gt; # Register a custom model\n&gt;&gt;&gt; @register_model(name=\"my_linear\")\n... class LinearModel(nn.Module):\n...    def __init__(self, in_features, out_features, *args, **kwargs):\n...        super().__init__()\n...        self.in_features = in_features\n...        self.out_features = out_features\n...        self.weight = nn.Parameter(ones(in_features, out_features))\n...        self.bias = nn.Parameter(ones(out_features))\n...    def forward(self, input):\n...        return (input @ self.weight) + self.bias\n...\n&gt;&gt;&gt; # Create a configuration\n&gt;&gt;&gt; config_dict = {\n...     \"architecture\": \"Custom\",\n...     \"name\": \"my_linear\",\n...     \"in_features\": 10,\n...     \"out_features\": 5,\n... }\n&gt;&gt;&gt; config = CustomModel(**config_dict)\n</code></pre> Source code in <code>src/careamics/config/architectures/custom_model.py</code> <pre><code>class CustomModel(ArchitectureModel):\n    \"\"\"Custom model configuration.\n\n    This Pydantic model allows storing parameters for a custom model. In order for the\n    model to be valid, the specific model needs to be registered using the\n    `register_model` decorator, and its name correctly passed to this model\n    configuration (see Examples).\n\n    Attributes\n    ----------\n    architecture : Literal[\"Custom\"]\n        Discriminator for the custom model, must be set to \"Custom\".\n    name : str\n        Name of the custom model.\n    parameters : CustomParametersModel\n        Parameters of the custom model.\n\n    Raises\n    ------\n    ValueError\n        If the custom model `name` is unknown.\n    ValueError\n        If the custom model is not a torch Module subclass.\n    ValueError\n        If the custom model parameters are not valid.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from torch import nn, ones\n    &gt;&gt;&gt; from careamics.config import CustomModel, register_model\n    &gt;&gt;&gt; # Register a custom model\n    &gt;&gt;&gt; @register_model(name=\"my_linear\")\n    ... class LinearModel(nn.Module):\n    ...    def __init__(self, in_features, out_features, *args, **kwargs):\n    ...        super().__init__()\n    ...        self.in_features = in_features\n    ...        self.out_features = out_features\n    ...        self.weight = nn.Parameter(ones(in_features, out_features))\n    ...        self.bias = nn.Parameter(ones(out_features))\n    ...    def forward(self, input):\n    ...        return (input @ self.weight) + self.bias\n    ...\n    &gt;&gt;&gt; # Create a configuration\n    &gt;&gt;&gt; config_dict = {\n    ...     \"architecture\": \"Custom\",\n    ...     \"name\": \"my_linear\",\n    ...     \"in_features\": 10,\n    ...     \"out_features\": 5,\n    ... }\n    &gt;&gt;&gt; config = CustomModel(**config_dict)\n    \"\"\"\n\n    # pydantic model config\n    model_config = ConfigDict(\n        extra=\"allow\",\n    )\n\n    # discriminator used for choosing the pydantic model in Model\n    architecture: Literal[\"Custom\"]\n\n    # name of the custom model\n    name: str\n\n    @field_validator(\"name\")\n    @classmethod\n    def custom_model_is_known(cls, value: str) -&gt; str:\n        \"\"\"Check whether the custom model is known.\n\n        Parameters\n        ----------\n        value : str\n            Name of the custom model as registered using the `@register_model`\n            decorator.\n\n        Returns\n        -------\n        str\n            The custom model name.\n        \"\"\"\n        # delegate error to get_custom_model\n        model = get_custom_model(value)\n\n        # check if it is a torch Module subclass\n        if not issubclass(model, Module):\n            raise ValueError(\n                f'Retrieved class {model} with name \"{value}\" is not a '\n                f\"torch.nn.Module subclass.\"\n            )\n\n        return value\n\n    @model_validator(mode=\"after\")\n    def check_parameters(self: Self) -&gt; Self:\n        \"\"\"Validate model by instantiating the model with the parameters.\n\n        Returns\n        -------\n        Self\n            The validated model.\n        \"\"\"\n        # instantiate model\n        try:\n            get_custom_model(self.name)(**self.model_dump())\n        except Exception as e:\n            raise ValueError(\n                f\"error while passing parameters to the model {e}. Verify that all \"\n                f\"mandatory parameters are provided, and that either the {e} accepts \"\n                f\"*args and **kwargs in its __init__() method, or that no additional\"\n                f\"parameter is provided.\"\n            ) from None\n\n        return self\n\n    def __str__(self) -&gt; str:\n        \"\"\"Pretty string representing the configuration.\n\n        Returns\n        -------\n        str\n            Pretty string.\n        \"\"\"\n        return pformat(self.model_dump())\n\n    def model_dump(self, **kwargs: Any) -&gt; Dict[str, Any]:\n        \"\"\"Dump the model configuration.\n\n        Parameters\n        ----------\n        **kwargs : Any\n            Additional keyword arguments from Pydantic BaseModel model_dump method.\n\n        Returns\n        -------\n        Dict[str, Any]\n            Model configuration.\n        \"\"\"\n        model_dict = super().model_dump()\n\n        # remove the name key\n        model_dict.pop(\"name\")\n\n        return model_dict\n</code></pre>"},{"location":"reference/careamics/config/architectures/custom_model/#careamics.config.architectures.custom_model.CustomModel.__str__","title":"<code>__str__()</code>","text":"<p>Pretty string representing the configuration.</p> <p>Returns:</p> Type Description <code>str</code> <p>Pretty string.</p> Source code in <code>src/careamics/config/architectures/custom_model.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Pretty string representing the configuration.\n\n    Returns\n    -------\n    str\n        Pretty string.\n    \"\"\"\n    return pformat(self.model_dump())\n</code></pre>"},{"location":"reference/careamics/config/architectures/custom_model/#careamics.config.architectures.custom_model.CustomModel.check_parameters","title":"<code>check_parameters()</code>","text":"<p>Validate model by instantiating the model with the parameters.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The validated model.</p> Source code in <code>src/careamics/config/architectures/custom_model.py</code> <pre><code>@model_validator(mode=\"after\")\ndef check_parameters(self: Self) -&gt; Self:\n    \"\"\"Validate model by instantiating the model with the parameters.\n\n    Returns\n    -------\n    Self\n        The validated model.\n    \"\"\"\n    # instantiate model\n    try:\n        get_custom_model(self.name)(**self.model_dump())\n    except Exception as e:\n        raise ValueError(\n            f\"error while passing parameters to the model {e}. Verify that all \"\n            f\"mandatory parameters are provided, and that either the {e} accepts \"\n            f\"*args and **kwargs in its __init__() method, or that no additional\"\n            f\"parameter is provided.\"\n        ) from None\n\n    return self\n</code></pre>"},{"location":"reference/careamics/config/architectures/custom_model/#careamics.config.architectures.custom_model.CustomModel.custom_model_is_known","title":"<code>custom_model_is_known(value)</code>  <code>classmethod</code>","text":"<p>Check whether the custom model is known.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Name of the custom model as registered using the <code>@register_model</code> decorator.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The custom model name.</p> Source code in <code>src/careamics/config/architectures/custom_model.py</code> <pre><code>@field_validator(\"name\")\n@classmethod\ndef custom_model_is_known(cls, value: str) -&gt; str:\n    \"\"\"Check whether the custom model is known.\n\n    Parameters\n    ----------\n    value : str\n        Name of the custom model as registered using the `@register_model`\n        decorator.\n\n    Returns\n    -------\n    str\n        The custom model name.\n    \"\"\"\n    # delegate error to get_custom_model\n    model = get_custom_model(value)\n\n    # check if it is a torch Module subclass\n    if not issubclass(model, Module):\n        raise ValueError(\n            f'Retrieved class {model} with name \"{value}\" is not a '\n            f\"torch.nn.Module subclass.\"\n        )\n\n    return value\n</code></pre>"},{"location":"reference/careamics/config/architectures/custom_model/#careamics.config.architectures.custom_model.CustomModel.model_dump","title":"<code>model_dump(**kwargs)</code>","text":"<p>Dump the model configuration.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments from Pydantic BaseModel model_dump method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Model configuration.</p> Source code in <code>src/careamics/config/architectures/custom_model.py</code> <pre><code>def model_dump(self, **kwargs: Any) -&gt; Dict[str, Any]:\n    \"\"\"Dump the model configuration.\n\n    Parameters\n    ----------\n    **kwargs : Any\n        Additional keyword arguments from Pydantic BaseModel model_dump method.\n\n    Returns\n    -------\n    Dict[str, Any]\n        Model configuration.\n    \"\"\"\n    model_dict = super().model_dump()\n\n    # remove the name key\n    model_dict.pop(\"name\")\n\n    return model_dict\n</code></pre>"},{"location":"reference/careamics/config/architectures/register_model/","title":"register_model","text":"<p>Custom model registration utilities.</p>"},{"location":"reference/careamics/config/architectures/register_model/#careamics.config.architectures.register_model.clear_custom_models","title":"<code>clear_custom_models()</code>","text":"<p>Clear the custom models registry.</p> Source code in <code>src/careamics/config/architectures/register_model.py</code> <pre><code>def clear_custom_models() -&gt; None:\n    \"\"\"Clear the custom models registry.\"\"\"\n    # clear dictionary\n    CUSTOM_MODELS.clear()\n</code></pre>"},{"location":"reference/careamics/config/architectures/register_model/#careamics.config.architectures.register_model.get_custom_model","title":"<code>get_custom_model(name)</code>","text":"<p>Get the custom model corresponding to <code>name</code> from the registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the model to retrieve.</p> required <p>Returns:</p> Type Description <code>Module</code> <p>The requested model.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model is not registered.</p> Source code in <code>src/careamics/config/architectures/register_model.py</code> <pre><code>def get_custom_model(name: str) -&gt; Module:\n    \"\"\"Get the custom model corresponding to `name` from the registry.\n\n    Parameters\n    ----------\n    name : str\n        Name of the model to retrieve.\n\n    Returns\n    -------\n    Module\n        The requested model.\n\n    Raises\n    ------\n    ValueError\n        If the model is not registered.\n    \"\"\"\n    if name not in CUSTOM_MODELS:\n        raise ValueError(\n            f\"Model {name} is unknown. Have you registered it using \"\n            f'@register_model(\"{name}\") as decorator?'\n        )\n\n    return CUSTOM_MODELS[name]\n</code></pre>"},{"location":"reference/careamics/config/architectures/register_model/#careamics.config.architectures.register_model.register_model","title":"<code>register_model(name)</code>","text":"<p>Decorator used to register a torch.nn.Module class with a given <code>name</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the model.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>Function allowing to instantiate the wrapped Module class.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a model is already registered with that name.</p> <p>Examples:</p> <pre><code>@register_model(name=\"linear\")\nclass LinearModel(nn.Module):\n    def __init__(self, in_features, out_features):\n        super().__init__()\n\n        self.weight = nn.Parameter(ones(in_features, out_features))\n        self.bias = nn.Parameter(ones(out_features))\n\n    def forward(self, input):\n        return (input @ self.weight) + self.bias\n</code></pre> Source code in <code>src/careamics/config/architectures/register_model.py</code> <pre><code>def register_model(name: str) -&gt; Callable:\n    \"\"\"Decorator used to register a torch.nn.Module class with a given `name`.\n\n    Parameters\n    ----------\n    name : str\n        Name of the model.\n\n    Returns\n    -------\n    Callable\n        Function allowing to instantiate the wrapped Module class.\n\n    Raises\n    ------\n    ValueError\n        If a model is already registered with that name.\n\n    Examples\n    --------\n    ```python\n    @register_model(name=\"linear\")\n    class LinearModel(nn.Module):\n        def __init__(self, in_features, out_features):\n            super().__init__()\n\n            self.weight = nn.Parameter(ones(in_features, out_features))\n            self.bias = nn.Parameter(ones(out_features))\n\n        def forward(self, input):\n            return (input @ self.weight) + self.bias\n    ```\n    \"\"\"\n    if name is None or name == \"\":\n        raise ValueError(\"Model name cannot be empty.\")\n\n    if name in CUSTOM_MODELS:\n        raise ValueError(\n            f\"Model {name} already exists. Choose a different name or run \"\n            f\"`clear_custom_models()` to empty the registry.\"\n        )\n\n    def add_custom_model(model: Module) -&gt; Module:\n        \"\"\"Add a custom model to the registry and return it.\n\n        Parameters\n        ----------\n        model : Module\n            Module class to register.\n\n        Returns\n        -------\n        Module\n            The registered model.\n        \"\"\"\n        # add model to the registry\n        CUSTOM_MODELS[name] = model\n\n        return model\n\n    return add_custom_model\n</code></pre>"},{"location":"reference/careamics/config/architectures/unet_model/","title":"unet_model","text":"<p>UNet Pydantic model.</p>"},{"location":"reference/careamics/config/architectures/unet_model/#careamics.config.architectures.unet_model.UNetModel","title":"<code>UNetModel</code>","text":"<p>               Bases: <code>ArchitectureModel</code></p> <p>Pydantic model for a N2V(2)-compatible UNet.</p> <p>Attributes:</p> Name Type Description <code>depth</code> <code>int</code> <p>Depth of the model, between 1 and 10 (default 2).</p> <code>num_channels_init</code> <code>int</code> <p>Number of filters of the first level of the network, should be even and minimum 8 (default 96).</p> Source code in <code>src/careamics/config/architectures/unet_model.py</code> <pre><code>class UNetModel(ArchitectureModel):\n    \"\"\"\n    Pydantic model for a N2V(2)-compatible UNet.\n\n    Attributes\n    ----------\n    depth : int\n        Depth of the model, between 1 and 10 (default 2).\n    num_channels_init : int\n        Number of filters of the first level of the network, should be even\n        and minimum 8 (default 96).\n    \"\"\"\n\n    # pydantic model config\n    model_config = ConfigDict(validate_assignment=True)\n\n    # discriminator used for choosing the pydantic model in Model\n    architecture: Literal[\"UNet\"]\n\n    # parameters\n    # validate_defaults allow ignoring default values in the dump if they were not set\n    conv_dims: Literal[2, 3] = Field(default=2, validate_default=True)\n    num_classes: int = Field(default=1, ge=1, validate_default=True)\n    in_channels: int = Field(default=1, ge=1, validate_default=True)\n    depth: int = Field(default=2, ge=1, le=10, validate_default=True)\n    num_channels_init: int = Field(default=32, ge=8, le=1024, validate_default=True)\n    final_activation: Literal[\n        \"None\", \"Sigmoid\", \"Softmax\", \"Tanh\", \"ReLU\", \"LeakyReLU\"\n    ] = Field(default=\"None\", validate_default=True)\n    n2v2: bool = Field(default=False, validate_default=True)\n    independent_channels: bool = Field(default=True, validate_default=True)\n\n    @field_validator(\"num_channels_init\")\n    @classmethod\n    def validate_num_channels_init(cls, num_channels_init: int) -&gt; int:\n        \"\"\"\n        Validate that num_channels_init is even.\n\n        Parameters\n        ----------\n        num_channels_init : int\n            Number of channels.\n\n        Returns\n        -------\n        int\n            Validated number of channels.\n\n        Raises\n        ------\n        ValueError\n            If the number of channels is odd.\n        \"\"\"\n        # if odd\n        if num_channels_init % 2 != 0:\n            raise ValueError(\n                f\"Number of channels for the bottom layer must be even\"\n                f\" (got {num_channels_init}).\"\n            )\n\n        return num_channels_init\n\n    def set_3D(self, is_3D: bool) -&gt; None:\n        \"\"\"\n        Set 3D model by setting the `conv_dims` parameters.\n\n        Parameters\n        ----------\n        is_3D : bool\n            Whether the algorithm is 3D or not.\n        \"\"\"\n        if is_3D:\n            self.conv_dims = 3\n        else:\n            self.conv_dims = 2\n\n    def is_3D(self) -&gt; bool:\n        \"\"\"\n        Return whether the model is 3D or not.\n\n        Returns\n        -------\n        bool\n            Whether the model is 3D or not.\n        \"\"\"\n        return self.conv_dims == 3\n</code></pre>"},{"location":"reference/careamics/config/architectures/unet_model/#careamics.config.architectures.unet_model.UNetModel.is_3D","title":"<code>is_3D()</code>","text":"<p>Return whether the model is 3D or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the model is 3D or not.</p> Source code in <code>src/careamics/config/architectures/unet_model.py</code> <pre><code>def is_3D(self) -&gt; bool:\n    \"\"\"\n    Return whether the model is 3D or not.\n\n    Returns\n    -------\n    bool\n        Whether the model is 3D or not.\n    \"\"\"\n    return self.conv_dims == 3\n</code></pre>"},{"location":"reference/careamics/config/architectures/unet_model/#careamics.config.architectures.unet_model.UNetModel.set_3D","title":"<code>set_3D(is_3D)</code>","text":"<p>Set 3D model by setting the <code>conv_dims</code> parameters.</p> <p>Parameters:</p> Name Type Description Default <code>is_3D</code> <code>bool</code> <p>Whether the algorithm is 3D or not.</p> required Source code in <code>src/careamics/config/architectures/unet_model.py</code> <pre><code>def set_3D(self, is_3D: bool) -&gt; None:\n    \"\"\"\n    Set 3D model by setting the `conv_dims` parameters.\n\n    Parameters\n    ----------\n    is_3D : bool\n        Whether the algorithm is 3D or not.\n    \"\"\"\n    if is_3D:\n        self.conv_dims = 3\n    else:\n        self.conv_dims = 2\n</code></pre>"},{"location":"reference/careamics/config/architectures/unet_model/#careamics.config.architectures.unet_model.UNetModel.validate_num_channels_init","title":"<code>validate_num_channels_init(num_channels_init)</code>  <code>classmethod</code>","text":"<p>Validate that num_channels_init is even.</p> <p>Parameters:</p> Name Type Description Default <code>num_channels_init</code> <code>int</code> <p>Number of channels.</p> required <p>Returns:</p> Type Description <code>int</code> <p>Validated number of channels.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of channels is odd.</p> Source code in <code>src/careamics/config/architectures/unet_model.py</code> <pre><code>@field_validator(\"num_channels_init\")\n@classmethod\ndef validate_num_channels_init(cls, num_channels_init: int) -&gt; int:\n    \"\"\"\n    Validate that num_channels_init is even.\n\n    Parameters\n    ----------\n    num_channels_init : int\n        Number of channels.\n\n    Returns\n    -------\n    int\n        Validated number of channels.\n\n    Raises\n    ------\n    ValueError\n        If the number of channels is odd.\n    \"\"\"\n    # if odd\n    if num_channels_init % 2 != 0:\n        raise ValueError(\n            f\"Number of channels for the bottom layer must be even\"\n            f\" (got {num_channels_init}).\"\n        )\n\n    return num_channels_init\n</code></pre>"},{"location":"reference/careamics/config/architectures/vae_model/","title":"vae_model","text":"<p>VAE Pydantic model.</p>"},{"location":"reference/careamics/config/architectures/vae_model/#careamics.config.architectures.vae_model.VAEModel","title":"<code>VAEModel</code>","text":"<p>               Bases: <code>ArchitectureModel</code></p> <p>VAE model placeholder.</p> Source code in <code>src/careamics/config/architectures/vae_model.py</code> <pre><code>class VAEModel(ArchitectureModel):\n    \"\"\"VAE model placeholder.\"\"\"\n\n    model_config = ConfigDict(\n        use_enum_values=True, protected_namespaces=(), validate_assignment=True\n    )\n\n    architecture: Literal[\"VAE\"]\n\n    def set_3D(self, is_3D: bool) -&gt; None:\n        \"\"\"\n        Set 3D model by setting the `conv_dims` parameters.\n\n        Parameters\n        ----------\n        is_3D : bool\n            Whether the algorithm is 3D or not.\n        \"\"\"\n        raise NotImplementedError(\"VAE is not implemented yet.\")\n\n    def is_3D(self) -&gt; bool:\n        \"\"\"\n        Return whether the model is 3D or not.\n\n        Returns\n        -------\n        bool\n            Whether the model is 3D or not.\n        \"\"\"\n        raise NotImplementedError(\"VAE is not implemented yet.\")\n</code></pre>"},{"location":"reference/careamics/config/architectures/vae_model/#careamics.config.architectures.vae_model.VAEModel.is_3D","title":"<code>is_3D()</code>","text":"<p>Return whether the model is 3D or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the model is 3D or not.</p> Source code in <code>src/careamics/config/architectures/vae_model.py</code> <pre><code>def is_3D(self) -&gt; bool:\n    \"\"\"\n    Return whether the model is 3D or not.\n\n    Returns\n    -------\n    bool\n        Whether the model is 3D or not.\n    \"\"\"\n    raise NotImplementedError(\"VAE is not implemented yet.\")\n</code></pre>"},{"location":"reference/careamics/config/architectures/vae_model/#careamics.config.architectures.vae_model.VAEModel.set_3D","title":"<code>set_3D(is_3D)</code>","text":"<p>Set 3D model by setting the <code>conv_dims</code> parameters.</p> <p>Parameters:</p> Name Type Description Default <code>is_3D</code> <code>bool</code> <p>Whether the algorithm is 3D or not.</p> required Source code in <code>src/careamics/config/architectures/vae_model.py</code> <pre><code>def set_3D(self, is_3D: bool) -&gt; None:\n    \"\"\"\n    Set 3D model by setting the `conv_dims` parameters.\n\n    Parameters\n    ----------\n    is_3D : bool\n        Whether the algorithm is 3D or not.\n    \"\"\"\n    raise NotImplementedError(\"VAE is not implemented yet.\")\n</code></pre>"},{"location":"reference/careamics/config/references/algorithm_descriptions/","title":"algorithm_descriptions","text":"<p>Descriptions of the algorithms used in CAREmics.</p>"},{"location":"reference/careamics/config/references/algorithm_descriptions/#careamics.config.references.algorithm_descriptions.AlgorithmDescription","title":"<code>AlgorithmDescription</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Description of an algorithm.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>Description of the algorithm.</p> Source code in <code>src/careamics/config/references/algorithm_descriptions.py</code> <pre><code>class AlgorithmDescription(BaseModel):\n    \"\"\"Description of an algorithm.\n\n    Attributes\n    ----------\n    description : str\n        Description of the algorithm.\n    \"\"\"\n\n    description: str\n</code></pre>"},{"location":"reference/careamics/config/references/algorithm_descriptions/#careamics.config.references.algorithm_descriptions.CAREDescription","title":"<code>CAREDescription</code>","text":"<p>               Bases: <code>AlgorithmDescription</code></p> <p>Description of CARE.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>Description of CARE.</p> Source code in <code>src/careamics/config/references/algorithm_descriptions.py</code> <pre><code>class CAREDescription(AlgorithmDescription):\n    \"\"\"Description of CARE.\n\n    Attributes\n    ----------\n    description : str\n        Description of CARE.\n    \"\"\"\n\n    description: str = \"CARE\"  # TODO\n</code></pre>"},{"location":"reference/careamics/config/references/algorithm_descriptions/#careamics.config.references.algorithm_descriptions.N2NDescription","title":"<code>N2NDescription</code>","text":"<p>               Bases: <code>AlgorithmDescription</code></p> <p>Description of Noise2Noise.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>Description of Noise2Noise.</p> Source code in <code>src/careamics/config/references/algorithm_descriptions.py</code> <pre><code>class N2NDescription(AlgorithmDescription):\n    \"\"\"Description of Noise2Noise.\n\n    Attributes\n    ----------\n    description : str\n        Description of Noise2Noise.\n    \"\"\"\n\n    description: str = \"Noise2Noise\"  # TODO\n</code></pre>"},{"location":"reference/careamics/config/references/algorithm_descriptions/#careamics.config.references.algorithm_descriptions.N2V2Description","title":"<code>N2V2Description</code>","text":"<p>               Bases: <code>AlgorithmDescription</code></p> <p>Description of N2V2.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>Description of N2V2.</p> Source code in <code>src/careamics/config/references/algorithm_descriptions.py</code> <pre><code>class N2V2Description(AlgorithmDescription):\n    \"\"\"Description of N2V2.\n\n    Attributes\n    ----------\n    description : str\n        Description of N2V2.\n    \"\"\"\n\n    description: str = (\n        \"N2V2 is a variant of Noise2Void. \"\n        + N2V_DESCRIPTION\n        + \"\\nN2V2 introduces blur-pool layers and removed skip \"\n        \"connections in the UNet architecture to remove checkboard \"\n        \"artefacts, a common artefacts ocurring in Noise2Void.\"\n    )\n</code></pre>"},{"location":"reference/careamics/config/references/algorithm_descriptions/#careamics.config.references.algorithm_descriptions.N2VDescription","title":"<code>N2VDescription</code>","text":"<p>               Bases: <code>AlgorithmDescription</code></p> <p>Description of Noise2Void.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>Description of Noise2Void.</p> Source code in <code>src/careamics/config/references/algorithm_descriptions.py</code> <pre><code>class N2VDescription(AlgorithmDescription):\n    \"\"\"Description of Noise2Void.\n\n    Attributes\n    ----------\n    description : str\n        Description of Noise2Void.\n    \"\"\"\n\n    description: str = N2V_DESCRIPTION\n</code></pre>"},{"location":"reference/careamics/config/references/algorithm_descriptions/#careamics.config.references.algorithm_descriptions.StructN2V2Description","title":"<code>StructN2V2Description</code>","text":"<p>               Bases: <code>AlgorithmDescription</code></p> <p>Description of StructN2V2.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>Description of StructN2V2.</p> Source code in <code>src/careamics/config/references/algorithm_descriptions.py</code> <pre><code>class StructN2V2Description(AlgorithmDescription):\n    \"\"\"Description of StructN2V2.\n\n    Attributes\n    ----------\n    description : str\n        Description of StructN2V2.\n    \"\"\"\n\n    description: str = (\n        \"StructN2V2 is a a variant of Noise2Void that uses both \"\n        \"structN2V and N2V2. \"\n        + N2V_DESCRIPTION\n        + \"\\nStructN2V2 uses a linear mask (horizontal or vertical) to replace \"\n        \"the pixel values of neighbors of the masked pixels by a random \"\n        \"value. Such masking allows removing 1D structured noise from the \"\n        \"the images, the main failure case of the original N2V.\"\n        \"\\nN2V2 introduces blur-pool layers and removed skip connections in \"\n        \"the UNet architecture to remove checkboard artefacts, a common \"\n        \"artefacts ocurring in Noise2Void.\"\n    )\n</code></pre>"},{"location":"reference/careamics/config/references/algorithm_descriptions/#careamics.config.references.algorithm_descriptions.StructN2VDescription","title":"<code>StructN2VDescription</code>","text":"<p>               Bases: <code>AlgorithmDescription</code></p> <p>Description of StructN2V.</p> <p>Attributes:</p> Name Type Description <code>description</code> <code>str</code> <p>Description of StructN2V.</p> Source code in <code>src/careamics/config/references/algorithm_descriptions.py</code> <pre><code>class StructN2VDescription(AlgorithmDescription):\n    \"\"\"Description of StructN2V.\n\n    Attributes\n    ----------\n    description : str\n        Description of StructN2V.\n    \"\"\"\n\n    description: str = (\n        \"StructN2V is a variant of Noise2Void. \"\n        + N2V_DESCRIPTION\n        + \"\\nStructN2V uses a linear mask (horizontal or vertical) to replace \"\n        \"the pixel values of neighbors of the masked pixels by a random \"\n        \"value. Such masking allows removing 1D structured noise from the \"\n        \"the images, the main failure case of the original N2V.\"\n    )\n</code></pre>"},{"location":"reference/careamics/config/references/references/","title":"references","text":"<p>References for the CAREamics algorithms.</p>"},{"location":"reference/careamics/config/support/supported_activations/","title":"supported_activations","text":"<p>Activations supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_activations/#careamics.config.support.supported_activations.SupportedActivation","title":"<code>SupportedActivation</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Supported activation functions.</p> <ul> <li>None, no activation will be used.</li> <li>Sigmoid</li> <li>Softmax</li> <li>Tanh</li> <li>ReLU</li> <li>LeakyReLU</li> </ul> <p>All activations are defined in PyTorch.</p> <p>See: https://pytorch.org/docs/stable/nn.html#loss-functions</p> Source code in <code>src/careamics/config/support/supported_activations.py</code> <pre><code>class SupportedActivation(str, BaseEnum):\n    \"\"\"Supported activation functions.\n\n    - None, no activation will be used.\n    - Sigmoid\n    - Softmax\n    - Tanh\n    - ReLU\n    - LeakyReLU\n\n    All activations are defined in PyTorch.\n\n    See: https://pytorch.org/docs/stable/nn.html#loss-functions\n    \"\"\"\n\n    NONE = \"None\"\n    SIGMOID = \"Sigmoid\"\n    SOFTMAX = \"Softmax\"\n    TANH = \"Tanh\"\n    RELU = \"ReLU\"\n    LEAKYRELU = \"LeakyReLU\"\n</code></pre>"},{"location":"reference/careamics/config/support/supported_algorithms/","title":"supported_algorithms","text":"<p>Algorithms supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_algorithms/#careamics.config.support.supported_algorithms.SupportedAlgorithm","title":"<code>SupportedAlgorithm</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Algorithms available in CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_algorithms/#careamics.config.support.supported_algorithms.SupportedAlgorithm--todo","title":"TODO","text":"Source code in <code>src/careamics/config/support/supported_algorithms.py</code> <pre><code>class SupportedAlgorithm(str, BaseEnum):\n    \"\"\"Algorithms available in CAREamics.\n\n    # TODO\n    \"\"\"\n\n    N2V = \"n2v\"\n    CARE = \"care\"\n    N2N = \"n2n\"\n    CUSTOM = \"custom\"\n</code></pre>"},{"location":"reference/careamics/config/support/supported_architectures/","title":"supported_architectures","text":"<p>Architectures supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_architectures/#careamics.config.support.supported_architectures.SupportedArchitecture","title":"<code>SupportedArchitecture</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Supported architectures.</p>"},{"location":"reference/careamics/config/support/supported_architectures/#careamics.config.support.supported_architectures.SupportedArchitecture--todo-add-details-in-particular-where-to-find-the-api-for-the-models","title":"TODO add details, in particular where to find the API for the models","text":"<ul> <li>UNet: classical UNet compatible with N2V2</li> <li>VAE: variational Autoencoder</li> <li>Custom: custom model registered with <code>@register_model</code> decorator</li> </ul> Source code in <code>src/careamics/config/support/supported_architectures.py</code> <pre><code>class SupportedArchitecture(str, BaseEnum):\n    \"\"\"Supported architectures.\n\n    # TODO add details, in particular where to find the API for the models\n\n    - UNet: classical UNet compatible with N2V2\n    - VAE: variational Autoencoder\n    - Custom: custom model registered with `@register_model` decorator\n    \"\"\"\n\n    UNET = \"UNet\"\n    VAE = \"VAE\"\n    CUSTOM = (\n        \"Custom\"  # TODO all the others tags are small letters, except the architect\n    )\n</code></pre>"},{"location":"reference/careamics/config/support/supported_data/","title":"supported_data","text":"<p>Data supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_data/#careamics.config.support.supported_data.SupportedData","title":"<code>SupportedData</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Supported data types.</p> <p>Attributes:</p> Name Type Description <code>ARRAY</code> <code>str</code> <p>Array data.</p> <code>TIFF</code> <code>str</code> <p>TIFF image data.</p> <code>CUSTOM</code> <code>str</code> <p>Custom data.</p> Source code in <code>src/careamics/config/support/supported_data.py</code> <pre><code>class SupportedData(str, BaseEnum):\n    \"\"\"Supported data types.\n\n    Attributes\n    ----------\n    ARRAY : str\n        Array data.\n    TIFF : str\n        TIFF image data.\n    CUSTOM : str\n        Custom data.\n    \"\"\"\n\n    ARRAY = \"array\"\n    TIFF = \"tiff\"\n    CUSTOM = \"custom\"\n    # ZARR = \"zarr\"\n\n    # TODO remove?\n    @classmethod\n    def _missing_(cls, value: object) -&gt; str:\n        \"\"\"\n        Override default behaviour for missing values.\n\n        This method is called when `value` is not found in the enum values. It converts\n        `value` to lowercase, removes \".\" if it is the first character and tries to\n        match it with enum values.\n\n        Parameters\n        ----------\n        value : object\n            Value to be matched with enum values.\n\n        Returns\n        -------\n        str\n            Matched enum value.\n        \"\"\"\n        if isinstance(value, str):\n            lower_value = value.lower()\n\n            if lower_value.startswith(\".\"):\n                lower_value = lower_value[1:]\n\n            # attempt to match lowercase value with enum values\n            for member in cls:\n                if member.value == lower_value:\n                    return member\n\n        # still missing\n        return super()._missing_(value)\n\n    @classmethod\n    def get_extension(cls, data_type: Union[str, SupportedData]) -&gt; str:\n        \"\"\"\n        Path.rglob and fnmatch compatible extension.\n\n        Parameters\n        ----------\n        data_type : SupportedData\n            Data type.\n\n        Returns\n        -------\n        str\n            Corresponding extension.\n        \"\"\"\n        if data_type == cls.ARRAY:\n            raise NotImplementedError(f\"Data {data_type} are not loaded from file.\")\n        elif data_type == cls.TIFF:\n            return \"*.tif*\"\n        elif data_type == cls.CUSTOM:\n            return \"*.*\"\n        else:\n            raise ValueError(f\"Data type {data_type} is not supported.\")\n</code></pre>"},{"location":"reference/careamics/config/support/supported_data/#careamics.config.support.supported_data.SupportedData.get_extension","title":"<code>get_extension(data_type)</code>  <code>classmethod</code>","text":"<p>Path.rglob and fnmatch compatible extension.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>SupportedData</code> <p>Data type.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Corresponding extension.</p> Source code in <code>src/careamics/config/support/supported_data.py</code> <pre><code>@classmethod\ndef get_extension(cls, data_type: Union[str, SupportedData]) -&gt; str:\n    \"\"\"\n    Path.rglob and fnmatch compatible extension.\n\n    Parameters\n    ----------\n    data_type : SupportedData\n        Data type.\n\n    Returns\n    -------\n    str\n        Corresponding extension.\n    \"\"\"\n    if data_type == cls.ARRAY:\n        raise NotImplementedError(f\"Data {data_type} are not loaded from file.\")\n    elif data_type == cls.TIFF:\n        return \"*.tif*\"\n    elif data_type == cls.CUSTOM:\n        return \"*.*\"\n    else:\n        raise ValueError(f\"Data type {data_type} is not supported.\")\n</code></pre>"},{"location":"reference/careamics/config/support/supported_loggers/","title":"supported_loggers","text":"<p>Logger supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_loggers/#careamics.config.support.supported_loggers.SupportedLogger","title":"<code>SupportedLogger</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Available loggers.</p> Source code in <code>src/careamics/config/support/supported_loggers.py</code> <pre><code>class SupportedLogger(str, BaseEnum):\n    \"\"\"Available loggers.\"\"\"\n\n    WANDB = \"wandb\"\n    TENSORBOARD = \"tensorboard\"\n</code></pre>"},{"location":"reference/careamics/config/support/supported_losses/","title":"supported_losses","text":"<p>Losses supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_losses/#careamics.config.support.supported_losses.SupportedLoss","title":"<code>SupportedLoss</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Supported losses.</p> <p>Attributes:</p> Name Type Description <code>MSE</code> <code>str</code> <p>Mean Squared Error loss.</p> <code>MAE</code> <code>str</code> <p>Mean Absolute Error loss.</p> <code>N2V</code> <code>str</code> <p>Noise2Void loss.</p> Source code in <code>src/careamics/config/support/supported_losses.py</code> <pre><code>class SupportedLoss(str, BaseEnum):\n    \"\"\"Supported losses.\n\n    Attributes\n    ----------\n    MSE : str\n        Mean Squared Error loss.\n    MAE : str\n        Mean Absolute Error loss.\n    N2V : str\n        Noise2Void loss.\n    \"\"\"\n\n    MSE = \"mse\"\n    MAE = \"mae\"\n    N2V = \"n2v\"\n</code></pre>"},{"location":"reference/careamics/config/support/supported_optimizers/","title":"supported_optimizers","text":"<p>Optimizers and schedulers supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_optimizers/#careamics.config.support.supported_optimizers.SupportedOptimizer","title":"<code>SupportedOptimizer</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Supported optimizers.</p> <p>Attributes:</p> Name Type Description <code>Adam</code> <code>str</code> <p>Adam optimizer.</p> <code>SGD</code> <code>str</code> <p>Stochastic Gradient Descent optimizer.</p> Source code in <code>src/careamics/config/support/supported_optimizers.py</code> <pre><code>class SupportedOptimizer(str, BaseEnum):\n    \"\"\"Supported optimizers.\n\n    Attributes\n    ----------\n    Adam : str\n        Adam optimizer.\n    SGD : str\n        Stochastic Gradient Descent optimizer.\n    \"\"\"\n\n    # ASGD = \"ASGD\"\n    # Adadelta = \"Adadelta\"\n    # Adagrad = \"Adagrad\"\n    ADAM = \"Adam\"\n    # AdamW = \"AdamW\"\n    # Adamax = \"Adamax\"\n    # LBFGS = \"LBFGS\"\n    # NAdam = \"NAdam\"\n    # RAdam = \"RAdam\"\n    # RMSprop = \"RMSprop\"\n    # Rprop = \"Rprop\"\n    SGD = \"SGD\"\n</code></pre>"},{"location":"reference/careamics/config/support/supported_optimizers/#careamics.config.support.supported_optimizers.SupportedScheduler","title":"<code>SupportedScheduler</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Supported schedulers.</p> <p>Attributes:</p> Name Type Description <code>ReduceLROnPlateau</code> <code>str</code> <p>Reduce learning rate on plateau.</p> <code>StepLR</code> <code>str</code> <p>Step learning rate.</p> Source code in <code>src/careamics/config/support/supported_optimizers.py</code> <pre><code>class SupportedScheduler(str, BaseEnum):\n    \"\"\"Supported schedulers.\n\n    Attributes\n    ----------\n    ReduceLROnPlateau : str\n        Reduce learning rate on plateau.\n    StepLR : str\n        Step learning rate.\n    \"\"\"\n\n    # ChainedScheduler = \"ChainedScheduler\"\n    # ConstantLR = \"ConstantLR\"\n    # CosineAnnealingLR = \"CosineAnnealingLR\"\n    # CosineAnnealingWarmRestarts = \"CosineAnnealingWarmRestarts\"\n    # CyclicLR = \"CyclicLR\"\n    # ExponentialLR = \"ExponentialLR\"\n    # LambdaLR = \"LambdaLR\"\n    # LinearLR = \"LinearLR\"\n    # MultiStepLR = \"MultiStepLR\"\n    # MultiplicativeLR = \"MultiplicativeLR\"\n    # OneCycleLR = \"OneCycleLR\"\n    # PolynomialLR = \"PolynomialLR\"\n    REDUCE_LR_ON_PLATEAU = \"ReduceLROnPlateau\"\n    # SequentialLR = \"SequentialLR\"\n    STEP_LR = \"StepLR\"\n</code></pre>"},{"location":"reference/careamics/config/support/supported_pixel_manipulations/","title":"supported_pixel_manipulations","text":"<p>Pixel manipulation methods supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_pixel_manipulations/#careamics.config.support.supported_pixel_manipulations.SupportedPixelManipulation","title":"<code>SupportedPixelManipulation</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Supported Noise2Void pixel manipulations.</p> <ul> <li>Uniform: Replace masked pixel value by a (uniformly) randomly selected neighbor     pixel value.</li> <li>Median: Replace masked pixel value by the mean of the neighborhood.</li> </ul> Source code in <code>src/careamics/config/support/supported_pixel_manipulations.py</code> <pre><code>class SupportedPixelManipulation(str, BaseEnum):\n    \"\"\"Supported Noise2Void pixel manipulations.\n\n    - Uniform: Replace masked pixel value by a (uniformly) randomly selected neighbor\n        pixel value.\n    - Median: Replace masked pixel value by the mean of the neighborhood.\n    \"\"\"\n\n    UNIFORM = \"uniform\"\n    MEDIAN = \"median\"\n</code></pre>"},{"location":"reference/careamics/config/support/supported_struct_axis/","title":"supported_struct_axis","text":"<p>StructN2V axes supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_struct_axis/#careamics.config.support.supported_struct_axis.SupportedStructAxis","title":"<code>SupportedStructAxis</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Supported structN2V mask axes.</p> <p>Attributes:</p> Name Type Description <code>HORIZONTAL</code> <code>str</code> <p>Horizontal axis.</p> <code>VERTICAL</code> <code>str</code> <p>Vertical axis.</p> <code>NONE</code> <code>str</code> <p>No axis, the mask is not applied.</p> Source code in <code>src/careamics/config/support/supported_struct_axis.py</code> <pre><code>class SupportedStructAxis(str, BaseEnum):\n    \"\"\"Supported structN2V mask axes.\n\n    Attributes\n    ----------\n    HORIZONTAL : str\n        Horizontal axis.\n    VERTICAL : str\n        Vertical axis.\n    NONE : str\n        No axis, the mask is not applied.\n    \"\"\"\n\n    HORIZONTAL = \"horizontal\"\n    VERTICAL = \"vertical\"\n    NONE = \"none\"\n</code></pre>"},{"location":"reference/careamics/config/support/supported_transforms/","title":"supported_transforms","text":"<p>Transforms supported by CAREamics.</p>"},{"location":"reference/careamics/config/support/supported_transforms/#careamics.config.support.supported_transforms.SupportedTransform","title":"<code>SupportedTransform</code>","text":"<p>               Bases: <code>str</code>, <code>BaseEnum</code></p> <p>Transforms officially supported by CAREamics.</p> Source code in <code>src/careamics/config/support/supported_transforms.py</code> <pre><code>class SupportedTransform(str, BaseEnum):\n    \"\"\"Transforms officially supported by CAREamics.\"\"\"\n\n    XY_FLIP = \"XYFlip\"\n    XY_RANDOM_ROTATE90 = \"XYRandomRotate90\"\n    NORMALIZE = \"Normalize\"\n    N2V_MANIPULATE = \"N2VManipulate\"\n</code></pre>"},{"location":"reference/careamics/config/transformations/n2v_manipulate_model/","title":"n2v_manipulate_model","text":"<p>Pydantic model for the N2VManipulate transform.</p>"},{"location":"reference/careamics/config/transformations/n2v_manipulate_model/#careamics.config.transformations.n2v_manipulate_model.N2VManipulateModel","title":"<code>N2VManipulateModel</code>","text":"<p>               Bases: <code>TransformModel</code></p> <p>Pydantic model used to represent N2V manipulation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['N2VManipulate']</code> <p>Name of the transformation.</p> <code>roi_size</code> <code>int</code> <p>Size of the masking region, by default 11.</p> <code>masked_pixel_percentage</code> <code>float</code> <p>Percentage of masked pixels, by default 0.2.</p> <code>strategy</code> <code>Literal['uniform', 'median']</code> <p>Strategy pixel value replacement, by default \"uniform\".</p> <code>struct_mask_axis</code> <code>Literal['horizontal', 'vertical', 'none']</code> <p>Axis of the structN2V mask, by default \"none\".</p> <code>struct_mask_span</code> <code>int</code> <p>Span of the structN2V mask, by default 5.</p> Source code in <code>src/careamics/config/transformations/n2v_manipulate_model.py</code> <pre><code>class N2VManipulateModel(TransformModel):\n    \"\"\"\n    Pydantic model used to represent N2V manipulation.\n\n    Attributes\n    ----------\n    name : Literal[\"N2VManipulate\"]\n        Name of the transformation.\n    roi_size : int\n        Size of the masking region, by default 11.\n    masked_pixel_percentage : float\n        Percentage of masked pixels, by default 0.2.\n    strategy : Literal[\"uniform\", \"median\"]\n        Strategy pixel value replacement, by default \"uniform\".\n    struct_mask_axis : Literal[\"horizontal\", \"vertical\", \"none\"]\n        Axis of the structN2V mask, by default \"none\".\n    struct_mask_span : int\n        Span of the structN2V mask, by default 5.\n    \"\"\"\n\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    name: Literal[\"N2VManipulate\"] = \"N2VManipulate\"\n    roi_size: int = Field(default=11, ge=3, le=21)\n    masked_pixel_percentage: float = Field(default=0.2, ge=0.05, le=1.0)\n    strategy: Literal[\"uniform\", \"median\"] = Field(default=\"uniform\")\n    struct_mask_axis: Literal[\"horizontal\", \"vertical\", \"none\"] = Field(default=\"none\")\n    struct_mask_span: int = Field(default=5, ge=3, le=15)\n\n    @field_validator(\"roi_size\", \"struct_mask_span\")\n    @classmethod\n    def odd_value(cls, v: int) -&gt; int:\n        \"\"\"\n        Validate that the value is odd.\n\n        Parameters\n        ----------\n        v : int\n            Value to validate.\n\n        Returns\n        -------\n        int\n            The validated value.\n\n        Raises\n        ------\n        ValueError\n            If the value is even.\n        \"\"\"\n        if v % 2 == 0:\n            raise ValueError(\"Size must be an odd number.\")\n        return v\n</code></pre>"},{"location":"reference/careamics/config/transformations/n2v_manipulate_model/#careamics.config.transformations.n2v_manipulate_model.N2VManipulateModel.odd_value","title":"<code>odd_value(v)</code>  <code>classmethod</code>","text":"<p>Validate that the value is odd.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>int</code> <p>Value to validate.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The validated value.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value is even.</p> Source code in <code>src/careamics/config/transformations/n2v_manipulate_model.py</code> <pre><code>@field_validator(\"roi_size\", \"struct_mask_span\")\n@classmethod\ndef odd_value(cls, v: int) -&gt; int:\n    \"\"\"\n    Validate that the value is odd.\n\n    Parameters\n    ----------\n    v : int\n        Value to validate.\n\n    Returns\n    -------\n    int\n        The validated value.\n\n    Raises\n    ------\n    ValueError\n        If the value is even.\n    \"\"\"\n    if v % 2 == 0:\n        raise ValueError(\"Size must be an odd number.\")\n    return v\n</code></pre>"},{"location":"reference/careamics/config/transformations/normalize_model/","title":"normalize_model","text":"<p>Pydantic model for the Normalize transform.</p>"},{"location":"reference/careamics/config/transformations/normalize_model/#careamics.config.transformations.normalize_model.NormalizeModel","title":"<code>NormalizeModel</code>","text":"<p>               Bases: <code>TransformModel</code></p> <p>Pydantic model used to represent Normalize transformation.</p> <p>The Normalize transform is a zero mean and unit variance transformation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['Normalize']</code> <p>Name of the transformation.</p> <code>mean</code> <code>float</code> <p>Mean value for normalization.</p> <code>std</code> <code>float</code> <p>Standard deviation value for normalization.</p> Source code in <code>src/careamics/config/transformations/normalize_model.py</code> <pre><code>class NormalizeModel(TransformModel):\n    \"\"\"\n    Pydantic model used to represent Normalize transformation.\n\n    The Normalize transform is a zero mean and unit variance transformation.\n\n    Attributes\n    ----------\n    name : Literal[\"Normalize\"]\n        Name of the transformation.\n    mean : float\n        Mean value for normalization.\n    std : float\n        Standard deviation value for normalization.\n    \"\"\"\n\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    name: Literal[\"Normalize\"] = \"Normalize\"\n    mean: float = Field(default=0.485)  # albumentations defaults\n    std: float = Field(default=0.229)\n</code></pre>"},{"location":"reference/careamics/config/transformations/transform_model/","title":"transform_model","text":"<p>Parent model for the transforms.</p>"},{"location":"reference/careamics/config/transformations/transform_model/#careamics.config.transformations.transform_model.TransformModel","title":"<code>TransformModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Pydantic model used to represent a transformation.</p> <p>The <code>model_dump</code> method is overwritten to exclude the name field.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the transformation.</p> Source code in <code>src/careamics/config/transformations/transform_model.py</code> <pre><code>class TransformModel(BaseModel):\n    \"\"\"\n    Pydantic model used to represent a transformation.\n\n    The `model_dump` method is overwritten to exclude the name field.\n\n    Attributes\n    ----------\n    name : str\n        Name of the transformation.\n    \"\"\"\n\n    model_config = ConfigDict(\n        extra=\"forbid\",  # throw errors if the parameters are not properly passed\n    )\n\n    name: str\n\n    def model_dump(self, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Return the model as a dictionary.\n\n        Parameters\n        ----------\n        **kwargs\n            Pydantic BaseMode model_dump method keyword arguments.\n\n        Returns\n        -------\n        Dict[str, Any]\n            Dictionary representation of the model.\n        \"\"\"\n        model_dict = super().model_dump(**kwargs)\n\n        # remove the name field\n        model_dict.pop(\"name\")\n\n        return model_dict\n</code></pre>"},{"location":"reference/careamics/config/transformations/transform_model/#careamics.config.transformations.transform_model.TransformModel.model_dump","title":"<code>model_dump(**kwargs)</code>","text":"<p>Return the model as a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Pydantic BaseMode model_dump method keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary representation of the model.</p> Source code in <code>src/careamics/config/transformations/transform_model.py</code> <pre><code>def model_dump(self, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Return the model as a dictionary.\n\n    Parameters\n    ----------\n    **kwargs\n        Pydantic BaseMode model_dump method keyword arguments.\n\n    Returns\n    -------\n    Dict[str, Any]\n        Dictionary representation of the model.\n    \"\"\"\n    model_dict = super().model_dump(**kwargs)\n\n    # remove the name field\n    model_dict.pop(\"name\")\n\n    return model_dict\n</code></pre>"},{"location":"reference/careamics/config/transformations/xy_flip_model/","title":"xy_flip_model","text":"<p>Pydantic model for the XYFlip transform.</p>"},{"location":"reference/careamics/config/transformations/xy_flip_model/#careamics.config.transformations.xy_flip_model.XYFlipModel","title":"<code>XYFlipModel</code>","text":"<p>               Bases: <code>TransformModel</code></p> <p>Pydantic model used to represent XYFlip transformation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['XYFlip']</code> <p>Name of the transformation.</p> <code>seed</code> <code>Optional[int]</code> <p>Seed for the random number generator.</p> Source code in <code>src/careamics/config/transformations/xy_flip_model.py</code> <pre><code>class XYFlipModel(TransformModel):\n    \"\"\"\n    Pydantic model used to represent XYFlip transformation.\n\n    Attributes\n    ----------\n    name : Literal[\"XYFlip\"]\n        Name of the transformation.\n    seed : Optional[int]\n        Seed for the random number generator.\n    \"\"\"\n\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    name: Literal[\"XYFlip\"] = \"XYFlip\"\n    seed: Optional[int] = None\n</code></pre>"},{"location":"reference/careamics/config/transformations/xy_random_rotate90_model/","title":"xy_random_rotate90_model","text":"<p>Pydantic model for the XYRandomRotate90 transform.</p>"},{"location":"reference/careamics/config/transformations/xy_random_rotate90_model/#careamics.config.transformations.xy_random_rotate90_model.XYRandomRotate90Model","title":"<code>XYRandomRotate90Model</code>","text":"<p>               Bases: <code>TransformModel</code></p> <p>Pydantic model used to represent NDFlip transformation.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>Literal['XYRandomRotate90']</code> <p>Name of the transformation.</p> <code>seed</code> <code>Optional[int]</code> <p>Seed for the random number generator.</p> Source code in <code>src/careamics/config/transformations/xy_random_rotate90_model.py</code> <pre><code>class XYRandomRotate90Model(TransformModel):\n    \"\"\"\n    Pydantic model used to represent NDFlip transformation.\n\n    Attributes\n    ----------\n    name : Literal[\"XYRandomRotate90\"]\n        Name of the transformation.\n    seed : Optional[int]\n        Seed for the random number generator.\n    \"\"\"\n\n    model_config = ConfigDict(\n        validate_assignment=True,\n    )\n\n    name: Literal[\"XYRandomRotate90\"] = \"XYRandomRotate90\"\n    seed: Optional[int] = None\n</code></pre>"},{"location":"reference/careamics/config/validators/validator_utils/","title":"validator_utils","text":"<p>Validator functions.</p> <p>These functions are used to validate dimensions and axes of inputs.</p>"},{"location":"reference/careamics/config/validators/validator_utils/#careamics.config.validators.validator_utils.check_axes_validity","title":"<code>check_axes_validity(axes)</code>","text":"<p>Sanity check on axes.</p> <p>The constraints on the axes are the following: - must be a combination of 'STCZYX' - must not contain duplicates - must contain at least 2 contiguous axes: X and Y - must contain at most 4 axes - cannot contain both S and T axes</p> <p>Axes do not need to be in the order 'STCZYX', as this depends on the user data.</p> <p>Parameters:</p> Name Type Description Default <code>axes</code> <code>str</code> <p>Axes to validate.</p> required Source code in <code>src/careamics/config/validators/validator_utils.py</code> <pre><code>def check_axes_validity(axes: str) -&gt; None:\n    \"\"\"\n    Sanity check on axes.\n\n    The constraints on the axes are the following:\n    - must be a combination of 'STCZYX'\n    - must not contain duplicates\n    - must contain at least 2 contiguous axes: X and Y\n    - must contain at most 4 axes\n    - cannot contain both S and T axes\n\n    Axes do not need to be in the order 'STCZYX', as this depends on the user data.\n\n    Parameters\n    ----------\n    axes : str\n        Axes to validate.\n    \"\"\"\n    _axes = axes.upper()\n\n    # Minimum is 2 (XY) and maximum is 4 (TZYX)\n    if len(_axes) &lt; 2 or len(_axes) &gt; 6:\n        raise ValueError(\n            f\"Invalid axes {axes}. Must contain at least 2 and at most 6 axes.\"\n        )\n\n    if \"YX\" not in _axes and \"XY\" not in _axes:\n        raise ValueError(\n            f\"Invalid axes {axes}. Must contain at least X and Y axes consecutively.\"\n        )\n\n    # all characters must be in REF_AXES = 'STCZYX'\n    if not all(s in _AXES for s in _axes):\n        raise ValueError(f\"Invalid axes {axes}. Must be a combination of {_AXES}.\")\n\n    # check for repeating characters\n    for i, s in enumerate(_axes):\n        if i != _axes.rfind(s):\n            raise ValueError(\n                f\"Invalid axes {axes}. Cannot contain duplicate axes\"\n                f\" (got multiple {axes[i]}).\"\n            )\n</code></pre>"},{"location":"reference/careamics/config/validators/validator_utils/#careamics.config.validators.validator_utils.patch_size_ge_than_8_power_of_2","title":"<code>patch_size_ge_than_8_power_of_2(patch_list)</code>","text":"<p>Validate that each entry is greater or equal than 8 and a power of 2.</p> <p>Parameters:</p> Name Type Description Default <code>patch_list</code> <code>Optional[Union[List[int]]]</code> <p>Patch size.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the patch size if smaller than 8.</p> <code>ValueError</code> <p>If the patch size is not a power of 2.</p> Source code in <code>src/careamics/config/validators/validator_utils.py</code> <pre><code>def patch_size_ge_than_8_power_of_2(\n    patch_list: Optional[Union[List[int], Union[Tuple[int, ...]]]],\n) -&gt; None:\n    \"\"\"\n    Validate that each entry is greater or equal than 8 and a power of 2.\n\n    Parameters\n    ----------\n    patch_list : Optional[Union[List[int]]]\n        Patch size.\n\n    Raises\n    ------\n    ValueError\n        If the patch size if smaller than 8.\n    ValueError\n        If the patch size is not a power of 2.\n    \"\"\"\n    if patch_list is not None:\n        for dim in patch_list:\n            value_ge_than_8_power_of_2(dim)\n</code></pre>"},{"location":"reference/careamics/config/validators/validator_utils/#careamics.config.validators.validator_utils.value_ge_than_8_power_of_2","title":"<code>value_ge_than_8_power_of_2(value)</code>","text":"<p>Validate that the value is greater or equal than 8 and a power of 2.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>int</code> <p>Value to validate.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value is smaller than 8.</p> <code>ValueError</code> <p>If the value is not a power of 2.</p> Source code in <code>src/careamics/config/validators/validator_utils.py</code> <pre><code>def value_ge_than_8_power_of_2(\n    value: int,\n) -&gt; None:\n    \"\"\"\n    Validate that the value is greater or equal than 8 and a power of 2.\n\n    Parameters\n    ----------\n    value : int\n        Value to validate.\n\n    Raises\n    ------\n    ValueError\n        If the value is smaller than 8.\n    ValueError\n        If the value is not a power of 2.\n    \"\"\"\n    if value &lt; 8:\n        raise ValueError(f\"Value must be non-zero positive (got {value}).\")\n\n    if (value &amp; (value - 1)) != 0:\n        raise ValueError(f\"Value must be a power of 2 (got {value}).\")\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/","title":"in_memory_dataset","text":"<p>In-memory dataset module.</p>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryDataset","title":"<code>InMemoryDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Dataset storing data in memory and allowing generating patches from it.</p> <p>Parameters:</p> Name Type Description Default <code>data_config</code> <code>DataConfig</code> <p>Data configuration.</p> required <code>inputs</code> <code>Union[ndarray, List[Path]]</code> <p>Input data.</p> required <code>data_target</code> <code>Optional[Union[ndarray, List[Path]]]</code> <p>Target data, by default None.</p> required <code>read_source_func</code> <code>Callable</code> <p>Read source function for custom types, by default read_tiff.</p> <code>read_tiff</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments, unused.</p> <code>{}</code> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>class InMemoryDataset(Dataset):\n    \"\"\"Dataset storing data in memory and allowing generating patches from it.\n\n    Parameters\n    ----------\n    data_config : DataConfig\n        Data configuration.\n    inputs : Union[np.ndarray, List[Path]]\n        Input data.\n    data_target : Optional[Union[np.ndarray, List[Path]]], optional\n        Target data, by default None.\n    read_source_func : Callable, optional\n        Read source function for custom types, by default read_tiff.\n    **kwargs : Any\n        Additional keyword arguments, unused.\n    \"\"\"\n\n    def __init__(\n        self,\n        data_config: DataConfig,\n        inputs: Union[np.ndarray, List[Path]],\n        input_target: Optional[Union[np.ndarray, List[Path]]] = None,\n        read_source_func: Callable = read_tiff,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        data_config : DataConfig\n            Data configuration.\n        inputs : Union[np.ndarray, List[Path]]\n            Input data.\n        data_target : Optional[Union[np.ndarray, List[Path]]], optional\n            Target data, by default None.\n        read_source_func : Callable, optional\n            Read source function for custom types, by default read_tiff.\n        **kwargs : Any\n            Additional keyword arguments, unused.\n        \"\"\"\n        self.data_config = data_config\n        self.inputs = inputs\n        self.input_targets = input_target\n        self.axes = self.data_config.axes\n        self.patch_size = self.data_config.patch_size\n\n        # read function\n        self.read_source_func = read_source_func\n\n        # Generate patches\n        supervised = self.input_targets is not None\n        patch_data = self._prepare_patches(supervised)\n\n        # Add results to members\n        self.patches, self.patch_targets, computed_mean, computed_std = patch_data\n\n        if not self.data_config.mean or not self.data_config.std:\n            self.mean, self.std = computed_mean, computed_std\n            logger.info(f\"Computed dataset mean: {self.mean}, std: {self.std}\")\n\n            # update mean and std in configuration\n            # the object is mutable and should then be recorded in the CAREamist obj\n            self.data_config.set_mean_and_std(self.mean, self.std)\n        else:\n            self.mean, self.std = self.data_config.mean, self.data_config.std\n\n        # get transforms\n        self.patch_transform = Compose(\n            transform_list=self.data_config.transforms,\n        )\n\n    def _prepare_patches(\n        self, supervised: bool\n    ) -&gt; Tuple[np.ndarray, Optional[np.ndarray], float, float]:\n        \"\"\"\n        Iterate over data source and create an array of patches.\n\n        Parameters\n        ----------\n        supervised : bool\n            Whether the dataset is supervised or not.\n\n        Returns\n        -------\n        np.ndarray\n            Array of patches.\n        \"\"\"\n        if supervised:\n            if isinstance(self.inputs, np.ndarray) and isinstance(\n                self.input_targets, np.ndarray\n            ):\n                return prepare_patches_supervised_array(\n                    self.inputs,\n                    self.axes,\n                    self.input_targets,\n                    self.patch_size,\n                )\n            elif isinstance(self.inputs, list) and isinstance(self.input_targets, list):\n                return prepare_patches_supervised(\n                    self.inputs,\n                    self.input_targets,\n                    self.axes,\n                    self.patch_size,\n                    self.read_source_func,\n                )\n            else:\n                raise ValueError(\n                    f\"Data and target must be of the same type, either both numpy \"\n                    f\"arrays or both lists of paths, got {type(self.inputs)} (data) \"\n                    f\"and {type(self.input_targets)} (target).\"\n                )\n        else:\n            if isinstance(self.inputs, np.ndarray):\n                return prepare_patches_unsupervised_array(\n                    self.inputs,\n                    self.axes,\n                    self.patch_size,\n                )\n            else:\n                return prepare_patches_unsupervised(\n                    self.inputs,\n                    self.axes,\n                    self.patch_size,\n                    self.read_source_func,\n                )\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Return the length of the dataset.\n\n        Returns\n        -------\n        int\n            Length of the dataset.\n        \"\"\"\n        return len(self.patches)\n\n    def __getitem__(self, index: int) -&gt; Tuple[np.ndarray, ...]:\n        \"\"\"\n        Return the patch corresponding to the provided index.\n\n        Parameters\n        ----------\n        index : int\n            Index of the patch to return.\n\n        Returns\n        -------\n        Tuple[np.ndarray]\n            Patch.\n\n        Raises\n        ------\n        ValueError\n            If dataset mean and std are not set.\n        \"\"\"\n        patch = self.patches[index]\n\n        # if there is a target\n        if self.patch_targets is not None:\n            # get target\n            target = self.patch_targets[index]\n\n            return self.patch_transform(patch=patch, target=target)\n\n        elif self.data_config.has_n2v_manipulate():\n            return self.patch_transform(patch=patch)\n        else:\n            raise ValueError(\n                \"Something went wrong! No target provided (not supervised training) \"\n                \"and no N2V manipulation (no N2V training).\"\n            )\n\n    def split_dataset(\n        self,\n        percentage: float = 0.1,\n        minimum_patches: int = 1,\n    ) -&gt; InMemoryDataset:\n        \"\"\"Split a new dataset away from the current one.\n\n        This method is used to extract random validation patches from the dataset.\n\n        Parameters\n        ----------\n        percentage : float, optional\n            Percentage of patches to extract, by default 0.1.\n        minimum_patches : int, optional\n            Minimum number of patches to extract, by default 5.\n\n        Returns\n        -------\n        InMemoryDataset\n            New dataset with the extracted patches.\n\n        Raises\n        ------\n        ValueError\n            If `percentage` is not between 0 and 1.\n        ValueError\n            If `minimum_number` is not between 1 and the number of patches.\n        \"\"\"\n        if percentage &lt; 0 or percentage &gt; 1:\n            raise ValueError(f\"Percentage must be between 0 and 1, got {percentage}.\")\n\n        if minimum_patches &lt; 1 or minimum_patches &gt; len(self):\n            raise ValueError(\n                f\"Minimum number of patches must be between 1 and \"\n                f\"{len(self)} (number of patches), got \"\n                f\"{minimum_patches}. Adjust the patch size or the minimum number of \"\n                f\"patches.\"\n            )\n\n        total_patches = len(self)\n\n        # number of patches to extract (either percentage rounded or minimum number)\n        n_patches = max(round(total_patches * percentage), minimum_patches)\n\n        # get random indices\n        indices = np.random.choice(total_patches, n_patches, replace=False)\n\n        # extract patches\n        val_patches = self.patches[indices]\n\n        # remove patches from self.patch\n        self.patches = np.delete(self.patches, indices, axis=0)\n\n        # same for targets\n        if self.patch_targets is not None:\n            val_targets = self.patch_targets[indices]\n            self.patch_targets = np.delete(self.patch_targets, indices, axis=0)\n\n        # clone the dataset\n        dataset = copy.deepcopy(self)\n\n        # reassign patches\n        dataset.patches = val_patches\n\n        # reassign targets\n        if self.patch_targets is not None:\n            dataset.patch_targets = val_targets\n\n        return dataset\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryDataset.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Return the patch corresponding to the provided index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the patch to return.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray]</code> <p>Patch.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If dataset mean and std are not set.</p> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def __getitem__(self, index: int) -&gt; Tuple[np.ndarray, ...]:\n    \"\"\"\n    Return the patch corresponding to the provided index.\n\n    Parameters\n    ----------\n    index : int\n        Index of the patch to return.\n\n    Returns\n    -------\n    Tuple[np.ndarray]\n        Patch.\n\n    Raises\n    ------\n    ValueError\n        If dataset mean and std are not set.\n    \"\"\"\n    patch = self.patches[index]\n\n    # if there is a target\n    if self.patch_targets is not None:\n        # get target\n        target = self.patch_targets[index]\n\n        return self.patch_transform(patch=patch, target=target)\n\n    elif self.data_config.has_n2v_manipulate():\n        return self.patch_transform(patch=patch)\n    else:\n        raise ValueError(\n            \"Something went wrong! No target provided (not supervised training) \"\n            \"and no N2V manipulation (no N2V training).\"\n        )\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryDataset.__init__","title":"<code>__init__(data_config, inputs, input_target=None, read_source_func=read_tiff, **kwargs)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>data_config</code> <code>DataConfig</code> <p>Data configuration.</p> required <code>inputs</code> <code>Union[ndarray, List[Path]]</code> <p>Input data.</p> required <code>data_target</code> <code>Optional[Union[ndarray, List[Path]]]</code> <p>Target data, by default None.</p> required <code>read_source_func</code> <code>Callable</code> <p>Read source function for custom types, by default read_tiff.</p> <code>read_tiff</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments, unused.</p> <code>{}</code> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def __init__(\n    self,\n    data_config: DataConfig,\n    inputs: Union[np.ndarray, List[Path]],\n    input_target: Optional[Union[np.ndarray, List[Path]]] = None,\n    read_source_func: Callable = read_tiff,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    data_config : DataConfig\n        Data configuration.\n    inputs : Union[np.ndarray, List[Path]]\n        Input data.\n    data_target : Optional[Union[np.ndarray, List[Path]]], optional\n        Target data, by default None.\n    read_source_func : Callable, optional\n        Read source function for custom types, by default read_tiff.\n    **kwargs : Any\n        Additional keyword arguments, unused.\n    \"\"\"\n    self.data_config = data_config\n    self.inputs = inputs\n    self.input_targets = input_target\n    self.axes = self.data_config.axes\n    self.patch_size = self.data_config.patch_size\n\n    # read function\n    self.read_source_func = read_source_func\n\n    # Generate patches\n    supervised = self.input_targets is not None\n    patch_data = self._prepare_patches(supervised)\n\n    # Add results to members\n    self.patches, self.patch_targets, computed_mean, computed_std = patch_data\n\n    if not self.data_config.mean or not self.data_config.std:\n        self.mean, self.std = computed_mean, computed_std\n        logger.info(f\"Computed dataset mean: {self.mean}, std: {self.std}\")\n\n        # update mean and std in configuration\n        # the object is mutable and should then be recorded in the CAREamist obj\n        self.data_config.set_mean_and_std(self.mean, self.std)\n    else:\n        self.mean, self.std = self.data_config.mean, self.data_config.std\n\n    # get transforms\n    self.patch_transform = Compose(\n        transform_list=self.data_config.transforms,\n    )\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the dataset.</p> <p>Returns:</p> Type Description <code>int</code> <p>Length of the dataset.</p> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Return the length of the dataset.\n\n    Returns\n    -------\n    int\n        Length of the dataset.\n    \"\"\"\n    return len(self.patches)\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryDataset.split_dataset","title":"<code>split_dataset(percentage=0.1, minimum_patches=1)</code>","text":"<p>Split a new dataset away from the current one.</p> <p>This method is used to extract random validation patches from the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>percentage</code> <code>float</code> <p>Percentage of patches to extract, by default 0.1.</p> <code>0.1</code> <code>minimum_patches</code> <code>int</code> <p>Minimum number of patches to extract, by default 5.</p> <code>1</code> <p>Returns:</p> Type Description <code>InMemoryDataset</code> <p>New dataset with the extracted patches.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>percentage</code> is not between 0 and 1.</p> <code>ValueError</code> <p>If <code>minimum_number</code> is not between 1 and the number of patches.</p> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def split_dataset(\n    self,\n    percentage: float = 0.1,\n    minimum_patches: int = 1,\n) -&gt; InMemoryDataset:\n    \"\"\"Split a new dataset away from the current one.\n\n    This method is used to extract random validation patches from the dataset.\n\n    Parameters\n    ----------\n    percentage : float, optional\n        Percentage of patches to extract, by default 0.1.\n    minimum_patches : int, optional\n        Minimum number of patches to extract, by default 5.\n\n    Returns\n    -------\n    InMemoryDataset\n        New dataset with the extracted patches.\n\n    Raises\n    ------\n    ValueError\n        If `percentage` is not between 0 and 1.\n    ValueError\n        If `minimum_number` is not between 1 and the number of patches.\n    \"\"\"\n    if percentage &lt; 0 or percentage &gt; 1:\n        raise ValueError(f\"Percentage must be between 0 and 1, got {percentage}.\")\n\n    if minimum_patches &lt; 1 or minimum_patches &gt; len(self):\n        raise ValueError(\n            f\"Minimum number of patches must be between 1 and \"\n            f\"{len(self)} (number of patches), got \"\n            f\"{minimum_patches}. Adjust the patch size or the minimum number of \"\n            f\"patches.\"\n        )\n\n    total_patches = len(self)\n\n    # number of patches to extract (either percentage rounded or minimum number)\n    n_patches = max(round(total_patches * percentage), minimum_patches)\n\n    # get random indices\n    indices = np.random.choice(total_patches, n_patches, replace=False)\n\n    # extract patches\n    val_patches = self.patches[indices]\n\n    # remove patches from self.patch\n    self.patches = np.delete(self.patches, indices, axis=0)\n\n    # same for targets\n    if self.patch_targets is not None:\n        val_targets = self.patch_targets[indices]\n        self.patch_targets = np.delete(self.patch_targets, indices, axis=0)\n\n    # clone the dataset\n    dataset = copy.deepcopy(self)\n\n    # reassign patches\n    dataset.patches = val_patches\n\n    # reassign targets\n    if self.patch_targets is not None:\n        dataset.patch_targets = val_targets\n\n    return dataset\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryPredictionDataset","title":"<code>InMemoryPredictionDataset</code>","text":"<p>               Bases: <code>Dataset</code></p> <p>Dataset storing data in memory and allowing generating patches from it.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_config</code> <code>InferenceConfig</code> <p>Prediction configuration.</p> required <code>inputs</code> <code>ndarray</code> <p>Input data.</p> required <code>data_target</code> <code>Optional[ndarray]</code> <p>Target data, by default None.</p> <code>None</code> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Read source function for custom types, by default read_tiff.</p> <code>read_tiff</code> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>class InMemoryPredictionDataset(Dataset):\n    \"\"\"\n    Dataset storing data in memory and allowing generating patches from it.\n\n    Parameters\n    ----------\n    prediction_config : InferenceConfig\n        Prediction configuration.\n    inputs : np.ndarray\n        Input data.\n    data_target : Optional[np.ndarray], optional\n        Target data, by default None.\n    read_source_func : Optional[Callable], optional\n        Read source function for custom types, by default read_tiff.\n    \"\"\"\n\n    def __init__(\n        self,\n        prediction_config: InferenceConfig,\n        inputs: np.ndarray,\n        data_target: Optional[np.ndarray] = None,\n        read_source_func: Optional[Callable] = read_tiff,\n    ) -&gt; None:\n        \"\"\"Constructor.\n\n        Parameters\n        ----------\n        prediction_config : InferenceConfig\n            Prediction configuration.\n        inputs : np.ndarray\n            Input data.\n        data_target : Optional[np.ndarray], optional\n            Target data, by default None.\n        read_source_func : Optional[Callable], optional\n            Read source function for custom types, by default read_tiff.\n\n        Raises\n        ------\n        ValueError\n            If data_path is not a directory.\n        \"\"\"\n        self.pred_config = prediction_config\n        self.input_array = inputs\n        self.axes = self.pred_config.axes\n        self.tile_size = self.pred_config.tile_size\n        self.tile_overlap = self.pred_config.tile_overlap\n        self.mean = self.pred_config.mean\n        self.std = self.pred_config.std\n        self.data_target = data_target\n\n        # tiling only if both tile size and overlap are provided\n        self.tiling = self.tile_size is not None and self.tile_overlap is not None\n\n        # read function\n        self.read_source_func = read_source_func\n\n        # Generate patches\n        self.data = self._prepare_tiles()\n        self.mean, self.std = self.pred_config.mean, self.pred_config.std\n\n        # get transforms\n        self.patch_transform = Compose(\n            transform_list=[NormalizeModel(mean=self.mean, std=self.std)],\n        )\n\n    def _prepare_tiles(self) -&gt; List[Tuple[np.ndarray, TileInformation]]:\n        \"\"\"\n        Iterate over data source and create an array of patches.\n\n        Returns\n        -------\n        List[XArrayTile]\n            List of tiles.\n        \"\"\"\n        # reshape array\n        reshaped_sample = reshape_array(self.input_array, self.axes)\n\n        if self.tiling and self.tile_size is not None and self.tile_overlap is not None:\n            # generate patches, which returns a generator\n            patch_generator = extract_tiles(\n                arr=reshaped_sample,\n                tile_size=self.tile_size,\n                overlaps=self.tile_overlap,\n            )\n            patches_list = list(patch_generator)\n\n            if len(patches_list) == 0:\n                raise ValueError(\"No tiles generated, \")\n\n            return patches_list\n        else:\n            array_shape = reshaped_sample.squeeze().shape\n            return [(reshaped_sample, TileInformation(array_shape=array_shape))]\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Return the length of the dataset.\n\n        Returns\n        -------\n        int\n            Length of the dataset.\n        \"\"\"\n        return len(self.data)\n\n    def __getitem__(self, index: int) -&gt; Tuple[np.ndarray, TileInformation]:\n        \"\"\"\n        Return the patch corresponding to the provided index.\n\n        Parameters\n        ----------\n        index : int\n            Index of the patch to return.\n\n        Returns\n        -------\n        Tuple[np.ndarray, TileInformation]\n            Transformed patch.\n        \"\"\"\n        tile_array, tile_info = self.data[index]\n\n        # Apply transforms\n        transformed_tile, _ = self.patch_transform(patch=tile_array)\n\n        return transformed_tile, tile_info\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryPredictionDataset.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Return the patch corresponding to the provided index.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Index of the patch to return.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, TileInformation]</code> <p>Transformed patch.</p> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def __getitem__(self, index: int) -&gt; Tuple[np.ndarray, TileInformation]:\n    \"\"\"\n    Return the patch corresponding to the provided index.\n\n    Parameters\n    ----------\n    index : int\n        Index of the patch to return.\n\n    Returns\n    -------\n    Tuple[np.ndarray, TileInformation]\n        Transformed patch.\n    \"\"\"\n    tile_array, tile_info = self.data[index]\n\n    # Apply transforms\n    transformed_tile, _ = self.patch_transform(patch=tile_array)\n\n    return transformed_tile, tile_info\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryPredictionDataset.__init__","title":"<code>__init__(prediction_config, inputs, data_target=None, read_source_func=read_tiff)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_config</code> <code>InferenceConfig</code> <p>Prediction configuration.</p> required <code>inputs</code> <code>ndarray</code> <p>Input data.</p> required <code>data_target</code> <code>Optional[ndarray]</code> <p>Target data, by default None.</p> <code>None</code> <code>read_source_func</code> <code>Optional[Callable]</code> <p>Read source function for custom types, by default read_tiff.</p> <code>read_tiff</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If data_path is not a directory.</p> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def __init__(\n    self,\n    prediction_config: InferenceConfig,\n    inputs: np.ndarray,\n    data_target: Optional[np.ndarray] = None,\n    read_source_func: Optional[Callable] = read_tiff,\n) -&gt; None:\n    \"\"\"Constructor.\n\n    Parameters\n    ----------\n    prediction_config : InferenceConfig\n        Prediction configuration.\n    inputs : np.ndarray\n        Input data.\n    data_target : Optional[np.ndarray], optional\n        Target data, by default None.\n    read_source_func : Optional[Callable], optional\n        Read source function for custom types, by default read_tiff.\n\n    Raises\n    ------\n    ValueError\n        If data_path is not a directory.\n    \"\"\"\n    self.pred_config = prediction_config\n    self.input_array = inputs\n    self.axes = self.pred_config.axes\n    self.tile_size = self.pred_config.tile_size\n    self.tile_overlap = self.pred_config.tile_overlap\n    self.mean = self.pred_config.mean\n    self.std = self.pred_config.std\n    self.data_target = data_target\n\n    # tiling only if both tile size and overlap are provided\n    self.tiling = self.tile_size is not None and self.tile_overlap is not None\n\n    # read function\n    self.read_source_func = read_source_func\n\n    # Generate patches\n    self.data = self._prepare_tiles()\n    self.mean, self.std = self.pred_config.mean, self.pred_config.std\n\n    # get transforms\n    self.patch_transform = Compose(\n        transform_list=[NormalizeModel(mean=self.mean, std=self.std)],\n    )\n</code></pre>"},{"location":"reference/careamics/dataset/in_memory_dataset/#careamics.dataset.in_memory_dataset.InMemoryPredictionDataset.__len__","title":"<code>__len__()</code>","text":"<p>Return the length of the dataset.</p> <p>Returns:</p> Type Description <code>int</code> <p>Length of the dataset.</p> Source code in <code>src/careamics/dataset/in_memory_dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Return the length of the dataset.\n\n    Returns\n    -------\n    int\n        Length of the dataset.\n    \"\"\"\n    return len(self.data)\n</code></pre>"},{"location":"reference/careamics/dataset/iterable_dataset/","title":"iterable_dataset","text":"<p>Iterable dataset used to load data file by file.</p>"},{"location":"reference/careamics/dataset/iterable_dataset/#careamics.dataset.iterable_dataset.IterablePredictionDataset","title":"<code>IterablePredictionDataset</code>","text":"<p>               Bases: <code>IterableDataset</code></p> <p>Prediction dataset.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_config</code> <code>InferenceConfig</code> <p>Inference configuration.</p> required <code>src_files</code> <code>List[Path]</code> <p>List of data files.</p> required <code>read_source_func</code> <code>Callable</code> <p>Read source function for custom types, by default read_tiff.</p> <code>read_tiff</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments, unused.</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>data_path</code> <code>Union[str, Path]</code> <p>Path to the data, must be a directory.</p> <code>axes</code> <code>str</code> <p>Description of axes in format STCZYX.</p> <code>mean</code> <code>(Optional[float], optional)</code> <p>Expected mean of the dataset, by default None.</p> <code>std</code> <code>(Optional[float], optional)</code> <p>Expected standard deviation of the dataset, by default None.</p> <code>patch_transform</code> <code>(Optional[Callable], optional)</code> <p>Patch transform callable, by default None.</p> Source code in <code>src/careamics/dataset/iterable_dataset.py</code> <pre><code>class IterablePredictionDataset(IterableDataset):\n    \"\"\"\n    Prediction dataset.\n\n    Parameters\n    ----------\n    prediction_config : InferenceConfig\n        Inference configuration.\n    src_files : List[Path]\n        List of data files.\n    read_source_func : Callable, optional\n        Read source function for custom types, by default read_tiff.\n    **kwargs : Any\n        Additional keyword arguments, unused.\n\n    Attributes\n    ----------\n    data_path : Union[str, Path]\n        Path to the data, must be a directory.\n    axes : str\n        Description of axes in format STCZYX.\n    mean : Optional[float], optional\n        Expected mean of the dataset, by default None.\n    std : Optional[float], optional\n        Expected standard deviation of the dataset, by default None.\n    patch_transform : Optional[Callable], optional\n        Patch transform callable, by default None.\n    \"\"\"\n\n    def __init__(\n        self,\n        prediction_config: InferenceConfig,\n        src_files: List[Path],\n        read_source_func: Callable = read_tiff,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Constructor.\n\n        Parameters\n        ----------\n        prediction_config : InferenceConfig\n            Inference configuration.\n        src_files : List[Path]\n            List of data files.\n        read_source_func : Callable, optional\n            Read source function for custom types, by default read_tiff.\n        **kwargs : Any\n            Additional keyword arguments, unused.\n\n        Raises\n        ------\n        ValueError\n            If mean and std are not provided in the inference configuration.\n        \"\"\"\n        self.prediction_config = prediction_config\n        self.data_files = src_files\n        self.axes = prediction_config.axes\n        self.tile_size = self.prediction_config.tile_size\n        self.tile_overlap = self.prediction_config.tile_overlap\n        self.read_source_func = read_source_func\n\n        # tile only if both tile size and overlaps are provided\n        self.tile = self.tile_size is not None and self.tile_overlap is not None\n\n        # check mean and std and create normalize transform\n        if self.prediction_config.mean is None or self.prediction_config.std is None:\n            raise ValueError(\"Mean and std must be provided for prediction.\")\n        else:\n            self.mean = self.prediction_config.mean\n            self.std = self.prediction_config.std\n\n            # instantiate normalize transform\n            self.patch_transform = Compose(\n                transform_list=[\n                    NormalizeModel(\n                        mean=prediction_config.mean, std=prediction_config.std\n                    )\n                ],\n            )\n\n    def __iter__(\n        self,\n    ) -&gt; Generator[Tuple[np.ndarray, TileInformation], None, None]:\n        \"\"\"\n        Iterate over data source and yield single patch.\n\n        Yields\n        ------\n        np.ndarray\n            Single patch.\n        \"\"\"\n        assert (\n            self.mean is not None and self.std is not None\n        ), \"Mean and std must be provided\"\n\n        for sample, _ in _iterate_over_files(\n            self.prediction_config,\n            self.data_files,\n            read_source_func=self.read_source_func,\n        ):\n            # reshape array\n            reshaped_sample = reshape_array(sample, self.axes)\n\n            if (\n                self.tile\n                and self.tile_size is not None\n                and self.tile_overlap is not None\n            ):\n                # generate patches, return a generator\n                patch_gen = extract_tiles(\n                    arr=reshaped_sample,\n                    tile_size=self.tile_size,\n                    overlaps=self.tile_overlap,\n                )\n            else:\n                # just wrap the sample in a generator with default tiling info\n                array_shape = reshaped_sample.squeeze().shape\n                patch_gen = (\n                    (reshaped_sample, TileInformation(array_shape=array_shape))\n                    for _ in range(1)\n                )\n\n            # apply transform to patches\n            for patch_array, tile_info in patch_gen:\n                transformed_patch, _ = self.patch_transform(patch=patch_array)\n\n                yield transformed_patch, tile_info\n</code></pre>"},{"location":"reference/careamics/dataset/iterable_dataset/#careamics.dataset.iterable_dataset.IterablePredictionDataset.__init__","title":"<code>__init__(prediction_config, src_files, read_source_func=read_tiff, **kwargs)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>prediction_config</code> <code>InferenceConfig</code> <p>Inference configuration.</p> required <code>src_files</code> <code>List[Path]</code> <p>List of data files.</p> required <code>read_source_func</code> <code>Callable</code> <p>Read source function for custom types, by default read_tiff.</p> <code>read_tiff</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments, unused.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If mean and std are not provided in the inference configuration.</p> Source code in <code>src/careamics/dataset/iterable_dataset.py</code> <pre><code>def __init__(\n    self,\n    prediction_config: InferenceConfig,\n    src_files: List[Path],\n    read_source_func: Callable = read_tiff,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Constructor.\n\n    Parameters\n    ----------\n    prediction_config : InferenceConfig\n        Inference configuration.\n    src_files : List[Path]\n        List of data files.\n    read_source_func : Callable, optional\n        Read source function for custom types, by default read_tiff.\n    **kwargs : Any\n        Additional keyword arguments, unused.\n\n    Raises\n    ------\n    ValueError\n        If mean and std are not provided in the inference configuration.\n    \"\"\"\n    self.prediction_config = prediction_config\n    self.data_files = src_files\n    self.axes = prediction_config.axes\n    self.tile_size = self.prediction_config.tile_size\n    self.tile_overlap = self.prediction_config.tile_overlap\n    self.read_source_func = read_source_func\n\n    # tile only if both tile size and overlaps are provided\n    self.tile = self.tile_size is not None and self.tile_overlap is not None\n\n    # check mean and std and create normalize transform\n    if self.prediction_config.mean is None or self.prediction_config.std is None:\n        raise ValueError(\"Mean and std must be provided for prediction.\")\n    else:\n        self.mean = self.prediction_config.mean\n        self.std = self.prediction_config.std\n\n        # instantiate normalize transform\n        self.patch_transform = Compose(\n            transform_list=[\n                NormalizeModel(\n                    mean=prediction_config.mean, std=prediction_config.std\n                )\n            ],\n        )\n</code></pre>"},{"location":"reference/careamics/dataset/iterable_dataset/#careamics.dataset.iterable_dataset.IterablePredictionDataset.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over data source and yield single patch.</p> <p>Yields:</p> Type Description <code>ndarray</code> <p>Single patch.</p> Source code in <code>src/careamics/dataset/iterable_dataset.py</code> <pre><code>def __iter__(\n    self,\n) -&gt; Generator[Tuple[np.ndarray, TileInformation], None, None]:\n    \"\"\"\n    Iterate over data source and yield single patch.\n\n    Yields\n    ------\n    np.ndarray\n        Single patch.\n    \"\"\"\n    assert (\n        self.mean is not None and self.std is not None\n    ), \"Mean and std must be provided\"\n\n    for sample, _ in _iterate_over_files(\n        self.prediction_config,\n        self.data_files,\n        read_source_func=self.read_source_func,\n    ):\n        # reshape array\n        reshaped_sample = reshape_array(sample, self.axes)\n\n        if (\n            self.tile\n            and self.tile_size is not None\n            and self.tile_overlap is not None\n        ):\n            # generate patches, return a generator\n            patch_gen = extract_tiles(\n                arr=reshaped_sample,\n                tile_size=self.tile_size,\n                overlaps=self.tile_overlap,\n            )\n        else:\n            # just wrap the sample in a generator with default tiling info\n            array_shape = reshaped_sample.squeeze().shape\n            patch_gen = (\n                (reshaped_sample, TileInformation(array_shape=array_shape))\n                for _ in range(1)\n            )\n\n        # apply transform to patches\n        for patch_array, tile_info in patch_gen:\n            transformed_patch, _ = self.patch_transform(patch=patch_array)\n\n            yield transformed_patch, tile_info\n</code></pre>"},{"location":"reference/careamics/dataset/iterable_dataset/#careamics.dataset.iterable_dataset.PathIterableDataset","title":"<code>PathIterableDataset</code>","text":"<p>               Bases: <code>IterableDataset</code></p> <p>Dataset allowing extracting patches w/o loading whole data into memory.</p> <p>Parameters:</p> Name Type Description Default <code>data_config</code> <code>DataConfig</code> <p>Data configuration.</p> required <code>src_files</code> <code>List[Path]</code> <p>List of data files.</p> required <code>target_files</code> <code>Optional[List[Path]]</code> <p>Optional list of target files, by default None.</p> <code>None</code> <code>read_source_func</code> <code>Callable</code> <p>Read source function for custom types, by default read_tiff.</p> <code>read_tiff</code> <p>Attributes:</p> Name Type Description <code>data_path</code> <code>List[Path]</code> <p>Path to the data, must be a directory.</p> <code>axes</code> <code>str</code> <p>Description of axes in format STCZYX.</p> <code>patch_extraction_method</code> <code>Union[ExtractionStrategies, None]</code> <p>Patch extraction strategy, as defined in extraction_strategy.</p> <code>patch_size</code> <code>(Optional[Union[List[int], Tuple[int]]], optional)</code> <p>Size of the patches in each dimension, by default None.</p> <code>patch_overlap</code> <code>(Optional[Union[List[int], Tuple[int]]], optional)</code> <p>Overlap of the patches in each dimension, by default None.</p> <code>mean</code> <code>(Optional[float], optional)</code> <p>Expected mean of the dataset, by default None.</p> <code>std</code> <code>(Optional[float], optional)</code> <p>Expected standard deviation of the dataset, by default None.</p> <code>patch_transform</code> <code>(Optional[Callable], optional)</code> <p>Patch transform callable, by default None.</p> Source code in <code>src/careamics/dataset/iterable_dataset.py</code> <pre><code>class PathIterableDataset(IterableDataset):\n    \"\"\"\n    Dataset allowing extracting patches w/o loading whole data into memory.\n\n    Parameters\n    ----------\n    data_config : DataConfig\n        Data configuration.\n    src_files : List[Path]\n        List of data files.\n    target_files : Optional[List[Path]], optional\n        Optional list of target files, by default None.\n    read_source_func : Callable, optional\n        Read source function for custom types, by default read_tiff.\n\n    Attributes\n    ----------\n    data_path : List[Path]\n        Path to the data, must be a directory.\n    axes : str\n        Description of axes in format STCZYX.\n    patch_extraction_method : Union[ExtractionStrategies, None]\n        Patch extraction strategy, as defined in extraction_strategy.\n    patch_size : Optional[Union[List[int], Tuple[int]]], optional\n        Size of the patches in each dimension, by default None.\n    patch_overlap : Optional[Union[List[int], Tuple[int]]], optional\n        Overlap of the patches in each dimension, by default None.\n    mean : Optional[float], optional\n        Expected mean of the dataset, by default None.\n    std : Optional[float], optional\n        Expected standard deviation of the dataset, by default None.\n    patch_transform : Optional[Callable], optional\n        Patch transform callable, by default None.\n    \"\"\"\n\n    def __init__(\n        self,\n        data_config: DataConfig,\n        src_files: List[Path],\n        target_files: Optional[List[Path]] = None,\n        read_source_func: Callable = read_tiff,\n    ) -&gt; None:\n        \"\"\"Constructors.\n\n        Parameters\n        ----------\n        data_config : DataConfig\n            Data configuration.\n        src_files : List[Path]\n            List of data files.\n        target_files : Optional[List[Path]], optional\n            Optional list of target files, by default None.\n        read_source_func : Callable, optional\n            Read source function for custom types, by default read_tiff.\n        \"\"\"\n        self.data_config = data_config\n        self.data_files = src_files\n        self.target_files = target_files\n        self.data_config = data_config\n        self.read_source_func = read_source_func\n\n        # compute mean and std over the dataset\n        if not data_config.mean or not data_config.std:\n            self.mean, self.std = self._calculate_mean_and_std()\n\n            # update mean and std in configuration\n            # the object is mutable and should then be recorded in the CAREamist\n            data_config.set_mean_and_std(self.mean, self.std)\n        else:\n            self.mean = data_config.mean\n            self.std = data_config.std\n\n        # get transforms\n        self.patch_transform = Compose(transform_list=data_config.transforms)\n\n    def _calculate_mean_and_std(self) -&gt; Tuple[float, float]:\n        \"\"\"\n        Calculate mean and std of the dataset.\n\n        Returns\n        -------\n        Tuple[float, float]\n            Tuple containing mean and standard deviation.\n        \"\"\"\n        means, stds = 0, 0\n        num_samples = 0\n\n        for sample, _ in _iterate_over_files(\n            self.data_config, self.data_files, self.target_files, self.read_source_func\n        ):\n            means += sample.mean()\n            stds += sample.std()\n            num_samples += 1\n\n        if num_samples == 0:\n            raise ValueError(\"No samples found in the dataset.\")\n\n        result_mean = means / num_samples\n        result_std = stds / num_samples\n\n        logger.info(f\"Calculated mean and std for {num_samples} images\")\n        logger.info(f\"Mean: {result_mean}, std: {result_std}\")\n        return result_mean, result_std\n\n    def __iter__(\n        self,\n    ) -&gt; Generator[Tuple[np.ndarray, ...], None, None]:\n        \"\"\"\n        Iterate over data source and yield single patch.\n\n        Yields\n        ------\n        np.ndarray\n            Single patch.\n        \"\"\"\n        assert (\n            self.mean is not None and self.std is not None\n        ), \"Mean and std must be provided\"\n\n        # iterate over files\n        for sample_input, sample_target in _iterate_over_files(\n            self.data_config, self.data_files, self.target_files, self.read_source_func\n        ):\n            reshaped_sample = reshape_array(sample_input, self.data_config.axes)\n            reshaped_target = (\n                None\n                if sample_target is None\n                else reshape_array(sample_target, self.data_config.axes)\n            )\n\n            patches = extract_patches_random(\n                arr=reshaped_sample,\n                patch_size=self.data_config.patch_size,\n                target=reshaped_target,\n            )\n\n            # iterate over patches\n            # patches are tuples of (patch, target) if target is available\n            # or (patch, None) only if no target is available\n            # patch is of dimensions (C)ZYX\n            for patch_data in patches:\n                yield self.patch_transform(\n                    patch=patch_data[0],\n                    target=patch_data[1],\n                )\n\n    def get_number_of_files(self) -&gt; int:\n        \"\"\"\n        Return the number of files in the dataset.\n\n        Returns\n        -------\n        int\n            Number of files in the dataset.\n        \"\"\"\n        return len(self.data_files)\n\n    def split_dataset(\n        self,\n        percentage: float = 0.1,\n        minimum_number: int = 5,\n    ) -&gt; PathIterableDataset:\n        \"\"\"Split up dataset in two.\n\n        Splits the datest sing a percentage of the data (files) to extract, or the\n        minimum number of the percentage is less than the minimum number.\n\n        Parameters\n        ----------\n        percentage : float, optional\n            Percentage of files to split up, by default 0.1.\n        minimum_number : int, optional\n            Minimum number of files to split up, by default 5.\n\n        Returns\n        -------\n        IterableDataset\n            Dataset containing the split data.\n\n        Raises\n        ------\n        ValueError\n            If the percentage is smaller than 0 or larger than 1.\n        ValueError\n            If the minimum number is smaller than 1 or larger than the number of files.\n        \"\"\"\n        if percentage &lt; 0 or percentage &gt; 1:\n            raise ValueError(f\"Percentage must be between 0 and 1, got {percentage}.\")\n\n        if minimum_number &lt; 1 or minimum_number &gt; self.get_number_of_files():\n            raise ValueError(\n                f\"Minimum number of files must be between 1 and \"\n                f\"{self.get_number_of_files()} (number of files), got \"\n                f\"{minimum_number}.\"\n            )\n\n        # compute number of files\n        total_files = self.get_number_of_files()\n        n_files = max(round(percentage * total_files), minimum_number)\n\n        # get random indices\n        indices = np.random.choice(total_files, n_files, replace=False)\n\n        # extract files\n        val_files = [self.data_files[i] for i in indices]\n\n        # remove patches from self.patch\n        data_files = []\n        for i, file in enumerate(self.data_files):\n            if i not in indices:\n                data_files.append(file)\n        self.data_files = data_files\n\n        # same for targets\n        if self.target_files is not None:\n            val_target_files = [self.target_files[i] for i in indices]\n\n            data_target_files = []\n            for i, file in enumerate(self.target_files):\n                if i not in indices:\n                    data_target_files.append(file)\n            self.target_files = data_target_files\n\n        # clone the dataset\n        dataset = copy.deepcopy(self)\n\n        # reassign patches\n        dataset.data_files = val_files\n\n        # reassign targets\n        if self.target_files is not None:\n            dataset.target_files = val_target_files\n\n        return dataset\n</code></pre>"},{"location":"reference/careamics/dataset/iterable_dataset/#careamics.dataset.iterable_dataset.PathIterableDataset.__init__","title":"<code>__init__(data_config, src_files, target_files=None, read_source_func=read_tiff)</code>","text":"<p>Constructors.</p> <p>Parameters:</p> Name Type Description Default <code>data_config</code> <code>DataConfig</code> <p>Data configuration.</p> required <code>src_files</code> <code>List[Path]</code> <p>List of data files.</p> required <code>target_files</code> <code>Optional[List[Path]]</code> <p>Optional list of target files, by default None.</p> <code>None</code> <code>read_source_func</code> <code>Callable</code> <p>Read source function for custom types, by default read_tiff.</p> <code>read_tiff</code> Source code in <code>src/careamics/dataset/iterable_dataset.py</code> <pre><code>def __init__(\n    self,\n    data_config: DataConfig,\n    src_files: List[Path],\n    target_files: Optional[List[Path]] = None,\n    read_source_func: Callable = read_tiff,\n) -&gt; None:\n    \"\"\"Constructors.\n\n    Parameters\n    ----------\n    data_config : DataConfig\n        Data configuration.\n    src_files : List[Path]\n        List of data files.\n    target_files : Optional[List[Path]], optional\n        Optional list of target files, by default None.\n    read_source_func : Callable, optional\n        Read source function for custom types, by default read_tiff.\n    \"\"\"\n    self.data_config = data_config\n    self.data_files = src_files\n    self.target_files = target_files\n    self.data_config = data_config\n    self.read_source_func = read_source_func\n\n    # compute mean and std over the dataset\n    if not data_config.mean or not data_config.std:\n        self.mean, self.std = self._calculate_mean_and_std()\n\n        # update mean and std in configuration\n        # the object is mutable and should then be recorded in the CAREamist\n        data_config.set_mean_and_std(self.mean, self.std)\n    else:\n        self.mean = data_config.mean\n        self.std = data_config.std\n\n    # get transforms\n    self.patch_transform = Compose(transform_list=data_config.transforms)\n</code></pre>"},{"location":"reference/careamics/dataset/iterable_dataset/#careamics.dataset.iterable_dataset.PathIterableDataset.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterate over data source and yield single patch.</p> <p>Yields:</p> Type Description <code>ndarray</code> <p>Single patch.</p> Source code in <code>src/careamics/dataset/iterable_dataset.py</code> <pre><code>def __iter__(\n    self,\n) -&gt; Generator[Tuple[np.ndarray, ...], None, None]:\n    \"\"\"\n    Iterate over data source and yield single patch.\n\n    Yields\n    ------\n    np.ndarray\n        Single patch.\n    \"\"\"\n    assert (\n        self.mean is not None and self.std is not None\n    ), \"Mean and std must be provided\"\n\n    # iterate over files\n    for sample_input, sample_target in _iterate_over_files(\n        self.data_config, self.data_files, self.target_files, self.read_source_func\n    ):\n        reshaped_sample = reshape_array(sample_input, self.data_config.axes)\n        reshaped_target = (\n            None\n            if sample_target is None\n            else reshape_array(sample_target, self.data_config.axes)\n        )\n\n        patches = extract_patches_random(\n            arr=reshaped_sample,\n            patch_size=self.data_config.patch_size,\n            target=reshaped_target,\n        )\n\n        # iterate over patches\n        # patches are tuples of (patch, target) if target is available\n        # or (patch, None) only if no target is available\n        # patch is of dimensions (C)ZYX\n        for patch_data in patches:\n            yield self.patch_transform(\n                patch=patch_data[0],\n                target=patch_data[1],\n            )\n</code></pre>"},{"location":"reference/careamics/dataset/iterable_dataset/#careamics.dataset.iterable_dataset.PathIterableDataset.get_number_of_files","title":"<code>get_number_of_files()</code>","text":"<p>Return the number of files in the dataset.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of files in the dataset.</p> Source code in <code>src/careamics/dataset/iterable_dataset.py</code> <pre><code>def get_number_of_files(self) -&gt; int:\n    \"\"\"\n    Return the number of files in the dataset.\n\n    Returns\n    -------\n    int\n        Number of files in the dataset.\n    \"\"\"\n    return len(self.data_files)\n</code></pre>"},{"location":"reference/careamics/dataset/iterable_dataset/#careamics.dataset.iterable_dataset.PathIterableDataset.split_dataset","title":"<code>split_dataset(percentage=0.1, minimum_number=5)</code>","text":"<p>Split up dataset in two.</p> <p>Splits the datest sing a percentage of the data (files) to extract, or the minimum number of the percentage is less than the minimum number.</p> <p>Parameters:</p> Name Type Description Default <code>percentage</code> <code>float</code> <p>Percentage of files to split up, by default 0.1.</p> <code>0.1</code> <code>minimum_number</code> <code>int</code> <p>Minimum number of files to split up, by default 5.</p> <code>5</code> <p>Returns:</p> Type Description <code>IterableDataset</code> <p>Dataset containing the split data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the percentage is smaller than 0 or larger than 1.</p> <code>ValueError</code> <p>If the minimum number is smaller than 1 or larger than the number of files.</p> Source code in <code>src/careamics/dataset/iterable_dataset.py</code> <pre><code>def split_dataset(\n    self,\n    percentage: float = 0.1,\n    minimum_number: int = 5,\n) -&gt; PathIterableDataset:\n    \"\"\"Split up dataset in two.\n\n    Splits the datest sing a percentage of the data (files) to extract, or the\n    minimum number of the percentage is less than the minimum number.\n\n    Parameters\n    ----------\n    percentage : float, optional\n        Percentage of files to split up, by default 0.1.\n    minimum_number : int, optional\n        Minimum number of files to split up, by default 5.\n\n    Returns\n    -------\n    IterableDataset\n        Dataset containing the split data.\n\n    Raises\n    ------\n    ValueError\n        If the percentage is smaller than 0 or larger than 1.\n    ValueError\n        If the minimum number is smaller than 1 or larger than the number of files.\n    \"\"\"\n    if percentage &lt; 0 or percentage &gt; 1:\n        raise ValueError(f\"Percentage must be between 0 and 1, got {percentage}.\")\n\n    if minimum_number &lt; 1 or minimum_number &gt; self.get_number_of_files():\n        raise ValueError(\n            f\"Minimum number of files must be between 1 and \"\n            f\"{self.get_number_of_files()} (number of files), got \"\n            f\"{minimum_number}.\"\n        )\n\n    # compute number of files\n    total_files = self.get_number_of_files()\n    n_files = max(round(percentage * total_files), minimum_number)\n\n    # get random indices\n    indices = np.random.choice(total_files, n_files, replace=False)\n\n    # extract files\n    val_files = [self.data_files[i] for i in indices]\n\n    # remove patches from self.patch\n    data_files = []\n    for i, file in enumerate(self.data_files):\n        if i not in indices:\n            data_files.append(file)\n    self.data_files = data_files\n\n    # same for targets\n    if self.target_files is not None:\n        val_target_files = [self.target_files[i] for i in indices]\n\n        data_target_files = []\n        for i, file in enumerate(self.target_files):\n            if i not in indices:\n                data_target_files.append(file)\n        self.target_files = data_target_files\n\n    # clone the dataset\n    dataset = copy.deepcopy(self)\n\n    # reassign patches\n    dataset.data_files = val_files\n\n    # reassign targets\n    if self.target_files is not None:\n        dataset.target_files = val_target_files\n\n    return dataset\n</code></pre>"},{"location":"reference/careamics/dataset/zarr_dataset/","title":"zarr_dataset","text":"<p>Zarr dataset.</p>"},{"location":"reference/careamics/dataset/dataset_utils/dataset_utils/","title":"dataset_utils","text":"<p>Dataset utilities.</p>"},{"location":"reference/careamics/dataset/dataset_utils/dataset_utils/#careamics.dataset.dataset_utils.dataset_utils.reshape_array","title":"<code>reshape_array(x, axes)</code>","text":"<p>Reshape the data to (S, C, (Z), Y, X) by moving axes.</p> <p>If the data has both S and T axes, the two axes will be merged. A singleton dimension is added if there are no C axis.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array.</p> required <code>axes</code> <code>str</code> <p>Description of axes in format <code>STCZYX</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Reshaped array with shape (S, C, (Z), Y, X).</p> Source code in <code>src/careamics/dataset/dataset_utils/dataset_utils.py</code> <pre><code>def reshape_array(x: np.ndarray, axes: str) -&gt; np.ndarray:\n    \"\"\"Reshape the data to (S, C, (Z), Y, X) by moving axes.\n\n    If the data has both S and T axes, the two axes will be merged. A singleton\n    dimension is added if there are no C axis.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        Input array.\n    axes : str\n        Description of axes in format `STCZYX`.\n\n    Returns\n    -------\n    np.ndarray\n        Reshaped array with shape (S, C, (Z), Y, X).\n    \"\"\"\n    _x = x\n    _axes = axes\n\n    # sanity checks\n    if len(_axes) != len(_x.shape):\n        raise ValueError(\n            f\"Incompatible data shape ({_x.shape}) and axes ({_axes}). Are the axes \"\n            f\"correct?\"\n        )\n\n    # get new x shape\n    new_x_shape, new_axes, indices = _get_shape_order(_x.shape, _axes)\n\n    # if S is not in the list of axes, then add a singleton S\n    if \"S\" not in new_axes:\n        new_axes = \"S\" + new_axes\n        _x = _x[np.newaxis, ...]\n        new_x_shape = (1,) + new_x_shape\n\n        # need to change the array of indices\n        indices = [0] + [1 + i for i in indices]\n\n    # reshape by moving axes\n    destination = list(range(len(indices)))\n    _x = np.moveaxis(_x, indices, destination)\n\n    # remove T if necessary\n    if \"T\" in new_axes:\n        new_x_shape = (-1,) + new_x_shape[2:]  # remove T and S\n        new_axes = new_axes.replace(\"T\", \"\")\n\n        # reshape S and T together\n        _x = _x.reshape(new_x_shape)\n\n    # add channel\n    if \"C\" not in new_axes:\n        # Add channel axis after S\n        _x = np.expand_dims(_x, new_axes.index(\"S\") + 1)\n\n    return _x\n</code></pre>"},{"location":"reference/careamics/dataset/dataset_utils/file_utils/","title":"file_utils","text":"<p>File utilities.</p>"},{"location":"reference/careamics/dataset/dataset_utils/file_utils/#careamics.dataset.dataset_utils.file_utils.get_files_size","title":"<code>get_files_size(files)</code>","text":"<p>Get files size in MB.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>List[Path]</code> <p>List of files.</p> required <p>Returns:</p> Type Description <code>float</code> <p>Total size of the files in MB.</p> Source code in <code>src/careamics/dataset/dataset_utils/file_utils.py</code> <pre><code>def get_files_size(files: List[Path]) -&gt; float:\n    \"\"\"Get files size in MB.\n\n    Parameters\n    ----------\n    files : List[Path]\n        List of files.\n\n    Returns\n    -------\n    float\n        Total size of the files in MB.\n    \"\"\"\n    return np.sum([f.stat().st_size / 1024**2 for f in files])\n</code></pre>"},{"location":"reference/careamics/dataset/dataset_utils/file_utils/#careamics.dataset.dataset_utils.file_utils.list_files","title":"<code>list_files(data_path, data_type, extension_filter='')</code>","text":"<p>Create a recursive list of files in <code>data_path</code>.</p> <p>If <code>data_path</code> is a file, its name is validated against the <code>data_type</code> using <code>fnmatch</code>, and the method returns <code>data_path</code> itself.</p> <p>By default, if <code>data_type</code> is equal to <code>custom</code>, all files will be listed. To further filter the files, use <code>extension_filter</code>.</p> <p><code>extension_filter</code> must be compatible with <code>fnmatch</code> and <code>Path.rglob</code>, e.g. \".npy\" or \".czi\".</p> <p>Parameters:</p> Name Type Description Default <code>data_path</code> <code>Union[str, Path]</code> <p>Path to the folder containing the data.</p> required <code>data_type</code> <code>Union[str, SupportedData]</code> <p>One of the supported data type (e.g. tif, custom).</p> required <code>extension_filter</code> <code>str</code> <p>Extension filter, by default \"\".</p> <code>''</code> <p>Returns:</p> Type Description <code>List[Path]</code> <p>List of pathlib.Path objects.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the data path does not exist.</p> <code>ValueError</code> <p>If the data path is empty or no files with the extension were found.</p> <code>ValueError</code> <p>If the file does not match the requested extension.</p> Source code in <code>src/careamics/dataset/dataset_utils/file_utils.py</code> <pre><code>def list_files(\n    data_path: Union[str, Path],\n    data_type: Union[str, SupportedData],\n    extension_filter: str = \"\",\n) -&gt; List[Path]:\n    \"\"\"Create a recursive list of files in `data_path`.\n\n    If `data_path` is a file, its name is validated against the `data_type` using\n    `fnmatch`, and the method returns `data_path` itself.\n\n    By default, if `data_type` is equal to `custom`, all files will be listed. To\n    further filter the files, use `extension_filter`.\n\n    `extension_filter` must be compatible with `fnmatch` and `Path.rglob`, e.g. \"*.npy\"\n    or \"*.czi\".\n\n    Parameters\n    ----------\n    data_path : Union[str, Path]\n        Path to the folder containing the data.\n    data_type : Union[str, SupportedData]\n        One of the supported data type (e.g. tif, custom).\n    extension_filter : str, optional\n        Extension filter, by default \"\".\n\n    Returns\n    -------\n    List[Path]\n        List of pathlib.Path objects.\n\n    Raises\n    ------\n    FileNotFoundError\n        If the data path does not exist.\n    ValueError\n        If the data path is empty or no files with the extension were found.\n    ValueError\n        If the file does not match the requested extension.\n    \"\"\"\n    # convert to Path\n    data_path = Path(data_path)\n\n    # raise error if does not exists\n    if not data_path.exists():\n        raise FileNotFoundError(f\"Data path {data_path} does not exist.\")\n\n    # get extension compatible with fnmatch and rglob search\n    extension = SupportedData.get_extension(data_type)\n\n    if data_type == SupportedData.CUSTOM and extension_filter != \"\":\n        extension = extension_filter\n\n    # search recurively\n    if data_path.is_dir():\n        # search recursively the path for files with the extension\n        files = sorted(data_path.rglob(extension))\n    else:\n        # raise error if it has the wrong extension\n        if not fnmatch(str(data_path.absolute()), extension):\n            raise ValueError(\n                f\"File {data_path} does not match the requested extension \"\n                f'\"{extension}\".'\n            )\n\n        # save in list\n        files = [data_path]\n\n    # raise error if no files were found\n    if len(files) == 0:\n        raise ValueError(\n            f'Data path {data_path} is empty or files with extension \"{extension}\" '\n            f\"were not found.\"\n        )\n\n    return files\n</code></pre>"},{"location":"reference/careamics/dataset/dataset_utils/file_utils/#careamics.dataset.dataset_utils.file_utils.validate_source_target_files","title":"<code>validate_source_target_files(src_files, tar_files)</code>","text":"<p>Validate source and target path lists.</p> <p>The two lists should have the same number of files, and the filenames should match.</p> <p>Parameters:</p> Name Type Description Default <code>src_files</code> <code>List[Path]</code> <p>List of source files.</p> required <code>tar_files</code> <code>List[Path]</code> <p>List of target files.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of files in source and target folders is not the same.</p> <code>ValueError</code> <p>If some filenames in Train and target folders are not the same.</p> Source code in <code>src/careamics/dataset/dataset_utils/file_utils.py</code> <pre><code>def validate_source_target_files(src_files: List[Path], tar_files: List[Path]) -&gt; None:\n    \"\"\"\n    Validate source and target path lists.\n\n    The two lists should have the same number of files, and the filenames should match.\n\n    Parameters\n    ----------\n    src_files : List[Path]\n        List of source files.\n    tar_files : List[Path]\n        List of target files.\n\n    Raises\n    ------\n    ValueError\n        If the number of files in source and target folders is not the same.\n    ValueError\n        If some filenames in Train and target folders are not the same.\n    \"\"\"\n    # check equal length\n    if len(src_files) != len(tar_files):\n        raise ValueError(\n            f\"The number of source files ({len(src_files)}) is not equal to the number \"\n            f\"of target files ({len(tar_files)}).\"\n        )\n\n    # check identical names\n    src_names = {f.name for f in src_files}\n    tar_names = {f.name for f in tar_files}\n    difference = src_names.symmetric_difference(tar_names)\n\n    if len(difference) &gt; 0:\n        raise ValueError(f\"Source and target files have different names: {difference}.\")\n</code></pre>"},{"location":"reference/careamics/dataset/dataset_utils/read_tiff/","title":"read_tiff","text":"<p>Funtions to read tiff images.</p>"},{"location":"reference/careamics/dataset/dataset_utils/read_tiff/#careamics.dataset.dataset_utils.read_tiff.read_tiff","title":"<code>read_tiff(file_path, *args, **kwargs)</code>","text":"<p>Read a tiff file and return a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>Path</code> <p>Path to a file.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Resulting array.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file failed to open.</p> <code>OSError</code> <p>If the file failed to open.</p> <code>ValueError</code> <p>If the file is not a valid tiff.</p> <code>ValueError</code> <p>If the data dimensions are incorrect.</p> <code>ValueError</code> <p>If the axes length is incorrect.</p> Source code in <code>src/careamics/dataset/dataset_utils/read_tiff.py</code> <pre><code>def read_tiff(file_path: Path, *args: list, **kwargs: dict) -&gt; np.ndarray:\n    \"\"\"\n    Read a tiff file and return a numpy array.\n\n    Parameters\n    ----------\n    file_path : Path\n        Path to a file.\n\n    Returns\n    -------\n    np.ndarray\n        Resulting array.\n\n    Raises\n    ------\n    ValueError\n        If the file failed to open.\n    OSError\n        If the file failed to open.\n    ValueError\n        If the file is not a valid tiff.\n    ValueError\n        If the data dimensions are incorrect.\n    ValueError\n        If the axes length is incorrect.\n    \"\"\"\n    if fnmatch(file_path.suffix, SupportedData.get_extension(SupportedData.TIFF)):\n        try:\n            array = tifffile.imread(file_path)\n        except (ValueError, OSError) as e:\n            logging.exception(f\"Exception in file {file_path}: {e}, skipping it.\")\n            raise e\n    else:\n        raise ValueError(f\"File {file_path} is not a valid tiff.\")\n\n    # check dimensions\n    # TODO or should this really be done here? probably in the LightningDataModule\n    # TODO this should also be centralized somewhere else (validate_dimensions)\n    if len(array.shape) &lt; 2 or len(array.shape) &gt; 6:\n        raise ValueError(\n            f\"Incorrect data dimensions. Must be 2, 3 or 4 (got {array.shape} for\"\n            f\"file {file_path}).\"\n        )\n\n    return array\n</code></pre>"},{"location":"reference/careamics/dataset/dataset_utils/read_utils/","title":"read_utils","text":"<p>Read function utilities.</p>"},{"location":"reference/careamics/dataset/dataset_utils/read_utils/#careamics.dataset.dataset_utils.read_utils.get_read_func","title":"<code>get_read_func(data_type)</code>","text":"<p>Get the read function for the data type.</p> <p>Parameters:</p> Name Type Description Default <code>data_type</code> <code>SupportedData</code> <p>Data type.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>Read function.</p> Source code in <code>src/careamics/dataset/dataset_utils/read_utils.py</code> <pre><code>def get_read_func(data_type: Union[SupportedData, str]) -&gt; Callable:\n    \"\"\"\n    Get the read function for the data type.\n\n    Parameters\n    ----------\n    data_type : SupportedData\n        Data type.\n\n    Returns\n    -------\n    Callable\n        Read function.\n    \"\"\"\n    if data_type == SupportedData.TIFF:\n        return read_tiff\n    else:\n        raise NotImplementedError(f\"Data type {data_type} is not supported.\")\n</code></pre>"},{"location":"reference/careamics/dataset/dataset_utils/read_zarr/","title":"read_zarr","text":"<p>Function to read zarr images.</p>"},{"location":"reference/careamics/dataset/dataset_utils/read_zarr/#careamics.dataset.dataset_utils.read_zarr.read_zarr","title":"<code>read_zarr(zarr_source, axes)</code>","text":"<p>Read a file and returns a pointer.</p> <p>Parameters:</p> Name Type Description Default <code>zarr_source</code> <code>Group</code> <p>Zarr storage.</p> required <code>axes</code> <code>str</code> <p>Axes of the data.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Pointer to zarr storage.</p> <p>Raises:</p> Type Description <code>(ValueError, OSError)</code> <p>if a file is not a valid tiff or damaged.</p> <code>ValueError</code> <p>if data dimensions are not 2, 3 or 4.</p> <code>ValueError</code> <p>if axes parameter from config is not consistent with data dimensions.</p> Source code in <code>src/careamics/dataset/dataset_utils/read_zarr.py</code> <pre><code>def read_zarr(\n    zarr_source: Group, axes: str\n) -&gt; Union[core.Array, storage.DirectoryStore, hierarchy.Group]:\n    \"\"\"Read a file and returns a pointer.\n\n    Parameters\n    ----------\n    zarr_source : Group\n        Zarr storage.\n    axes : str\n        Axes of the data.\n\n    Returns\n    -------\n    np.ndarray\n        Pointer to zarr storage.\n\n    Raises\n    ------\n    ValueError, OSError\n        if a file is not a valid tiff or damaged.\n    ValueError\n        if data dimensions are not 2, 3 or 4.\n    ValueError\n        if axes parameter from config is not consistent with data dimensions.\n    \"\"\"\n    if isinstance(zarr_source, hierarchy.Group):\n        array = zarr_source[0]\n\n    elif isinstance(zarr_source, storage.DirectoryStore):\n        raise NotImplementedError(\"DirectoryStore not supported yet\")\n\n    elif isinstance(zarr_source, core.Array):\n        # array should be of shape (S, (C), (Z), Y, X), iterating over S ?\n        if zarr_source.dtype == \"O\":\n            raise NotImplementedError(\"Object type not supported yet\")\n        else:\n            array = zarr_source\n    else:\n        raise ValueError(f\"Unsupported zarr object type {type(zarr_source)}\")\n\n    # sanity check on dimensions\n    if len(array.shape) &lt; 2 or len(array.shape) &gt; 4:\n        raise ValueError(\n            f\"Incorrect data dimensions. Must be 2, 3 or 4 (got {array.shape}).\"\n        )\n\n    # sanity check on axes length\n    if len(axes) != len(array.shape):\n        raise ValueError(f\"Incorrect axes length (got {axes}).\")\n\n    # arr = fix_axes(arr, axes)\n    return array\n</code></pre>"},{"location":"reference/careamics/dataset/patching/patching/","title":"patching","text":"<p>Patching functions.</p>"},{"location":"reference/careamics/dataset/patching/patching/#careamics.dataset.patching.patching.prepare_patches_supervised","title":"<code>prepare_patches_supervised(train_files, target_files, axes, patch_size, read_source_func)</code>","text":"<p>Iterate over data source and create an array of patches and corresponding targets.</p> <p>Parameters:</p> Name Type Description Default <code>train_files</code> <code>List[Path]</code> <p>List of paths to training data.</p> required <code>target_files</code> <code>List[Path]</code> <p>List of paths to target data.</p> required <code>axes</code> <code>str</code> <p>Axes of the data.</p> required <code>patch_size</code> <code>Union[List[int], Tuple[int]]</code> <p>Size of the patches.</p> required <code>read_source_func</code> <code>Callable</code> <p>Function to read the data.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of patches.</p> Source code in <code>src/careamics/dataset/patching/patching.py</code> <pre><code>def prepare_patches_supervised(\n    train_files: List[Path],\n    target_files: List[Path],\n    axes: str,\n    patch_size: Union[List[int], Tuple[int, ...]],\n    read_source_func: Callable,\n) -&gt; Tuple[np.ndarray, np.ndarray, float, float]:\n    \"\"\"\n    Iterate over data source and create an array of patches and corresponding targets.\n\n    Parameters\n    ----------\n    train_files : List[Path]\n        List of paths to training data.\n    target_files : List[Path]\n        List of paths to target data.\n    axes : str\n        Axes of the data.\n    patch_size : Union[List[int], Tuple[int]]\n        Size of the patches.\n    read_source_func : Callable\n        Function to read the data.\n\n    Returns\n    -------\n    np.ndarray\n        Array of patches.\n    \"\"\"\n    train_files.sort()\n    target_files.sort()\n\n    means, stds, num_samples = 0, 0, 0\n    all_patches, all_targets = [], []\n    for train_filename, target_filename in zip(train_files, target_files):\n        try:\n            sample: np.ndarray = read_source_func(train_filename, axes)\n            target: np.ndarray = read_source_func(target_filename, axes)\n            means += sample.mean()\n            stds += sample.std()\n            num_samples += 1\n\n            # reshape array\n            sample = reshape_array(sample, axes)\n            target = reshape_array(target, axes)\n\n            # generate patches, return a generator\n            patches, targets = extract_patches_sequential(\n                sample, patch_size=patch_size, target=target\n            )\n\n            # convert generator to list and add to all_patches\n            all_patches.append(patches)\n\n            # ensure targets are not None (type checking)\n            if targets is not None:\n                all_targets.append(targets)\n            else:\n                raise ValueError(f\"No target found for {target_filename}.\")\n\n        except Exception as e:\n            # emit warning and continue\n            logger.error(f\"Failed to read {train_filename} or {target_filename}: {e}\")\n\n    # raise error if no valid samples found\n    if num_samples == 0 or len(all_patches) == 0:\n        raise ValueError(\n            f\"No valid samples found in the input data: {train_files} and \"\n            f\"{target_files}.\"\n        )\n\n    result_mean, result_std = means / num_samples, stds / num_samples\n\n    patch_array: np.ndarray = np.concatenate(all_patches, axis=0)\n    target_array: np.ndarray = np.concatenate(all_targets, axis=0)\n    logger.info(f\"Extracted {patch_array.shape[0]} patches from input array.\")\n\n    return (\n        patch_array,\n        target_array,\n        result_mean,\n        result_std,\n    )\n</code></pre>"},{"location":"reference/careamics/dataset/patching/patching/#careamics.dataset.patching.patching.prepare_patches_supervised_array","title":"<code>prepare_patches_supervised_array(data, axes, data_target, patch_size)</code>","text":"<p>Iterate over data source and create an array of patches.</p> <p>This method expects an array of shape SC(Z)YX, where S and C can be singleton dimensions.</p> <p>Patches returned are of shape SC(Z)YX, where S is now the patches dimension.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data array.</p> required <code>axes</code> <code>str</code> <p>Axes of the data.</p> required <code>data_target</code> <code>ndarray</code> <p>Target data array.</p> required <code>patch_size</code> <code>Union[List[int], Tuple[int]]</code> <p>Size of the patches.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, float, float]</code> <p>Source and target patches, mean and standard deviation.</p> Source code in <code>src/careamics/dataset/patching/patching.py</code> <pre><code>def prepare_patches_supervised_array(\n    data: np.ndarray,\n    axes: str,\n    data_target: np.ndarray,\n    patch_size: Union[List[int], Tuple[int]],\n) -&gt; Tuple[np.ndarray, np.ndarray, float, float]:\n    \"\"\"Iterate over data source and create an array of patches.\n\n    This method expects an array of shape SC(Z)YX, where S and C can be singleton\n    dimensions.\n\n    Patches returned are of shape SC(Z)YX, where S is now the patches dimension.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Input data array.\n    axes : str\n        Axes of the data.\n    data_target : np.ndarray\n        Target data array.\n    patch_size : Union[List[int], Tuple[int]]\n        Size of the patches.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, float, float]\n        Source and target patches, mean and standard deviation.\n    \"\"\"\n    # compute statistics\n    mean = data.mean()\n    std = data.std()\n\n    # reshape array\n    reshaped_sample = reshape_array(data, axes)\n    reshaped_target = reshape_array(data_target, axes)\n\n    # generate patches, return a generator\n    patches, patch_targets = extract_patches_sequential(\n        reshaped_sample, patch_size=patch_size, target=reshaped_target\n    )\n\n    if patch_targets is None:\n        raise ValueError(\"No target extracted.\")\n\n    logger.info(f\"Extracted {patches.shape[0]} patches from input array.\")\n\n    return (\n        patches,\n        patch_targets,\n        mean,\n        std,\n    )\n</code></pre>"},{"location":"reference/careamics/dataset/patching/patching/#careamics.dataset.patching.patching.prepare_patches_unsupervised","title":"<code>prepare_patches_unsupervised(train_files, axes, patch_size, read_source_func)</code>","text":"<p>Iterate over data source and create an array of patches.</p> <p>This method returns the mean and standard deviation of the image.</p> <p>Parameters:</p> Name Type Description Default <code>train_files</code> <code>List[Path]</code> <p>List of paths to training data.</p> required <code>axes</code> <code>str</code> <p>Axes of the data.</p> required <code>patch_size</code> <code>Union[List[int], Tuple[int]]</code> <p>Size of the patches.</p> required <code>read_source_func</code> <code>Callable</code> <p>Function to read the data.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, None, float, float]</code> <p>Source and target patches, mean and standard deviation.</p> Source code in <code>src/careamics/dataset/patching/patching.py</code> <pre><code>def prepare_patches_unsupervised(\n    train_files: List[Path],\n    axes: str,\n    patch_size: Union[List[int], Tuple[int]],\n    read_source_func: Callable,\n) -&gt; Tuple[np.ndarray, None, float, float]:\n    \"\"\"Iterate over data source and create an array of patches.\n\n    This method returns the mean and standard deviation of the image.\n\n    Parameters\n    ----------\n    train_files : List[Path]\n        List of paths to training data.\n    axes : str\n        Axes of the data.\n    patch_size : Union[List[int], Tuple[int]]\n        Size of the patches.\n    read_source_func : Callable\n        Function to read the data.\n\n    Returns\n    -------\n    Tuple[np.ndarray, None, float, float]\n        Source and target patches, mean and standard deviation.\n    \"\"\"\n    means, stds, num_samples = 0, 0, 0\n    all_patches = []\n    for filename in train_files:\n        try:\n            sample: np.ndarray = read_source_func(filename, axes)\n            means += sample.mean()\n            stds += sample.std()\n            num_samples += 1\n\n            # reshape array\n            sample = reshape_array(sample, axes)\n\n            # generate patches, return a generator\n            patches, _ = extract_patches_sequential(sample, patch_size=patch_size)\n\n            # convert generator to list and add to all_patches\n            all_patches.append(patches)\n        except Exception as e:\n            # emit warning and continue\n            logger.error(f\"Failed to read {filename}: {e}\")\n\n    # raise error if no valid samples found\n    if num_samples == 0:\n        raise ValueError(f\"No valid samples found in the input data: {train_files}.\")\n\n    result_mean, result_std = means / num_samples, stds / num_samples\n\n    patch_array: np.ndarray = np.concatenate(all_patches)\n    logger.info(f\"Extracted {patch_array.shape[0]} patches from input array.\")\n\n    return patch_array, _, result_mean, result_std  # TODO return object?\n</code></pre>"},{"location":"reference/careamics/dataset/patching/patching/#careamics.dataset.patching.patching.prepare_patches_unsupervised_array","title":"<code>prepare_patches_unsupervised_array(data, axes, patch_size)</code>","text":"<p>Iterate over data source and create an array of patches.</p> <p>This method expects an array of shape SC(Z)YX, where S and C can be singleton dimensions.</p> <p>Patches returned are of shape SC(Z)YX, where S is now the patches dimension.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data array.</p> required <code>axes</code> <code>str</code> <p>Axes of the data.</p> required <code>patch_size</code> <code>Union[List[int], Tuple[int]]</code> <p>Size of the patches.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, None, float, float]</code> <p>Source patches, mean and standard deviation.</p> Source code in <code>src/careamics/dataset/patching/patching.py</code> <pre><code>def prepare_patches_unsupervised_array(\n    data: np.ndarray,\n    axes: str,\n    patch_size: Union[List[int], Tuple[int]],\n) -&gt; Tuple[np.ndarray, None, float, float]:\n    \"\"\"\n    Iterate over data source and create an array of patches.\n\n    This method expects an array of shape SC(Z)YX, where S and C can be singleton\n    dimensions.\n\n    Patches returned are of shape SC(Z)YX, where S is now the patches dimension.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        Input data array.\n    axes : str\n        Axes of the data.\n    patch_size : Union[List[int], Tuple[int]]\n        Size of the patches.\n\n    Returns\n    -------\n    Tuple[np.ndarray, None, float, float]\n        Source patches, mean and standard deviation.\n    \"\"\"\n    # calculate mean and std\n    mean = data.mean()\n    std = data.std()\n\n    # reshape array\n    reshaped_sample = reshape_array(data, axes)\n\n    # generate patches, return a generator\n    patches, _ = extract_patches_sequential(reshaped_sample, patch_size=patch_size)\n\n    return patches, _, mean, std  # TODO inelegant, replace by dataclass?\n</code></pre>"},{"location":"reference/careamics/dataset/patching/random_patching/","title":"random_patching","text":"<p>Random patching utilities.</p>"},{"location":"reference/careamics/dataset/patching/random_patching/#careamics.dataset.patching.random_patching.extract_patches_random","title":"<code>extract_patches_random(arr, patch_size, target=None)</code>","text":"<p>Generate patches from an array in a random manner.</p> <p>The method calculates how many patches the image can be divided into and then extracts an equal number of random patches.</p> <p>It returns a generator that yields the following:</p> <ul> <li>patch: np.ndarray, dimension C(Z)YX.</li> <li>target_patch: np.ndarray, dimension C(Z)YX, if the target is present, None     otherwise.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>Input image array.</p> required <code>patch_size</code> <code>Tuple[int]</code> <p>Patch sizes in each dimension.</p> required <code>target</code> <code>Optional[ndarray]</code> <p>Target array, by default None.</p> <code>None</code> <p>Yields:</p> Type Description <code>Generator[ndarray, None, None]</code> <p>Generator of patches.</p> Source code in <code>src/careamics/dataset/patching/random_patching.py</code> <pre><code>def extract_patches_random(\n    arr: np.ndarray,\n    patch_size: Union[List[int], Tuple[int, ...]],\n    target: Optional[np.ndarray] = None,\n) -&gt; Generator[Tuple[np.ndarray, Optional[np.ndarray]], None, None]:\n    \"\"\"\n    Generate patches from an array in a random manner.\n\n    The method calculates how many patches the image can be divided into and then\n    extracts an equal number of random patches.\n\n    It returns a generator that yields the following:\n\n    - patch: np.ndarray, dimension C(Z)YX.\n    - target_patch: np.ndarray, dimension C(Z)YX, if the target is present, None\n        otherwise.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input image array.\n    patch_size : Tuple[int]\n        Patch sizes in each dimension.\n    target : Optional[np.ndarray], optional\n        Target array, by default None.\n\n    Yields\n    ------\n    Generator[np.ndarray, None, None]\n        Generator of patches.\n    \"\"\"\n    is_3d_patch = len(patch_size) == 3\n\n    # patches sanity check\n    validate_patch_dimensions(arr, patch_size, is_3d_patch)\n\n    # Update patch size to encompass S and C dimensions\n    patch_size = [1, arr.shape[1], *patch_size]\n\n    # random generator\n    rng = np.random.default_rng()\n\n    # iterate over the number of samples (S or T)\n    for sample_idx in range(arr.shape[0]):\n        # get sample array\n        sample: np.ndarray = arr[sample_idx, ...]\n\n        # same for target\n        if target is not None:\n            target_sample: np.ndarray = target[sample_idx, ...]\n\n        # calculate the number of patches\n        n_patches = np.ceil(np.prod(sample.shape) / np.prod(patch_size)).astype(int)\n\n        # iterate over the number of patches\n        for _ in range(n_patches):\n            # get crop coordinates\n            crop_coords = [\n                rng.integers(0, sample.shape[i] - patch_size[1:][i], endpoint=True)\n                for i in range(len(patch_size[1:]))\n            ]\n\n            # extract patch\n            patch = (\n                sample[\n                    (\n                        ...,  # type: ignore\n                        *[  # type: ignore\n                            slice(c, c + patch_size[1:][i])\n                            for i, c in enumerate(crop_coords)\n                        ],\n                    )\n                ]\n                .copy()\n                .astype(np.float32)\n            )\n\n            # same for target\n            if target is not None:\n                target_patch = (\n                    target_sample[\n                        (\n                            ...,  # type: ignore\n                            *[  # type: ignore\n                                slice(c, c + patch_size[1:][i])\n                                for i, c in enumerate(crop_coords)\n                            ],\n                        )\n                    ]\n                    .copy()\n                    .astype(np.float32)\n                )\n                # return patch and target patch\n                yield patch, target_patch\n            else:\n                # return patch\n                yield patch, None\n</code></pre>"},{"location":"reference/careamics/dataset/patching/random_patching/#careamics.dataset.patching.random_patching.extract_patches_random_from_chunks","title":"<code>extract_patches_random_from_chunks(arr, patch_size, chunk_size, chunk_limit=None)</code>","text":"<p>Generate patches from an array in a random manner.</p> <p>The method calculates how many patches the image can be divided into and then extracts an equal number of random patches.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>Input image array.</p> required <code>patch_size</code> <code>Union[List[int], Tuple[int, ...]]</code> <p>Patch sizes in each dimension.</p> required <code>chunk_size</code> <code>Union[List[int], Tuple[int, ...]]</code> <p>Chunk sizes to load from the.</p> required <code>chunk_limit</code> <code>Optional[int]</code> <p>Number of chunks to load, by default None.</p> <code>None</code> <p>Yields:</p> Type Description <code>Generator[ndarray, None, None]</code> <p>Generator of patches.</p> Source code in <code>src/careamics/dataset/patching/random_patching.py</code> <pre><code>def extract_patches_random_from_chunks(\n    arr: zarr.Array,\n    patch_size: Union[List[int], Tuple[int, ...]],\n    chunk_size: Union[List[int], Tuple[int, ...]],\n    chunk_limit: Optional[int] = None,\n) -&gt; Generator[np.ndarray, None, None]:\n    \"\"\"\n    Generate patches from an array in a random manner.\n\n    The method calculates how many patches the image can be divided into and then\n    extracts an equal number of random patches.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input image array.\n    patch_size : Union[List[int], Tuple[int, ...]]\n        Patch sizes in each dimension.\n    chunk_size : Union[List[int], Tuple[int, ...]]\n        Chunk sizes to load from the.\n    chunk_limit : Optional[int], optional\n        Number of chunks to load, by default None.\n\n    Yields\n    ------\n    Generator[np.ndarray, None, None]\n        Generator of patches.\n    \"\"\"\n    is_3d_patch = len(patch_size) == 3\n\n    # Patches sanity check\n    validate_patch_dimensions(arr, patch_size, is_3d_patch)\n\n    rng = np.random.default_rng()\n    num_chunks = chunk_limit if chunk_limit else np.prod(arr._cdata_shape)\n\n    # Iterate over num chunks in the array\n    for _ in range(num_chunks):\n        chunk_crop_coords = [\n            rng.integers(0, max(0, arr.shape[i] - chunk_size[i]), endpoint=True)\n            for i in range(len(chunk_size))\n        ]\n        chunk = arr[\n            (\n                ...,\n                *[slice(c, c + chunk_size[i]) for i, c in enumerate(chunk_crop_coords)],\n            )\n        ].squeeze()\n\n        # Add a singleton dimension if the chunk does not have a sample dimension\n        if len(chunk.shape) == len(patch_size):\n            chunk = np.expand_dims(chunk, axis=0)\n\n        # Iterate over num samples (S)\n        for sample_idx in range(chunk.shape[0]):\n            spatial_chunk = chunk[sample_idx]\n            assert len(spatial_chunk.shape) == len(\n                patch_size\n            ), \"Requested chunk shape is not equal to patch size\"\n\n            n_patches = np.ceil(\n                np.prod(spatial_chunk.shape) / np.prod(patch_size)\n            ).astype(int)\n\n            # Iterate over the number of patches\n            for _ in range(n_patches):\n                patch_crop_coords = [\n                    rng.integers(\n                        0, spatial_chunk.shape[i] - patch_size[i], endpoint=True\n                    )\n                    for i in range(len(patch_size))\n                ]\n                patch = (\n                    spatial_chunk[\n                        (\n                            ...,\n                            *[\n                                slice(c, c + patch_size[i])\n                                for i, c in enumerate(patch_crop_coords)\n                            ],\n                        )\n                    ]\n                    .copy()\n                    .astype(np.float32)\n                )\n                yield patch\n</code></pre>"},{"location":"reference/careamics/dataset/patching/sequential_patching/","title":"sequential_patching","text":"<p>Sequential patching functions.</p>"},{"location":"reference/careamics/dataset/patching/sequential_patching/#careamics.dataset.patching.sequential_patching.extract_patches_sequential","title":"<code>extract_patches_sequential(arr, patch_size, target=None)</code>","text":"<p>Generate patches from an array in a sequential manner.</p> <p>Array dimensions should be SC(Z)YX, where S and C can be singleton dimensions. The patches are generated sequentially and cover the whole array.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>Input image array.</p> required <code>patch_size</code> <code>Tuple[int]</code> <p>Patch sizes in each dimension.</p> required <code>target</code> <code>Optional[ndarray]</code> <p>Target array, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, Optional[ndarray]]</code> <p>Patches.</p> Source code in <code>src/careamics/dataset/patching/sequential_patching.py</code> <pre><code>def extract_patches_sequential(\n    arr: np.ndarray,\n    patch_size: Union[List[int], Tuple[int, ...]],\n    target: Optional[np.ndarray] = None,\n) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n    \"\"\"\n    Generate patches from an array in a sequential manner.\n\n    Array dimensions should be SC(Z)YX, where S and C can be singleton dimensions. The\n    patches are generated sequentially and cover the whole array.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input image array.\n    patch_size : Tuple[int]\n        Patch sizes in each dimension.\n    target : Optional[np.ndarray], optional\n        Target array, by default None.\n\n    Returns\n    -------\n    Tuple[np.ndarray, Optional[np.ndarray]]\n        Patches.\n    \"\"\"\n    is_3d_patch = len(patch_size) == 3\n\n    # Patches sanity check\n    validate_patch_dimensions(arr, patch_size, is_3d_patch)\n\n    # Update patch size to encompass S and C dimensions\n    patch_size = [1, arr.shape[1], *patch_size]\n\n    # Compute overlap\n    overlaps = _compute_overlap(arr_shape=arr.shape, patch_sizes=patch_size)\n\n    # Create view window and overlaps\n    window_steps = _compute_patch_steps(patch_sizes=patch_size, overlaps=overlaps)\n\n    output_shape = [\n        -1,\n    ] + patch_size[1:]\n\n    # Generate a view of the input array containing pre-calculated number of patches\n    # in each dimension with overlap.\n    # Resulting array is resized to (n_patches, C, Z, Y, X) or (n_patches, C, Y, X)\n    patches = _compute_patch_views(\n        arr,\n        window_shape=patch_size,\n        step=window_steps,\n        output_shape=output_shape,\n        target=target,\n    )\n\n    if target is not None:\n        # target was concatenated to patches in _compute_reshaped_view\n        return (\n            patches[:, 0, ...],\n            patches[:, 1, ...],\n        )  # TODO  in _compute_reshaped_view?\n    else:\n        return patches, None\n</code></pre>"},{"location":"reference/careamics/dataset/patching/tiled_patching/","title":"tiled_patching","text":"<p>Tiled patching utilities.</p>"},{"location":"reference/careamics/dataset/patching/tiled_patching/#careamics.dataset.patching.tiled_patching.extract_tiles","title":"<code>extract_tiles(arr, tile_size, overlaps)</code>","text":"<p>Generate tiles from the input array with specified overlap.</p> <p>The tiles cover the whole array. The method returns a generator that yields tuples of array and tile information, the latter includes whether the tile is the last one, the coordinates of the overlap crop, and the coordinates of the stitched tile.</p> <p>The array has shape C(Z)YX, where C can be a singleton.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>Array of shape (S, C, (Z), Y, X).</p> required <code>tile_size</code> <code>Union[List[int], Tuple[int]]</code> <p>Tile sizes in each dimension, of length 2 or 3.</p> required <code>overlaps</code> <code>Union[List[int], Tuple[int]]</code> <p>Overlap values in each dimension, of length 2 or 3.</p> required <p>Yields:</p> Type Description <code>Generator[Tuple[ndarray, TileInformation], None, None]</code> <p>Tile generator, yields the tile and additional information.</p> Source code in <code>src/careamics/dataset/patching/tiled_patching.py</code> <pre><code>def extract_tiles(\n    arr: np.ndarray,\n    tile_size: Union[List[int], Tuple[int, ...]],\n    overlaps: Union[List[int], Tuple[int, ...]],\n) -&gt; Generator[Tuple[np.ndarray, TileInformation], None, None]:\n    \"\"\"\n    Generate tiles from the input array with specified overlap.\n\n    The tiles cover the whole array. The method returns a generator that yields\n    tuples of array and tile information, the latter includes whether\n    the tile is the last one, the coordinates of the overlap crop, and the coordinates\n    of the stitched tile.\n\n    The array has shape C(Z)YX, where C can be a singleton.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Array of shape (S, C, (Z), Y, X).\n    tile_size : Union[List[int], Tuple[int]]\n        Tile sizes in each dimension, of length 2 or 3.\n    overlaps : Union[List[int], Tuple[int]]\n        Overlap values in each dimension, of length 2 or 3.\n\n    Yields\n    ------\n    Generator[Tuple[np.ndarray, TileInformation], None, None]\n        Tile generator, yields the tile and additional information.\n    \"\"\"\n    # Iterate over num samples (S)\n    for sample_idx in range(arr.shape[0]):\n        sample: np.ndarray = arr[sample_idx, ...]\n\n        # Create a list of coordinates for cropping and stitching all axes.\n        # [crop coordinates, stitching coordinates, overlap crop coordinates]\n        # For axis of size 35 and patch size of 32 compute_crop_and_stitch_coords_1d\n        # will output ([(0, 32), (3, 35)], [(0, 20), (20, 35)], [(0, 20), (17, 32)])\n        crop_and_stitch_coords_list = [\n            _compute_crop_and_stitch_coords_1d(\n                sample.shape[i + 1], tile_size[i], overlaps[i]\n            )\n            for i in range(len(tile_size))\n        ]\n\n        # Rearrange crop coordinates from a list of coordinate pairs per axis to a list\n        # grouped by type.\n        all_crop_coords, all_stitch_coords, all_overlap_crop_coords = zip(\n            *crop_and_stitch_coords_list\n        )\n\n        # Maximum tile index\n        max_tile_idx = np.prod([len(axis) for axis in all_crop_coords]) - 1\n\n        # Iterate over generated coordinate pairs:\n        for tile_idx, (crop_coords, stitch_coords, overlap_crop_coords) in enumerate(\n            zip(\n                itertools.product(*all_crop_coords),\n                itertools.product(*all_stitch_coords),\n                itertools.product(*all_overlap_crop_coords),\n            )\n        ):\n            # Extract tile from the sample\n            tile: np.ndarray = sample[\n                (..., *[slice(c[0], c[1]) for c in list(crop_coords)])  # type: ignore\n            ]\n\n            # Check if we are at the end of the sample by computing the length of the\n            # array that contains all the tiles\n            if tile_idx == max_tile_idx:\n                last_tile = True\n            else:\n                last_tile = False\n\n            # create tile information\n            tile_info = TileInformation(\n                array_shape=sample.squeeze().shape,\n                tiled=True,\n                last_tile=last_tile,\n                overlap_crop_coords=overlap_crop_coords,\n                stitch_coords=stitch_coords,\n            )\n\n            yield tile, tile_info\n</code></pre>"},{"location":"reference/careamics/dataset/patching/validate_patch_dimension/","title":"validate_patch_dimension","text":"<p>Patch validation functions.</p>"},{"location":"reference/careamics/dataset/patching/validate_patch_dimension/#careamics.dataset.patching.validate_patch_dimension.validate_patch_dimensions","title":"<code>validate_patch_dimensions(arr, patch_size, is_3d_patch)</code>","text":"<p>Check patch size and array compatibility.</p> <p>This method validates the patch sizes with respect to the array dimensions:</p> <ul> <li>Patch must have two dimensions fewer than the array (S and C).</li> <li>Patch sizes are smaller than the corresponding array dimensions.</li> </ul> <p>If one of these conditions is not met, a ValueError is raised.</p> <p>This method should be called after inputs have been resized.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>Input array.</p> required <code>patch_size</code> <code>Union[List[int], Tuple[int, ...]]</code> <p>Size of the patches along each dimension of the array, except the first.</p> required <code>is_3d_patch</code> <code>bool</code> <p>Whether the patch is 3D or not.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the patch size is not consistent with the array shape (one more array dimension).</p> <code>ValueError</code> <p>If the patch size in Z is larger than the array dimension.</p> <code>ValueError</code> <p>If either of the patch sizes in X or Y is larger than the corresponding array dimension.</p> Source code in <code>src/careamics/dataset/patching/validate_patch_dimension.py</code> <pre><code>def validate_patch_dimensions(\n    arr: np.ndarray,\n    patch_size: Union[List[int], Tuple[int, ...]],\n    is_3d_patch: bool,\n) -&gt; None:\n    \"\"\"\n    Check patch size and array compatibility.\n\n    This method validates the patch sizes with respect to the array dimensions:\n\n    - Patch must have two dimensions fewer than the array (S and C).\n    - Patch sizes are smaller than the corresponding array dimensions.\n\n    If one of these conditions is not met, a ValueError is raised.\n\n    This method should be called after inputs have been resized.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array.\n    patch_size : Union[List[int], Tuple[int, ...]]\n        Size of the patches along each dimension of the array, except the first.\n    is_3d_patch : bool\n        Whether the patch is 3D or not.\n\n    Raises\n    ------\n    ValueError\n        If the patch size is not consistent with the array shape (one more array\n        dimension).\n    ValueError\n        If the patch size in Z is larger than the array dimension.\n    ValueError\n        If either of the patch sizes in X or Y is larger than the corresponding array\n        dimension.\n    \"\"\"\n    if len(patch_size) != len(arr.shape[2:]):\n        raise ValueError(\n            f\"There must be a patch size for each spatial dimensions \"\n            f\"(got {patch_size} patches for dims {arr.shape}).\"\n        )\n\n    # Sanity checks on patch sizes versus array dimension\n    if is_3d_patch and patch_size[0] &gt; arr.shape[-3]:\n        raise ValueError(\n            f\"Z patch size is inconsistent with image shape \"\n            f\"(got {patch_size[0]} patches for dim {arr.shape[1]}).\"\n        )\n\n    if patch_size[-2] &gt; arr.shape[-2] or patch_size[-1] &gt; arr.shape[-1]:\n        raise ValueError(\n            f\"At least one of YX patch dimensions is larger than the corresponding \"\n            f\"image dimension (got {patch_size} patches for dims {arr.shape[-2:]}).\"\n        )\n</code></pre>"},{"location":"reference/careamics/losses/loss_factory/","title":"loss_factory","text":"<p>Loss factory module.</p> <p>This module contains a factory function for creating loss functions.</p>"},{"location":"reference/careamics/losses/loss_factory/#careamics.losses.loss_factory.loss_factory","title":"<code>loss_factory(loss)</code>","text":"<p>Return loss function.</p> <p>Parameters:</p> Name Type Description Default <code>loss</code> <code>Union[SupportedLoss, str]</code> <p>Requested loss.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>Loss function.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the loss is unknown.</p> Source code in <code>src/careamics/losses/loss_factory.py</code> <pre><code>def loss_factory(loss: Union[SupportedLoss, str]) -&gt; Callable:\n    \"\"\"Return loss function.\n\n    Parameters\n    ----------\n    loss : Union[SupportedLoss, str]\n        Requested loss.\n\n    Returns\n    -------\n    Callable\n        Loss function.\n\n    Raises\n    ------\n    NotImplementedError\n        If the loss is unknown.\n    \"\"\"\n    if loss == SupportedLoss.N2V:\n        return n2v_loss\n\n    # elif loss_type == SupportedLoss.PN2V:\n    #     return pn2v_loss\n\n    elif loss == SupportedLoss.MAE:\n        return mae_loss\n\n    elif loss == SupportedLoss.MSE:\n        return mse_loss\n\n    # elif loss_type == SupportedLoss.DICE:\n    #     return dice_loss\n\n    else:\n        raise NotImplementedError(f\"Loss {loss} is not yet supported.\")\n</code></pre>"},{"location":"reference/careamics/losses/losses/","title":"losses","text":"<p>Loss submodule.</p> <p>This submodule contains the various losses used in CAREamics.</p>"},{"location":"reference/careamics/losses/losses/#careamics.losses.losses.mae_loss","title":"<code>mae_loss(samples, labels)</code>","text":"<p>N2N Loss function described in to J Lehtinen et al 2018.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>Raw patches.</p> required <code>labels</code> <code>Tensor</code> <p>Different subset of noisy patches.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Loss value.</p> Source code in <code>src/careamics/losses/losses.py</code> <pre><code>def mae_loss(samples: torch.Tensor, labels: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    N2N Loss function described in to J Lehtinen et al 2018.\n\n    Parameters\n    ----------\n    samples : torch.Tensor\n        Raw patches.\n    labels : torch.Tensor\n        Different subset of noisy patches.\n\n    Returns\n    -------\n    torch.Tensor\n        Loss value.\n    \"\"\"\n    loss = L1Loss()\n    return loss(samples, labels)\n</code></pre>"},{"location":"reference/careamics/losses/losses/#careamics.losses.losses.mse_loss","title":"<code>mse_loss(source, target)</code>","text":"<p>Mean squared error loss.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Tensor</code> <p>Source patches.</p> required <code>target</code> <code>Tensor</code> <p>Target patches.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Loss value.</p> Source code in <code>src/careamics/losses/losses.py</code> <pre><code>def mse_loss(source: torch.Tensor, target: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Mean squared error loss.\n\n    Parameters\n    ----------\n    source : torch.Tensor\n        Source patches.\n    target : torch.Tensor\n        Target patches.\n\n    Returns\n    -------\n    torch.Tensor\n        Loss value.\n    \"\"\"\n    loss = MSELoss()\n    return loss(source, target)\n</code></pre>"},{"location":"reference/careamics/losses/losses/#careamics.losses.losses.n2v_loss","title":"<code>n2v_loss(manipulated_patches, original_patches, masks)</code>","text":"<p>N2V Loss function described in A Krull et al 2018.</p> <p>Parameters:</p> Name Type Description Default <code>manipulated_patches</code> <code>Tensor</code> <p>Patches with manipulated pixels.</p> required <code>original_patches</code> <code>Tensor</code> <p>Noisy patches.</p> required <code>masks</code> <code>Tensor</code> <p>Array containing masked pixel locations.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Loss value.</p> Source code in <code>src/careamics/losses/losses.py</code> <pre><code>def n2v_loss(\n    manipulated_patches: torch.Tensor,\n    original_patches: torch.Tensor,\n    masks: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"\n    N2V Loss function described in A Krull et al 2018.\n\n    Parameters\n    ----------\n    manipulated_patches : torch.Tensor\n        Patches with manipulated pixels.\n    original_patches : torch.Tensor\n        Noisy patches.\n    masks : torch.Tensor\n        Array containing masked pixel locations.\n\n    Returns\n    -------\n    torch.Tensor\n        Loss value.\n    \"\"\"\n    errors = (original_patches - manipulated_patches) ** 2\n    # Average over pixels and batch\n    loss = torch.sum(errors * masks) / torch.sum(masks)\n    return loss\n</code></pre>"},{"location":"reference/careamics/model_io/bmz_io/","title":"bmz_io","text":"<p>Function to export to the BioImage Model Zoo format.</p>"},{"location":"reference/careamics/model_io/bmz_io/#careamics.model_io.bmz_io.export_to_bmz","title":"<code>export_to_bmz(model, config, path, name, general_description, authors, input_array, output_array, channel_names=None, data_description=None)</code>","text":"<p>Export the model to BioImage Model Zoo format.</p> <p>Arrays are expected to be SC(Z)YX with singleton dimensions allowed for S and C.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>CAREamicsKiln</code> <p>CAREamics model to export.</p> required <code>config</code> <code>Configuration</code> <p>Model configuration.</p> required <code>path</code> <code>Union[Path, str]</code> <p>Path to the output file.</p> required <code>name</code> <code>str</code> <p>Model name.</p> required <code>general_description</code> <code>str</code> <p>General description of the model.</p> required <code>authors</code> <code>List[dict]</code> <p>Authors of the model.</p> required <code>input_array</code> <code>ndarray</code> <p>Input array.</p> required <code>output_array</code> <code>ndarray</code> <p>Output array.</p> required <code>channel_names</code> <code>Optional[List[str]]</code> <p>Channel names, by default None.</p> <code>None</code> <code>data_description</code> <code>Optional[str]</code> <p>Description of the data, by default None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model is a Custom model.</p> Source code in <code>src/careamics/model_io/bmz_io.py</code> <pre><code>def export_to_bmz(\n    model: CAREamicsModule,\n    config: Configuration,\n    path: Union[Path, str],\n    name: str,\n    general_description: str,\n    authors: List[dict],\n    input_array: np.ndarray,\n    output_array: np.ndarray,\n    channel_names: Optional[List[str]] = None,\n    data_description: Optional[str] = None,\n) -&gt; None:\n    \"\"\"Export the model to BioImage Model Zoo format.\n\n    Arrays are expected to be SC(Z)YX with singleton dimensions allowed for S and C.\n\n    Parameters\n    ----------\n    model : CAREamicsKiln\n        CAREamics model to export.\n    config : Configuration\n        Model configuration.\n    path : Union[Path, str]\n        Path to the output file.\n    name : str\n        Model name.\n    general_description : str\n        General description of the model.\n    authors : List[dict]\n        Authors of the model.\n    input_array : np.ndarray\n        Input array.\n    output_array : np.ndarray\n        Output array.\n    channel_names : Optional[List[str]], optional\n        Channel names, by default None.\n    data_description : Optional[str], optional\n        Description of the data, by default None.\n\n    Raises\n    ------\n    ValueError\n        If the model is a Custom model.\n    \"\"\"\n    path = Path(path)\n\n    # method is not compatible with Custom models\n    if config.algorithm_config.model.architecture == SupportedArchitecture.CUSTOM:\n        raise ValueError(\n            \"Exporting Custom models to BioImage Model Zoo format is not supported.\"\n        )\n\n    # make sure that input and output arrays have the same shape\n    assert input_array.shape == output_array.shape, (\n        f\"Input ({input_array.shape}) and output ({output_array.shape}) arrays \"\n        f\"have different shapes\"\n    )\n\n    # make sure it has the correct suffix\n    if path.suffix not in \".zip\":\n        path = path.with_suffix(\".zip\")\n\n    # versions\n    pytorch_version = __version__\n    careamics_version = pkg_resources.get_distribution(\"careamics\").version\n\n    # save files in temporary folder\n    with tempfile.TemporaryDirectory() as tmpdirname:\n        temp_path = Path(tmpdirname)\n\n        # create environment file\n        # TODO move in bioimage module\n        env_path = temp_path / \"environment.yml\"\n        env_path.write_text(create_env_text(pytorch_version))\n\n        # export input and ouputs\n        inputs = temp_path / \"inputs.npy\"\n        np.save(inputs, input_array)\n        outputs = temp_path / \"outputs.npy\"\n        np.save(outputs, output_array)\n\n        # export configuration\n        config_path = save_configuration(config, temp_path)\n\n        # export model state dictionary\n        weight_path = _export_state_dict(model, temp_path / \"weights.pth\")\n\n        # create model description\n        model_description = create_model_description(\n            config=config,\n            name=name,\n            general_description=general_description,\n            authors=authors,\n            inputs=inputs,\n            outputs=outputs,\n            weights_path=weight_path,\n            torch_version=pytorch_version,\n            careamics_version=careamics_version,\n            config_path=config_path,\n            env_path=env_path,\n            channel_names=channel_names,\n            data_description=data_description,\n        )\n\n        # test model description\n        summary: ValidationSummary = test_model(model_description, decimal=0)\n        if summary.status == \"failed\":\n            raise ValueError(f\"Model description test failed: {summary}\")\n\n        # save bmz model\n        save_bioimageio_package(model_description, output_path=path)\n</code></pre>"},{"location":"reference/careamics/model_io/bmz_io/#careamics.model_io.bmz_io.load_from_bmz","title":"<code>load_from_bmz(path)</code>","text":"<p>Load a model from a BioImage Model Zoo archive.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[Path, str]</code> <p>Path to the BioImage Model Zoo archive.</p> required <p>Returns:</p> Type Description <code>Tuple[CAREamicsKiln, Configuration]</code> <p>CAREamics model and configuration.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the path is not a zip file.</p> Source code in <code>src/careamics/model_io/bmz_io.py</code> <pre><code>def load_from_bmz(path: Union[Path, str]) -&gt; Tuple[CAREamicsModule, Configuration]:\n    \"\"\"Load a model from a BioImage Model Zoo archive.\n\n    Parameters\n    ----------\n    path : Union[Path, str]\n        Path to the BioImage Model Zoo archive.\n\n    Returns\n    -------\n    Tuple[CAREamicsKiln, Configuration]\n        CAREamics model and configuration.\n\n    Raises\n    ------\n    ValueError\n        If the path is not a zip file.\n    \"\"\"\n    path = Path(path)\n\n    if path.suffix != \".zip\":\n        raise ValueError(f\"Path must be a bioimage.io zip file, got {path}.\")\n\n    # load description, this creates an unzipped folder next to the archive\n    model_desc = load_description(path)\n\n    # extract relative paths\n    weights_path, config_path = extract_model_path(model_desc)\n\n    # create folder path and absolute paths\n    unzip_path = get_unzip_path(path)\n    weights_path = unzip_path / weights_path\n    config_path = unzip_path / config_path\n\n    # load configuration\n    config = load_configuration(config_path)\n\n    # create careamics lightning module\n    model = CAREamicsModule(algorithm_config=config.algorithm_config)\n\n    # load model state dictionary\n    _load_state_dict(model, weights_path)\n\n    return model, config\n</code></pre>"},{"location":"reference/careamics/model_io/model_io_utils/","title":"model_io_utils","text":"<p>Utility functions to load pretrained models.</p>"},{"location":"reference/careamics/model_io/model_io_utils/#careamics.model_io.model_io_utils.load_pretrained","title":"<code>load_pretrained(path)</code>","text":"<p>Load a pretrained model from a checkpoint or a BioImage Model Zoo model.</p> <p>Expected formats are .ckpt or .zip files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[Path, str]</code> <p>Path to the pretrained model.</p> required <p>Returns:</p> Type Description <code>Tuple[CAREamicsKiln, Configuration]</code> <p>Tuple of CAREamics model and its configuration.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the model format is not supported.</p> Source code in <code>src/careamics/model_io/model_io_utils.py</code> <pre><code>def load_pretrained(path: Union[Path, str]) -&gt; Tuple[CAREamicsModule, Configuration]:\n    \"\"\"\n    Load a pretrained model from a checkpoint or a BioImage Model Zoo model.\n\n    Expected formats are .ckpt or .zip files.\n\n    Parameters\n    ----------\n    path : Union[Path, str]\n        Path to the pretrained model.\n\n    Returns\n    -------\n    Tuple[CAREamicsKiln, Configuration]\n        Tuple of CAREamics model and its configuration.\n\n    Raises\n    ------\n    ValueError\n        If the model format is not supported.\n    \"\"\"\n    path = check_path_exists(path)\n\n    if path.suffix == \".ckpt\":\n        return _load_checkpoint(path)\n    elif path.suffix == \".zip\":\n        return load_from_bmz(path)\n    else:\n        raise ValueError(\n            f\"Invalid model format. Expected .ckpt or .zip, got {path.suffix}.\"\n        )\n</code></pre>"},{"location":"reference/careamics/model_io/bioimage/_readme_factory/","title":"_readme_factory","text":"<p>Functions used to create a README.md file for BMZ export.</p>"},{"location":"reference/careamics/model_io/bioimage/_readme_factory/#careamics.model_io.bioimage._readme_factory.readme_factory","title":"<code>readme_factory(config, careamics_version, data_description=None)</code>","text":"<p>Create a README file for the model.</p> <p><code>data_description</code> can be used to add more information about the content of the data the model was trained on.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>CAREamics configuration.</p> required <code>careamics_version</code> <code>str</code> <p>CAREamics version.</p> required <code>data_description</code> <code>Optional[str]</code> <p>Description of the data, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the README file.</p> Source code in <code>src/careamics/model_io/bioimage/_readme_factory.py</code> <pre><code>def readme_factory(\n    config: Configuration,\n    careamics_version: str,\n    data_description: Optional[str] = None,\n) -&gt; Path:\n    \"\"\"Create a README file for the model.\n\n    `data_description` can be used to add more information about the content of the\n    data the model was trained on.\n\n    Parameters\n    ----------\n    config : Configuration\n        CAREamics configuration.\n    careamics_version : str\n        CAREamics version.\n    data_description : Optional[str], optional\n        Description of the data, by default None.\n\n    Returns\n    -------\n    Path\n        Path to the README file.\n    \"\"\"\n    algorithm = config.algorithm_config\n    training = config.training_config\n    data = config.data_config\n\n    # create file\n    # TODO use tempfile as in the bmz_io module\n    with cwd(get_careamics_home()):\n        readme = Path(\"README.md\")\n        readme.touch()\n\n        # algorithm pretty name\n        algorithm_flavour = config.get_algorithm_flavour()\n        algorithm_pretty_name = algorithm_flavour + \" - CAREamics\"\n\n        description = [f\"# {algorithm_pretty_name}\\n\\n\"]\n\n        # algorithm description\n        description.append(\"Algorithm description:\\n\\n\")\n        description.append(config.get_algorithm_description())\n        description.append(\"\\n\\n\")\n\n        # algorithm details\n        description.append(\n            f\"{algorithm_flavour} was trained using CAREamics (version \"\n            f\"{careamics_version}) with the following algorithm \"\n            f\"parameters:\\n\\n\"\n        )\n        description.append(\n            _yaml_block(yaml.dump(algorithm.model_dump(exclude_none=True)))\n        )\n        description.append(\"\\n\\n\")\n\n        # data description\n        description.append(\"## Data description\\n\\n\")\n        if data_description is not None:\n            description.append(data_description)\n            description.append(\"\\n\\n\")\n\n        description.append(\"The data was processed using the following parameters:\\n\\n\")\n\n        description.append(_yaml_block(yaml.dump(data.model_dump(exclude_none=True))))\n        description.append(\"\\n\\n\")\n\n        # training description\n        description.append(\"## Training description\\n\\n\")\n\n        description.append(\"The model was trained using the following parameters:\\n\\n\")\n\n        description.append(\n            _yaml_block(yaml.dump(training.model_dump(exclude_none=True)))\n        )\n        description.append(\"\\n\\n\")\n\n        # references\n        reference = config.get_algorithm_references()\n        if reference != \"\":\n            description.append(\"## References\\n\\n\")\n            description.append(reference)\n            description.append(\"\\n\\n\")\n\n        # links\n        description.append(\n            \"## Links\\n\\n\"\n            \"- [CAREamics repository](https://github.com/CAREamics/careamics)\\n\"\n            \"- [CAREamics documentation](https://careamics.github.io/latest/)\\n\"\n        )\n\n        readme.write_text(\"\".join(description))\n\n        return readme.absolute()\n</code></pre>"},{"location":"reference/careamics/model_io/bioimage/bioimage_utils/","title":"bioimage_utils","text":"<p>Bioimage.io utils.</p>"},{"location":"reference/careamics/model_io/bioimage/bioimage_utils/#careamics.model_io.bioimage.bioimage_utils.create_env_text","title":"<code>create_env_text(pytorch_version)</code>","text":"<p>Create environment text for the bioimage model.</p> <p>Parameters:</p> Name Type Description Default <code>pytorch_version</code> <code>str</code> <p>Pytorch version.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Environment text.</p> Source code in <code>src/careamics/model_io/bioimage/bioimage_utils.py</code> <pre><code>def create_env_text(pytorch_version: str) -&gt; str:\n    \"\"\"Create environment text for the bioimage model.\n\n    Parameters\n    ----------\n    pytorch_version : str\n        Pytorch version.\n\n    Returns\n    -------\n    str\n        Environment text.\n    \"\"\"\n    env = (\n        f\"name: careamics\\n\"\n        f\"dependencies:\\n\"\n        f\"  - python=3.8\\n\"\n        f\"  - pytorch={pytorch_version}\\n\"\n        f\"  - torchvision={pytorch_version}\\n\"\n        f\"  - pip\\n\"\n        f\"  - pip:\\n\"\n        f\"    - git+https://github.com/CAREamics/careamics.git@dl4mia\\n\"\n    )\n    # TODO from pip with package version\n    return env\n</code></pre>"},{"location":"reference/careamics/model_io/bioimage/bioimage_utils/#careamics.model_io.bioimage.bioimage_utils.get_unzip_path","title":"<code>get_unzip_path(zip_path)</code>","text":"<p>Generate unzipped folder path from the bioimage.io model path.</p> <p>Parameters:</p> Name Type Description Default <code>zip_path</code> <code>Path</code> <p>Path to the bioimage.io model.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path to the unzipped folder.</p> Source code in <code>src/careamics/model_io/bioimage/bioimage_utils.py</code> <pre><code>def get_unzip_path(zip_path: Union[Path, str]) -&gt; Path:\n    \"\"\"Generate unzipped folder path from the bioimage.io model path.\n\n    Parameters\n    ----------\n    zip_path : Path\n        Path to the bioimage.io model.\n\n    Returns\n    -------\n    Path\n        Path to the unzipped folder.\n    \"\"\"\n    zip_path = Path(zip_path)\n\n    return zip_path.parent / (str(zip_path.name) + \".unzip\")\n</code></pre>"},{"location":"reference/careamics/model_io/bioimage/model_description/","title":"model_description","text":"<p>Module use to build BMZ model description.</p>"},{"location":"reference/careamics/model_io/bioimage/model_description/#careamics.model_io.bioimage.model_description.create_model_description","title":"<code>create_model_description(config, name, general_description, authors, inputs, outputs, weights_path, torch_version, careamics_version, config_path, env_path, channel_names=None, data_description=None)</code>","text":"<p>Create model description.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Configuration</code> <p>CAREamics configuration.</p> required <code>name</code> <code>str</code> <p>Name fo the model.</p> required <code>general_description</code> <code>str</code> <p>General description of the model.</p> required <code>authors</code> <code>List[Author]</code> <p>Authors of the model.</p> required <code>inputs</code> <code>Union[Path, str]</code> <p>Path to input .npy file.</p> required <code>outputs</code> <code>Union[Path, str]</code> <p>Path to output .npy file.</p> required <code>weights_path</code> <code>Union[Path, str]</code> <p>Path to model weights.</p> required <code>torch_version</code> <code>str</code> <p>Pytorch version.</p> required <code>careamics_version</code> <code>str</code> <p>CAREamics version.</p> required <code>config_path</code> <code>Union[Path, str]</code> <p>Path to model configuration.</p> required <code>env_path</code> <code>Union[Path, str]</code> <p>Path to environment file.</p> required <code>channel_names</code> <code>Optional[List[str]]</code> <p>Channel names, by default None.</p> <code>None</code> <code>data_description</code> <code>Optional[str]</code> <p>Description of the data, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ModelDescr</code> <p>Model description.</p> Source code in <code>src/careamics/model_io/bioimage/model_description.py</code> <pre><code>def create_model_description(\n    config: Configuration,\n    name: str,\n    general_description: str,\n    authors: List[Author],\n    inputs: Union[Path, str],\n    outputs: Union[Path, str],\n    weights_path: Union[Path, str],\n    torch_version: str,\n    careamics_version: str,\n    config_path: Union[Path, str],\n    env_path: Union[Path, str],\n    channel_names: Optional[List[str]] = None,\n    data_description: Optional[str] = None,\n) -&gt; ModelDescr:\n    \"\"\"Create model description.\n\n    Parameters\n    ----------\n    config : Configuration\n        CAREamics configuration.\n    name : str\n        Name fo the model.\n    general_description : str\n        General description of the model.\n    authors : List[Author]\n        Authors of the model.\n    inputs : Union[Path, str]\n        Path to input .npy file.\n    outputs : Union[Path, str]\n        Path to output .npy file.\n    weights_path : Union[Path, str]\n        Path to model weights.\n    torch_version : str\n        Pytorch version.\n    careamics_version : str\n        CAREamics version.\n    config_path : Union[Path, str]\n        Path to model configuration.\n    env_path : Union[Path, str]\n        Path to environment file.\n    channel_names : Optional[List[str]], optional\n        Channel names, by default None.\n    data_description : Optional[str], optional\n        Description of the data, by default None.\n\n    Returns\n    -------\n    ModelDescr\n        Model description.\n    \"\"\"\n    # documentation\n    doc = readme_factory(\n        config,\n        careamics_version=careamics_version,\n        data_description=data_description,\n    )\n\n    # inputs, outputs\n    input_descr, output_descr = _create_inputs_ouputs(\n        input_array=np.load(inputs),\n        output_array=np.load(outputs),\n        data_config=config.data_config,\n        input_path=inputs,\n        output_path=outputs,\n        channel_names=channel_names,\n    )\n\n    # weights description\n    architecture_descr = ArchitectureFromLibraryDescr(\n        import_from=\"careamics.models\",\n        callable=f\"{config.algorithm_config.model.architecture}\",\n        kwargs=config.algorithm_config.model.model_dump(),\n    )\n\n    weights_descr = WeightsDescr(\n        pytorch_state_dict=PytorchStateDictWeightsDescr(\n            source=weights_path,\n            architecture=architecture_descr,\n            pytorch_version=Version(torch_version),\n            dependencies=EnvironmentFileDescr(source=env_path),\n        ),\n    )\n\n    # overall model description\n    model = ModelDescr(\n        name=name,\n        authors=authors,\n        description=general_description,\n        documentation=doc,\n        inputs=[input_descr],\n        outputs=[output_descr],\n        tags=config.get_algorithm_keywords(),\n        links=[\n            \"https://github.com/CAREamics/careamics\",\n            \"https://careamics.github.io/latest/\",\n        ],\n        license=\"BSD-3-Clause\",\n        version=\"0.1.0\",\n        weights=weights_descr,\n        attachments=[FileDescr(source=config_path)],\n        cite=config.get_algorithm_citations(),\n        config={  # conversion from float32 to float64 creates small differences...\n            \"bioimageio\": {\n                \"test_kwargs\": {\n                    \"pytorch_state_dict\": {\n                        \"decimals\": 2,  # ...so we relax the constraints on the decimals\n                    }\n                }\n            }\n        },\n    )\n\n    return model\n</code></pre>"},{"location":"reference/careamics/model_io/bioimage/model_description/#careamics.model_io.bioimage.model_description.extract_model_path","title":"<code>extract_model_path(model_desc)</code>","text":"<p>Return the relative path to the weights and configuration files.</p> <p>Parameters:</p> Name Type Description Default <code>model_desc</code> <code>ModelDescr</code> <p>Model description.</p> required <p>Returns:</p> Type Description <code>Tuple[Path, Path]</code> <p>Weights and configuration paths.</p> Source code in <code>src/careamics/model_io/bioimage/model_description.py</code> <pre><code>def extract_model_path(model_desc: ModelDescr) -&gt; Tuple[Path, Path]:\n    \"\"\"Return the relative path to the weights and configuration files.\n\n    Parameters\n    ----------\n    model_desc : ModelDescr\n        Model description.\n\n    Returns\n    -------\n    Tuple[Path, Path]\n        Weights and configuration paths.\n    \"\"\"\n    weights_path = model_desc.weights.pytorch_state_dict.source.path\n\n    if len(model_desc.attachments) == 1:\n        config_path = model_desc.attachments[0].source.path\n    else:\n        for file in model_desc.attachments:\n            if file.source.path.suffix == \".yml\":\n                config_path = file.source.path\n                break\n\n        if config_path is None:\n            raise ValueError(\"Configuration file not found.\")\n\n    return weights_path, config_path\n</code></pre>"},{"location":"reference/careamics/models/activation/","title":"activation","text":"<p>Activations for CAREamics models.</p>"},{"location":"reference/careamics/models/activation/#careamics.models.activation.get_activation","title":"<code>get_activation(activation)</code>","text":"<p>Get activation function.</p> <p>Parameters:</p> Name Type Description Default <code>activation</code> <code>str</code> <p>Activation function name.</p> required <p>Returns:</p> Type Description <code>Callable</code> <p>Activation function.</p> Source code in <code>src/careamics/models/activation.py</code> <pre><code>def get_activation(activation: Union[SupportedActivation, str]) -&gt; Callable:\n    \"\"\"\n    Get activation function.\n\n    Parameters\n    ----------\n    activation : str\n        Activation function name.\n\n    Returns\n    -------\n    Callable\n        Activation function.\n    \"\"\"\n    if activation == SupportedActivation.RELU:\n        return nn.ReLU()\n    elif activation == SupportedActivation.LEAKYRELU:\n        return nn.LeakyReLU()\n    elif activation == SupportedActivation.TANH:\n        return nn.Tanh()\n    elif activation == SupportedActivation.SIGMOID:\n        return nn.Sigmoid()\n    elif activation == SupportedActivation.SOFTMAX:\n        return nn.Softmax(dim=1)\n    elif activation == SupportedActivation.NONE:\n        return nn.Identity()\n    else:\n        raise ValueError(f\"Activation {activation} not supported.\")\n</code></pre>"},{"location":"reference/careamics/models/layers/","title":"layers","text":"<p>Layer module.</p> <p>This submodule contains layers used in the CAREamics models.</p>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.Conv_Block","title":"<code>Conv_Block</code>","text":"<p>               Bases: <code>Module</code></p> <p>Convolution block used in UNets.</p> <p>Convolution block consist of two convolution layers with optional batch norm, dropout and with a final activation function.</p> <p>The parameters are directly mapped to PyTorch Conv2D and Conv3d parameters, see PyTorch torch.nn.Conv2d and torch.nn.Conv3d for more information.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolutions, 2 or 3.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>intermediate_channel_multiplier</code> <code>int</code> <p>Multiplied for the number of output channels, by default 1.</p> <code>1</code> <code>stride</code> <code>int</code> <p>Stride of the convolutions, by default 1.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding of the convolutions, by default 1.</p> <code>1</code> <code>bias</code> <code>bool</code> <p>Bias of the convolutions, by default True.</p> <code>True</code> <code>groups</code> <code>int</code> <p>Controls the connections between inputs and outputs, by default 1.</p> <code>1</code> <code>activation</code> <code>str</code> <p>Activation function, by default \"ReLU\".</p> <code>'ReLU'</code> <code>dropout_perc</code> <code>float</code> <p>Dropout percentage, by default 0.</p> <code>0</code> <code>use_batch_norm</code> <code>bool</code> <p>Use batch norm, by default False.</p> <code>False</code> Source code in <code>src/careamics/models/layers.py</code> <pre><code>class Conv_Block(nn.Module):\n    \"\"\"\n    Convolution block used in UNets.\n\n    Convolution block consist of two convolution layers with optional batch norm,\n    dropout and with a final activation function.\n\n    The parameters are directly mapped to PyTorch Conv2D and Conv3d parameters, see\n    PyTorch torch.nn.Conv2d and torch.nn.Conv3d for more information.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolutions, 2 or 3.\n    in_channels : int\n        Number of input channels.\n    out_channels : int\n        Number of output channels.\n    intermediate_channel_multiplier : int, optional\n        Multiplied for the number of output channels, by default 1.\n    stride : int, optional\n        Stride of the convolutions, by default 1.\n    padding : int, optional\n        Padding of the convolutions, by default 1.\n    bias : bool, optional\n        Bias of the convolutions, by default True.\n    groups : int, optional\n        Controls the connections between inputs and outputs, by default 1.\n    activation : str, optional\n        Activation function, by default \"ReLU\".\n    dropout_perc : float, optional\n        Dropout percentage, by default 0.\n    use_batch_norm : bool, optional\n        Use batch norm, by default False.\n    \"\"\"\n\n    def __init__(\n        self,\n        conv_dim: int,\n        in_channels: int,\n        out_channels: int,\n        intermediate_channel_multiplier: int = 1,\n        stride: int = 1,\n        padding: int = 1,\n        bias: bool = True,\n        groups: int = 1,\n        activation: str = \"ReLU\",\n        dropout_perc: float = 0,\n        use_batch_norm: bool = False,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        conv_dim : int\n            Number of dimension of the convolutions, 2 or 3.\n        in_channels : int\n            Number of input channels.\n        out_channels : int\n            Number of output channels.\n        intermediate_channel_multiplier : int, optional\n            Multiplied for the number of output channels, by default 1.\n        stride : int, optional\n            Stride of the convolutions, by default 1.\n        padding : int, optional\n            Padding of the convolutions, by default 1.\n        bias : bool, optional\n            Bias of the convolutions, by default True.\n        groups : int, optional\n            Controls the connections between inputs and outputs, by default 1.\n        activation : str, optional\n            Activation function, by default \"ReLU\".\n        dropout_perc : float, optional\n            Dropout percentage, by default 0.\n        use_batch_norm : bool, optional\n            Use batch norm, by default False.\n        \"\"\"\n        super().__init__()\n        self.use_batch_norm = use_batch_norm\n        self.conv1 = getattr(nn, f\"Conv{conv_dim}d\")(\n            in_channels,\n            out_channels * intermediate_channel_multiplier,\n            kernel_size=3,\n            stride=stride,\n            padding=padding,\n            bias=bias,\n            groups=groups,\n        )\n\n        self.conv2 = getattr(nn, f\"Conv{conv_dim}d\")(\n            out_channels * intermediate_channel_multiplier,\n            out_channels,\n            kernel_size=3,\n            stride=stride,\n            padding=padding,\n            bias=bias,\n            groups=groups,\n        )\n\n        self.batch_norm1 = getattr(nn, f\"BatchNorm{conv_dim}d\")(\n            out_channels * intermediate_channel_multiplier\n        )\n        self.batch_norm2 = getattr(nn, f\"BatchNorm{conv_dim}d\")(out_channels)\n\n        self.dropout = (\n            getattr(nn, f\"Dropout{conv_dim}d\")(dropout_perc)\n            if dropout_perc &gt; 0\n            else None\n        )\n        self.activation = (\n            getattr(nn, f\"{activation}\")() if activation is not None else nn.Identity()\n        )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        torch.Tensor\n            Output tensor.\n        \"\"\"\n        if self.use_batch_norm:\n            x = self.conv1(x)\n            x = self.batch_norm1(x)\n            x = self.activation(x)\n            x = self.conv2(x)\n            x = self.batch_norm2(x)\n            x = self.activation(x)\n        else:\n            x = self.conv1(x)\n            x = self.activation(x)\n            x = self.conv2(x)\n            x = self.activation(x)\n        if self.dropout is not None:\n            x = self.dropout(x)\n        return x\n</code></pre>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.Conv_Block.__init__","title":"<code>__init__(conv_dim, in_channels, out_channels, intermediate_channel_multiplier=1, stride=1, padding=1, bias=True, groups=1, activation='ReLU', dropout_perc=0, use_batch_norm=False)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolutions, 2 or 3.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels.</p> required <code>out_channels</code> <code>int</code> <p>Number of output channels.</p> required <code>intermediate_channel_multiplier</code> <code>int</code> <p>Multiplied for the number of output channels, by default 1.</p> <code>1</code> <code>stride</code> <code>int</code> <p>Stride of the convolutions, by default 1.</p> <code>1</code> <code>padding</code> <code>int</code> <p>Padding of the convolutions, by default 1.</p> <code>1</code> <code>bias</code> <code>bool</code> <p>Bias of the convolutions, by default True.</p> <code>True</code> <code>groups</code> <code>int</code> <p>Controls the connections between inputs and outputs, by default 1.</p> <code>1</code> <code>activation</code> <code>str</code> <p>Activation function, by default \"ReLU\".</p> <code>'ReLU'</code> <code>dropout_perc</code> <code>float</code> <p>Dropout percentage, by default 0.</p> <code>0</code> <code>use_batch_norm</code> <code>bool</code> <p>Use batch norm, by default False.</p> <code>False</code> Source code in <code>src/careamics/models/layers.py</code> <pre><code>def __init__(\n    self,\n    conv_dim: int,\n    in_channels: int,\n    out_channels: int,\n    intermediate_channel_multiplier: int = 1,\n    stride: int = 1,\n    padding: int = 1,\n    bias: bool = True,\n    groups: int = 1,\n    activation: str = \"ReLU\",\n    dropout_perc: float = 0,\n    use_batch_norm: bool = False,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolutions, 2 or 3.\n    in_channels : int\n        Number of input channels.\n    out_channels : int\n        Number of output channels.\n    intermediate_channel_multiplier : int, optional\n        Multiplied for the number of output channels, by default 1.\n    stride : int, optional\n        Stride of the convolutions, by default 1.\n    padding : int, optional\n        Padding of the convolutions, by default 1.\n    bias : bool, optional\n        Bias of the convolutions, by default True.\n    groups : int, optional\n        Controls the connections between inputs and outputs, by default 1.\n    activation : str, optional\n        Activation function, by default \"ReLU\".\n    dropout_perc : float, optional\n        Dropout percentage, by default 0.\n    use_batch_norm : bool, optional\n        Use batch norm, by default False.\n    \"\"\"\n    super().__init__()\n    self.use_batch_norm = use_batch_norm\n    self.conv1 = getattr(nn, f\"Conv{conv_dim}d\")(\n        in_channels,\n        out_channels * intermediate_channel_multiplier,\n        kernel_size=3,\n        stride=stride,\n        padding=padding,\n        bias=bias,\n        groups=groups,\n    )\n\n    self.conv2 = getattr(nn, f\"Conv{conv_dim}d\")(\n        out_channels * intermediate_channel_multiplier,\n        out_channels,\n        kernel_size=3,\n        stride=stride,\n        padding=padding,\n        bias=bias,\n        groups=groups,\n    )\n\n    self.batch_norm1 = getattr(nn, f\"BatchNorm{conv_dim}d\")(\n        out_channels * intermediate_channel_multiplier\n    )\n    self.batch_norm2 = getattr(nn, f\"BatchNorm{conv_dim}d\")(out_channels)\n\n    self.dropout = (\n        getattr(nn, f\"Dropout{conv_dim}d\")(dropout_perc)\n        if dropout_perc &gt; 0\n        else None\n    )\n    self.activation = (\n        getattr(nn, f\"{activation}\")() if activation is not None else nn.Identity()\n    )\n</code></pre>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.Conv_Block.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor.</p> Source code in <code>src/careamics/models/layers.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    torch.Tensor\n        Output tensor.\n    \"\"\"\n    if self.use_batch_norm:\n        x = self.conv1(x)\n        x = self.batch_norm1(x)\n        x = self.activation(x)\n        x = self.conv2(x)\n        x = self.batch_norm2(x)\n        x = self.activation(x)\n    else:\n        x = self.conv1(x)\n        x = self.activation(x)\n        x = self.conv2(x)\n        x = self.activation(x)\n    if self.dropout is not None:\n        x = self.dropout(x)\n    return x\n</code></pre>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.MaxBlurPool","title":"<code>MaxBlurPool</code>","text":"<p>               Bases: <code>Module</code></p> <p>Compute pools and blurs and downsample a given feature map.</p> <p>Inspired by Kornia MaxBlurPool implementation. Equivalent to <code>nn.Sequential(nn.MaxPool2d(...), BlurPool2D(...))</code></p>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.MaxBlurPool--parameters","title":"Parameters","text":"<p>dim : int     Toggles between 2D and 3D. kernel_size : Union[Tuple[int, int], int]     Kernel size for max pooling. stride : int     Stride for pooling. max_pool_size : int     Max kernel size for max pooling. ceil_mode : bool     Ceil mode, by default False. Set to True to match output size of conv2d.</p> Source code in <code>src/careamics/models/layers.py</code> <pre><code>class MaxBlurPool(nn.Module):\n    \"\"\"Compute pools and blurs and downsample a given feature map.\n\n    Inspired by Kornia MaxBlurPool implementation. Equivalent to\n    ```nn.Sequential(nn.MaxPool2d(...), BlurPool2D(...))```\n\n    Parameters\n    ----------\n    dim : int\n        Toggles between 2D and 3D.\n    kernel_size : Union[Tuple[int, int], int]\n        Kernel size for max pooling.\n    stride : int\n        Stride for pooling.\n    max_pool_size : int\n        Max kernel size for max pooling.\n    ceil_mode : bool\n        Ceil mode, by default False. Set to True to match output size of conv2d.\n    \"\"\"\n\n    def __init__(\n        self,\n        dim: int,\n        kernel_size: Union[Tuple[int, int], int],\n        stride: int = 2,\n        max_pool_size: int = 2,\n        ceil_mode: bool = False,\n    ) -&gt; None:\n        \"\"\"Constructor.\n\n        Parameters\n        ----------\n        dim : int\n            Dimension of the convolution.\n        kernel_size : Union[Tuple[int, int], int]\n            Kernel size for max pooling.\n        stride : int, optional\n            Stride, by default 2.\n        max_pool_size : int, optional\n            Maximum pool size, by default 2.\n        ceil_mode : bool, optional\n            Ceil mode, by default False. Set to True to match output size of conv2d.\n        \"\"\"\n        super().__init__()\n        self.dim = dim\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.max_pool_size = max_pool_size\n        self.ceil_mode = ceil_mode\n        self.kernel = _get_pascal_kernel_nd(kernel_size, norm=True, dim=self.dim)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Forward pass of the function.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        torch.Tensor\n            Output tensor.\n        \"\"\"\n        self.kernel = torch.as_tensor(self.kernel, device=x.device, dtype=x.dtype)\n        if self.dim == 2:\n            return _max_blur_pool_by_kernel2d(\n                x,\n                self.kernel.repeat((x.size(1), 1, 1, 1)),\n                self.stride,\n                self.max_pool_size,\n                self.ceil_mode,\n            )\n        else:\n            return _max_blur_pool_by_kernel3d(\n                x,\n                self.kernel.repeat((x.size(1), 1, 1, 1, 1)),\n                self.stride,\n                self.max_pool_size,\n                self.ceil_mode,\n            )\n</code></pre>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.MaxBlurPool.__init__","title":"<code>__init__(dim, kernel_size, stride=2, max_pool_size=2, ceil_mode=False)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>Dimension of the convolution.</p> required <code>kernel_size</code> <code>Union[Tuple[int, int], int]</code> <p>Kernel size for max pooling.</p> required <code>stride</code> <code>int</code> <p>Stride, by default 2.</p> <code>2</code> <code>max_pool_size</code> <code>int</code> <p>Maximum pool size, by default 2.</p> <code>2</code> <code>ceil_mode</code> <code>bool</code> <p>Ceil mode, by default False. Set to True to match output size of conv2d.</p> <code>False</code> Source code in <code>src/careamics/models/layers.py</code> <pre><code>def __init__(\n    self,\n    dim: int,\n    kernel_size: Union[Tuple[int, int], int],\n    stride: int = 2,\n    max_pool_size: int = 2,\n    ceil_mode: bool = False,\n) -&gt; None:\n    \"\"\"Constructor.\n\n    Parameters\n    ----------\n    dim : int\n        Dimension of the convolution.\n    kernel_size : Union[Tuple[int, int], int]\n        Kernel size for max pooling.\n    stride : int, optional\n        Stride, by default 2.\n    max_pool_size : int, optional\n        Maximum pool size, by default 2.\n    ceil_mode : bool, optional\n        Ceil mode, by default False. Set to True to match output size of conv2d.\n    \"\"\"\n    super().__init__()\n    self.dim = dim\n    self.kernel_size = kernel_size\n    self.stride = stride\n    self.max_pool_size = max_pool_size\n    self.ceil_mode = ceil_mode\n    self.kernel = _get_pascal_kernel_nd(kernel_size, norm=True, dim=self.dim)\n</code></pre>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.MaxBlurPool.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass of the function.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output tensor.</p> Source code in <code>src/careamics/models/layers.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Forward pass of the function.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    torch.Tensor\n        Output tensor.\n    \"\"\"\n    self.kernel = torch.as_tensor(self.kernel, device=x.device, dtype=x.dtype)\n    if self.dim == 2:\n        return _max_blur_pool_by_kernel2d(\n            x,\n            self.kernel.repeat((x.size(1), 1, 1, 1)),\n            self.stride,\n            self.max_pool_size,\n            self.ceil_mode,\n        )\n    else:\n        return _max_blur_pool_by_kernel3d(\n            x,\n            self.kernel.repeat((x.size(1), 1, 1, 1, 1)),\n            self.stride,\n            self.max_pool_size,\n            self.ceil_mode,\n        )\n</code></pre>"},{"location":"reference/careamics/models/layers/#careamics.models.layers.get_pascal_kernel_1d","title":"<code>get_pascal_kernel_1d(kernel_size, norm=False, *, device=None, dtype=None)</code>","text":"<p>Generate Yang Hui triangle (Pascal's triangle) for a given number.</p> <p>Inspired by Kornia implementation. TODO link</p> <p>Parameters:</p> Name Type Description Default <code>kernel_size</code> <code>int</code> <p>Kernel size.</p> required <code>norm</code> <code>bool</code> <p>Normalize the kernel, by default False.</p> <code>False</code> <code>device</code> <code>Optional[device]</code> <p>Device of the tensor, by default None.</p> <code>None</code> <code>dtype</code> <code>Optional[dtype]</code> <p>Data type of the tensor, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Pascal kernel.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_pascal_kernel_1d(1)\ntensor([1.])\n&gt;&gt;&gt; get_pascal_kernel_1d(2)\ntensor([1., 1.])\n&gt;&gt;&gt; get_pascal_kernel_1d(3)\ntensor([1., 2., 1.])\n&gt;&gt;&gt; get_pascal_kernel_1d(4)\ntensor([1., 3., 3., 1.])\n&gt;&gt;&gt; get_pascal_kernel_1d(5)\ntensor([1., 4., 6., 4., 1.])\n&gt;&gt;&gt; get_pascal_kernel_1d(6)\ntensor([ 1.,  5., 10., 10.,  5.,  1.])\n</code></pre> Source code in <code>src/careamics/models/layers.py</code> <pre><code>def get_pascal_kernel_1d(\n    kernel_size: int,\n    norm: bool = False,\n    *,\n    device: Optional[torch.device] = None,\n    dtype: Optional[torch.dtype] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Generate Yang Hui triangle (Pascal's triangle) for a given number.\n\n    Inspired by Kornia implementation. TODO link\n\n    Parameters\n    ----------\n    kernel_size : int\n        Kernel size.\n    norm : bool\n        Normalize the kernel, by default False.\n    device : Optional[torch.device]\n        Device of the tensor, by default None.\n    dtype : Optional[torch.dtype]\n        Data type of the tensor, by default None.\n\n    Returns\n    -------\n    torch.Tensor\n        Pascal kernel.\n\n    Examples\n    --------\n    &gt;&gt;&gt; get_pascal_kernel_1d(1)\n    tensor([1.])\n    &gt;&gt;&gt; get_pascal_kernel_1d(2)\n    tensor([1., 1.])\n    &gt;&gt;&gt; get_pascal_kernel_1d(3)\n    tensor([1., 2., 1.])\n    &gt;&gt;&gt; get_pascal_kernel_1d(4)\n    tensor([1., 3., 3., 1.])\n    &gt;&gt;&gt; get_pascal_kernel_1d(5)\n    tensor([1., 4., 6., 4., 1.])\n    &gt;&gt;&gt; get_pascal_kernel_1d(6)\n    tensor([ 1.,  5., 10., 10.,  5.,  1.])\n    \"\"\"\n    pre: List[float] = []\n    cur: List[float] = []\n    for i in range(kernel_size):\n        cur = [1.0] * (i + 1)\n\n        for j in range(1, i // 2 + 1):\n            value = pre[j - 1] + pre[j]\n            cur[j] = value\n            if i != 2 * j:\n                cur[-j - 1] = value\n        pre = cur\n\n    out = torch.tensor(cur, device=device, dtype=dtype)\n\n    if norm:\n        out = out / out.sum()\n\n    return out\n</code></pre>"},{"location":"reference/careamics/models/model_factory/","title":"model_factory","text":"<p>Model factory.</p> <p>Model creation factory functions.</p>"},{"location":"reference/careamics/models/model_factory/#careamics.models.model_factory.model_factory","title":"<code>model_factory(model_configuration)</code>","text":"<p>Deep learning model factory.</p> <p>Supported models are defined in careamics.config.SupportedArchitecture.</p> <p>Parameters:</p> Name Type Description Default <code>model_configuration</code> <code>Union[UNetModel, VAEModel]</code> <p>Model configuration.</p> required <p>Returns:</p> Type Description <code>Module</code> <p>Model class.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the requested architecture is not implemented.</p> Source code in <code>src/careamics/models/model_factory.py</code> <pre><code>def model_factory(\n    model_configuration: Union[UNetModel, VAEModel, CustomModel]\n) -&gt; torch.nn.Module:\n    \"\"\"\n    Deep learning model factory.\n\n    Supported models are defined in careamics.config.SupportedArchitecture.\n\n    Parameters\n    ----------\n    model_configuration : Union[UNetModel, VAEModel]\n        Model configuration.\n\n    Returns\n    -------\n    torch.nn.Module\n        Model class.\n\n    Raises\n    ------\n    NotImplementedError\n        If the requested architecture is not implemented.\n    \"\"\"\n    if model_configuration.architecture == SupportedArchitecture.UNET:\n        return UNet(**model_configuration.model_dump())\n    elif model_configuration.architecture == SupportedArchitecture.CUSTOM:\n        assert isinstance(model_configuration, CustomModel)\n        model = get_custom_model(model_configuration.name)\n\n        return model(**model_configuration.model_dump())\n    else:\n        raise NotImplementedError(\n            f\"Model {model_configuration.architecture} is not implemented or unknown.\"\n        )\n</code></pre>"},{"location":"reference/careamics/models/unet/","title":"unet","text":"<p>UNet model.</p> <p>A UNet encoder, decoder and complete model.</p>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UNet","title":"<code>UNet</code>","text":"<p>               Bases: <code>Module</code></p> <p>UNet model.</p> <p>Adapted for PyTorch from: https://github.com/juglab/n2v/blob/main/n2v/nets/unet_blocks.py.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dims</code> <code>int</code> <p>Number of dimensions of the convolution layers (2 or 3).</p> required <code>num_classes</code> <code>int</code> <p>Number of classes to predict, by default 1.</p> <code>1</code> <code>in_channels</code> <code>int</code> <p>Number of input channels, by default 1.</p> <code>1</code> <code>depth</code> <code>int</code> <p>Number of downsamplings, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of filters in the first convolution layer, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>pool_kernel</code> <code>int</code> <p>Kernel size of the pooling layers, by default 2.</p> <code>2</code> <code>final_activation</code> <code>Optional[Callable]</code> <p>Activation function to use for the last layer, by default None.</p> <code>NONE</code> <code>n2v2</code> <code>bool</code> <p>Whether to use N2V2 architecture, by default False.</p> <code>False</code> <code>independent_channels</code> <code>bool</code> <p>Whether to train the channels independently, by default True.</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments, unused.</p> <code>{}</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>class UNet(nn.Module):\n    \"\"\"\n    UNet model.\n\n    Adapted for PyTorch from:\n    https://github.com/juglab/n2v/blob/main/n2v/nets/unet_blocks.py.\n\n    Parameters\n    ----------\n    conv_dims : int\n        Number of dimensions of the convolution layers (2 or 3).\n    num_classes : int, optional\n        Number of classes to predict, by default 1.\n    in_channels : int, optional\n        Number of input channels, by default 1.\n    depth : int, optional\n        Number of downsamplings, by default 3.\n    num_channels_init : int, optional\n        Number of filters in the first convolution layer, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    pool_kernel : int, optional\n        Kernel size of the pooling layers, by default 2.\n    final_activation : Optional[Callable], optional\n        Activation function to use for the last layer, by default None.\n    n2v2 : bool, optional\n        Whether to use N2V2 architecture, by default False.\n    independent_channels : bool\n        Whether to train the channels independently, by default True.\n    **kwargs : Any\n        Additional keyword arguments, unused.\n    \"\"\"\n\n    def __init__(\n        self,\n        conv_dims: int,\n        num_classes: int = 1,\n        in_channels: int = 1,\n        depth: int = 3,\n        num_channels_init: int = 64,\n        use_batch_norm: bool = True,\n        dropout: float = 0.0,\n        pool_kernel: int = 2,\n        final_activation: Union[SupportedActivation, str] = SupportedActivation.NONE,\n        n2v2: bool = False,\n        independent_channels: bool = True,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        conv_dims : int\n            Number of dimensions of the convolution layers (2 or 3).\n        num_classes : int, optional\n            Number of classes to predict, by default 1.\n        in_channels : int, optional\n            Number of input channels, by default 1.\n        depth : int, optional\n            Number of downsamplings, by default 3.\n        num_channels_init : int, optional\n            Number of filters in the first convolution layer, by default 64.\n        use_batch_norm : bool, optional\n            Whether to use batch normalization, by default True.\n        dropout : float, optional\n            Dropout probability, by default 0.0.\n        pool_kernel : int, optional\n            Kernel size of the pooling layers, by default 2.\n        final_activation : Optional[Callable], optional\n            Activation function to use for the last layer, by default None.\n        n2v2 : bool, optional\n            Whether to use N2V2 architecture, by default False.\n        independent_channels : bool\n            Whether to train parallel independent networks for each channel, by\n            default True.\n        **kwargs : Any\n            Additional keyword arguments, unused.\n        \"\"\"\n        super().__init__()\n\n        groups = in_channels if independent_channels else 1\n\n        self.encoder = UnetEncoder(\n            conv_dims,\n            in_channels=in_channels,\n            depth=depth,\n            num_channels_init=num_channels_init,\n            use_batch_norm=use_batch_norm,\n            dropout=dropout,\n            pool_kernel=pool_kernel,\n            n2v2=n2v2,\n            groups=groups,\n        )\n\n        self.decoder = UnetDecoder(\n            conv_dims,\n            depth=depth,\n            num_channels_init=num_channels_init,\n            use_batch_norm=use_batch_norm,\n            dropout=dropout,\n            n2v2=n2v2,\n            groups=groups,\n        )\n        self.final_conv = getattr(nn, f\"Conv{conv_dims}d\")(\n            in_channels=num_channels_init * groups,\n            out_channels=num_classes,\n            kernel_size=1,\n            groups=groups,\n        )\n        self.final_activation = get_activation(final_activation)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x :  torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        torch.Tensor\n            Output of the model.\n        \"\"\"\n        encoder_features = self.encoder(x)\n        x = self.decoder(*encoder_features)\n        x = self.final_conv(x)\n        x = self.final_activation(x)\n        return x\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UNet.__init__","title":"<code>__init__(conv_dims, num_classes=1, in_channels=1, depth=3, num_channels_init=64, use_batch_norm=True, dropout=0.0, pool_kernel=2, final_activation=SupportedActivation.NONE, n2v2=False, independent_channels=True, **kwargs)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dims</code> <code>int</code> <p>Number of dimensions of the convolution layers (2 or 3).</p> required <code>num_classes</code> <code>int</code> <p>Number of classes to predict, by default 1.</p> <code>1</code> <code>in_channels</code> <code>int</code> <p>Number of input channels, by default 1.</p> <code>1</code> <code>depth</code> <code>int</code> <p>Number of downsamplings, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of filters in the first convolution layer, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>pool_kernel</code> <code>int</code> <p>Kernel size of the pooling layers, by default 2.</p> <code>2</code> <code>final_activation</code> <code>Optional[Callable]</code> <p>Activation function to use for the last layer, by default None.</p> <code>NONE</code> <code>n2v2</code> <code>bool</code> <p>Whether to use N2V2 architecture, by default False.</p> <code>False</code> <code>independent_channels</code> <code>bool</code> <p>Whether to train parallel independent networks for each channel, by default True.</p> <code>True</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments, unused.</p> <code>{}</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def __init__(\n    self,\n    conv_dims: int,\n    num_classes: int = 1,\n    in_channels: int = 1,\n    depth: int = 3,\n    num_channels_init: int = 64,\n    use_batch_norm: bool = True,\n    dropout: float = 0.0,\n    pool_kernel: int = 2,\n    final_activation: Union[SupportedActivation, str] = SupportedActivation.NONE,\n    n2v2: bool = False,\n    independent_channels: bool = True,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    conv_dims : int\n        Number of dimensions of the convolution layers (2 or 3).\n    num_classes : int, optional\n        Number of classes to predict, by default 1.\n    in_channels : int, optional\n        Number of input channels, by default 1.\n    depth : int, optional\n        Number of downsamplings, by default 3.\n    num_channels_init : int, optional\n        Number of filters in the first convolution layer, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    pool_kernel : int, optional\n        Kernel size of the pooling layers, by default 2.\n    final_activation : Optional[Callable], optional\n        Activation function to use for the last layer, by default None.\n    n2v2 : bool, optional\n        Whether to use N2V2 architecture, by default False.\n    independent_channels : bool\n        Whether to train parallel independent networks for each channel, by\n        default True.\n    **kwargs : Any\n        Additional keyword arguments, unused.\n    \"\"\"\n    super().__init__()\n\n    groups = in_channels if independent_channels else 1\n\n    self.encoder = UnetEncoder(\n        conv_dims,\n        in_channels=in_channels,\n        depth=depth,\n        num_channels_init=num_channels_init,\n        use_batch_norm=use_batch_norm,\n        dropout=dropout,\n        pool_kernel=pool_kernel,\n        n2v2=n2v2,\n        groups=groups,\n    )\n\n    self.decoder = UnetDecoder(\n        conv_dims,\n        depth=depth,\n        num_channels_init=num_channels_init,\n        use_batch_norm=use_batch_norm,\n        dropout=dropout,\n        n2v2=n2v2,\n        groups=groups,\n    )\n    self.final_conv = getattr(nn, f\"Conv{conv_dims}d\")(\n        in_channels=num_channels_init * groups,\n        out_channels=num_classes,\n        kernel_size=1,\n        groups=groups,\n    )\n    self.final_activation = get_activation(final_activation)\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UNet.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code> torch.Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Output of the model.</p> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass.\n\n    Parameters\n    ----------\n    x :  torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    torch.Tensor\n        Output of the model.\n    \"\"\"\n    encoder_features = self.encoder(x)\n    x = self.decoder(*encoder_features)\n    x = self.final_conv(x)\n    x = self.final_activation(x)\n    return x\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetDecoder","title":"<code>UnetDecoder</code>","text":"<p>               Bases: <code>Module</code></p> <p>Unet decoder pathway.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.</p> required <code>depth</code> <code>int</code> <p>Number of decoder blocks, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of channels in the first encoder block, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>n2v2</code> <code>bool</code> <p>Whether to use N2V2 architecture, by default False.</p> <code>False</code> <code>groups</code> <code>int</code> <p>Number of blocked connections from input channels to output channels, by default 1.</p> <code>1</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>class UnetDecoder(nn.Module):\n    \"\"\"\n    Unet decoder pathway.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n    depth : int, optional\n        Number of decoder blocks, by default 3.\n    num_channels_init : int, optional\n        Number of channels in the first encoder block, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    n2v2 : bool, optional\n        Whether to use N2V2 architecture, by default False.\n    groups : int, optional\n        Number of blocked connections from input channels to output\n        channels, by default 1.\n    \"\"\"\n\n    def __init__(\n        self,\n        conv_dim: int,\n        depth: int = 3,\n        num_channels_init: int = 64,\n        use_batch_norm: bool = True,\n        dropout: float = 0.0,\n        n2v2: bool = False,\n        groups: int = 1,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        conv_dim : int\n            Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n        depth : int, optional\n            Number of decoder blocks, by default 3.\n        num_channels_init : int, optional\n            Number of channels in the first encoder block, by default 64.\n        use_batch_norm : bool, optional\n            Whether to use batch normalization, by default True.\n        dropout : float, optional\n            Dropout probability, by default 0.0.\n        n2v2 : bool, optional\n            Whether to use N2V2 architecture, by default False.\n        groups : int, optional\n            Number of blocked connections from input channels to output\n            channels, by default 1.\n        \"\"\"\n        super().__init__()\n\n        upsampling = nn.Upsample(\n            scale_factor=2, mode=\"bilinear\" if conv_dim == 2 else \"trilinear\"\n        )\n        in_channels = out_channels = num_channels_init * groups * (2 ** (depth - 1))\n\n        self.n2v2 = n2v2\n        self.groups = groups\n\n        self.bottleneck = Conv_Block(\n            conv_dim,\n            in_channels=in_channels,\n            out_channels=out_channels,\n            intermediate_channel_multiplier=2,\n            use_batch_norm=use_batch_norm,\n            dropout_perc=dropout,\n            groups=self.groups,\n        )\n\n        decoder_blocks: List[nn.Module] = []\n        for n in range(depth):\n            decoder_blocks.append(upsampling)\n            in_channels = (num_channels_init * 2 ** (depth - n)) * groups\n            out_channels = in_channels // 2\n            decoder_blocks.append(\n                Conv_Block(\n                    conv_dim,\n                    in_channels=(\n                        in_channels + in_channels // 2 if n &gt; 0 else in_channels\n                    ),\n                    out_channels=out_channels,\n                    intermediate_channel_multiplier=2,\n                    dropout_perc=dropout,\n                    activation=\"ReLU\",\n                    use_batch_norm=use_batch_norm,\n                    groups=groups,\n                )\n            )\n\n        self.decoder_blocks = nn.ModuleList(decoder_blocks)\n\n    def forward(self, *features: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        *features :  List[torch.Tensor]\n            List containing the output of each encoder block(skip connections) and final\n            output of the encoder.\n\n        Returns\n        -------\n        torch.Tensor\n            Output of the decoder.\n        \"\"\"\n        x: torch.Tensor = features[0]\n        skip_connections: Tuple[torch.Tensor, ...] = features[-1:0:-1]\n\n        x = self.bottleneck(x)\n\n        for i, module in enumerate(self.decoder_blocks):\n            x = module(x)\n            if isinstance(module, nn.Upsample):\n                # divide index by 2 because of upsampling layers\n                skip_connection: torch.Tensor = skip_connections[i // 2]\n                if self.n2v2:\n                    if x.shape != skip_connections[-1].shape:\n                        x = self._interleave(x, skip_connection, self.groups)\n                else:\n                    x = self._interleave(x, skip_connection, self.groups)\n        return x\n\n    @staticmethod\n    def _interleave(A: torch.Tensor, B: torch.Tensor, groups: int) -&gt; torch.Tensor:\n        \"\"\"Interleave two tensors.\n\n        Splits the tensors `A` and `B` into equally sized groups along the channel\n        axis (axis=1); then concatenates the groups in alternating order along the\n        channel axis, starting with the first group from tensor A.\n\n        Parameters\n        ----------\n        A : torch.Tensor\n            First tensor.\n        B : torch.Tensor\n            Second tensor.\n        groups : int\n            The number of groups.\n\n        Returns\n        -------\n        torch.Tensor\n            Interleaved tensor.\n\n        Raises\n        ------\n        ValueError:\n            If either of `A` or `B`'s channel axis is not divisible by `groups`.\n        \"\"\"\n        if (A.shape[1] % groups != 0) or (B.shape[1] % groups != 0):\n            raise ValueError(f\"Number of channels not divisible by {groups} groups.\")\n\n        m = A.shape[1] // groups\n        n = B.shape[1] // groups\n\n        A_groups: List[torch.Tensor] = [\n            A[:, i * m : (i + 1) * m] for i in range(groups)\n        ]\n        B_groups: List[torch.Tensor] = [\n            B[:, i * n : (i + 1) * n] for i in range(groups)\n        ]\n\n        interleaved = torch.cat(\n            [\n                tensor_list[i]\n                for i in range(groups)\n                for tensor_list in [A_groups, B_groups]\n            ],\n            dim=1,\n        )\n\n        return interleaved\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetDecoder.__init__","title":"<code>__init__(conv_dim, depth=3, num_channels_init=64, use_batch_norm=True, dropout=0.0, n2v2=False, groups=1)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.</p> required <code>depth</code> <code>int</code> <p>Number of decoder blocks, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of channels in the first encoder block, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>n2v2</code> <code>bool</code> <p>Whether to use N2V2 architecture, by default False.</p> <code>False</code> <code>groups</code> <code>int</code> <p>Number of blocked connections from input channels to output channels, by default 1.</p> <code>1</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def __init__(\n    self,\n    conv_dim: int,\n    depth: int = 3,\n    num_channels_init: int = 64,\n    use_batch_norm: bool = True,\n    dropout: float = 0.0,\n    n2v2: bool = False,\n    groups: int = 1,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n    depth : int, optional\n        Number of decoder blocks, by default 3.\n    num_channels_init : int, optional\n        Number of channels in the first encoder block, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    n2v2 : bool, optional\n        Whether to use N2V2 architecture, by default False.\n    groups : int, optional\n        Number of blocked connections from input channels to output\n        channels, by default 1.\n    \"\"\"\n    super().__init__()\n\n    upsampling = nn.Upsample(\n        scale_factor=2, mode=\"bilinear\" if conv_dim == 2 else \"trilinear\"\n    )\n    in_channels = out_channels = num_channels_init * groups * (2 ** (depth - 1))\n\n    self.n2v2 = n2v2\n    self.groups = groups\n\n    self.bottleneck = Conv_Block(\n        conv_dim,\n        in_channels=in_channels,\n        out_channels=out_channels,\n        intermediate_channel_multiplier=2,\n        use_batch_norm=use_batch_norm,\n        dropout_perc=dropout,\n        groups=self.groups,\n    )\n\n    decoder_blocks: List[nn.Module] = []\n    for n in range(depth):\n        decoder_blocks.append(upsampling)\n        in_channels = (num_channels_init * 2 ** (depth - n)) * groups\n        out_channels = in_channels // 2\n        decoder_blocks.append(\n            Conv_Block(\n                conv_dim,\n                in_channels=(\n                    in_channels + in_channels // 2 if n &gt; 0 else in_channels\n                ),\n                out_channels=out_channels,\n                intermediate_channel_multiplier=2,\n                dropout_perc=dropout,\n                activation=\"ReLU\",\n                use_batch_norm=use_batch_norm,\n                groups=groups,\n            )\n        )\n\n    self.decoder_blocks = nn.ModuleList(decoder_blocks)\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetDecoder.forward","title":"<code>forward(*features)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>*features</code> <code> List[torch.Tensor]</code> <p>List containing the output of each encoder block(skip connections) and final output of the encoder.</p> <code>()</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Output of the decoder.</p> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def forward(self, *features: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Forward pass.\n\n    Parameters\n    ----------\n    *features :  List[torch.Tensor]\n        List containing the output of each encoder block(skip connections) and final\n        output of the encoder.\n\n    Returns\n    -------\n    torch.Tensor\n        Output of the decoder.\n    \"\"\"\n    x: torch.Tensor = features[0]\n    skip_connections: Tuple[torch.Tensor, ...] = features[-1:0:-1]\n\n    x = self.bottleneck(x)\n\n    for i, module in enumerate(self.decoder_blocks):\n        x = module(x)\n        if isinstance(module, nn.Upsample):\n            # divide index by 2 because of upsampling layers\n            skip_connection: torch.Tensor = skip_connections[i // 2]\n            if self.n2v2:\n                if x.shape != skip_connections[-1].shape:\n                    x = self._interleave(x, skip_connection, self.groups)\n            else:\n                x = self._interleave(x, skip_connection, self.groups)\n    return x\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetEncoder","title":"<code>UnetEncoder</code>","text":"<p>               Bases: <code>Module</code></p> <p>Unet encoder pathway.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels, by default 1.</p> <code>1</code> <code>depth</code> <code>int</code> <p>Number of encoder blocks, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of channels in the first encoder block, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>pool_kernel</code> <code>int</code> <p>Kernel size for the max pooling layers, by default 2.</p> <code>2</code> <code>n2v2</code> <code>bool</code> <p>Whether to use N2V2 architecture, by default False.</p> <code>False</code> <code>groups</code> <code>int</code> <p>Number of blocked connections from input channels to output channels, by default 1.</p> <code>1</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>class UnetEncoder(nn.Module):\n    \"\"\"\n    Unet encoder pathway.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n    in_channels : int, optional\n        Number of input channels, by default 1.\n    depth : int, optional\n        Number of encoder blocks, by default 3.\n    num_channels_init : int, optional\n        Number of channels in the first encoder block, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    pool_kernel : int, optional\n        Kernel size for the max pooling layers, by default 2.\n    n2v2 : bool, optional\n        Whether to use N2V2 architecture, by default False.\n    groups : int, optional\n        Number of blocked connections from input channels to output\n        channels, by default 1.\n    \"\"\"\n\n    def __init__(\n        self,\n        conv_dim: int,\n        in_channels: int = 1,\n        depth: int = 3,\n        num_channels_init: int = 64,\n        use_batch_norm: bool = True,\n        dropout: float = 0.0,\n        pool_kernel: int = 2,\n        n2v2: bool = False,\n        groups: int = 1,\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        conv_dim : int\n            Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n        in_channels : int, optional\n            Number of input channels, by default 1.\n        depth : int, optional\n            Number of encoder blocks, by default 3.\n        num_channels_init : int, optional\n            Number of channels in the first encoder block, by default 64.\n        use_batch_norm : bool, optional\n            Whether to use batch normalization, by default True.\n        dropout : float, optional\n            Dropout probability, by default 0.0.\n        pool_kernel : int, optional\n            Kernel size for the max pooling layers, by default 2.\n        n2v2 : bool, optional\n            Whether to use N2V2 architecture, by default False.\n        groups : int, optional\n            Number of blocked connections from input channels to output\n            channels, by default 1.\n        \"\"\"\n        super().__init__()\n\n        self.pooling = (\n            getattr(nn, f\"MaxPool{conv_dim}d\")(kernel_size=pool_kernel)\n            if not n2v2\n            else MaxBlurPool(dim=conv_dim, kernel_size=3, max_pool_size=pool_kernel)\n        )\n\n        encoder_blocks = []\n\n        for n in range(depth):\n            out_channels = num_channels_init * (2**n) * groups\n            in_channels = in_channels if n == 0 else out_channels // 2\n            encoder_blocks.append(\n                Conv_Block(\n                    conv_dim,\n                    in_channels=in_channels,\n                    out_channels=out_channels,\n                    dropout_perc=dropout,\n                    use_batch_norm=use_batch_norm,\n                    groups=groups,\n                )\n            )\n            encoder_blocks.append(self.pooling)\n        self.encoder_blocks = nn.ModuleList(encoder_blocks)\n\n    def forward(self, x: torch.Tensor) -&gt; List[torch.Tensor]:\n        \"\"\"\n        Forward pass.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            Input tensor.\n\n        Returns\n        -------\n        List[torch.Tensor]\n            Output of each encoder block (skip connections) and final output of the\n            encoder.\n        \"\"\"\n        encoder_features = []\n        for module in self.encoder_blocks:\n            x = module(x)\n            if isinstance(module, Conv_Block):\n                encoder_features.append(x)\n        features = [x, *encoder_features]\n        return features\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetEncoder.__init__","title":"<code>__init__(conv_dim, in_channels=1, depth=3, num_channels_init=64, use_batch_norm=True, dropout=0.0, pool_kernel=2, n2v2=False, groups=1)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>conv_dim</code> <code>int</code> <p>Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.</p> required <code>in_channels</code> <code>int</code> <p>Number of input channels, by default 1.</p> <code>1</code> <code>depth</code> <code>int</code> <p>Number of encoder blocks, by default 3.</p> <code>3</code> <code>num_channels_init</code> <code>int</code> <p>Number of channels in the first encoder block, by default 64.</p> <code>64</code> <code>use_batch_norm</code> <code>bool</code> <p>Whether to use batch normalization, by default True.</p> <code>True</code> <code>dropout</code> <code>float</code> <p>Dropout probability, by default 0.0.</p> <code>0.0</code> <code>pool_kernel</code> <code>int</code> <p>Kernel size for the max pooling layers, by default 2.</p> <code>2</code> <code>n2v2</code> <code>bool</code> <p>Whether to use N2V2 architecture, by default False.</p> <code>False</code> <code>groups</code> <code>int</code> <p>Number of blocked connections from input channels to output channels, by default 1.</p> <code>1</code> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def __init__(\n    self,\n    conv_dim: int,\n    in_channels: int = 1,\n    depth: int = 3,\n    num_channels_init: int = 64,\n    use_batch_norm: bool = True,\n    dropout: float = 0.0,\n    pool_kernel: int = 2,\n    n2v2: bool = False,\n    groups: int = 1,\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    conv_dim : int\n        Number of dimension of the convolution layers, 2 for 2D or 3 for 3D.\n    in_channels : int, optional\n        Number of input channels, by default 1.\n    depth : int, optional\n        Number of encoder blocks, by default 3.\n    num_channels_init : int, optional\n        Number of channels in the first encoder block, by default 64.\n    use_batch_norm : bool, optional\n        Whether to use batch normalization, by default True.\n    dropout : float, optional\n        Dropout probability, by default 0.0.\n    pool_kernel : int, optional\n        Kernel size for the max pooling layers, by default 2.\n    n2v2 : bool, optional\n        Whether to use N2V2 architecture, by default False.\n    groups : int, optional\n        Number of blocked connections from input channels to output\n        channels, by default 1.\n    \"\"\"\n    super().__init__()\n\n    self.pooling = (\n        getattr(nn, f\"MaxPool{conv_dim}d\")(kernel_size=pool_kernel)\n        if not n2v2\n        else MaxBlurPool(dim=conv_dim, kernel_size=3, max_pool_size=pool_kernel)\n    )\n\n    encoder_blocks = []\n\n    for n in range(depth):\n        out_channels = num_channels_init * (2**n) * groups\n        in_channels = in_channels if n == 0 else out_channels // 2\n        encoder_blocks.append(\n            Conv_Block(\n                conv_dim,\n                in_channels=in_channels,\n                out_channels=out_channels,\n                dropout_perc=dropout,\n                use_batch_norm=use_batch_norm,\n                groups=groups,\n            )\n        )\n        encoder_blocks.append(self.pooling)\n    self.encoder_blocks = nn.ModuleList(encoder_blocks)\n</code></pre>"},{"location":"reference/careamics/models/unet/#careamics.models.unet.UnetEncoder.forward","title":"<code>forward(x)</code>","text":"<p>Forward pass.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor.</p> required <p>Returns:</p> Type Description <code>List[Tensor]</code> <p>Output of each encoder block (skip connections) and final output of the encoder.</p> Source code in <code>src/careamics/models/unet.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; List[torch.Tensor]:\n    \"\"\"\n    Forward pass.\n\n    Parameters\n    ----------\n    x : torch.Tensor\n        Input tensor.\n\n    Returns\n    -------\n    List[torch.Tensor]\n        Output of each encoder block (skip connections) and final output of the\n        encoder.\n    \"\"\"\n    encoder_features = []\n    for module in self.encoder_blocks:\n        x = module(x)\n        if isinstance(module, Conv_Block):\n            encoder_features.append(x)\n    features = [x, *encoder_features]\n    return features\n</code></pre>"},{"location":"reference/careamics/prediction/stitch_prediction/","title":"stitch_prediction","text":"<p>Prediction utility functions.</p>"},{"location":"reference/careamics/prediction/stitch_prediction/#careamics.prediction.stitch_prediction.stitch_prediction","title":"<code>stitch_prediction(tiles, stitching_data)</code>","text":"<p>Stitch tiles back together to form a full image.</p> <p>Parameters:</p> Name Type Description Default <code>tiles</code> <code>List[Tensor]</code> <p>Cropped tiles and their respective stitching coordinates.</p> required <code>stitching_data</code> <code>List</code> <p>List of information and coordinates obtained from <code>dataset.tiled_patching.extract_tiles</code>.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Full image.</p> Source code in <code>src/careamics/prediction/stitch_prediction.py</code> <pre><code>def stitch_prediction(\n    tiles: List[torch.Tensor],\n    stitching_data: List[List[torch.Tensor]],\n) -&gt; torch.Tensor:\n    \"\"\"\n    Stitch tiles back together to form a full image.\n\n    Parameters\n    ----------\n    tiles : List[torch.Tensor]\n        Cropped tiles and their respective stitching coordinates.\n    stitching_data : List\n        List of information and coordinates obtained from\n        `dataset.tiled_patching.extract_tiles`.\n\n    Returns\n    -------\n    np.ndarray\n        Full image.\n    \"\"\"\n    # retrieve whole array size, there is two cases to consider:\n    # 1. the tiles are stored in a list\n    # 2. the tiles are stored in a list with batches along the first dim\n    if tiles[0].shape[0] &gt; 1:\n        input_shape = np.array(\n            [el.numpy() for el in stitching_data[0][0][0]], dtype=int\n        ).squeeze()\n    else:\n        input_shape = np.array(\n            [el.numpy() for el in stitching_data[0][0]], dtype=int\n        ).squeeze()\n\n    # TODO should use torch.zeros instead of np.zeros\n    predicted_image = torch.Tensor(np.zeros(input_shape, dtype=np.float32))\n\n    for tile_batch, (_, overlap_crop_coords_batch, stitch_coords_batch) in zip(\n        tiles, stitching_data\n    ):\n        for batch_idx in range(tile_batch.shape[0]):\n            # Compute coordinates for cropping predicted tile\n            slices = tuple(\n                [\n                    slice(c[0][batch_idx], c[1][batch_idx])\n                    for c in overlap_crop_coords_batch\n                ]\n            )\n\n            # Crop predited tile according to overlap coordinates\n            cropped_tile = tile_batch[batch_idx].squeeze()[slices]\n\n            # Insert cropped tile into predicted image using stitch coordinates\n            predicted_image[\n                (\n                    ...,\n                    *[\n                        slice(c[0][batch_idx], c[1][batch_idx])\n                        for c in stitch_coords_batch\n                    ],\n                )\n            ] = cropped_tile.to(torch.float32)\n\n    return predicted_image\n</code></pre>"},{"location":"reference/careamics/transforms/compose/","title":"compose","text":"<p>A class chaining transforms together.</p>"},{"location":"reference/careamics/transforms/compose/#careamics.transforms.compose.Compose","title":"<code>Compose</code>","text":"<p>A class chaining transforms together.</p> <p>Parameters:</p> Name Type Description Default <code>transform_list</code> <code>List[TRANSFORMS_UNION]</code> <p>A list of dictionaries where each dictionary contains the name of a transform and its parameters.</p> required <p>Attributes:</p> Name Type Description <code>_callable_transforms</code> <code>Callable</code> <p>A callable that applies the transforms to the input data.</p> Source code in <code>src/careamics/transforms/compose.py</code> <pre><code>class Compose:\n    \"\"\"A class chaining transforms together.\n\n    Parameters\n    ----------\n    transform_list : List[TRANSFORMS_UNION]\n        A list of dictionaries where each dictionary contains the name of a\n        transform and its parameters.\n\n    Attributes\n    ----------\n    _callable_transforms : Callable\n        A callable that applies the transforms to the input data.\n    \"\"\"\n\n    def __init__(self, transform_list: List[TRANSFORMS_UNION]) -&gt; None:\n        \"\"\"Instantiate a Compose object.\n\n        Parameters\n        ----------\n        transform_list : List[TRANSFORMS_UNION]\n            A list of dictionaries where each dictionary contains the name of a\n            transform and its parameters.\n        \"\"\"\n        # retrieve all available transforms\n        all_transforms = get_all_transforms()\n\n        # instantiate all transforms\n        transforms = [all_transforms[t.name](**t.model_dump()) for t in transform_list]\n\n        self._callable_transforms = self._chain_transforms(transforms)\n\n    def _chain_transforms(self, transforms: List[Transform]) -&gt; Callable:\n        \"\"\"Chain the transforms together.\n\n        Parameters\n        ----------\n        transforms : List[Transform]\n            A list of transforms to chain together.\n\n        Returns\n        -------\n        Callable\n            A callable that applies the transforms in order to the input data.\n        \"\"\"\n\n        def _chain(\n            patch: np.ndarray, target: Optional[np.ndarray]\n        ) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n            \"\"\"Chain transforms on the input data.\n\n            Parameters\n            ----------\n            patch : np.ndarray\n                Input data.\n            target : Optional[np.ndarray]\n                Target data, by default None.\n\n            Returns\n            -------\n            Tuple[np.ndarray, Optional[np.ndarray]]\n                The output of the transformations.\n            \"\"\"\n            params = (patch, target)\n\n            for t in transforms:\n                params = t(*params)\n\n            return params\n\n        return _chain\n\n    def __call__(\n        self, patch: np.ndarray, target: Optional[np.ndarray] = None\n    ) -&gt; Tuple[np.ndarray, ...]:\n        \"\"\"Apply the transforms to the input data.\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            The input data.\n        target : Optional[np.ndarray], optional\n            Target data, by default None.\n\n        Returns\n        -------\n        Tuple[np.ndarray, ...]\n            The output of the transformations.\n        \"\"\"\n        return self._callable_transforms(patch, target)\n</code></pre>"},{"location":"reference/careamics/transforms/compose/#careamics.transforms.compose.Compose.__call__","title":"<code>__call__(patch, target=None)</code>","text":"<p>Apply the transforms to the input data.</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>The input data.</p> required <code>target</code> <code>Optional[ndarray]</code> <p>Target data, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ...]</code> <p>The output of the transformations.</p> Source code in <code>src/careamics/transforms/compose.py</code> <pre><code>def __call__(\n    self, patch: np.ndarray, target: Optional[np.ndarray] = None\n) -&gt; Tuple[np.ndarray, ...]:\n    \"\"\"Apply the transforms to the input data.\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        The input data.\n    target : Optional[np.ndarray], optional\n        Target data, by default None.\n\n    Returns\n    -------\n    Tuple[np.ndarray, ...]\n        The output of the transformations.\n    \"\"\"\n    return self._callable_transforms(patch, target)\n</code></pre>"},{"location":"reference/careamics/transforms/compose/#careamics.transforms.compose.Compose.__init__","title":"<code>__init__(transform_list)</code>","text":"<p>Instantiate a Compose object.</p> <p>Parameters:</p> Name Type Description Default <code>transform_list</code> <code>List[TRANSFORMS_UNION]</code> <p>A list of dictionaries where each dictionary contains the name of a transform and its parameters.</p> required Source code in <code>src/careamics/transforms/compose.py</code> <pre><code>def __init__(self, transform_list: List[TRANSFORMS_UNION]) -&gt; None:\n    \"\"\"Instantiate a Compose object.\n\n    Parameters\n    ----------\n    transform_list : List[TRANSFORMS_UNION]\n        A list of dictionaries where each dictionary contains the name of a\n        transform and its parameters.\n    \"\"\"\n    # retrieve all available transforms\n    all_transforms = get_all_transforms()\n\n    # instantiate all transforms\n    transforms = [all_transforms[t.name](**t.model_dump()) for t in transform_list]\n\n    self._callable_transforms = self._chain_transforms(transforms)\n</code></pre>"},{"location":"reference/careamics/transforms/compose/#careamics.transforms.compose.get_all_transforms","title":"<code>get_all_transforms()</code>","text":"<p>Return all the transforms accepted by CAREamics.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with all the transforms accepted by CAREamics, where the keys are the transform names and the values are the transform classes.</p> Source code in <code>src/careamics/transforms/compose.py</code> <pre><code>def get_all_transforms() -&gt; Dict[str, type]:\n    \"\"\"Return all the transforms accepted by CAREamics.\n\n    Returns\n    -------\n    dict\n        A dictionary with all the transforms accepted by CAREamics, where the keys are\n        the transform names and the values are the transform classes.\n    \"\"\"\n    return ALL_TRANSFORMS\n</code></pre>"},{"location":"reference/careamics/transforms/n2v_manipulate/","title":"n2v_manipulate","text":"<p>N2V manipulation transform.</p>"},{"location":"reference/careamics/transforms/n2v_manipulate/#careamics.transforms.n2v_manipulate.N2VManipulate","title":"<code>N2VManipulate</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Default augmentation for the N2V model.</p> <p>This transform expects C(Z)YX dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>roi_size</code> <code>int</code> <p>Size of the replacement area, by default 11.</p> <code>11</code> <code>masked_pixel_percentage</code> <code>float</code> <p>Percentage of pixels to mask, by default 0.2.</p> <code>0.2</code> <code>strategy</code> <code>Literal['uniform', 'median']</code> <p>Replaccement strategy, uniform or median, by default uniform.</p> <code>value</code> <code>remove_center</code> <code>bool</code> <p>Whether to remove central pixel from patch, by default True.</p> <code>True</code> <code>struct_mask_axis</code> <code>Literal['horizontal', 'vertical', 'none']</code> <p>StructN2V mask axis, by default \"none\".</p> <code>'none'</code> <code>struct_mask_span</code> <code>int</code> <p>StructN2V mask span, by default 5.</p> <code>5</code> <code>seed</code> <code>Optional[int]</code> <p>Random seed, by default None.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>masked_pixel_percentage</code> <code>float</code> <p>Percentage of pixels to mask.</p> <code>roi_size</code> <code>int</code> <p>Size of the replacement area.</p> <code>strategy</code> <code>Literal['uniform', 'median']</code> <p>Replaccement strategy, uniform or median.</p> <code>remove_center</code> <code>bool</code> <p>Whether to remove central pixel from patch.</p> <code>struct_mask</code> <code>Optional[StructMaskParameters]</code> <p>StructN2V mask parameters.</p> <code>rng</code> <code>Generator</code> <p>Random number generator.</p> Source code in <code>src/careamics/transforms/n2v_manipulate.py</code> <pre><code>class N2VManipulate(Transform):\n    \"\"\"\n    Default augmentation for the N2V model.\n\n    This transform expects C(Z)YX dimensions.\n\n    Parameters\n    ----------\n    roi_size : int, optional\n        Size of the replacement area, by default 11.\n    masked_pixel_percentage : float, optional\n        Percentage of pixels to mask, by default 0.2.\n    strategy : Literal[ \"uniform\", \"median\" ], optional\n        Replaccement strategy, uniform or median, by default uniform.\n    remove_center : bool, optional\n        Whether to remove central pixel from patch, by default True.\n    struct_mask_axis : Literal[\"horizontal\", \"vertical\", \"none\"], optional\n        StructN2V mask axis, by default \"none\".\n    struct_mask_span : int, optional\n        StructN2V mask span, by default 5.\n    seed : Optional[int], optional\n        Random seed, by default None.\n\n    Attributes\n    ----------\n    masked_pixel_percentage : float\n        Percentage of pixels to mask.\n    roi_size : int\n        Size of the replacement area.\n    strategy : Literal[ \"uniform\", \"median\" ]\n        Replaccement strategy, uniform or median.\n    remove_center : bool\n        Whether to remove central pixel from patch.\n    struct_mask : Optional[StructMaskParameters]\n        StructN2V mask parameters.\n    rng : Generator\n        Random number generator.\n    \"\"\"\n\n    def __init__(\n        self,\n        roi_size: int = 11,\n        masked_pixel_percentage: float = 0.2,\n        strategy: Literal[\n            \"uniform\", \"median\"\n        ] = SupportedPixelManipulation.UNIFORM.value,\n        remove_center: bool = True,\n        struct_mask_axis: Literal[\"horizontal\", \"vertical\", \"none\"] = \"none\",\n        struct_mask_span: int = 5,\n        seed: Optional[int] = None,  # TODO use in pixel manipulation\n    ):\n        \"\"\"Constructor.\n\n        Parameters\n        ----------\n        roi_size : int, optional\n            Size of the replacement area, by default 11.\n        masked_pixel_percentage : float, optional\n            Percentage of pixels to mask, by default 0.2.\n        strategy : Literal[ \"uniform\", \"median\" ], optional\n            Replaccement strategy, uniform or median, by default uniform.\n        remove_center : bool, optional\n            Whether to remove central pixel from patch, by default True.\n        struct_mask_axis : Literal[\"horizontal\", \"vertical\", \"none\"], optional\n            StructN2V mask axis, by default \"none\".\n        struct_mask_span : int, optional\n            StructN2V mask span, by default 5.\n        seed : Optional[int], optional\n            Random seed, by default None.\n        \"\"\"\n        self.masked_pixel_percentage = masked_pixel_percentage\n        self.roi_size = roi_size\n        self.strategy = strategy\n        self.remove_center = remove_center  # TODO is this ever used?\n\n        if struct_mask_axis == SupportedStructAxis.NONE:\n            self.struct_mask: Optional[StructMaskParameters] = None\n        else:\n            self.struct_mask = StructMaskParameters(\n                axis=0 if struct_mask_axis == SupportedStructAxis.HORIZONTAL else 1,\n                span=struct_mask_span,\n            )\n\n        # numpy random generator\n        self.rng = np.random.default_rng(seed=seed)\n\n    def __call__(\n        self, patch: np.ndarray, *args: Any, **kwargs: Any\n    ) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Apply the transform to the image.\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            Image patch, 2D or 3D, shape C(Z)YX.\n        *args : Any\n            Additional arguments, unused.\n        **kwargs : Any\n            Additional keyword arguments, unused.\n\n        Returns\n        -------\n        Tuple[np.ndarray, np.ndarray, np.ndarray]\n            Masked patch, original patch, and mask.\n        \"\"\"\n        masked = np.zeros_like(patch)\n        mask = np.zeros_like(patch)\n        if self.strategy == SupportedPixelManipulation.UNIFORM:\n            # Iterate over the channels to apply manipulation separately\n            for c in range(patch.shape[0]):\n                masked[c, ...], mask[c, ...] = uniform_manipulate(\n                    patch=patch[c, ...],\n                    mask_pixel_percentage=self.masked_pixel_percentage,\n                    subpatch_size=self.roi_size,\n                    remove_center=self.remove_center,\n                    struct_params=self.struct_mask,\n                )\n        elif self.strategy == SupportedPixelManipulation.MEDIAN:\n            # Iterate over the channels to apply manipulation separately\n            for c in range(patch.shape[0]):\n                masked[c, ...], mask[c, ...] = median_manipulate(\n                    patch=patch[c, ...],\n                    mask_pixel_percentage=self.masked_pixel_percentage,\n                    subpatch_size=self.roi_size,\n                    struct_params=self.struct_mask,\n                )\n        else:\n            raise ValueError(f\"Unknown masking strategy ({self.strategy}).\")\n\n        # TODO why return patch?\n        return masked, patch, mask\n</code></pre>"},{"location":"reference/careamics/transforms/n2v_manipulate/#careamics.transforms.n2v_manipulate.N2VManipulate.__call__","title":"<code>__call__(patch, *args, **kwargs)</code>","text":"<p>Apply the transform to the image.</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>Image patch, 2D or 3D, shape C(Z)YX.</p> required <code>*args</code> <code>Any</code> <p>Additional arguments, unused.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments, unused.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>Masked patch, original patch, and mask.</p> Source code in <code>src/careamics/transforms/n2v_manipulate.py</code> <pre><code>def __call__(\n    self, patch: np.ndarray, *args: Any, **kwargs: Any\n) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Apply the transform to the image.\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        Image patch, 2D or 3D, shape C(Z)YX.\n    *args : Any\n        Additional arguments, unused.\n    **kwargs : Any\n        Additional keyword arguments, unused.\n\n    Returns\n    -------\n    Tuple[np.ndarray, np.ndarray, np.ndarray]\n        Masked patch, original patch, and mask.\n    \"\"\"\n    masked = np.zeros_like(patch)\n    mask = np.zeros_like(patch)\n    if self.strategy == SupportedPixelManipulation.UNIFORM:\n        # Iterate over the channels to apply manipulation separately\n        for c in range(patch.shape[0]):\n            masked[c, ...], mask[c, ...] = uniform_manipulate(\n                patch=patch[c, ...],\n                mask_pixel_percentage=self.masked_pixel_percentage,\n                subpatch_size=self.roi_size,\n                remove_center=self.remove_center,\n                struct_params=self.struct_mask,\n            )\n    elif self.strategy == SupportedPixelManipulation.MEDIAN:\n        # Iterate over the channels to apply manipulation separately\n        for c in range(patch.shape[0]):\n            masked[c, ...], mask[c, ...] = median_manipulate(\n                patch=patch[c, ...],\n                mask_pixel_percentage=self.masked_pixel_percentage,\n                subpatch_size=self.roi_size,\n                struct_params=self.struct_mask,\n            )\n    else:\n        raise ValueError(f\"Unknown masking strategy ({self.strategy}).\")\n\n    # TODO why return patch?\n    return masked, patch, mask\n</code></pre>"},{"location":"reference/careamics/transforms/n2v_manipulate/#careamics.transforms.n2v_manipulate.N2VManipulate.__init__","title":"<code>__init__(roi_size=11, masked_pixel_percentage=0.2, strategy=SupportedPixelManipulation.UNIFORM.value, remove_center=True, struct_mask_axis='none', struct_mask_span=5, seed=None)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>roi_size</code> <code>int</code> <p>Size of the replacement area, by default 11.</p> <code>11</code> <code>masked_pixel_percentage</code> <code>float</code> <p>Percentage of pixels to mask, by default 0.2.</p> <code>0.2</code> <code>strategy</code> <code>Literal['uniform', 'median']</code> <p>Replaccement strategy, uniform or median, by default uniform.</p> <code>value</code> <code>remove_center</code> <code>bool</code> <p>Whether to remove central pixel from patch, by default True.</p> <code>True</code> <code>struct_mask_axis</code> <code>Literal['horizontal', 'vertical', 'none']</code> <p>StructN2V mask axis, by default \"none\".</p> <code>'none'</code> <code>struct_mask_span</code> <code>int</code> <p>StructN2V mask span, by default 5.</p> <code>5</code> <code>seed</code> <code>Optional[int]</code> <p>Random seed, by default None.</p> <code>None</code> Source code in <code>src/careamics/transforms/n2v_manipulate.py</code> <pre><code>def __init__(\n    self,\n    roi_size: int = 11,\n    masked_pixel_percentage: float = 0.2,\n    strategy: Literal[\n        \"uniform\", \"median\"\n    ] = SupportedPixelManipulation.UNIFORM.value,\n    remove_center: bool = True,\n    struct_mask_axis: Literal[\"horizontal\", \"vertical\", \"none\"] = \"none\",\n    struct_mask_span: int = 5,\n    seed: Optional[int] = None,  # TODO use in pixel manipulation\n):\n    \"\"\"Constructor.\n\n    Parameters\n    ----------\n    roi_size : int, optional\n        Size of the replacement area, by default 11.\n    masked_pixel_percentage : float, optional\n        Percentage of pixels to mask, by default 0.2.\n    strategy : Literal[ \"uniform\", \"median\" ], optional\n        Replaccement strategy, uniform or median, by default uniform.\n    remove_center : bool, optional\n        Whether to remove central pixel from patch, by default True.\n    struct_mask_axis : Literal[\"horizontal\", \"vertical\", \"none\"], optional\n        StructN2V mask axis, by default \"none\".\n    struct_mask_span : int, optional\n        StructN2V mask span, by default 5.\n    seed : Optional[int], optional\n        Random seed, by default None.\n    \"\"\"\n    self.masked_pixel_percentage = masked_pixel_percentage\n    self.roi_size = roi_size\n    self.strategy = strategy\n    self.remove_center = remove_center  # TODO is this ever used?\n\n    if struct_mask_axis == SupportedStructAxis.NONE:\n        self.struct_mask: Optional[StructMaskParameters] = None\n    else:\n        self.struct_mask = StructMaskParameters(\n            axis=0 if struct_mask_axis == SupportedStructAxis.HORIZONTAL else 1,\n            span=struct_mask_span,\n        )\n\n    # numpy random generator\n    self.rng = np.random.default_rng(seed=seed)\n</code></pre>"},{"location":"reference/careamics/transforms/normalize/","title":"normalize","text":"<p>Normalization and denormalization transforms for image patches.</p>"},{"location":"reference/careamics/transforms/normalize/#careamics.transforms.normalize.Denormalize","title":"<code>Denormalize</code>","text":"<p>Denormalize an image or image patch.</p> <p>Denormalization is performed expecting a zero mean and unit variance input. This transform expects C(Z)YX dimensions.</p> <p>Not that an epsilon value of 1e-6 is added to the standard deviation to avoid division by zero during the normalization step, which is taken into account during denormalization.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>Mean value.</p> required <code>std</code> <code>float</code> <p>Standard deviation value.</p> required <p>Attributes:</p> Name Type Description <code>mean</code> <code>float</code> <p>Mean value.</p> <code>std</code> <code>float</code> <p>Standard deviation value.</p> Source code in <code>src/careamics/transforms/normalize.py</code> <pre><code>class Denormalize:\n    \"\"\"\n    Denormalize an image or image patch.\n\n    Denormalization is performed expecting a zero mean and unit variance input. This\n    transform expects C(Z)YX dimensions.\n\n    Not that an epsilon value of 1e-6 is added to the standard deviation to avoid\n    division by zero during the normalization step, which is taken into account during\n    denormalization.\n\n    Parameters\n    ----------\n    mean : float\n        Mean value.\n    std : float\n        Standard deviation value.\n\n    Attributes\n    ----------\n    mean : float\n        Mean value.\n    std : float\n        Standard deviation value.\n    \"\"\"\n\n    def __init__(\n        self,\n        mean: float,\n        std: float,\n    ):\n        \"\"\"Constructor.\n\n        Parameters\n        ----------\n        mean : float\n            Mean.\n        std : float\n            Standard deviation.\n        \"\"\"\n        self.mean = mean\n        self.std = std\n        self.eps = 1e-6\n\n    def __call__(\n        self, patch: np.ndarray, target: Optional[np.ndarray] = None\n    ) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n        \"\"\"Apply the transform to the source patch and the target (optional).\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            Patch, 2D or 3D, shape C(Z)YX.\n        target : Optional[np.ndarray], optional\n            Target for the patch, by default None.\n\n        Returns\n        -------\n        Tuple[np.ndarray, Optional[np.ndarray]]\n            Transformed patch and target.\n        \"\"\"\n        norm_patch = self._apply(patch)\n        norm_target = self._apply(target) if target is not None else None\n\n        return norm_patch, norm_target\n\n    def _apply(self, patch: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Apply the transform to the image.\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            Image patch, 2D or 3D, shape C(Z)YX.\n\n        Returns\n        -------\n        np.ndarray\n            Denormalized image patch.\n        \"\"\"\n        return patch * (self.std + self.eps) + self.mean\n</code></pre>"},{"location":"reference/careamics/transforms/normalize/#careamics.transforms.normalize.Denormalize.__call__","title":"<code>__call__(patch, target=None)</code>","text":"<p>Apply the transform to the source patch and the target (optional).</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>Patch, 2D or 3D, shape C(Z)YX.</p> required <code>target</code> <code>Optional[ndarray]</code> <p>Target for the patch, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, Optional[ndarray]]</code> <p>Transformed patch and target.</p> Source code in <code>src/careamics/transforms/normalize.py</code> <pre><code>def __call__(\n    self, patch: np.ndarray, target: Optional[np.ndarray] = None\n) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n    \"\"\"Apply the transform to the source patch and the target (optional).\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        Patch, 2D or 3D, shape C(Z)YX.\n    target : Optional[np.ndarray], optional\n        Target for the patch, by default None.\n\n    Returns\n    -------\n    Tuple[np.ndarray, Optional[np.ndarray]]\n        Transformed patch and target.\n    \"\"\"\n    norm_patch = self._apply(patch)\n    norm_target = self._apply(target) if target is not None else None\n\n    return norm_patch, norm_target\n</code></pre>"},{"location":"reference/careamics/transforms/normalize/#careamics.transforms.normalize.Denormalize.__init__","title":"<code>__init__(mean, std)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>Mean.</p> required <code>std</code> <code>float</code> <p>Standard deviation.</p> required Source code in <code>src/careamics/transforms/normalize.py</code> <pre><code>def __init__(\n    self,\n    mean: float,\n    std: float,\n):\n    \"\"\"Constructor.\n\n    Parameters\n    ----------\n    mean : float\n        Mean.\n    std : float\n        Standard deviation.\n    \"\"\"\n    self.mean = mean\n    self.std = std\n    self.eps = 1e-6\n</code></pre>"},{"location":"reference/careamics/transforms/normalize/#careamics.transforms.normalize.Normalize","title":"<code>Normalize</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Normalize an image or image patch.</p> <p>Normalization is a zero mean and unit variance. This transform expects C(Z)YX dimensions.</p> <p>Not that an epsilon value of 1e-6 is added to the standard deviation to avoid division by zero and that it returns a float32 image.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>Mean value.</p> required <code>std</code> <code>float</code> <p>Standard deviation value.</p> required <p>Attributes:</p> Name Type Description <code>mean</code> <code>float</code> <p>Mean value.</p> <code>std</code> <code>float</code> <p>Standard deviation value.</p> Source code in <code>src/careamics/transforms/normalize.py</code> <pre><code>class Normalize(Transform):\n    \"\"\"\n    Normalize an image or image patch.\n\n    Normalization is a zero mean and unit variance. This transform expects C(Z)YX\n    dimensions.\n\n    Not that an epsilon value of 1e-6 is added to the standard deviation to avoid\n    division by zero and that it returns a float32 image.\n\n    Parameters\n    ----------\n    mean : float\n        Mean value.\n    std : float\n        Standard deviation value.\n\n    Attributes\n    ----------\n    mean : float\n        Mean value.\n    std : float\n        Standard deviation value.\n    \"\"\"\n\n    def __init__(\n        self,\n        mean: float,\n        std: float,\n    ):\n        \"\"\"Constructor.\n\n        Parameters\n        ----------\n        mean : float\n            Mean value.\n        std : float\n            Standard deviation value.\n        \"\"\"\n        self.mean = mean\n        self.std = std\n        self.eps = 1e-6\n\n    def __call__(\n        self, patch: np.ndarray, target: Optional[np.ndarray] = None\n    ) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n        \"\"\"Apply the transform to the source patch and the target (optional).\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            Patch, 2D or 3D, shape C(Z)YX.\n        target : Optional[np.ndarray], optional\n            Target for the patch, by default None.\n\n        Returns\n        -------\n        Tuple[np.ndarray, Optional[np.ndarray]]\n            Transformed patch and target.\n        \"\"\"\n        norm_patch = self._apply(patch)\n        norm_target = self._apply(target) if target is not None else None\n\n        return norm_patch, norm_target\n\n    def _apply(self, patch: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Apply the transform to the image.\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            Image patch, 2D or 3D, shape C(Z)YX.\n\n        Returns\n        -------\n        np.ndarray\n            Normalizedimage patch.\n        \"\"\"\n        return ((patch - self.mean) / (self.std + self.eps)).astype(np.float32)\n</code></pre>"},{"location":"reference/careamics/transforms/normalize/#careamics.transforms.normalize.Normalize.__call__","title":"<code>__call__(patch, target=None)</code>","text":"<p>Apply the transform to the source patch and the target (optional).</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>Patch, 2D or 3D, shape C(Z)YX.</p> required <code>target</code> <code>Optional[ndarray]</code> <p>Target for the patch, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, Optional[ndarray]]</code> <p>Transformed patch and target.</p> Source code in <code>src/careamics/transforms/normalize.py</code> <pre><code>def __call__(\n    self, patch: np.ndarray, target: Optional[np.ndarray] = None\n) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n    \"\"\"Apply the transform to the source patch and the target (optional).\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        Patch, 2D or 3D, shape C(Z)YX.\n    target : Optional[np.ndarray], optional\n        Target for the patch, by default None.\n\n    Returns\n    -------\n    Tuple[np.ndarray, Optional[np.ndarray]]\n        Transformed patch and target.\n    \"\"\"\n    norm_patch = self._apply(patch)\n    norm_target = self._apply(target) if target is not None else None\n\n    return norm_patch, norm_target\n</code></pre>"},{"location":"reference/careamics/transforms/normalize/#careamics.transforms.normalize.Normalize.__init__","title":"<code>__init__(mean, std)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>float</code> <p>Mean value.</p> required <code>std</code> <code>float</code> <p>Standard deviation value.</p> required Source code in <code>src/careamics/transforms/normalize.py</code> <pre><code>def __init__(\n    self,\n    mean: float,\n    std: float,\n):\n    \"\"\"Constructor.\n\n    Parameters\n    ----------\n    mean : float\n        Mean value.\n    std : float\n        Standard deviation value.\n    \"\"\"\n    self.mean = mean\n    self.std = std\n    self.eps = 1e-6\n</code></pre>"},{"location":"reference/careamics/transforms/pixel_manipulation/","title":"pixel_manipulation","text":"<p>Pixel manipulation methods.</p> <p>Pixel manipulation is used in N2V and similar algorithm to replace the value of masked pixels.</p>"},{"location":"reference/careamics/transforms/pixel_manipulation/#careamics.transforms.pixel_manipulation.median_manipulate","title":"<code>median_manipulate(patch, mask_pixel_percentage, subpatch_size=11, struct_params=None)</code>","text":"<p>Manipulate pixels by replacing them with the median of their surrounding subpatch.</p> <p>N2V2 version, manipulated pixels are selected randomly away from a grid with an approximate uniform probability to be selected across the whole patch.</p> <p>If <code>struct_params</code> is not None, an additional structN2V mask is applied to the data, replacing the pixels in the mask with random values (excluding the pixel already manipulated).</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>Image patch, 2D or 3D, shape (y, x) or (z, y, x).</p> required <code>mask_pixel_percentage</code> <code>floar</code> <p>Approximate percentage of pixels to be masked.</p> required <code>subpatch_size</code> <code>int</code> <p>Size of the subpatch the new pixel value is sampled from, by default 11.</p> <code>11</code> <code>struct_params</code> <code>Optional[StructMaskParameters]</code> <p>Parameters for the structN2V mask (axis and span).</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray]</code> <p>Tuple containing the manipulated patch, the original patch and the mask.</p> Source code in <code>src/careamics/transforms/pixel_manipulation.py</code> <pre><code>def median_manipulate(\n    patch: np.ndarray,\n    mask_pixel_percentage: float,\n    subpatch_size: int = 11,\n    struct_params: Optional[StructMaskParameters] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Manipulate pixels by replacing them with the median of their surrounding subpatch.\n\n    N2V2 version, manipulated pixels are selected randomly away from a grid with an\n    approximate uniform probability to be selected across the whole patch.\n\n    If `struct_params` is not None, an additional structN2V mask is applied to the data,\n    replacing the pixels in the mask with random values (excluding the pixel already\n    manipulated).\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        Image patch, 2D or 3D, shape (y, x) or (z, y, x).\n    mask_pixel_percentage : floar\n        Approximate percentage of pixels to be masked.\n    subpatch_size : int\n        Size of the subpatch the new pixel value is sampled from, by default 11.\n    struct_params : Optional[StructMaskParameters]\n        Parameters for the structN2V mask (axis and span).\n\n    Returns\n    -------\n    Tuple[np.ndarray]\n           Tuple containing the manipulated patch, the original patch and the mask.\n    \"\"\"\n    transformed_patch = patch.copy()\n\n    # Get the coordinates of the pixels to be replaced\n    subpatch_centers = _get_stratified_coords(mask_pixel_percentage, patch.shape)\n\n    # Generate coordinate grid for subpatch\n    roi_span = np.array(\n        [-np.floor(subpatch_size / 2), np.ceil(subpatch_size / 2)]\n    ).astype(np.int32)\n\n    subpatch_crops_span_full = subpatch_centers[np.newaxis, ...].T + roi_span\n\n    # Dimensions n dims, n centers, (min, max)\n    subpatch_crops_span_clipped = np.clip(\n        subpatch_crops_span_full,\n        a_min=np.zeros_like(patch.shape)[:, np.newaxis, np.newaxis],\n        a_max=np.array(patch.shape)[:, np.newaxis, np.newaxis],\n    )\n\n    for idx in range(subpatch_crops_span_clipped.shape[1]):\n        subpatch_coords = subpatch_crops_span_clipped[:, idx, ...]\n        idxs = [\n            slice(x[0], x[1]) if x[1] - x[0] &gt; 0 else slice(0, 1)\n            for x in subpatch_coords\n        ]\n        subpatch = patch[tuple(idxs)]\n        subpatch_center_adjusted = subpatch_centers[idx] - subpatch_coords[:, 0]\n\n        if struct_params is None:\n            subpatch_mask = _create_subpatch_center_mask(\n                subpatch, subpatch_center_adjusted\n            )\n        else:\n            subpatch_mask = _create_subpatch_struct_mask(\n                subpatch, subpatch_center_adjusted, struct_params\n            )\n        transformed_patch[tuple(subpatch_centers[idx])] = np.median(\n            subpatch[subpatch_mask]\n        )\n\n    mask = np.where(transformed_patch != patch, 1, 0).astype(np.uint8)\n\n    if struct_params is not None:\n        transformed_patch = _apply_struct_mask(\n            transformed_patch, subpatch_centers, struct_params\n        )\n\n    return (\n        transformed_patch,\n        mask,\n    )\n</code></pre>"},{"location":"reference/careamics/transforms/pixel_manipulation/#careamics.transforms.pixel_manipulation.uniform_manipulate","title":"<code>uniform_manipulate(patch, mask_pixel_percentage, subpatch_size=11, remove_center=True, struct_params=None)</code>","text":"<p>Manipulate pixels by replacing them with a neighbor values.</p> <p>Manipulated pixels are selected unformly selected in a subpatch, away from a grid with an approximate uniform probability to be selected across the whole patch. If <code>struct_params</code> is not None, an additional structN2V mask is applied to the data, replacing the pixels in the mask with random values (excluding the pixel already manipulated).</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>Image patch, 2D or 3D, shape (y, x) or (z, y, x).</p> required <code>mask_pixel_percentage</code> <code>float</code> <p>Approximate percentage of pixels to be masked.</p> required <code>subpatch_size</code> <code>int</code> <p>Size of the subpatch the new pixel value is sampled from, by default 11.</p> <code>11</code> <code>remove_center</code> <code>bool</code> <p>Whether to remove the center pixel from the subpatch, by default False.</p> <code>True</code> <code>struct_params</code> <code>Optional[StructMaskParameters]</code> <p>Parameters for the structN2V mask (axis and span).</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray]</code> <p>Tuple containing the manipulated patch and the corresponding mask.</p> Source code in <code>src/careamics/transforms/pixel_manipulation.py</code> <pre><code>def uniform_manipulate(\n    patch: np.ndarray,\n    mask_pixel_percentage: float,\n    subpatch_size: int = 11,\n    remove_center: bool = True,\n    struct_params: Optional[StructMaskParameters] = None,\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Manipulate pixels by replacing them with a neighbor values.\n\n    Manipulated pixels are selected unformly selected in a subpatch, away from a grid\n    with an approximate uniform probability to be selected across the whole patch.\n    If `struct_params` is not None, an additional structN2V mask is applied to the\n    data, replacing the pixels in the mask with random values (excluding the pixel\n    already manipulated).\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        Image patch, 2D or 3D, shape (y, x) or (z, y, x).\n    mask_pixel_percentage : float\n        Approximate percentage of pixels to be masked.\n    subpatch_size : int\n        Size of the subpatch the new pixel value is sampled from, by default 11.\n    remove_center : bool\n        Whether to remove the center pixel from the subpatch, by default False.\n    struct_params : Optional[StructMaskParameters]\n        Parameters for the structN2V mask (axis and span).\n\n    Returns\n    -------\n    Tuple[np.ndarray]\n        Tuple containing the manipulated patch and the corresponding mask.\n    \"\"\"\n    # Get the coordinates of the pixels to be replaced\n    transformed_patch = patch.copy()\n\n    subpatch_centers = _get_stratified_coords(mask_pixel_percentage, patch.shape)\n    rng = np.random.default_rng()\n\n    # Generate coordinate grid for subpatch\n    roi_span_full = np.arange(\n        -np.floor(subpatch_size / 2), np.ceil(subpatch_size / 2)\n    ).astype(np.int32)\n\n    # Remove the center pixel from the grid if needed\n    roi_span = roi_span_full[roi_span_full != 0] if remove_center else roi_span_full\n\n    # Randomly select coordinates from the grid\n    random_increment = rng.choice(roi_span, size=subpatch_centers.shape)\n\n    # Clip the coordinates to the patch size\n    replacement_coords = np.clip(\n        subpatch_centers + random_increment,\n        0,\n        [patch.shape[i] - 1 for i in range(len(patch.shape))],\n    )\n\n    # Get the replacement pixels from all subpatchs\n    replacement_pixels = patch[tuple(replacement_coords.T.tolist())]\n\n    # Replace the original pixels with the replacement pixels\n    transformed_patch[tuple(subpatch_centers.T.tolist())] = replacement_pixels\n    mask = np.where(transformed_patch != patch, 1, 0).astype(np.uint8)\n\n    if struct_params is not None:\n        transformed_patch = _apply_struct_mask(\n            transformed_patch, subpatch_centers, struct_params\n        )\n\n    return (\n        transformed_patch,\n        mask,\n    )\n</code></pre>"},{"location":"reference/careamics/transforms/struct_mask_parameters/","title":"struct_mask_parameters","text":"<p>Class representing the parameters of structN2V masks.</p>"},{"location":"reference/careamics/transforms/struct_mask_parameters/#careamics.transforms.struct_mask_parameters.StructMaskParameters","title":"<code>StructMaskParameters</code>  <code>dataclass</code>","text":"<p>Parameters of structN2V masks.</p> <p>Attributes:</p> Name Type Description <code>axis</code> <code>Literal[0, 1]</code> <p>Axis along which to apply the mask, horizontal (0) or vertical (1).</p> <code>span</code> <code>int</code> <p>Span of the mask.</p> Source code in <code>src/careamics/transforms/struct_mask_parameters.py</code> <pre><code>@dataclass\nclass StructMaskParameters:\n    \"\"\"Parameters of structN2V masks.\n\n    Attributes\n    ----------\n    axis : Literal[0, 1]\n        Axis along which to apply the mask, horizontal (0) or vertical (1).\n    span : int\n        Span of the mask.\n    \"\"\"\n\n    axis: Literal[0, 1]\n    span: int\n</code></pre>"},{"location":"reference/careamics/transforms/transform/","title":"transform","text":"<p>A general parent class for transforms.</p>"},{"location":"reference/careamics/transforms/transform/#careamics.transforms.transform.Transform","title":"<code>Transform</code>","text":"<p>A general parent class for transforms.</p> Source code in <code>src/careamics/transforms/transform.py</code> <pre><code>class Transform:\n    \"\"\"A general parent class for transforms.\"\"\"\n\n    def __call__(self, *args: Any, **kwargs: Any) -&gt; Any:\n        \"\"\"Apply the transform.\n\n        Parameters\n        ----------\n        *args : Any\n            Arguments.\n        **kwargs : Any\n            Keyword arguments.\n\n        Returns\n        -------\n        Any\n            Transformed data.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/careamics/transforms/transform/#careamics.transforms.transform.Transform.__call__","title":"<code>__call__(*args, **kwargs)</code>","text":"<p>Apply the transform.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <code>Any</code> <p>Arguments.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>Transformed data.</p> Source code in <code>src/careamics/transforms/transform.py</code> <pre><code>def __call__(self, *args: Any, **kwargs: Any) -&gt; Any:\n    \"\"\"Apply the transform.\n\n    Parameters\n    ----------\n    *args : Any\n        Arguments.\n    **kwargs : Any\n        Keyword arguments.\n\n    Returns\n    -------\n    Any\n        Transformed data.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/careamics/transforms/tta/","title":"tta","text":"<p>Test-time augmentations.</p>"},{"location":"reference/careamics/transforms/tta/#careamics.transforms.tta.ImageRestorationTTA","title":"<code>ImageRestorationTTA</code>","text":"<p>Test-time augmentation for image restoration tasks.</p> <p>The augmentation is performed using all 90 deg rotations and their flipped version, as well as the original image flipped.</p> <p>Tensors should be of shape SC(Z)YX</p> <p>This transformation is used in the LightningModule in order to perform test-time agumentation.</p> Source code in <code>src/careamics/transforms/tta.py</code> <pre><code>class ImageRestorationTTA:\n    \"\"\"\n    Test-time augmentation for image restoration tasks.\n\n    The augmentation is performed using all 90 deg rotations and their flipped version,\n    as well as the original image flipped.\n\n    Tensors should be of shape SC(Z)YX\n\n    This transformation is used in the LightningModule in order to perform test-time\n    agumentation.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        \"\"\"Constructor.\"\"\"\n        pass\n\n    def forward(self, x: Tensor) -&gt; List[Tensor]:\n        \"\"\"\n        Apply test-time augmentation to the input tensor.\n\n        Parameters\n        ----------\n        x : Tensor\n            Input tensor, shape SC(Z)YX.\n\n        Returns\n        -------\n        List[Tensor]\n            List of augmented tensors.\n        \"\"\"\n        augmented = [\n            x,\n            rot90(x, 1, dims=(-2, -1)),\n            rot90(x, 2, dims=(-2, -1)),\n            rot90(x, 3, dims=(-2, -1)),\n        ]\n        augmented_flip = augmented.copy()\n        for x_ in augmented:\n            augmented_flip.append(flip(x_, dims=(-3, -1)))\n        return augmented_flip\n\n    def backward(self, x: List[Tensor]) -&gt; Tensor:\n        \"\"\"Undo the test-time augmentation.\n\n        Parameters\n        ----------\n        x : Any\n            List of augmented tensors.\n\n        Returns\n        -------\n        Any\n            Original tensor.\n        \"\"\"\n        reverse = [\n            x[0],\n            rot90(x[1], -1, dims=(-2, -1)),\n            rot90(x[2], -2, dims=(-2, -1)),\n            rot90(x[3], -3, dims=(-2, -1)),\n            flip(x[4], dims=(-3, -1)),\n            rot90(flip(x[5], dims=(-3, -1)), -1, dims=(-2, -1)),\n            rot90(flip(x[6], dims=(-3, -1)), -2, dims=(-2, -1)),\n            rot90(flip(x[7], dims=(-3, -1)), -3, dims=(-2, -1)),\n        ]\n        return mean(stack(reverse), dim=0)\n</code></pre>"},{"location":"reference/careamics/transforms/tta/#careamics.transforms.tta.ImageRestorationTTA.__init__","title":"<code>__init__()</code>","text":"<p>Constructor.</p> Source code in <code>src/careamics/transforms/tta.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Constructor.\"\"\"\n    pass\n</code></pre>"},{"location":"reference/careamics/transforms/tta/#careamics.transforms.tta.ImageRestorationTTA.backward","title":"<code>backward(x)</code>","text":"<p>Undo the test-time augmentation.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Any</code> <p>List of augmented tensors.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Original tensor.</p> Source code in <code>src/careamics/transforms/tta.py</code> <pre><code>def backward(self, x: List[Tensor]) -&gt; Tensor:\n    \"\"\"Undo the test-time augmentation.\n\n    Parameters\n    ----------\n    x : Any\n        List of augmented tensors.\n\n    Returns\n    -------\n    Any\n        Original tensor.\n    \"\"\"\n    reverse = [\n        x[0],\n        rot90(x[1], -1, dims=(-2, -1)),\n        rot90(x[2], -2, dims=(-2, -1)),\n        rot90(x[3], -3, dims=(-2, -1)),\n        flip(x[4], dims=(-3, -1)),\n        rot90(flip(x[5], dims=(-3, -1)), -1, dims=(-2, -1)),\n        rot90(flip(x[6], dims=(-3, -1)), -2, dims=(-2, -1)),\n        rot90(flip(x[7], dims=(-3, -1)), -3, dims=(-2, -1)),\n    ]\n    return mean(stack(reverse), dim=0)\n</code></pre>"},{"location":"reference/careamics/transforms/tta/#careamics.transforms.tta.ImageRestorationTTA.forward","title":"<code>forward(x)</code>","text":"<p>Apply test-time augmentation to the input tensor.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor, shape SC(Z)YX.</p> required <p>Returns:</p> Type Description <code>List[Tensor]</code> <p>List of augmented tensors.</p> Source code in <code>src/careamics/transforms/tta.py</code> <pre><code>def forward(self, x: Tensor) -&gt; List[Tensor]:\n    \"\"\"\n    Apply test-time augmentation to the input tensor.\n\n    Parameters\n    ----------\n    x : Tensor\n        Input tensor, shape SC(Z)YX.\n\n    Returns\n    -------\n    List[Tensor]\n        List of augmented tensors.\n    \"\"\"\n    augmented = [\n        x,\n        rot90(x, 1, dims=(-2, -1)),\n        rot90(x, 2, dims=(-2, -1)),\n        rot90(x, 3, dims=(-2, -1)),\n    ]\n    augmented_flip = augmented.copy()\n    for x_ in augmented:\n        augmented_flip.append(flip(x_, dims=(-3, -1)))\n    return augmented_flip\n</code></pre>"},{"location":"reference/careamics/transforms/xy_flip/","title":"xy_flip","text":"<p>XY flip transform.</p>"},{"location":"reference/careamics/transforms/xy_flip/#careamics.transforms.xy_flip.XYFlip","title":"<code>XYFlip</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Flip image along X or Y axis.</p> <p>This transform ignores singleton axes and randomly flips one of the other last two axes.</p> <p>This transform expects C(Z)YX dimensions.</p> <p>Attributes:</p> Name Type Description <code>axis_indices</code> <code>List[int]</code> <p>Indices of the axes that can be flipped.</p> <code>rng</code> <code>Generator</code> <p>Random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>Optional[int]</code> <p>Random seed, by default None.</p> <code>None</code> Source code in <code>src/careamics/transforms/xy_flip.py</code> <pre><code>class XYFlip(Transform):\n    \"\"\"Flip image along X or Y axis.\n\n    This transform ignores singleton axes and randomly flips one of the other\n    last two axes.\n\n    This transform expects C(Z)YX dimensions.\n\n    Attributes\n    ----------\n    axis_indices : List[int]\n        Indices of the axes that can be flipped.\n    rng : np.random.Generator\n        Random number generator.\n\n    Parameters\n    ----------\n    seed : Optional[int], optional\n        Random seed, by default None.\n    \"\"\"\n\n    def __init__(self, seed: Optional[int] = None) -&gt; None:\n        \"\"\"Constructor.\n\n        Parameters\n        ----------\n        seed : Optional[int], optional\n            Random seed, by default None.\n        \"\"\"\n        # \"flippable\" axes\n        self.axis_indices = [-2, -1]\n\n        # numpy random generator\n        self.rng = np.random.default_rng(seed=seed)\n\n    def __call__(\n        self, patch: np.ndarray, target: Optional[np.ndarray] = None\n    ) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n        \"\"\"Apply the transform to the source patch and the target (optional).\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            Patch, 2D or 3D, shape C(Z)YX.\n        target : Optional[np.ndarray], optional\n            Target for the patch, by default None.\n\n        Returns\n        -------\n        Tuple[np.ndarray, Optional[np.ndarray]]\n            Transformed patch and target.\n        \"\"\"\n        # choose an axis to flip\n        axis = self.rng.choice(self.axis_indices)\n\n        patch_transformed = self._apply(patch, axis)\n        target_transformed = self._apply(target, axis) if target is not None else None\n\n        return patch_transformed, target_transformed\n\n    def _apply(self, patch: np.ndarray, axis: int) -&gt; np.ndarray:\n        \"\"\"Apply the transform to the image.\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            Image patch, 2D or 3D, shape C(Z)YX.\n        axis : int\n            Axis to flip.\n\n        Returns\n        -------\n        np.ndarray\n            Flipped image patch.\n        \"\"\"\n        # TODO why ascontiguousarray?\n        return np.ascontiguousarray(np.flip(patch, axis=axis))\n</code></pre>"},{"location":"reference/careamics/transforms/xy_flip/#careamics.transforms.xy_flip.XYFlip.__call__","title":"<code>__call__(patch, target=None)</code>","text":"<p>Apply the transform to the source patch and the target (optional).</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>Patch, 2D or 3D, shape C(Z)YX.</p> required <code>target</code> <code>Optional[ndarray]</code> <p>Target for the patch, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, Optional[ndarray]]</code> <p>Transformed patch and target.</p> Source code in <code>src/careamics/transforms/xy_flip.py</code> <pre><code>def __call__(\n    self, patch: np.ndarray, target: Optional[np.ndarray] = None\n) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n    \"\"\"Apply the transform to the source patch and the target (optional).\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        Patch, 2D or 3D, shape C(Z)YX.\n    target : Optional[np.ndarray], optional\n        Target for the patch, by default None.\n\n    Returns\n    -------\n    Tuple[np.ndarray, Optional[np.ndarray]]\n        Transformed patch and target.\n    \"\"\"\n    # choose an axis to flip\n    axis = self.rng.choice(self.axis_indices)\n\n    patch_transformed = self._apply(patch, axis)\n    target_transformed = self._apply(target, axis) if target is not None else None\n\n    return patch_transformed, target_transformed\n</code></pre>"},{"location":"reference/careamics/transforms/xy_flip/#careamics.transforms.xy_flip.XYFlip.__init__","title":"<code>__init__(seed=None)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>Optional[int]</code> <p>Random seed, by default None.</p> <code>None</code> Source code in <code>src/careamics/transforms/xy_flip.py</code> <pre><code>def __init__(self, seed: Optional[int] = None) -&gt; None:\n    \"\"\"Constructor.\n\n    Parameters\n    ----------\n    seed : Optional[int], optional\n        Random seed, by default None.\n    \"\"\"\n    # \"flippable\" axes\n    self.axis_indices = [-2, -1]\n\n    # numpy random generator\n    self.rng = np.random.default_rng(seed=seed)\n</code></pre>"},{"location":"reference/careamics/transforms/xy_random_rotate90/","title":"xy_random_rotate90","text":"<p>Patch transform applying XY random 90 degrees rotations.</p>"},{"location":"reference/careamics/transforms/xy_random_rotate90/#careamics.transforms.xy_random_rotate90.XYRandomRotate90","title":"<code>XYRandomRotate90</code>","text":"<p>               Bases: <code>Transform</code></p> <p>Applies random 90 degree rotations to the YX axis.</p> <p>This transform expects C(Z)YX dimensions.</p> <p>Attributes:</p> Name Type Description <code>rng</code> <code>Generator</code> <p>Random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>Optional[int]</code> <p>Random seed, by default None.</p> <code>None</code> Source code in <code>src/careamics/transforms/xy_random_rotate90.py</code> <pre><code>class XYRandomRotate90(Transform):\n    \"\"\"Applies random 90 degree rotations to the YX axis.\n\n    This transform expects C(Z)YX dimensions.\n\n    Attributes\n    ----------\n    rng : np.random.Generator\n        Random number generator.\n\n    Parameters\n    ----------\n    seed : Optional[int]\n        Random seed, by default None.\n    \"\"\"\n\n    def __init__(self, seed: Optional[int] = None):\n        \"\"\"Constructor.\n\n        Parameters\n        ----------\n        seed : Optional[int]\n            Random seed, by default None.\n        \"\"\"\n        # numpy random generator\n        self.rng = np.random.default_rng(seed=seed)\n\n    def __call__(\n        self, patch: np.ndarray, target: Optional[np.ndarray] = None\n    ) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n        \"\"\"Apply the transform to the source patch and the target (optional).\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            Patch, 2D or 3D, shape C(Z)YX.\n        target : Optional[np.ndarray], optional\n            Target for the patch, by default None.\n\n        Returns\n        -------\n        Tuple[np.ndarray, Optional[np.ndarray]]\n            Transformed patch and target.\n        \"\"\"\n        # number of rotations\n        n_rot = self.rng.integers(1, 4)\n\n        axes = (-2, -1)\n        patch_transformed = self._apply(patch, n_rot, axes)\n        target_transformed = (\n            self._apply(target, n_rot, axes) if target is not None else None\n        )\n\n        return patch_transformed, target_transformed\n\n    def _apply(\n        self, patch: np.ndarray, n_rot: int, axes: Tuple[int, int]\n    ) -&gt; np.ndarray:\n        \"\"\"Apply the transform to the image.\n\n        Parameters\n        ----------\n        patch : np.ndarray\n            Image or image patch, 2D or 3D, shape C(Z)YX.\n        n_rot : int\n            Number of 90 degree rotations.\n        axes : Tuple[int, int]\n            Axes along which to rotate the patch.\n\n        Returns\n        -------\n        np.ndarray\n            Transformed patch.\n        \"\"\"\n        # TODO why ascontiguousarray?\n        return np.ascontiguousarray(np.rot90(patch, k=n_rot, axes=axes))\n</code></pre>"},{"location":"reference/careamics/transforms/xy_random_rotate90/#careamics.transforms.xy_random_rotate90.XYRandomRotate90.__call__","title":"<code>__call__(patch, target=None)</code>","text":"<p>Apply the transform to the source patch and the target (optional).</p> <p>Parameters:</p> Name Type Description Default <code>patch</code> <code>ndarray</code> <p>Patch, 2D or 3D, shape C(Z)YX.</p> required <code>target</code> <code>Optional[ndarray]</code> <p>Target for the patch, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, Optional[ndarray]]</code> <p>Transformed patch and target.</p> Source code in <code>src/careamics/transforms/xy_random_rotate90.py</code> <pre><code>def __call__(\n    self, patch: np.ndarray, target: Optional[np.ndarray] = None\n) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:\n    \"\"\"Apply the transform to the source patch and the target (optional).\n\n    Parameters\n    ----------\n    patch : np.ndarray\n        Patch, 2D or 3D, shape C(Z)YX.\n    target : Optional[np.ndarray], optional\n        Target for the patch, by default None.\n\n    Returns\n    -------\n    Tuple[np.ndarray, Optional[np.ndarray]]\n        Transformed patch and target.\n    \"\"\"\n    # number of rotations\n    n_rot = self.rng.integers(1, 4)\n\n    axes = (-2, -1)\n    patch_transformed = self._apply(patch, n_rot, axes)\n    target_transformed = (\n        self._apply(target, n_rot, axes) if target is not None else None\n    )\n\n    return patch_transformed, target_transformed\n</code></pre>"},{"location":"reference/careamics/transforms/xy_random_rotate90/#careamics.transforms.xy_random_rotate90.XYRandomRotate90.__init__","title":"<code>__init__(seed=None)</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>Optional[int]</code> <p>Random seed, by default None.</p> <code>None</code> Source code in <code>src/careamics/transforms/xy_random_rotate90.py</code> <pre><code>def __init__(self, seed: Optional[int] = None):\n    \"\"\"Constructor.\n\n    Parameters\n    ----------\n    seed : Optional[int]\n        Random seed, by default None.\n    \"\"\"\n    # numpy random generator\n    self.rng = np.random.default_rng(seed=seed)\n</code></pre>"},{"location":"reference/careamics/utils/base_enum/","title":"base_enum","text":"<p>A base class for Enum that allows checking if a value is in the Enum.</p>"},{"location":"reference/careamics/utils/base_enum/#careamics.utils.base_enum.BaseEnum","title":"<code>BaseEnum</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Base Enum class, allowing checking if a value is in the enum.</p> Example <p>from careamics.utils.base_enum import BaseEnum</p> Source code in <code>src/careamics/utils/base_enum.py</code> <pre><code>class BaseEnum(Enum, metaclass=_ContainerEnum):\n    \"\"\"Base Enum class, allowing checking if a value is in the enum.\n\n    Example\n    -------\n    &gt;&gt;&gt; from careamics.utils.base_enum import BaseEnum\n    &gt;&gt;&gt; # Define a new enum\n    &gt;&gt;&gt; class BaseEnumExtension(BaseEnum):\n    ...     VALUE = \"value\"\n    &gt;&gt;&gt; # Check if value is in the enum\n    &gt;&gt;&gt; \"value\" in BaseEnumExtension\n    True\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"reference/careamics/utils/base_enum/#careamics.utils.base_enum.BaseEnum--define-a-new-enum","title":"Define a new enum","text":"<p>class BaseEnumExtension(BaseEnum): ...     VALUE = \"value\"</p>"},{"location":"reference/careamics/utils/base_enum/#careamics.utils.base_enum.BaseEnum--check-if-value-is-in-the-enum","title":"Check if value is in the enum","text":"<p>\"value\" in BaseEnumExtension True</p>"},{"location":"reference/careamics/utils/context/","title":"context","text":"<p>Context submodule.</p> <p>A convenience function to change the working directory in order to save data.</p>"},{"location":"reference/careamics/utils/context/#careamics.utils.context.cwd","title":"<code>cwd(path)</code>","text":"<p>Change the current working directory to the given path.</p> <p>This method can be used to generate files in a specific directory, once out of the context, the working directory is set back to the original one.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>New working directory path.</p> required <p>Returns:</p> Type Description <code>Iterator[None]</code> <p>None values.</p> <p>Examples:</p> <p>The context is whcnaged within the block and then restored to the original one.</p> <pre><code>&gt;&gt;&gt; with cwd(my_path):\n...     pass # do something\n</code></pre> Source code in <code>src/careamics/utils/context.py</code> <pre><code>@contextmanager\ndef cwd(path: Union[str, Path]) -&gt; Iterator[None]:\n    \"\"\"\n    Change the current working directory to the given path.\n\n    This method can be used to generate files in a specific directory, once out of the\n    context, the working directory is set back to the original one.\n\n    Parameters\n    ----------\n    path : Union[str,Path]\n        New working directory path.\n\n    Returns\n    -------\n    Iterator[None]\n        None values.\n\n    Examples\n    --------\n    The context is whcnaged within the block and then restored to the original one.\n\n    &gt;&gt;&gt; with cwd(my_path):\n    ...     pass # do something\n    \"\"\"\n    path = Path(path)\n\n    if not path.exists():\n        path.mkdir(parents=True, exist_ok=True)\n\n    old_pwd = Path(\".\").absolute()\n    os.chdir(path)\n    try:\n        yield\n    finally:\n        os.chdir(old_pwd)\n</code></pre>"},{"location":"reference/careamics/utils/context/#careamics.utils.context.get_careamics_home","title":"<code>get_careamics_home()</code>","text":"<p>Return the CAREamics home directory.</p> <p>CAREamics home directory is a hidden folder in home.</p> <p>Returns:</p> Type Description <code>Path</code> <p>CAREamics home directory path.</p> Source code in <code>src/careamics/utils/context.py</code> <pre><code>def get_careamics_home() -&gt; Path:\n    \"\"\"Return the CAREamics home directory.\n\n    CAREamics home directory is a hidden folder in home.\n\n    Returns\n    -------\n    Path\n        CAREamics home directory path.\n    \"\"\"\n    home = Path.home() / \".careamics\"\n\n    if not home.exists():\n        home.mkdir(parents=True, exist_ok=True)\n\n    return home\n</code></pre>"},{"location":"reference/careamics/utils/logging/","title":"logging","text":"<p>Logging submodule.</p> <p>The methods are responsible for the in-console logger.</p>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar","title":"<code>ProgressBar</code>","text":"<p>Keras style progress bar.</p> <p>Adapted from https://github.com/yueyericardo/pkbar.</p> <p>Parameters:</p> Name Type Description Default <code>max_value</code> <code>Optional[int]</code> <p>Maximum progress bar value, by default None.</p> <code>None</code> <code>epoch</code> <code>Optional[int]</code> <p>Zero-indexed current epoch, by default None.</p> <code>None</code> <code>num_epochs</code> <code>Optional[int]</code> <p>Total number of epochs, by default None.</p> <code>None</code> <code>stateful_metrics</code> <code>Optional[List]</code> <p>Iterable of string names of metrics that should not be averaged over time. Metrics in this list will be displayed as-is. All others will be averaged by the progress bar before display, by default None.</p> <code>None</code> <code>always_stateful</code> <code>bool</code> <pre><code>Whether to set all metrics to be stateful, by default False.\n</code></pre> <code>False</code> <code>mode</code> <code>str</code> <p>Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".</p> <code>'train'</code> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>class ProgressBar:\n    \"\"\"\n    Keras style progress bar.\n\n    Adapted from https://github.com/yueyericardo/pkbar.\n\n    Parameters\n    ----------\n    max_value : Optional[int], optional\n        Maximum progress bar value, by default None.\n    epoch : Optional[int], optional\n        Zero-indexed current epoch, by default None.\n    num_epochs : Optional[int], optional\n        Total number of epochs, by default None.\n    stateful_metrics : Optional[List], optional\n        Iterable of string names of metrics that should *not* be averaged over time.\n        Metrics in this list will be displayed as-is. All others will be averaged by\n        the progress bar before display, by default None.\n    always_stateful : bool, optional\n            Whether to set all metrics to be stateful, by default False.\n    mode : str, optional\n        Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".\n    \"\"\"\n\n    def __init__(\n        self,\n        max_value: Optional[int] = None,\n        epoch: Optional[int] = None,\n        num_epochs: Optional[int] = None,\n        stateful_metrics: Optional[List] = None,\n        always_stateful: bool = False,\n        mode: str = \"train\",\n    ) -&gt; None:\n        \"\"\"\n        Constructor.\n\n        Parameters\n        ----------\n        max_value : Optional[int], optional\n            Maximum progress bar value, by default None.\n        epoch : Optional[int], optional\n            Zero-indexed current epoch, by default None.\n        num_epochs : Optional[int], optional\n            Total number of epochs, by default None.\n        stateful_metrics : Optional[List], optional\n            Iterable of string names of metrics that should *not* be averaged over time.\n            Metrics in this list will be displayed as-is. All others will be averaged by\n            the progress bar before display, by default None.\n        always_stateful : bool, optional\n             Whether to set all metrics to be stateful, by default False.\n        mode : str, optional\n            Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".\n        \"\"\"\n        self.max_value = max_value\n        # Width of the progress bar\n        self.width = 30\n        self.always_stateful = always_stateful\n\n        if (epoch is not None) and (num_epochs is not None):\n            print(f\"Epoch: {epoch + 1}/{num_epochs}\")\n\n        if stateful_metrics:\n            self.stateful_metrics = set(stateful_metrics)\n        else:\n            self.stateful_metrics = set()\n\n        self._dynamic_display = (\n            (hasattr(sys.stdout, \"isatty\") and sys.stdout.isatty())\n            or \"ipykernel\" in sys.modules\n            or \"posix\" in sys.modules\n        )\n        self._total_width = 0\n        self._seen_so_far = 0\n        # We use a dict + list to avoid garbage collection\n        # issues found in OrderedDict\n        self._values: Dict[Any, Any] = {}\n        self._values_order: List[Any] = []\n        self._start = time.time()\n        self._last_update = 0.0\n        self.spin = self.spinning_cursor() if self.max_value is None else None\n        if mode == \"train\" and self.max_value is None:\n            self.message = \"Estimating dataset size\"\n        elif mode == \"val\":\n            self.message = \"Validating\"\n        elif mode == \"predict\":\n            self.message = \"Denoising\"\n\n    def update(\n        self, current_step: int, batch_size: int = 1, values: Optional[List] = None\n    ) -&gt; None:\n        \"\"\"\n        Update the progress bar.\n\n        Parameters\n        ----------\n        current_step : int\n            Index of the current step.\n        batch_size : int, optional\n            Batch size, by default 1.\n        values : Optional[List], optional\n            Updated metrics values, by default None.\n        \"\"\"\n        values = values or []\n        for k, v in values:\n            # if torch tensor, convert it to numpy\n            if str(type(v)) == \"&lt;class 'torch.Tensor'&gt;\":\n                v = v.detach().cpu().numpy()\n\n            if k not in self._values_order:\n                self._values_order.append(k)\n            if k not in self.stateful_metrics and not self.always_stateful:\n                if k not in self._values:\n                    self._values[k] = [\n                        v * (current_step - self._seen_so_far),\n                        current_step - self._seen_so_far,\n                    ]\n                else:\n                    self._values[k][0] += v * (current_step - self._seen_so_far)\n                    self._values[k][1] += current_step - self._seen_so_far\n            else:\n                # Stateful metrics output a numeric value. This representation\n                # means \"take an average from a single value\" but keeps the\n                # numeric formatting.\n                self._values[k] = [v, 1]\n\n        self._seen_so_far = current_step\n\n        now = time.time()\n        info = f\" - {(now - self._start):.0f}s\"\n\n        prev_total_width = self._total_width\n        if self._dynamic_display:\n            sys.stdout.write(\"\\b\" * prev_total_width)\n            sys.stdout.write(\"\\r\")\n        else:\n            sys.stdout.write(\"\\n\")\n\n        if self.max_value is not None:\n            bar = f\"{current_step}/{self.max_value} [\"\n            progress = float(current_step) / self.max_value\n            progress_width = int(self.width * progress)\n            if progress_width &gt; 0:\n                bar += \"=\" * (progress_width - 1)\n                if current_step &lt; self.max_value:\n                    bar += \"&gt;\"\n                else:\n                    bar += \"=\"\n            bar += \".\" * (self.width - progress_width)\n            bar += \"]\"\n        else:\n            bar = (\n                f\"{self.message} {next(self.spin)}, tile \"  # type: ignore\n                f\"No. {current_step * batch_size}\"\n            )\n\n        self._total_width = len(bar)\n        sys.stdout.write(bar)\n\n        if current_step &gt; 0:\n            time_per_unit = (now - self._start) / current_step\n        else:\n            time_per_unit = 0\n\n        if time_per_unit &gt;= 1 or time_per_unit == 0:\n            info += f\" {time_per_unit:.0f}s/step\"\n        elif time_per_unit &gt;= 1e-3:\n            info += f\" {time_per_unit * 1e3:.0f}ms/step\"\n        else:\n            info += f\" {time_per_unit * 1e6:.0f}us/step\"\n\n        for k in self._values_order:\n            info += f\" - {k}:\"\n            if isinstance(self._values[k], list):\n                avg = self._values[k][0] / max(1, self._values[k][1])\n                if abs(avg) &gt; 1e-3:\n                    info += f\" {avg:.4f}\"\n                else:\n                    info += f\" {avg:.4e}\"\n            else:\n                info += f\" {self._values[k]}s\"\n\n        self._total_width += len(info)\n        if prev_total_width &gt; self._total_width:\n            info += \" \" * (prev_total_width - self._total_width)\n\n        if self.max_value is not None and current_step &gt;= self.max_value:\n            info += \"\\n\"\n\n        sys.stdout.write(info)\n        sys.stdout.flush()\n\n        self._last_update = now\n\n    def add(self, n: int, values: Optional[List] = None) -&gt; None:\n        \"\"\"\n        Update the progress bar by n steps.\n\n        Parameters\n        ----------\n        n : int\n            Number of steps to increase the progress bar with.\n        values : Optional[List], optional\n            Updated metrics values, by default None.\n        \"\"\"\n        self.update(self._seen_so_far + n, 1, values=values)\n\n    def spinning_cursor(self) -&gt; Generator:\n        \"\"\"\n        Generate a spinning cursor animation.\n\n        Taken from https://github.com/manrajgrover/py-spinners/tree/master.\n\n        Returns\n        -------\n        Generator\n            Generator of animation frames.\n        \"\"\"\n        while True:\n            yield from [\n                \"\u2593 ----- \u2592\",\n                \"\u2593 ----- \u2592\",\n                \"\u2593 ----- \u2592\",\n                \"\u2593 -&gt;--- \u2592\",\n                \"\u2593 -&gt;--- \u2592\",\n                \"\u2593 -&gt;--- \u2592\",\n                \"\u2593 --&gt;-- \u2592\",\n                \"\u2593 --&gt;-- \u2592\",\n                \"\u2593 --&gt;-- \u2592\",\n                \"\u2593 ---&gt;- \u2592\",\n                \"\u2593 ---&gt;- \u2592\",\n                \"\u2593 ---&gt;- \u2592\",\n                \"\u2593 ----&gt; \u2592\",\n                \"\u2593 ----&gt; \u2592\",\n                \"\u2593 ----&gt; \u2592\",\n                \"\u2592 ----- \u2591\",\n                \"\u2592 ----- \u2591\",\n                \"\u2592 ----- \u2591\",\n                \"\u2592 -&gt;--- \u2591\",\n                \"\u2592 -&gt;--- \u2591\",\n                \"\u2592 -&gt;--- \u2591\",\n                \"\u2592 --&gt;-- \u2591\",\n                \"\u2592 --&gt;-- \u2591\",\n                \"\u2592 --&gt;-- \u2591\",\n                \"\u2592 ---&gt;- \u2591\",\n                \"\u2592 ---&gt;- \u2591\",\n                \"\u2592 ---&gt;- \u2591\",\n                \"\u2592 ----&gt; \u2591\",\n                \"\u2592 ----&gt; \u2591\",\n                \"\u2592 ----&gt; \u2591\",\n            ]\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar.__init__","title":"<code>__init__(max_value=None, epoch=None, num_epochs=None, stateful_metrics=None, always_stateful=False, mode='train')</code>","text":"<p>Constructor.</p> <p>Parameters:</p> Name Type Description Default <code>max_value</code> <code>Optional[int]</code> <p>Maximum progress bar value, by default None.</p> <code>None</code> <code>epoch</code> <code>Optional[int]</code> <p>Zero-indexed current epoch, by default None.</p> <code>None</code> <code>num_epochs</code> <code>Optional[int]</code> <p>Total number of epochs, by default None.</p> <code>None</code> <code>stateful_metrics</code> <code>Optional[List]</code> <p>Iterable of string names of metrics that should not be averaged over time. Metrics in this list will be displayed as-is. All others will be averaged by the progress bar before display, by default None.</p> <code>None</code> <code>always_stateful</code> <code>bool</code> <p>Whether to set all metrics to be stateful, by default False.</p> <code>False</code> <code>mode</code> <code>str</code> <p>Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".</p> <code>'train'</code> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def __init__(\n    self,\n    max_value: Optional[int] = None,\n    epoch: Optional[int] = None,\n    num_epochs: Optional[int] = None,\n    stateful_metrics: Optional[List] = None,\n    always_stateful: bool = False,\n    mode: str = \"train\",\n) -&gt; None:\n    \"\"\"\n    Constructor.\n\n    Parameters\n    ----------\n    max_value : Optional[int], optional\n        Maximum progress bar value, by default None.\n    epoch : Optional[int], optional\n        Zero-indexed current epoch, by default None.\n    num_epochs : Optional[int], optional\n        Total number of epochs, by default None.\n    stateful_metrics : Optional[List], optional\n        Iterable of string names of metrics that should *not* be averaged over time.\n        Metrics in this list will be displayed as-is. All others will be averaged by\n        the progress bar before display, by default None.\n    always_stateful : bool, optional\n         Whether to set all metrics to be stateful, by default False.\n    mode : str, optional\n        Mode, one of \"train\", \"val\", or \"predict\", by default \"train\".\n    \"\"\"\n    self.max_value = max_value\n    # Width of the progress bar\n    self.width = 30\n    self.always_stateful = always_stateful\n\n    if (epoch is not None) and (num_epochs is not None):\n        print(f\"Epoch: {epoch + 1}/{num_epochs}\")\n\n    if stateful_metrics:\n        self.stateful_metrics = set(stateful_metrics)\n    else:\n        self.stateful_metrics = set()\n\n    self._dynamic_display = (\n        (hasattr(sys.stdout, \"isatty\") and sys.stdout.isatty())\n        or \"ipykernel\" in sys.modules\n        or \"posix\" in sys.modules\n    )\n    self._total_width = 0\n    self._seen_so_far = 0\n    # We use a dict + list to avoid garbage collection\n    # issues found in OrderedDict\n    self._values: Dict[Any, Any] = {}\n    self._values_order: List[Any] = []\n    self._start = time.time()\n    self._last_update = 0.0\n    self.spin = self.spinning_cursor() if self.max_value is None else None\n    if mode == \"train\" and self.max_value is None:\n        self.message = \"Estimating dataset size\"\n    elif mode == \"val\":\n        self.message = \"Validating\"\n    elif mode == \"predict\":\n        self.message = \"Denoising\"\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar.add","title":"<code>add(n, values=None)</code>","text":"<p>Update the progress bar by n steps.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of steps to increase the progress bar with.</p> required <code>values</code> <code>Optional[List]</code> <p>Updated metrics values, by default None.</p> <code>None</code> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def add(self, n: int, values: Optional[List] = None) -&gt; None:\n    \"\"\"\n    Update the progress bar by n steps.\n\n    Parameters\n    ----------\n    n : int\n        Number of steps to increase the progress bar with.\n    values : Optional[List], optional\n        Updated metrics values, by default None.\n    \"\"\"\n    self.update(self._seen_so_far + n, 1, values=values)\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar.spinning_cursor","title":"<code>spinning_cursor()</code>","text":"<p>Generate a spinning cursor animation.</p> <p>Taken from https://github.com/manrajgrover/py-spinners/tree/master.</p> <p>Returns:</p> Type Description <code>Generator</code> <p>Generator of animation frames.</p> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def spinning_cursor(self) -&gt; Generator:\n    \"\"\"\n    Generate a spinning cursor animation.\n\n    Taken from https://github.com/manrajgrover/py-spinners/tree/master.\n\n    Returns\n    -------\n    Generator\n        Generator of animation frames.\n    \"\"\"\n    while True:\n        yield from [\n            \"\u2593 ----- \u2592\",\n            \"\u2593 ----- \u2592\",\n            \"\u2593 ----- \u2592\",\n            \"\u2593 -&gt;--- \u2592\",\n            \"\u2593 -&gt;--- \u2592\",\n            \"\u2593 -&gt;--- \u2592\",\n            \"\u2593 --&gt;-- \u2592\",\n            \"\u2593 --&gt;-- \u2592\",\n            \"\u2593 --&gt;-- \u2592\",\n            \"\u2593 ---&gt;- \u2592\",\n            \"\u2593 ---&gt;- \u2592\",\n            \"\u2593 ---&gt;- \u2592\",\n            \"\u2593 ----&gt; \u2592\",\n            \"\u2593 ----&gt; \u2592\",\n            \"\u2593 ----&gt; \u2592\",\n            \"\u2592 ----- \u2591\",\n            \"\u2592 ----- \u2591\",\n            \"\u2592 ----- \u2591\",\n            \"\u2592 -&gt;--- \u2591\",\n            \"\u2592 -&gt;--- \u2591\",\n            \"\u2592 -&gt;--- \u2591\",\n            \"\u2592 --&gt;-- \u2591\",\n            \"\u2592 --&gt;-- \u2591\",\n            \"\u2592 --&gt;-- \u2591\",\n            \"\u2592 ---&gt;- \u2591\",\n            \"\u2592 ---&gt;- \u2591\",\n            \"\u2592 ---&gt;- \u2591\",\n            \"\u2592 ----&gt; \u2591\",\n            \"\u2592 ----&gt; \u2591\",\n            \"\u2592 ----&gt; \u2591\",\n        ]\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.ProgressBar.update","title":"<code>update(current_step, batch_size=1, values=None)</code>","text":"<p>Update the progress bar.</p> <p>Parameters:</p> Name Type Description Default <code>current_step</code> <code>int</code> <p>Index of the current step.</p> required <code>batch_size</code> <code>int</code> <p>Batch size, by default 1.</p> <code>1</code> <code>values</code> <code>Optional[List]</code> <p>Updated metrics values, by default None.</p> <code>None</code> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def update(\n    self, current_step: int, batch_size: int = 1, values: Optional[List] = None\n) -&gt; None:\n    \"\"\"\n    Update the progress bar.\n\n    Parameters\n    ----------\n    current_step : int\n        Index of the current step.\n    batch_size : int, optional\n        Batch size, by default 1.\n    values : Optional[List], optional\n        Updated metrics values, by default None.\n    \"\"\"\n    values = values or []\n    for k, v in values:\n        # if torch tensor, convert it to numpy\n        if str(type(v)) == \"&lt;class 'torch.Tensor'&gt;\":\n            v = v.detach().cpu().numpy()\n\n        if k not in self._values_order:\n            self._values_order.append(k)\n        if k not in self.stateful_metrics and not self.always_stateful:\n            if k not in self._values:\n                self._values[k] = [\n                    v * (current_step - self._seen_so_far),\n                    current_step - self._seen_so_far,\n                ]\n            else:\n                self._values[k][0] += v * (current_step - self._seen_so_far)\n                self._values[k][1] += current_step - self._seen_so_far\n        else:\n            # Stateful metrics output a numeric value. This representation\n            # means \"take an average from a single value\" but keeps the\n            # numeric formatting.\n            self._values[k] = [v, 1]\n\n    self._seen_so_far = current_step\n\n    now = time.time()\n    info = f\" - {(now - self._start):.0f}s\"\n\n    prev_total_width = self._total_width\n    if self._dynamic_display:\n        sys.stdout.write(\"\\b\" * prev_total_width)\n        sys.stdout.write(\"\\r\")\n    else:\n        sys.stdout.write(\"\\n\")\n\n    if self.max_value is not None:\n        bar = f\"{current_step}/{self.max_value} [\"\n        progress = float(current_step) / self.max_value\n        progress_width = int(self.width * progress)\n        if progress_width &gt; 0:\n            bar += \"=\" * (progress_width - 1)\n            if current_step &lt; self.max_value:\n                bar += \"&gt;\"\n            else:\n                bar += \"=\"\n        bar += \".\" * (self.width - progress_width)\n        bar += \"]\"\n    else:\n        bar = (\n            f\"{self.message} {next(self.spin)}, tile \"  # type: ignore\n            f\"No. {current_step * batch_size}\"\n        )\n\n    self._total_width = len(bar)\n    sys.stdout.write(bar)\n\n    if current_step &gt; 0:\n        time_per_unit = (now - self._start) / current_step\n    else:\n        time_per_unit = 0\n\n    if time_per_unit &gt;= 1 or time_per_unit == 0:\n        info += f\" {time_per_unit:.0f}s/step\"\n    elif time_per_unit &gt;= 1e-3:\n        info += f\" {time_per_unit * 1e3:.0f}ms/step\"\n    else:\n        info += f\" {time_per_unit * 1e6:.0f}us/step\"\n\n    for k in self._values_order:\n        info += f\" - {k}:\"\n        if isinstance(self._values[k], list):\n            avg = self._values[k][0] / max(1, self._values[k][1])\n            if abs(avg) &gt; 1e-3:\n                info += f\" {avg:.4f}\"\n            else:\n                info += f\" {avg:.4e}\"\n        else:\n            info += f\" {self._values[k]}s\"\n\n    self._total_width += len(info)\n    if prev_total_width &gt; self._total_width:\n        info += \" \" * (prev_total_width - self._total_width)\n\n    if self.max_value is not None and current_step &gt;= self.max_value:\n        info += \"\\n\"\n\n    sys.stdout.write(info)\n    sys.stdout.flush()\n\n    self._last_update = now\n</code></pre>"},{"location":"reference/careamics/utils/logging/#careamics.utils.logging.get_logger","title":"<code>get_logger(name, log_level=logging.INFO, log_path=None)</code>","text":"<p>Create a python logger instance with configured handlers.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the logger.</p> required <code>log_level</code> <code>int</code> <p>Log level (info, error etc.), by default logging.INFO.</p> <code>INFO</code> <code>log_path</code> <code>Optional[Union[str, Path]]</code> <p>Path in which to save the log, by default None.</p> <code>None</code> <p>Returns:</p> Type Description <code>Logger</code> <p>Logger.</p> Source code in <code>src/careamics/utils/logging.py</code> <pre><code>def get_logger(\n    name: str,\n    log_level: int = logging.INFO,\n    log_path: Optional[Union[str, Path]] = None,\n) -&gt; logging.Logger:\n    \"\"\"\n    Create a python logger instance with configured handlers.\n\n    Parameters\n    ----------\n    name : str\n        Name of the logger.\n    log_level : int, optional\n        Log level (info, error etc.), by default logging.INFO.\n    log_path : Optional[Union[str, Path]], optional\n        Path in which to save the log, by default None.\n\n    Returns\n    -------\n    logging.Logger\n        Logger.\n    \"\"\"\n    logger = logging.getLogger(name)\n    logger.propagate = False\n\n    if name in LOGGERS:\n        return logger\n\n    for logger_name in LOGGERS:\n        if name.startswith(logger_name):\n            return logger\n\n    logger.propagate = False\n\n    if log_path:\n        handlers = [\n            logging.StreamHandler(),\n            logging.FileHandler(log_path),\n        ]\n    else:\n        handlers = [logging.StreamHandler()]\n\n    formatter = logging.Formatter(\"%(message)s\")\n\n    for handler in handlers:\n        handler.setFormatter(formatter)  # type: ignore\n        handler.setLevel(log_level)  # type: ignore\n        logger.addHandler(handler)  # type: ignore\n\n    logger.setLevel(log_level)\n    LOGGERS[name] = True\n\n    logger.propagate = False\n\n    return logger\n</code></pre>"},{"location":"reference/careamics/utils/metrics/","title":"metrics","text":"<p>Metrics submodule.</p> <p>This module contains various metrics and a metrics tracking class.</p>"},{"location":"reference/careamics/utils/metrics/#careamics.utils.metrics.psnr","title":"<code>psnr(gt, pred, range=255.0)</code>","text":"<p>Peak Signal to Noise Ratio.</p> <p>This method calls skimage.metrics.peak_signal_noise_ratio. See: https://scikit-image.org/docs/dev/api/skimage.metrics.html.</p> <p>Parameters:</p> Name Type Description Default <code>gt</code> <code>NumPy array</code> <p>Ground truth image.</p> required <code>pred</code> <code>NumPy array</code> <p>Predicted image.</p> required <code>range</code> <code>float</code> <p>The images pixel range, by default 255.0.</p> <code>255.0</code> <p>Returns:</p> Type Description <code>float</code> <p>PSNR value.</p> Source code in <code>src/careamics/utils/metrics.py</code> <pre><code>def psnr(gt: np.ndarray, pred: np.ndarray, range: float = 255.0) -&gt; float:\n    \"\"\"\n    Peak Signal to Noise Ratio.\n\n    This method calls skimage.metrics.peak_signal_noise_ratio. See:\n    https://scikit-image.org/docs/dev/api/skimage.metrics.html.\n\n    Parameters\n    ----------\n    gt : NumPy array\n        Ground truth image.\n    pred : NumPy array\n        Predicted image.\n    range : float, optional\n        The images pixel range, by default 255.0.\n\n    Returns\n    -------\n    float\n        PSNR value.\n    \"\"\"\n    return peak_signal_noise_ratio(gt, pred, data_range=range)\n</code></pre>"},{"location":"reference/careamics/utils/metrics/#careamics.utils.metrics.scale_invariant_psnr","title":"<code>scale_invariant_psnr(gt, pred)</code>","text":"<p>Scale invariant PSNR.</p> <p>Parameters:</p> Name Type Description Default <code>gt</code> <code>ndarray</code> <p>Ground truth image.</p> required <code>pred</code> <code>ndarray</code> <p>Predicted image.</p> required <p>Returns:</p> Type Description <code>Union[float, tensor]</code> <p>Scale invariant PSNR value.</p> Source code in <code>src/careamics/utils/metrics.py</code> <pre><code>def scale_invariant_psnr(\n    gt: np.ndarray, pred: np.ndarray\n) -&gt; Union[float, torch.tensor]:\n    \"\"\"\n    Scale invariant PSNR.\n\n    Parameters\n    ----------\n    gt : np.ndarray\n        Ground truth image.\n    pred : np.ndarray\n        Predicted image.\n\n    Returns\n    -------\n    Union[float, torch.tensor]\n        Scale invariant PSNR value.\n    \"\"\"\n    range_parameter = (np.max(gt) - np.min(gt)) / np.std(gt)\n    gt_ = _zero_mean(gt) / np.std(gt)\n    return psnr(_zero_mean(gt_), _fix(gt_, pred), range_parameter)\n</code></pre>"},{"location":"reference/careamics/utils/path_utils/","title":"path_utils","text":"<p>Utility functions for paths.</p>"},{"location":"reference/careamics/utils/path_utils/#careamics.utils.path_utils.check_path_exists","title":"<code>check_path_exists(path)</code>","text":"<p>Check if a path exists. If not, raise an error.</p> <p>Note that it returns <code>path</code> as a Path object.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to check.</p> required <p>Returns:</p> Type Description <code>Path</code> <p>Path as a Path object.</p> Source code in <code>src/careamics/utils/path_utils.py</code> <pre><code>def check_path_exists(path: Union[str, Path]) -&gt; Path:\n    \"\"\"Check if a path exists. If not, raise an error.\n\n    Note that it returns `path` as a Path object.\n\n    Parameters\n    ----------\n    path : Union[str, Path]\n        Path to check.\n\n    Returns\n    -------\n    Path\n        Path as a Path object.\n    \"\"\"\n    path = Path(path)\n    if not path.exists():\n        raise FileNotFoundError(f\"Data path {path} is incorrect or does not exist.\")\n\n    return path\n</code></pre>"},{"location":"reference/careamics/utils/ram/","title":"ram","text":"<p>Utility function to get RAM size.</p>"},{"location":"reference/careamics/utils/ram/#careamics.utils.ram.get_ram_size","title":"<code>get_ram_size()</code>","text":"<p>Get RAM size in bytes.</p> <p>Returns:</p> Type Description <code>int</code> <p>RAM size in mbytes.</p> Source code in <code>src/careamics/utils/ram.py</code> <pre><code>def get_ram_size() -&gt; int:\n    \"\"\"\n    Get RAM size in bytes.\n\n    Returns\n    -------\n    int\n        RAM size in mbytes.\n    \"\"\"\n    return psutil.virtual_memory().total / 1024**2\n</code></pre>"},{"location":"reference/careamics/utils/receptive_field/","title":"receptive_field","text":"<p>Receptive field calculation for computing the tile overlap.</p>"},{"location":"reference/careamics/utils/running_stats/","title":"running_stats","text":"<p>Running stats submodule, used in the Zarr dataset.</p>"},{"location":"reference/careamics/utils/torch_utils/","title":"torch_utils","text":"<p>Convenience functions using torch.</p> <p>These functions are used to control certain aspects and behaviours of PyTorch.</p>"},{"location":"reference/careamics/utils/torch_utils/#careamics.utils.torch_utils.filter_parameters","title":"<code>filter_parameters(func, user_params)</code>","text":"<p>Filter parameters according to the function signature.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>type</code> <p>Class object.</p> required <code>user_params</code> <code>Dict</code> <p>User provided parameters.</p> required <p>Returns:</p> Type Description <code>Dict</code> <p>Parameters matching <code>func</code>'s signature.</p> Source code in <code>src/careamics/utils/torch_utils.py</code> <pre><code>def filter_parameters(\n    func: type,\n    user_params: dict,\n) -&gt; dict:\n    \"\"\"\n    Filter parameters according to the function signature.\n\n    Parameters\n    ----------\n    func : type\n        Class object.\n    user_params : Dict\n        User provided parameters.\n\n    Returns\n    -------\n    Dict\n        Parameters matching `func`'s signature.\n    \"\"\"\n    # Get the list of all default parameters\n    default_params = list(inspect.signature(func).parameters.keys())\n\n    # Filter matching parameters\n    params_to_be_used = set(user_params.keys()) &amp; set(default_params)\n\n    return {key: user_params[key] for key in params_to_be_used}\n</code></pre>"},{"location":"reference/careamics/utils/torch_utils/#careamics.utils.torch_utils.get_optimizer","title":"<code>get_optimizer(name)</code>","text":"<p>Return the optimizer class given its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Optimizer name.</p> required <p>Returns:</p> Type Description <code>Optimizer</code> <p>Optimizer class.</p> Source code in <code>src/careamics/utils/torch_utils.py</code> <pre><code>def get_optimizer(name: str) -&gt; torch.optim.Optimizer:\n    \"\"\"\n    Return the optimizer class given its name.\n\n    Parameters\n    ----------\n    name : str\n        Optimizer name.\n\n    Returns\n    -------\n    torch.nn.Optimizer\n        Optimizer class.\n    \"\"\"\n    if name not in SupportedOptimizer:\n        raise NotImplementedError(f\"Optimizer {name} is not yet supported.\")\n\n    return getattr(torch.optim, name)\n</code></pre>"},{"location":"reference/careamics/utils/torch_utils/#careamics.utils.torch_utils.get_optimizers","title":"<code>get_optimizers()</code>","text":"<p>Return the list of all optimizers available in torch.optim.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>Optimizers available in torch.optim.</p> Source code in <code>src/careamics/utils/torch_utils.py</code> <pre><code>def get_optimizers() -&gt; Dict[str, str]:\n    \"\"\"\n    Return the list of all optimizers available in torch.optim.\n\n    Returns\n    -------\n    Dict\n        Optimizers available in torch.optim.\n    \"\"\"\n    optims = {}\n    for name, obj in inspect.getmembers(torch.optim):\n        if inspect.isclass(obj) and issubclass(obj, torch.optim.Optimizer):\n            if name != \"Optimizer\":\n                optims[name] = name\n    return optims\n</code></pre>"},{"location":"reference/careamics/utils/torch_utils/#careamics.utils.torch_utils.get_scheduler","title":"<code>get_scheduler(name)</code>","text":"<p>Return the scheduler class given its name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Scheduler name.</p> required <p>Returns:</p> Type Description <code>Union</code> <p>Scheduler class.</p> Source code in <code>src/careamics/utils/torch_utils.py</code> <pre><code>def get_scheduler(\n    name: str,\n) -&gt; Union[\n    torch.optim.lr_scheduler.LRScheduler,\n    torch.optim.lr_scheduler.ReduceLROnPlateau,\n]:\n    \"\"\"\n    Return the scheduler class given its name.\n\n    Parameters\n    ----------\n    name : str\n        Scheduler name.\n\n    Returns\n    -------\n    Union\n        Scheduler class.\n    \"\"\"\n    if name not in SupportedScheduler:\n        raise NotImplementedError(f\"Scheduler {name} is not yet supported.\")\n\n    return getattr(torch.optim.lr_scheduler, name)\n</code></pre>"},{"location":"reference/careamics/utils/torch_utils/#careamics.utils.torch_utils.get_schedulers","title":"<code>get_schedulers()</code>","text":"<p>Return the list of all schedulers available in torch.optim.lr_scheduler.</p> <p>Returns:</p> Type Description <code>Dict</code> <p>Schedulers available in torch.optim.lr_scheduler.</p> Source code in <code>src/careamics/utils/torch_utils.py</code> <pre><code>def get_schedulers() -&gt; Dict[str, str]:\n    \"\"\"\n    Return the list of all schedulers available in torch.optim.lr_scheduler.\n\n    Returns\n    -------\n    Dict\n        Schedulers available in torch.optim.lr_scheduler.\n    \"\"\"\n    schedulers = {}\n    for name, obj in inspect.getmembers(torch.optim.lr_scheduler):\n        if inspect.isclass(obj) and issubclass(\n            obj, torch.optim.lr_scheduler.LRScheduler\n        ):\n            if \"LRScheduler\" not in name:\n                schedulers[name] = name\n        elif name == \"ReduceLROnPlateau\":  # somewhat not a subclass of LRScheduler\n            schedulers[name] = name\n    return schedulers\n</code></pre>"},{"location":"reference/careamics_portfolio/","title":"CAREamics portfolio","text":"<p>Use the navigation index on the left to explore the documentation.</p>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/","title":"denoiseg_datasets","text":""},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.DSB2018","title":"<code>DSB2018</code>","text":"<p>               Bases: <code>PortfolioEntry</code>, <code>NoisyObject</code></p> <p>The 2018 Data Science Bowl dataset used by DenoiSeg.</p> <p>The dataset is available in three different noise levels: N0, N10 and N20.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>noise_level (NoiseLevel): Noise level of the dataset. name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class DSB2018(PortfolioEntry, NoisyObject):\n    \"\"\"The 2018 Data Science Bowl dataset used by DenoiSeg.\n\n    The dataset is available in three different noise levels: N0, N10 and N20.\n\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        noise_level (NoiseLevel): Noise level of the dataset.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n        \"\"\"Initialize a DSB2018 instance.\n\n        Parameters\n        ----------\n        noise_level : NoiseLevel, optional\n            Noise level of the dataset, by default NoiseLevel.N0\n        \"\"\"\n        super().__init__(\n            portfolio=DENOISEG,\n            noise_level=noise_level,\n            name=f\"DSB2018_n{noise_level.value}\",\n            url=self._get_url(noise_level),\n            file_name=f\"DSB2018_n{noise_level.value}.zip\",\n            sha256=self._get_hash(noise_level),\n            description=\"From the Kaggle 2018 Data Science Bowl challenge, the \"\n            \"training and validation sets consist of 3800 and 670 patches \"\n            \"respectively, while the test set counts 50 images.\\n\"\n            \"Original data: \"\n            \"https://www.kaggle.com/competitions/data-science-bowl-2018/data\",\n            license=\"GPL-3.0\",\n            citation=\"Caicedo, J.C., Goodman, A., Karhohs, K.W. et al. Nucleus \"\n            \"segmentation across imaging experiments: the 2018 Data Science \"\n            \"Bowl. Nat Methods 16, 1247-1253 (2019). \"\n            \"https://doi.org/10.1038/s41592-019-0612-7\",\n            size=self._get_size(noise_level),\n            tags=[\"denoising\", \"segmentation\", \"nuclei\", \"fluorescence\"],\n        )\n\n    @staticmethod\n    def _get_url(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"https://zenodo.org/record/5156969/files/DSB2018_n0.zip?download=1\"\n        elif noise == NoiseLevel.N10:\n            return \"https://zenodo.org/record/5156977/files/DSB2018_n10.zip?download=1\"\n        else:\n            return \"https://zenodo.org/record/5156983/files/DSB2018_n20.zip?download=1\"\n\n    @staticmethod\n    def _get_hash(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"729d7683ccfa1ad437f666256b23e73b3b3b3da6a8e47bb37303f0c64376a299\"\n        elif noise == NoiseLevel.N10:\n            return \"a4cf731aa0652f8198275f8ce29fb98e0c76c391a96b6092d0792fe447e4103a\"\n        else:\n            return \"6a732a12bf18fecc590230b1cd4df5e32acfa1b35ef2fca42db811cb8277c67c\"\n\n    @staticmethod\n    def _get_size(noise: NoiseLevel) -&gt; float:\n        if noise == NoiseLevel.N0:\n            return 40.2\n        elif noise == NoiseLevel.N10:\n            return 366.0\n        else:\n            return 368.0\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.DSB2018.__init__","title":"<code>__init__(noise_level=NoiseLevel.N0)</code>","text":"<p>Initialize a DSB2018 instance.</p> <p>Parameters:</p> Name Type Description Default <code>noise_level</code> <code>NoiseLevel</code> <p>Noise level of the dataset, by default NoiseLevel.N0</p> <code>N0</code> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n    \"\"\"Initialize a DSB2018 instance.\n\n    Parameters\n    ----------\n    noise_level : NoiseLevel, optional\n        Noise level of the dataset, by default NoiseLevel.N0\n    \"\"\"\n    super().__init__(\n        portfolio=DENOISEG,\n        noise_level=noise_level,\n        name=f\"DSB2018_n{noise_level.value}\",\n        url=self._get_url(noise_level),\n        file_name=f\"DSB2018_n{noise_level.value}.zip\",\n        sha256=self._get_hash(noise_level),\n        description=\"From the Kaggle 2018 Data Science Bowl challenge, the \"\n        \"training and validation sets consist of 3800 and 670 patches \"\n        \"respectively, while the test set counts 50 images.\\n\"\n        \"Original data: \"\n        \"https://www.kaggle.com/competitions/data-science-bowl-2018/data\",\n        license=\"GPL-3.0\",\n        citation=\"Caicedo, J.C., Goodman, A., Karhohs, K.W. et al. Nucleus \"\n        \"segmentation across imaging experiments: the 2018 Data Science \"\n        \"Bowl. Nat Methods 16, 1247-1253 (2019). \"\n        \"https://doi.org/10.1038/s41592-019-0612-7\",\n        size=self._get_size(noise_level),\n        tags=[\"denoising\", \"segmentation\", \"nuclei\", \"fluorescence\"],\n    )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.MouseNuclei","title":"<code>MouseNuclei</code>","text":"<p>               Bases: <code>PortfolioEntry</code>, <code>NoisyObject</code></p> <p>Mouse nuclei dataset used by DenoiSeg.</p> <p>The dataset is available in three different noise levels: N0, N10 and N20.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>noise_level (NoiseLevel): Noise level of the dataset. name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class MouseNuclei(PortfolioEntry, NoisyObject):\n    \"\"\"Mouse nuclei dataset used by DenoiSeg.\n\n    The dataset is available in three different noise levels: N0, N10 and N20.\n\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        noise_level (NoiseLevel): Noise level of the dataset.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n        \"\"\"Initialize a MouseNuclei instance.\n\n        Parameters\n        ----------\n        noise_level : NoiseLevel, optional\n            Noise level of the dataset, by default NoiseLevel.N0\n        \"\"\"\n        super().__init__(\n            portfolio=DENOISEG,\n            noise_level=noise_level,\n            name=f\"MouseNuclei_n{noise_level.value}\",\n            url=self._get_url(noise_level),\n            file_name=f\"MouseNuclei_n{noise_level.value}.zip\",\n            sha256=self._get_hash(noise_level),\n            description=\"A dataset depicting diverse and non-uniformly \"\n            \"clustered nuclei in the mouse skull, consisting of 908 training \"\n            \"and 160 validation patches. The test set counts 67 additional images\",\n            license=\"CC BY-SA 4.0\",\n            citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n            \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n            \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n            size=self._get_size(noise_level),\n            tags=[\"denoising\", \"segmentation\", \"nuclei\", \"fluorescence\"],\n        )\n\n    @staticmethod\n    def _get_url(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"https://zenodo.org/record/5157001/files/Mouse_n0.zip?download=1\"\n        elif noise == NoiseLevel.N10:\n            return \"https://zenodo.org/record/5157003/files/Mouse_n10.zip?download=1\"\n        else:\n            return \"https://zenodo.org/record/5157008/files/Mouse_n20.zip?download=1\"\n\n    @staticmethod\n    def _get_hash(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"5d6fd2fc23ab991a8fde4bd0ec5e9fc9299f9a9ddc2a8acb7095f9b02ff3c9d7\"\n        elif noise == NoiseLevel.N10:\n            return \"de634496e3e46a4887907b713fe6f575e410c3006046054bce67ef9398523c2c\"\n        else:\n            return \"d3d1bf8c89bb97a673a0791874e5b75a6a516ccaaeece0244b4e1e0afe7ab3ec\"\n\n    @staticmethod\n    def _get_size(noise: NoiseLevel) -&gt; float:\n        if noise == NoiseLevel.N0:\n            return 12.4\n        elif noise == NoiseLevel.N10:\n            return 161.0\n        else:\n            return 160.0\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.MouseNuclei.__init__","title":"<code>__init__(noise_level=NoiseLevel.N0)</code>","text":"<p>Initialize a MouseNuclei instance.</p> <p>Parameters:</p> Name Type Description Default <code>noise_level</code> <code>NoiseLevel</code> <p>Noise level of the dataset, by default NoiseLevel.N0</p> <code>N0</code> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n    \"\"\"Initialize a MouseNuclei instance.\n\n    Parameters\n    ----------\n    noise_level : NoiseLevel, optional\n        Noise level of the dataset, by default NoiseLevel.N0\n    \"\"\"\n    super().__init__(\n        portfolio=DENOISEG,\n        noise_level=noise_level,\n        name=f\"MouseNuclei_n{noise_level.value}\",\n        url=self._get_url(noise_level),\n        file_name=f\"MouseNuclei_n{noise_level.value}.zip\",\n        sha256=self._get_hash(noise_level),\n        description=\"A dataset depicting diverse and non-uniformly \"\n        \"clustered nuclei in the mouse skull, consisting of 908 training \"\n        \"and 160 validation patches. The test set counts 67 additional images\",\n        license=\"CC BY-SA 4.0\",\n        citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n        \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n        \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n        size=self._get_size(noise_level),\n        tags=[\"denoising\", \"segmentation\", \"nuclei\", \"fluorescence\"],\n    )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.NoiseLevel","title":"<code>NoiseLevel</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>An IntEnum representing the noise level of a dataset.</p> <p>N0 corresponds to the noise-free version of the dataset, N10 and N20 to images corrupted with Gaussian noise with zero-mean and standard deviations of 10 and 20, respectively.</p> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class NoiseLevel(str, Enum):\n    \"\"\"An IntEnum representing the noise level of a dataset.\n\n    N0 corresponds to the noise-free version of the dataset, N10 and N20 to\n    images corrupted with Gaussian noise with zero-mean and standard deviations\n    of 10 and 20, respectively.\n    \"\"\"\n\n    N0 = \"0\"\n    N10 = \"10\"\n    N20 = \"20\"\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.NoisyObject","title":"<code>NoisyObject</code>","text":"<p>A mixin class for datasets with different noise levels.</p> <p>Attributes:</p> Name Type Description <code>noise_level (NoiseLevel)</code> <code>Noise level of the dataset.</code> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class NoisyObject:\n    \"\"\"A mixin class for datasets with different noise levels.\n\n    Attributes\n    ----------\n    noise_level (NoiseLevel): Noise level of the dataset.\n    \"\"\"\n\n    def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0, **kwargs: str) -&gt; None:\n        self._noise_level = noise_level\n\n    @property\n    def noise_level(self) -&gt; NoiseLevel:\n        \"\"\"Noise level of the dataset.\"\"\"\n        return self._noise_level\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.NoisyObject.noise_level","title":"<code>noise_level: NoiseLevel</code>  <code>property</code>","text":"<p>Noise level of the dataset.</p>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.SegFlywing","title":"<code>SegFlywing</code>","text":"<p>               Bases: <code>PortfolioEntry</code>, <code>NoisyObject</code></p> <p>Flywing dataset used by DenoiSeg.</p> <p>The dataset is available in three different noise levels: N0, N10 and N20.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>noise_level (NoiseLevel): Noise level of the dataset. name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>class SegFlywing(PortfolioEntry, NoisyObject):\n    \"\"\"Flywing dataset used by DenoiSeg.\n\n    The dataset is available in three different noise levels: N0, N10 and N20.\n\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        noise_level (NoiseLevel): Noise level of the dataset.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n        \"\"\"Initialize a Flywing instance.\n\n        Parameters\n        ----------\n        noise_level : NoiseLevel, optional\n            Noise level of the dataset, by default NoiseLevel.N0\n        \"\"\"\n        super().__init__(\n            portfolio=DENOISEG,\n            noise_level=noise_level,\n            name=f\"Flywing_n{noise_level.value}\",\n            url=self._get_url(noise_level),\n            file_name=f\"Flywing_n{noise_level.value}.zip\",\n            sha256=self._get_hash(noise_level),\n            description=\"This dataset consist of 1428 training and 252 \"\n            \"validation patches of a membrane labeled fly wing. The test set \"\n            \"is comprised of 50 additional images.\",\n            license=\"CC BY-SA 4.0\",\n            citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n            \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n            \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n            size=self._get_size(noise_level),\n            tags=[\"denoising\", \"segmentation\", \"membrane\", \"fluorescence\"],\n        )\n\n    @staticmethod\n    def _get_url(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"https://zenodo.org/record/5156991/files/Flywing_n0.zip?download=1\"\n        elif noise == NoiseLevel.N10:\n            return \"https://zenodo.org/record/5156993/files/Flywing_n10.zip?download=1\"\n        else:\n            return \"https://zenodo.org/record/5156995/files/Flywing_n20.zip?download=1\"\n\n    @staticmethod\n    def _get_hash(noise: NoiseLevel) -&gt; str:\n        if noise == NoiseLevel.N0:\n            return \"3fb49ba44e7e3e20b4fc3c77754f1bbff7184af7f343f23653f258d50e5d5aca\"\n        elif noise == NoiseLevel.N10:\n            return \"c599981b0900e6b43f0a742f84a5fde664373600dc5334f537b61a76a7be2a3c\"\n        else:\n            return \"604b3a3a081eaa57ee25d708bc9b76b85d05235ba09d7c2b25b171e201ea966f\"\n\n    @staticmethod\n    def _get_size(noise: NoiseLevel) -&gt; float:\n        if noise == NoiseLevel.N0:\n            return 47.0\n        elif noise == NoiseLevel.N10:\n            return 282.0\n        else:\n            return 293.0\n</code></pre>"},{"location":"reference/careamics_portfolio/denoiseg_datasets/#careamics_portfolio.denoiseg_datasets.SegFlywing.__init__","title":"<code>__init__(noise_level=NoiseLevel.N0)</code>","text":"<p>Initialize a Flywing instance.</p> <p>Parameters:</p> Name Type Description Default <code>noise_level</code> <code>NoiseLevel</code> <p>Noise level of the dataset, by default NoiseLevel.N0</p> <code>N0</code> Source code in <code>src/careamics_portfolio/denoiseg_datasets.py</code> <pre><code>def __init__(self, noise_level: NoiseLevel = NoiseLevel.N0) -&gt; None:\n    \"\"\"Initialize a Flywing instance.\n\n    Parameters\n    ----------\n    noise_level : NoiseLevel, optional\n        Noise level of the dataset, by default NoiseLevel.N0\n    \"\"\"\n    super().__init__(\n        portfolio=DENOISEG,\n        noise_level=noise_level,\n        name=f\"Flywing_n{noise_level.value}\",\n        url=self._get_url(noise_level),\n        file_name=f\"Flywing_n{noise_level.value}.zip\",\n        sha256=self._get_hash(noise_level),\n        description=\"This dataset consist of 1428 training and 252 \"\n        \"validation patches of a membrane labeled fly wing. The test set \"\n        \"is comprised of 50 additional images.\",\n        license=\"CC BY-SA 4.0\",\n        citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n        \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n        \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n        size=self._get_size(noise_level),\n        tags=[\"denoising\", \"segmentation\", \"membrane\", \"fluorescence\"],\n    )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/","title":"denoising_datasets","text":""},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.CARE_U2OS","title":"<code>CARE_U2OS</code>","text":"<p>               Bases: <code>PortfolioEntry</code></p> <p>U2OS cells with artificial noise dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class CARE_U2OS(PortfolioEntry):\n    \"\"\"U2OS cells with artificial noise dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"CARE_U2OS\",\n            url=\"https://dl-at-mbl-2023-data.s3.us-east-2.amazonaws.com/\"\n            \"image_restoration_data.zip\",\n            file_name=\"image_restoration_data.zip\",\n            sha256=\"4112d3666a4f419bbd51ab0b7853c12e16c904f89481cbe7f1a90e48f3241f72\",\n            description=\"CARE dataset used during the MBL course. Original data from\"\n            \"the image set BBBC006v1 of the Broad Bioimage Benchmark Collection \"\n            \"(Ljosa et al., Nature Methods, 2012). The iamges were corrupted with \"\n            \"artificial noise.\",\n            license=\"CC0-1.0\",\n            citation=\"We used the image set BBBC006v1 from the Broad Bioimage \"\n            \"Benchmark Collection [Ljosa et al., Nature Methods, 2012].\",\n            size=760.5,\n            tags=[\"denoising\", \"nuclei\", \"fluorescence\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.Convallaria","title":"<code>Convallaria</code>","text":"<p>               Bases: <code>PortfolioEntry</code></p> <p>Convallaria dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class Convallaria(PortfolioEntry):\n    \"\"\"Convallaria dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"Convallaria\",\n            url=\"https://cloud.mpi-cbg.de/index.php/s/BE8raMtHQlgLDF3/download\",\n            file_name=\"Convallaria_diaphragm.zip\",\n            sha256=\"8a2ac3e2792334c833ee8a3ca449fc14eada18145f9d56fa2cb40f462c2e8909\",\n            description=\"Image of a convallaria flower (35x692x520 pixels).\\n\"\n            \"The image also comes with a defocused image in order to allow \\n\"\n            \"estimating the noise distribution.\",\n            license=\"CC-BY-4.0\",\n            citation=\"Krull, A., Vi\u010dar, T., Prakash, M., Lalit, M., &amp; Jug, F. (2020). \"\n            \"Probabilistic noise2void: Unsupervised content-aware denoising. Frontiers\"\n            \" in Computer Science, 2, 5.\",\n            size=344.0,\n            tags=[\"denoising\", \"membrane\", \"fluorescence\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.Flywing","title":"<code>Flywing</code>","text":"<p>               Bases: <code>PortfolioEntry</code></p> <p>Flywing dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class Flywing(PortfolioEntry):\n    \"\"\"Flywing dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"Flywing\",\n            url=\"https://download.fht.org/jug/n2v/flywing-data.zip\",\n            file_name=\"flywing-data.zip\",\n            sha256=\"01106b6dc096c423babfca47ef27059a01c2ca053769da06e8649381089a559f\",\n            description=\"Image of a membrane-labeled fly wing (35x692x520 pixels).\",\n            license=\"CC-BY-4.0\",\n            citation=\"Buchholz, T.O., Prakash, M., Schmidt, D., Krull, A., Jug, \"\n            \"F.: Denoiseg: joint denoising and segmentation. In: European \"\n            \"Conference on Computer Vision (ECCV). pp. 324-337. Springer (2020) 8, 9\",\n            size=10.2,\n            tags=[\"denoising\", \"membrane\", \"fluorescence\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.N2N_SEM","title":"<code>N2N_SEM</code>","text":"<p>               Bases: <code>PortfolioEntry</code></p> <p>SEM dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class N2N_SEM(PortfolioEntry):\n    \"\"\"SEM dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"N2N_SEM\",\n            url=\"https://download.fht.org/jug/n2n/SEM.zip\",\n            file_name=\"SEM.zip\",\n            sha256=\"03aca31eac4d00a8381577579de2d48b98c77bab91e2f8f925999ec3252d0dac\",\n            description=\"SEM dataset from T.-O. Buchholz et al \"\n            \"(Methods Cell Biol, 2020).\",\n            license=\"CC-BY-4.0\",\n            citation=\"T.-O. Buchholz, A. Krull, R. Shahidi, G. Pigino, G. J\u00e9kely, \"\n            'F. Jug, \"Content-aware image restoration for electron '\n            'microscopy\", Methods Cell Biol 152, 277-289',\n            size=172.7,\n            tags=[\"denoising\", \"electron microscopy\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.N2V_BSD68","title":"<code>N2V_BSD68</code>","text":"<p>               Bases: <code>PortfolioEntry</code></p> <p>BSD68 dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class N2V_BSD68(PortfolioEntry):\n    \"\"\"BSD68 dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"N2V_BSD68\",\n            url=\"https://download.fht.org/jug/n2v/BSD68_reproducibility_data.zip\",\n            file_name=\"BSD68_reproducibility_data.zip\",\n            sha256=\"32c66d41196c9cafff465f3c7c42730f851c24766f70383672e18b8832ea8e55\",\n            description=\"This dataset is taken from K. Zhang et al (TIP, 2017). \\n\"\n            \"It consists of 400 gray-scale 180x180 images (cropped from the \"\n            \"BSD dataset) and splitted between training and validation, and \"\n            \"68 gray-scale test images (BSD68).\\n\"\n            \"All images were corrupted with Gaussian noise with standard \"\n            \"deviation of 25 pixels. The test dataset contains the uncorrupted \"\n            \"images as well.\\n\"\n            \"Original dataset: \"\n            \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/\",\n            license=\"Unknown\",\n            citation='D. Martin, C. Fowlkes, D. Tal and J. Malik, \"A database of '\n            \"human segmented natural images and its application to \"\n            \"evaluating segmentation algorithms and measuring ecological \"\n            'statistics,\" Proceedings Eighth IEEE International '\n            \"Conference on Computer Vision. ICCV 2001, Vancouver, BC, \"\n            \"Canada, 2001, pp. 416-423 vol.2, doi: \"\n            \"10.1109/ICCV.2001.937655.\",\n            size=395.0,\n            tags=[\"denoising\", \"natural images\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.N2V_RGB","title":"<code>N2V_RGB</code>","text":"<p>               Bases: <code>PortfolioEntry</code></p> <p>RGB dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class N2V_RGB(PortfolioEntry):\n    \"\"\"RGB dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"N2V_RGB\",\n            url=\"https://download.fht.org/jug/n2v/RGB.zip\",\n            file_name=\"RGB.zip\",\n            sha256=\"4c2010c6b5c253d3a580afe744cbff969d387617c9dde29fea4463636d285657\",\n            description=\"Banner of the CVPR 2019 conference with extra noise.\",\n            license=\"CC-BY-4.0\",\n            citation='A. Krull, T.-O. Buchholz and F. Jug, \"Noise2Void - Learning '\n            'Denoising From Single Noisy Images,\" 2019 IEEE/CVF '\n            \"Conference on Computer Vision and Pattern Recognition (CVPR),\"\n            \" 2019, pp. 2124-2132\",\n            size=10.4,\n            tags=[\"denoising\", \"natural images\", \"RGB\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/denoising_datasets/#careamics_portfolio.denoising_datasets.N2V_SEM","title":"<code>N2V_SEM</code>","text":"<p>               Bases: <code>PortfolioEntry</code></p> <p>SEM dataset.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/denoising_datasets.py</code> <pre><code>class N2V_SEM(PortfolioEntry):\n    \"\"\"SEM dataset.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=DENOISING,\n            name=\"N2V_SEM\",\n            url=\"https://download.fht.org/jug/n2v/SEM.zip\",\n            file_name=\"SEM.zip\",\n            sha256=\"7600a17c3dbd4992ea547be12458640c21e797eef6a9f776f36ba5890f26855d\",\n            description=\"Cropped images from a SEM dataset from T.-O. Buchholz et al \"\n            \"(Methods Cell Biol, 2020).\",\n            license=\"CC-BY-4.0\",\n            citation=\"T.-O. Buchholz, A. Krull, R. Shahidi, G. Pigino, G. J\u00e9kely, \"\n            'F. Jug, \"Content-aware image restoration for electron '\n            'microscopy\", Methods Cell Biol 152, 277-289',\n            size=13.0,\n            tags=[\"denoising\", \"electron microscopy\"],\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/","title":"portfolio","text":""},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg","title":"<code>DenoiSeg</code>","text":"<p>               Bases: <code>IterablePortfolio</code></p> <p>An IterablePortfolio of DenoiSeg datasets.</p> <p>Attributes:</p> Name Type Description <code>DSB2018_n0 (DSB2018)</code> <code>DSB2018 dataset with noise level 0.</code> <p>DSB2018_n10 (DSB2018): DSB2018 dataset with noise level 10. DSB2018_n20 (DSB2018): DSB2018 dataset with noise level 20. Flywing_n0 (SegFlywing): Flywing dataset with noise level 0. Flywing_n10 (SegFlywing): Flywing dataset with noise level 10. Flywing_n20 (SegFlywing): Flywing dataset with noise level 20. MouseNuclei_n0 (MouseNuclei): MouseNuclei dataset with noise level 0. MouseNuclei_n10 (MouseNuclei): MouseNuclei dataset with noise level 10. MouseNuclei_n20 (MouseNuclei): MouseNuclei dataset with noise level 20.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>class DenoiSeg(IterablePortfolio):\n    \"\"\"An IterablePortfolio of DenoiSeg datasets.\n\n    Attributes\n    ----------\n        DSB2018_n0 (DSB2018): DSB2018 dataset with noise level 0.\n        DSB2018_n10 (DSB2018): DSB2018 dataset with noise level 10.\n        DSB2018_n20 (DSB2018): DSB2018 dataset with noise level 20.\n        Flywing_n0 (SegFlywing): Flywing dataset with noise level 0.\n        Flywing_n10 (SegFlywing): Flywing dataset with noise level 10.\n        Flywing_n20 (SegFlywing): Flywing dataset with noise level 20.\n        MouseNuclei_n0 (MouseNuclei): MouseNuclei dataset with noise level 0.\n        MouseNuclei_n10 (MouseNuclei): MouseNuclei dataset with noise level 10.\n        MouseNuclei_n20 (MouseNuclei): MouseNuclei dataset with noise level 20.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._DSB2018_n0 = DSB2018(NoiseLevel.N0)\n        self._DSB2018_n10 = DSB2018(NoiseLevel.N10)\n        self._DSB2018_n20 = DSB2018(NoiseLevel.N20)\n        self._SegFlywing_n0 = SegFlywing(NoiseLevel.N0)\n        self._SegFlywing_n10 = SegFlywing(NoiseLevel.N10)\n        self._SegFlywing_n20 = SegFlywing(NoiseLevel.N20)\n        self._MouseNuclei_n0 = MouseNuclei(NoiseLevel.N0)\n        self._MouseNuclei_n10 = MouseNuclei(NoiseLevel.N10)\n        self._MouseNuclei_n20 = MouseNuclei(NoiseLevel.N20)\n\n        super().__init__(DENOISEG)\n\n    @property\n    def DSB2018_n0(self) -&gt; DSB2018:\n        \"\"\"DSB2018 dataset with noise level 0.\n\n        Returns\n        -------\n        DSB2018\n            DSB2018 dataset with noise level 0.\n        \"\"\"\n        return self._DSB2018_n0\n\n    @property\n    def DSB2018_n10(self) -&gt; DSB2018:\n        \"\"\"DSB2018 dataset with noise level 10.\n\n        Returns\n        -------\n        DSB2018\n            DSB2018 dataset with noise level 10.\n        \"\"\"\n        return self._DSB2018_n10\n\n    @property\n    def DSB2018_n20(self) -&gt; DSB2018:\n        \"\"\"DSB2018 dataset with noise level 20.\n\n        Returns\n        -------\n        DSB2018\n            DSB2018 dataset with noise level 20.\n        \"\"\"\n        return self._DSB2018_n20\n\n    @property\n    def Flywing_n0(self) -&gt; SegFlywing:\n        \"\"\"Flywing dataset with noise level 0.\n\n        Returns\n        -------\n        SegFlywing\n            Flywing dataset with noise level 0.\n        \"\"\"\n        return self._SegFlywing_n0\n\n    @property\n    def Flywing_n10(self) -&gt; SegFlywing:\n        \"\"\"Flywing dataset with noise level 10.\n\n        Returns\n        -------\n        SegFlywing\n            Flywing dataset with noise level 10.\n        \"\"\"\n        return self._SegFlywing_n10\n\n    @property\n    def Flywing_n20(self) -&gt; SegFlywing:\n        \"\"\"Flywing dataset with noise level 20.\n\n        Returns\n        -------\n        SegFlywing\n            Flywing dataset with noise level 20.\n        \"\"\"\n        return self._SegFlywing_n20\n\n    @property\n    def MouseNuclei_n0(self) -&gt; MouseNuclei:\n        \"\"\"MouseNuclei dataset with noise level 0.\n\n        Returns\n        -------\n        MouseNuclei\n            MouseNuclei dataset with noise level 0.\n        \"\"\"\n        return self._MouseNuclei_n0\n\n    @property\n    def MouseNuclei_n10(self) -&gt; MouseNuclei:\n        \"\"\"MouseNuclei dataset with noise level 10.\n\n        Returns\n        -------\n        MouseNuclei\n            MouseNuclei dataset with noise level 10.\n        \"\"\"\n        return self._MouseNuclei_n10\n\n    @property\n    def MouseNuclei_n20(self) -&gt; MouseNuclei:\n        \"\"\"MouseNuclei dataset with noise level 20.\n\n        Returns\n        -------\n        MouseNuclei\n            MouseNuclei dataset with noise level 20.\n        \"\"\"\n        return self._MouseNuclei_n20\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.DSB2018_n0","title":"<code>DSB2018_n0: DSB2018</code>  <code>property</code>","text":"<p>DSB2018 dataset with noise level 0.</p> <p>Returns:</p> Type Description <code>DSB2018</code> <p>DSB2018 dataset with noise level 0.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.DSB2018_n10","title":"<code>DSB2018_n10: DSB2018</code>  <code>property</code>","text":"<p>DSB2018 dataset with noise level 10.</p> <p>Returns:</p> Type Description <code>DSB2018</code> <p>DSB2018 dataset with noise level 10.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.DSB2018_n20","title":"<code>DSB2018_n20: DSB2018</code>  <code>property</code>","text":"<p>DSB2018 dataset with noise level 20.</p> <p>Returns:</p> Type Description <code>DSB2018</code> <p>DSB2018 dataset with noise level 20.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.Flywing_n0","title":"<code>Flywing_n0: SegFlywing</code>  <code>property</code>","text":"<p>Flywing dataset with noise level 0.</p> <p>Returns:</p> Type Description <code>SegFlywing</code> <p>Flywing dataset with noise level 0.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.Flywing_n10","title":"<code>Flywing_n10: SegFlywing</code>  <code>property</code>","text":"<p>Flywing dataset with noise level 10.</p> <p>Returns:</p> Type Description <code>SegFlywing</code> <p>Flywing dataset with noise level 10.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.Flywing_n20","title":"<code>Flywing_n20: SegFlywing</code>  <code>property</code>","text":"<p>Flywing dataset with noise level 20.</p> <p>Returns:</p> Type Description <code>SegFlywing</code> <p>Flywing dataset with noise level 20.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.MouseNuclei_n0","title":"<code>MouseNuclei_n0: MouseNuclei</code>  <code>property</code>","text":"<p>MouseNuclei dataset with noise level 0.</p> <p>Returns:</p> Type Description <code>MouseNuclei</code> <p>MouseNuclei dataset with noise level 0.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.MouseNuclei_n10","title":"<code>MouseNuclei_n10: MouseNuclei</code>  <code>property</code>","text":"<p>MouseNuclei dataset with noise level 10.</p> <p>Returns:</p> Type Description <code>MouseNuclei</code> <p>MouseNuclei dataset with noise level 10.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.DenoiSeg.MouseNuclei_n20","title":"<code>MouseNuclei_n20: MouseNuclei</code>  <code>property</code>","text":"<p>MouseNuclei dataset with noise level 20.</p> <p>Returns:</p> Type Description <code>MouseNuclei</code> <p>MouseNuclei dataset with noise level 20.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising","title":"<code>Denoising</code>","text":"<p>               Bases: <code>IterablePortfolio</code></p> <p>An IterablePortfolio of denoising datasets.</p> <p>Attributes:</p> Name Type Description <code>N2V_BSD68 (N2V_BSD68)</code> <code>BSD68 dataset.</code> <code>N2V_SEM (N2V_SEM)</code> <code>SEM dataset.</code> <code>N2V_RGB (N2V_RGB)</code> <code>RGB dataset.</code> <code>flywing (Flywing)</code> <code>Flywing dataset.</code> <code>Convallaria (Convallaria)</code> <code>Convallaria dataset.</code> <code>CARE_U2OS (CARE_U2OS)</code> <code>CARE_U2OS dataset.</code> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>class Denoising(IterablePortfolio):\n    \"\"\"An IterablePortfolio of denoising datasets.\n\n    Attributes\n    ----------\n    N2V_BSD68 (N2V_BSD68): BSD68 dataset.\n    N2V_SEM (N2V_SEM): SEM dataset.\n    N2V_RGB (N2V_RGB): RGB dataset.\n    flywing (Flywing): Flywing dataset.\n    Convallaria (Convallaria): Convallaria dataset.\n    CARE_U2OS (CARE_U2OS): CARE_U2OS dataset.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._N2N_SEM = N2N_SEM()\n        self._N2V_BSD68 = N2V_BSD68()\n        self._N2V_SEM = N2V_SEM()\n        self._N2V_RGB = N2V_RGB()\n        self._flywing = Flywing()\n        self._Convallaria = Convallaria()\n        self._CARE_U2OS = CARE_U2OS()\n\n        super().__init__(DENOISING)\n\n    @property\n    def N2N_SEM(self) -&gt; N2N_SEM:\n        \"\"\"SEM dataset.\n\n        Returns\n        -------\n        N2N_SEM\n            SEM dataset.\n        \"\"\"\n        return self._N2N_SEM\n\n    @property\n    def N2V_BSD68(self) -&gt; N2V_BSD68:\n        \"\"\"BSD68 dataset.\n\n        Returns\n        -------\n        N2V_BSD68\n            BSD68 dataset.\n        \"\"\"\n        return self._N2V_BSD68\n\n    @property\n    def N2V_SEM(self) -&gt; N2V_SEM:\n        \"\"\"SEM dataset.\n\n        Returns\n        -------\n        N2V_SEM\n            SEM dataset.\n        \"\"\"\n        return self._N2V_SEM\n\n    @property\n    def N2V_RGB(self) -&gt; N2V_RGB:\n        \"\"\"RGB dataset.\n\n        Returns\n        -------\n        N2V_RGB\n            RGB dataset.\n        \"\"\"\n        return self._N2V_RGB\n\n    @property\n    def Flywing(self) -&gt; Flywing:\n        \"\"\"Flywing dataset.\n\n        Returns\n        -------\n        Flywing\n            Flywing dataset.\n        \"\"\"\n        return self._flywing\n\n    @property\n    def Convallaria(self) -&gt; Convallaria:\n        \"\"\"Convallaria dataset.\n\n        Returns\n        -------\n        Convallaria\n            Convallaria dataset.\n        \"\"\"\n        return self._Convallaria\n\n    @property\n    def CARE_U2OS(self) -&gt; CARE_U2OS:\n        \"\"\"CARE_U2OS dataset.\n\n        Returns\n        -------\n        CARE_U2OS\n            CARE_U2OS dataset.\n        \"\"\"\n        return self._CARE_U2OS\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.CARE_U2OS","title":"<code>CARE_U2OS: CARE_U2OS</code>  <code>property</code>","text":"<p>CARE_U2OS dataset.</p> <p>Returns:</p> Type Description <code>CARE_U2OS</code> <p>CARE_U2OS dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.Convallaria","title":"<code>Convallaria: Convallaria</code>  <code>property</code>","text":"<p>Convallaria dataset.</p> <p>Returns:</p> Type Description <code>Convallaria</code> <p>Convallaria dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.Flywing","title":"<code>Flywing: Flywing</code>  <code>property</code>","text":"<p>Flywing dataset.</p> <p>Returns:</p> Type Description <code>Flywing</code> <p>Flywing dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.N2N_SEM","title":"<code>N2N_SEM: N2N_SEM</code>  <code>property</code>","text":"<p>SEM dataset.</p> <p>Returns:</p> Type Description <code>N2N_SEM</code> <p>SEM dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.N2V_BSD68","title":"<code>N2V_BSD68: N2V_BSD68</code>  <code>property</code>","text":"<p>BSD68 dataset.</p> <p>Returns:</p> Type Description <code>N2V_BSD68</code> <p>BSD68 dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.N2V_RGB","title":"<code>N2V_RGB: N2V_RGB</code>  <code>property</code>","text":"<p>RGB dataset.</p> <p>Returns:</p> Type Description <code>N2V_RGB</code> <p>RGB dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.Denoising.N2V_SEM","title":"<code>N2V_SEM: N2V_SEM</code>  <code>property</code>","text":"<p>SEM dataset.</p> <p>Returns:</p> Type Description <code>N2V_SEM</code> <p>SEM dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.ItarablePortfolioEncoder","title":"<code>ItarablePortfolioEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>Portfolio encoder class.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>class ItarablePortfolioEncoder(JSONEncoder):\n    \"\"\"Portfolio encoder class.\"\"\"\n\n    def default(self, o: IterablePortfolio) -&gt; dict[str, dict[str, str]]:\n        \"\"\"Default method for json export.\n\n        Parameters\n        ----------\n        o : IterablePortfolio\n            Portfolio to export.\n\n        Returns\n        -------\n        dict[str, str]\n            Dictionary representation of the portfolio.\n        \"\"\"\n        return o.as_dict()\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.ItarablePortfolioEncoder.default","title":"<code>default(o)</code>","text":"<p>Default method for json export.</p> <p>Parameters:</p> Name Type Description Default <code>o</code> <code>IterablePortfolio</code> <p>Portfolio to export.</p> required <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary representation of the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def default(self, o: IterablePortfolio) -&gt; dict[str, dict[str, str]]:\n    \"\"\"Default method for json export.\n\n    Parameters\n    ----------\n    o : IterablePortfolio\n        Portfolio to export.\n\n    Returns\n    -------\n    dict[str, str]\n        Dictionary representation of the portfolio.\n    \"\"\"\n    return o.as_dict()\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio","title":"<code>IterablePortfolio</code>","text":"<p>Iterable portfolio class.</p> <p>Subclass this class and add PortfolioEntry objects as attributes.</p> <p>Attributes:</p> Name Type Description <code>_name</code> <code>str</code> <p>Name of the portfolio.</p> <code>_datasets</code> <code>List[PortfolioEntry]</code> <p>List of datasets in the portfolio.</p> <code>_current_index</code> <code>int</code> <code>Current index of the iterator.</code> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>class IterablePortfolio:\n    \"\"\"Iterable portfolio class.\n\n    Subclass this class and add PortfolioEntry objects as attributes.\n\n\n    Attributes\n    ----------\n    _name : str\n        Name of the portfolio.\n    _datasets : List[PortfolioEntry]\n        List of datasets in the portfolio.\n    _current_index : int\n    Current index of the iterator.\n    \"\"\"\n\n    def __init__(self, name: str) -&gt; None:\n        self._name = name\n\n        # create list of datasets\n        datasets = []\n        for dataset in vars(self).values():\n            if isinstance(dataset, PortfolioEntry):\n                datasets.append(dataset)\n\n        # record datasets\n        self._datasets = datasets\n        self._current_index = 0\n\n    def __iter__(self) -&gt; IterablePortfolio:\n        \"\"\"Iterator method.\n\n        Returns\n        -------\n        IterablePortfolio\n            Iterator over the portfolio.\n        \"\"\"\n        return self\n\n    def __next__(self) -&gt; PortfolioEntry:\n        \"\"\"Next method.\n\n        Returns\n        -------\n        PortfolioEntry\n            Next dataset in the portfolio.\n        \"\"\"\n        if self._current_index &lt; len(self._datasets):\n            next_dataset = self._datasets[self._current_index]\n            self._current_index += 1\n            return next_dataset\n        raise StopIteration(\"The iterator does not have any more elements.\")\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Name of the portfolio.\n\n        Returns\n        -------\n        str\n            Name of the portfolio.\n        \"\"\"\n        return self._name\n\n    def list_datasets(self) -&gt; list[str]:\n        \"\"\"List datasets in the portfolio using friendly names.\n\n        The friendly names are the names of the portfolio entries, rather\n        than that of the IterablePortfolio attributes.\n\n        Returns\n        -------\n        list[str]\n            List of datasets in the portfolio.\n        \"\"\"\n        attributes = []\n\n        # for each attribute\n        for attribute in vars(self).values():\n            if isinstance(attribute, PortfolioEntry):\n                attributes.append(attribute.name)\n\n        return attributes\n\n    def as_dict(self) -&gt; dict:\n        \"\"\"Dictionary representation of a portfolio.\n\n        Used to serialize the class to json, with friendly names as entries.\n\n        Returns\n        -------\n        dict[str]\n            Dictionary representation of the DenoiSeg portfolio.\n        \"\"\"\n        entries = {}\n\n        # for each attribute\n        for attribute in vars(self).values():\n            # if the attribute is a PortfolioEntry\n            if isinstance(attribute, PortfolioEntry):\n                # add the attribute to the entries dictionary\n                entries[attribute.name] = {\n                    \"URL\": attribute.url,\n                    \"Description\": attribute.description,\n                    \"Citation\": attribute.citation,\n                    \"License\": attribute.license,\n                    \"Hash\": attribute.hash,\n                    \"File size\": f\"{attribute.size} MB\",\n                    \"Tags\": attribute.tags,\n                }\n        return entries\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of a portfolio.\n\n        Returns\n        -------\n        str\n        String representation of a portfolio.\n        \"\"\"\n        return f\"{self.name} datasets: {self.list_datasets()}\"\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.name","title":"<code>name: str</code>  <code>property</code>","text":"<p>Name of the portfolio.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the portfolio.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterator method.</p> <p>Returns:</p> Type Description <code>IterablePortfolio</code> <p>Iterator over the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def __iter__(self) -&gt; IterablePortfolio:\n    \"\"\"Iterator method.\n\n    Returns\n    -------\n    IterablePortfolio\n        Iterator over the portfolio.\n    \"\"\"\n    return self\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.__next__","title":"<code>__next__()</code>","text":"<p>Next method.</p> <p>Returns:</p> Type Description <code>PortfolioEntry</code> <p>Next dataset in the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def __next__(self) -&gt; PortfolioEntry:\n    \"\"\"Next method.\n\n    Returns\n    -------\n    PortfolioEntry\n        Next dataset in the portfolio.\n    \"\"\"\n    if self._current_index &lt; len(self._datasets):\n        next_dataset = self._datasets[self._current_index]\n        self._current_index += 1\n        return next_dataset\n    raise StopIteration(\"The iterator does not have any more elements.\")\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.__str__","title":"<code>__str__()</code>","text":"<p>String representation of a portfolio.</p> <p>Returns:</p> Type Description <code>str</code> <code>String representation of a portfolio.</code> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of a portfolio.\n\n    Returns\n    -------\n    str\n    String representation of a portfolio.\n    \"\"\"\n    return f\"{self.name} datasets: {self.list_datasets()}\"\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.as_dict","title":"<code>as_dict()</code>","text":"<p>Dictionary representation of a portfolio.</p> <p>Used to serialize the class to json, with friendly names as entries.</p> <p>Returns:</p> Type Description <code>dict[str]</code> <p>Dictionary representation of the DenoiSeg portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def as_dict(self) -&gt; dict:\n    \"\"\"Dictionary representation of a portfolio.\n\n    Used to serialize the class to json, with friendly names as entries.\n\n    Returns\n    -------\n    dict[str]\n        Dictionary representation of the DenoiSeg portfolio.\n    \"\"\"\n    entries = {}\n\n    # for each attribute\n    for attribute in vars(self).values():\n        # if the attribute is a PortfolioEntry\n        if isinstance(attribute, PortfolioEntry):\n            # add the attribute to the entries dictionary\n            entries[attribute.name] = {\n                \"URL\": attribute.url,\n                \"Description\": attribute.description,\n                \"Citation\": attribute.citation,\n                \"License\": attribute.license,\n                \"Hash\": attribute.hash,\n                \"File size\": f\"{attribute.size} MB\",\n                \"Tags\": attribute.tags,\n            }\n    return entries\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.IterablePortfolio.list_datasets","title":"<code>list_datasets()</code>","text":"<p>List datasets in the portfolio using friendly names.</p> <p>The friendly names are the names of the portfolio entries, rather than that of the IterablePortfolio attributes.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of datasets in the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def list_datasets(self) -&gt; list[str]:\n    \"\"\"List datasets in the portfolio using friendly names.\n\n    The friendly names are the names of the portfolio entries, rather\n    than that of the IterablePortfolio attributes.\n\n    Returns\n    -------\n    list[str]\n        List of datasets in the portfolio.\n    \"\"\"\n    attributes = []\n\n    # for each attribute\n    for attribute in vars(self).values():\n        if isinstance(attribute, PortfolioEntry):\n            attributes.append(attribute.name)\n\n    return attributes\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager","title":"<code>PortfolioManager</code>  <code>dataclass</code>","text":"<p>Portfolio of datasets.</p> <p>Attributes:</p> Name Type Description <code>denoising (Denoising)</code> <code>Denoising datasets.</code> <code>denoiseg (DenoiSeg)</code> <code>DenoiSeg datasets.</code> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>@dataclass\nclass PortfolioManager:\n    \"\"\"Portfolio of datasets.\n\n    Attributes\n    ----------\n    denoising (Denoising): Denoising datasets.\n    denoiseg (DenoiSeg): DenoiSeg datasets.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._denoising = Denoising()\n        self._denoiseg = DenoiSeg()\n        # self._segmentation = Segmentation()\n\n    @property\n    def denoising(self) -&gt; Denoising:\n        \"\"\"Denoising datasets.\n\n        Returns\n        -------\n        Denoising\n            Denoising datasets.\n        \"\"\"\n        return self._denoising\n\n    @property\n    def denoiseg(self) -&gt; DenoiSeg:\n        \"\"\"DenoiSeg datasets.\n\n        Returns\n        -------\n        DenoiSeg\n            DenoiSeg datasets.\n        \"\"\"\n        return self._denoiseg\n\n    def __str__(self) -&gt; str:\n        \"\"\"String representation of the portfolio.\n\n        This method allows having a frendly representation of the portfolio as string.\n\n        Returns\n        -------\n        str\n            String representation of the portfolio.\n        \"\"\"\n        return (\n            f\"Portfolio:\\n\"\n            f\"Denoising datasets: {self.denoising.list_datasets()}\\n\"\n            f\"DenoiSeg datasets: {self.denoiseg.list_datasets()}\"\n        )\n\n    def as_dict(self) -&gt; dict[str, IterablePortfolio]:\n        \"\"\"Portfolio as dictionary.\n\n        This method is used during json serialization to maintain human readable\n        keys.\n\n        Returns\n        -------\n        dict[str, IterablePortfolio]\n            Portfolio as dictionary.\n        \"\"\"\n        attributes = {}\n\n        for attribute in vars(self).values():\n            if isinstance(attribute, IterablePortfolio):\n                attributes[attribute.name] = attribute\n\n        return attributes\n\n    def to_json(self, path: str | Path) -&gt; None:\n        \"\"\"Save portfolio to json file using the `as_dict` method.\n\n        Parameters\n        ----------\n        path : str or Path\n            Path to json file.\n        \"\"\"\n        with open(path, \"w\") as f:\n            json.dump(self.as_dict(), f, indent=4, cls=ItarablePortfolioEncoder)\n\n    def to_registry(self, path: str | Path) -&gt; None:\n        \"\"\"Save portfolio as registry (Pooch).\n\n        See: https://www.fatiando.org/pooch/latest/registry-files.html\n\n        Parameters\n        ----------\n        path : str or Path\n            Path to json file.\n        \"\"\"\n        portfolios = self.as_dict()\n        with open(path, \"w\") as file:\n            file.write(\"# Portfolio datasets - pooch registry\\n\")\n            file.write(\"# Generated by running \" \"scripts/update_registry.py\\n\\n\")\n\n            # write each portfolio\n            for key in portfolios.keys():\n                file.write(f\"# {key} \\n\")\n                for entry in portfolios[key]:\n                    file.write(\n                        f\"{entry.get_registry_name()} \" f\"{entry.hash} {entry.url}\\n\"\n                    )\n                file.write(\"\\n\")\n\n            # add pale blue dot for testing purposes\n            file.write(\"# Test sample\\n\")\n            pale_blue_dot = PaleBlueDot()\n            file.write(\n                f\"{pale_blue_dot.get_registry_name()} \"\n                f\"{pale_blue_dot.hash} {pale_blue_dot.url}\\n\"\n            )\n            pale_blue_dot_zip = PaleBlueDotZip()\n            file.write(\n                f\"{pale_blue_dot_zip.get_registry_name()} \"\n                f\"{pale_blue_dot_zip.hash} {pale_blue_dot_zip.url}\\n\"\n            )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.denoiseg","title":"<code>denoiseg: DenoiSeg</code>  <code>property</code>","text":"<p>DenoiSeg datasets.</p> <p>Returns:</p> Type Description <code>DenoiSeg</code> <p>DenoiSeg datasets.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.denoising","title":"<code>denoising: Denoising</code>  <code>property</code>","text":"<p>Denoising datasets.</p> <p>Returns:</p> Type Description <code>Denoising</code> <p>Denoising datasets.</p>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.__str__","title":"<code>__str__()</code>","text":"<p>String representation of the portfolio.</p> <p>This method allows having a frendly representation of the portfolio as string.</p> <p>Returns:</p> Type Description <code>str</code> <p>String representation of the portfolio.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"String representation of the portfolio.\n\n    This method allows having a frendly representation of the portfolio as string.\n\n    Returns\n    -------\n    str\n        String representation of the portfolio.\n    \"\"\"\n    return (\n        f\"Portfolio:\\n\"\n        f\"Denoising datasets: {self.denoising.list_datasets()}\\n\"\n        f\"DenoiSeg datasets: {self.denoiseg.list_datasets()}\"\n    )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.as_dict","title":"<code>as_dict()</code>","text":"<p>Portfolio as dictionary.</p> <p>This method is used during json serialization to maintain human readable keys.</p> <p>Returns:</p> Type Description <code>dict[str, IterablePortfolio]</code> <p>Portfolio as dictionary.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def as_dict(self) -&gt; dict[str, IterablePortfolio]:\n    \"\"\"Portfolio as dictionary.\n\n    This method is used during json serialization to maintain human readable\n    keys.\n\n    Returns\n    -------\n    dict[str, IterablePortfolio]\n        Portfolio as dictionary.\n    \"\"\"\n    attributes = {}\n\n    for attribute in vars(self).values():\n        if isinstance(attribute, IterablePortfolio):\n            attributes[attribute.name] = attribute\n\n    return attributes\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.to_json","title":"<code>to_json(path)</code>","text":"<p>Save portfolio to json file using the <code>as_dict</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Path to json file.</p> required Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def to_json(self, path: str | Path) -&gt; None:\n    \"\"\"Save portfolio to json file using the `as_dict` method.\n\n    Parameters\n    ----------\n    path : str or Path\n        Path to json file.\n    \"\"\"\n    with open(path, \"w\") as f:\n        json.dump(self.as_dict(), f, indent=4, cls=ItarablePortfolioEncoder)\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.PortfolioManager.to_registry","title":"<code>to_registry(path)</code>","text":"<p>Save portfolio as registry (Pooch).</p> <p>See: https://www.fatiando.org/pooch/latest/registry-files.html</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str or Path</code> <p>Path to json file.</p> required Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def to_registry(self, path: str | Path) -&gt; None:\n    \"\"\"Save portfolio as registry (Pooch).\n\n    See: https://www.fatiando.org/pooch/latest/registry-files.html\n\n    Parameters\n    ----------\n    path : str or Path\n        Path to json file.\n    \"\"\"\n    portfolios = self.as_dict()\n    with open(path, \"w\") as file:\n        file.write(\"# Portfolio datasets - pooch registry\\n\")\n        file.write(\"# Generated by running \" \"scripts/update_registry.py\\n\\n\")\n\n        # write each portfolio\n        for key in portfolios.keys():\n            file.write(f\"# {key} \\n\")\n            for entry in portfolios[key]:\n                file.write(\n                    f\"{entry.get_registry_name()} \" f\"{entry.hash} {entry.url}\\n\"\n                )\n            file.write(\"\\n\")\n\n        # add pale blue dot for testing purposes\n        file.write(\"# Test sample\\n\")\n        pale_blue_dot = PaleBlueDot()\n        file.write(\n            f\"{pale_blue_dot.get_registry_name()} \"\n            f\"{pale_blue_dot.hash} {pale_blue_dot.url}\\n\"\n        )\n        pale_blue_dot_zip = PaleBlueDotZip()\n        file.write(\n            f\"{pale_blue_dot_zip.get_registry_name()} \"\n            f\"{pale_blue_dot_zip.hash} {pale_blue_dot_zip.url}\\n\"\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio/#careamics_portfolio.portfolio.update_registry","title":"<code>update_registry(path=None)</code>","text":"<p>Update the registry.txt file.</p> Source code in <code>src/careamics_portfolio/portfolio.py</code> <pre><code>def update_registry(path: str | Path | None = None) -&gt; None:\n    \"\"\"Update the registry.txt file.\"\"\"\n    if path is None:\n        path = get_registry_path()\n\n    portfolio = PortfolioManager()\n    portfolio.to_registry(path)\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/","title":"portfolio_entry","text":""},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry","title":"<code>PortfolioEntry</code>","text":"<p>Base class for portfolio entries.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>class PortfolioEntry:\n    \"\"\"Base class for portfolio entries.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(\n        self,\n        portfolio: str,\n        name: str,\n        url: str,\n        description: str,\n        license: str,\n        citation: str,\n        file_name: str,\n        sha256: str,\n        size: float,\n        tags: List[str],\n        is_zip: bool = True,\n        **kwargs: str,\n    ) -&gt; None:\n        self._portfolio = portfolio\n\n        if \" \" in name:\n            raise ValueError(\"Dataset name cannot contain spaces.\")\n        self._name = name\n\n        self._url = url\n        self._description = description\n        self._license = license\n        self._citation = citation\n        self._file_name = file_name\n        self._hash = sha256\n        self._size = size\n        self._tags = tags\n        self._is_zip = is_zip\n\n    @property\n    def portfolio(self) -&gt; str:\n        \"\"\"Name of the portfolio the dataset belong to.\n\n        Returns\n        -------\n        str\n            Name of the portfolio the dataset belong to.\n        \"\"\"\n        return self._portfolio\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Name of the dataset.\n\n        Returns\n        -------\n        str\n            Name of the dataset.\n        \"\"\"\n        return self._name\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"URL of the dataset.\n\n        Returns\n        -------\n        str\n            URL of the dataset.\n        \"\"\"\n        return self._url\n\n    @property\n    def description(self) -&gt; str:\n        \"\"\"Description of the dataset.\n\n        Returns\n        -------\n        str\n            Description of the dataset.\n        \"\"\"\n        return self._description\n\n    @property\n    def license(self) -&gt; str:\n        \"\"\"License of the dataset.\n\n        Returns\n        -------\n        str\n            License of the dataset.\n        \"\"\"\n        return self._license\n\n    @property\n    def citation(self) -&gt; str:\n        \"\"\"Citation to use when referring to the dataset.\n\n        Returns\n        -------\n        str\n            Citation to use when referring to the dataset.\n        \"\"\"\n        return self._citation\n\n    @property\n    def file_name(self) -&gt; str:\n        \"\"\"Name of the downloaded file.\n\n        Returns\n        -------\n        str\n            Name of the downloaded file.\n        \"\"\"\n        return self._file_name\n\n    @property\n    def hash(self) -&gt; str:\n        \"\"\"SHA256 hash of the downloaded file.\n\n        Returns\n        -------\n        str\n            SHA256 hash of the downloaded file.\n        \"\"\"\n        return self._hash\n\n    @property\n    def size(self) -&gt; float:\n        \"\"\"Size of the dataset in MB.\n\n        Returns\n        -------\n        float\n            Size of the dataset in MB.\n        \"\"\"\n        return self._size\n\n    @property\n    def tags(self) -&gt; List[str]:\n        \"\"\"List of tags associated to the dataset.\n\n        Returns\n        -------\n        List[str]\n            List of tags associated to the dataset.\n        \"\"\"\n        return self._tags\n\n    @property\n    def is_zip(self) -&gt; bool:\n        \"\"\"Whether the dataset is a zip file.\n\n        Returns\n        -------\n        bool\n            Whether the dataset is a zip file.\n        \"\"\"\n        return self._is_zip\n\n    def __str__(self) -&gt; str:\n        \"\"\"Convert PortfolioEntry to a string.\n\n        Returns\n        -------\n        str: A string containing the PortfolioEntry attributes.\n        \"\"\"\n        return str(self.to_dict())\n\n    def get_registry_name(self) -&gt; str:\n        \"\"\"Return the name of the entry in the global registry.\n\n        Returns\n        -------\n        str\n            Name of the entry.\n        \"\"\"\n        return self.portfolio + \"-\" + self.name\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Convert PortfolioEntry to a dictionary.\n\n        Returns\n        -------\n            dict: A dictionary containing the PortfolioEntry attributes.\n        \"\"\"\n        return {\n            \"name\": self.name,\n            \"url\": self.url,\n            \"description\": self.description,\n            \"license\": self.license,\n            \"citation\": self.citation,\n            \"file_name\": self.file_name,\n            \"hash\": self.hash,\n            \"size\": self.size,\n            \"tags\": self.tags,\n        }\n\n    def download(\n        self,\n        path: Optional[Union[str, Path]] = None,\n    ) -&gt; Union[List[str], Any]:\n        \"\"\"Download dataset in the specified path.\n\n        By default the files will be downloaded in the system's cache folder,\n        and can be retrieved using this function without downloading the file\n        anew (thanks pooch!).\n\n        Parameters\n        ----------\n        path : str | Path\n            Path to the folder in which to download the dataset. Defaults to\n            None.\n\n        Returns\n        -------\n        List[str]\n            List of path(s) to the downloaded file(s).\n        \"\"\"\n        poochfolio = get_poochfolio(path)\n\n        # download data\n        if self.is_zip:\n            return poochfolio.fetch(\n                fname=self.get_registry_name(),\n                processor=Unzip(),\n                progressbar=True,\n            )\n        else:\n            return poochfolio.fetch(\n                fname=self.get_registry_name(),\n                progressbar=True,\n            )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.citation","title":"<code>citation: str</code>  <code>property</code>","text":"<p>Citation to use when referring to the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>Citation to use when referring to the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.description","title":"<code>description: str</code>  <code>property</code>","text":"<p>Description of the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>Description of the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.file_name","title":"<code>file_name: str</code>  <code>property</code>","text":"<p>Name of the downloaded file.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the downloaded file.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.hash","title":"<code>hash: str</code>  <code>property</code>","text":"<p>SHA256 hash of the downloaded file.</p> <p>Returns:</p> Type Description <code>str</code> <p>SHA256 hash of the downloaded file.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.is_zip","title":"<code>is_zip: bool</code>  <code>property</code>","text":"<p>Whether the dataset is a zip file.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether the dataset is a zip file.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.license","title":"<code>license: str</code>  <code>property</code>","text":"<p>License of the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>License of the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.name","title":"<code>name: str</code>  <code>property</code>","text":"<p>Name of the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.portfolio","title":"<code>portfolio: str</code>  <code>property</code>","text":"<p>Name of the portfolio the dataset belong to.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the portfolio the dataset belong to.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.size","title":"<code>size: float</code>  <code>property</code>","text":"<p>Size of the dataset in MB.</p> <p>Returns:</p> Type Description <code>float</code> <p>Size of the dataset in MB.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.tags","title":"<code>tags: List[str]</code>  <code>property</code>","text":"<p>List of tags associated to the dataset.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of tags associated to the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.url","title":"<code>url: str</code>  <code>property</code>","text":"<p>URL of the dataset.</p> <p>Returns:</p> Type Description <code>str</code> <p>URL of the dataset.</p>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.__str__","title":"<code>__str__()</code>","text":"<p>Convert PortfolioEntry to a string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>A string containing the PortfolioEntry attributes.</code> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Convert PortfolioEntry to a string.\n\n    Returns\n    -------\n    str: A string containing the PortfolioEntry attributes.\n    \"\"\"\n    return str(self.to_dict())\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.download","title":"<code>download(path=None)</code>","text":"<p>Download dataset in the specified path.</p> <p>By default the files will be downloaded in the system's cache folder, and can be retrieved using this function without downloading the file anew (thanks pooch!).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the folder in which to download the dataset. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of path(s) to the downloaded file(s).</p> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>def download(\n    self,\n    path: Optional[Union[str, Path]] = None,\n) -&gt; Union[List[str], Any]:\n    \"\"\"Download dataset in the specified path.\n\n    By default the files will be downloaded in the system's cache folder,\n    and can be retrieved using this function without downloading the file\n    anew (thanks pooch!).\n\n    Parameters\n    ----------\n    path : str | Path\n        Path to the folder in which to download the dataset. Defaults to\n        None.\n\n    Returns\n    -------\n    List[str]\n        List of path(s) to the downloaded file(s).\n    \"\"\"\n    poochfolio = get_poochfolio(path)\n\n    # download data\n    if self.is_zip:\n        return poochfolio.fetch(\n            fname=self.get_registry_name(),\n            processor=Unzip(),\n            progressbar=True,\n        )\n    else:\n        return poochfolio.fetch(\n            fname=self.get_registry_name(),\n            progressbar=True,\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.get_registry_name","title":"<code>get_registry_name()</code>","text":"<p>Return the name of the entry in the global registry.</p> <p>Returns:</p> Type Description <code>str</code> <p>Name of the entry.</p> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>def get_registry_name(self) -&gt; str:\n    \"\"\"Return the name of the entry in the global registry.\n\n    Returns\n    -------\n    str\n        Name of the entry.\n    \"\"\"\n    return self.portfolio + \"-\" + self.name\n</code></pre>"},{"location":"reference/careamics_portfolio/portfolio_entry/#careamics_portfolio.portfolio_entry.PortfolioEntry.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert PortfolioEntry to a dictionary.</p> <p>Returns:</p> Type Description <code>    dict: A dictionary containing the PortfolioEntry attributes.</code> Source code in <code>src/careamics_portfolio/portfolio_entry.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Convert PortfolioEntry to a dictionary.\n\n    Returns\n    -------\n        dict: A dictionary containing the PortfolioEntry attributes.\n    \"\"\"\n    return {\n        \"name\": self.name,\n        \"url\": self.url,\n        \"description\": self.description,\n        \"license\": self.license,\n        \"citation\": self.citation,\n        \"file_name\": self.file_name,\n        \"hash\": self.hash,\n        \"size\": self.size,\n        \"tags\": self.tags,\n    }\n</code></pre>"},{"location":"reference/careamics_portfolio/utils/download_utils/","title":"download_utils","text":""},{"location":"reference/careamics_portfolio/utils/download_utils/#careamics_portfolio.utils.download_utils.get_poochfolio","title":"<code>get_poochfolio(path=None)</code>","text":"<p>Create the pooch object for the whole portfolio.</p> <p>By default the files will be downloaded and cached in the user's cache folder and can be retrieved automatically without downloading the file anew (thanks pooch!).</p> <p>Attributes:</p> Name Type Description <code>path</code> <code>Path</code> <p>Path to the folder in which to download the dataset. Defaults to None.</p> <p>Returns:</p> Type Description <code>Pooch</code> <p>Pooch object for the whole portfolio.</p> Source code in <code>src/careamics_portfolio/utils/download_utils.py</code> <pre><code>def get_poochfolio(path: Optional[Union[str, Path]] = None) -&gt; Pooch:\n    \"\"\"Create the pooch object for the whole portfolio.\n\n    By default the files will be downloaded and cached in the user's\n    cache folder and can be retrieved automatically without downloading\n    the file anew (thanks pooch!).\n\n\n    Attributes\n    ----------\n    path : Path\n        Path to the folder in which to download the dataset. Defaults to None.\n\n    Returns\n    -------\n    Pooch\n        Pooch object for the whole portfolio.\n\n    \"\"\"\n    if path is None:\n        path = pooch.os_cache(\"portfolio\")\n\n    poochfolio = pooch.create(\n        path=path,\n        base_url=\"\",\n    )\n\n    # Path to the registry.txt file\n    poochfolio.load_registry(get_registry_path())\n\n    return poochfolio\n</code></pre>"},{"location":"reference/careamics_portfolio/utils/download_utils/#careamics_portfolio.utils.download_utils.get_registry_path","title":"<code>get_registry_path()</code>","text":"<p>Get the path to the registry.txt file.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the registry.txt file.</p> Source code in <code>src/careamics_portfolio/utils/download_utils.py</code> <pre><code>def get_registry_path() -&gt; Path:\n    \"\"\"Get the path to the registry.txt file.\n\n    Returns\n    -------\n    Path\n        Path to the registry.txt file.\n    \"\"\"\n    return Path(__file__).parent / \"../registry/registry.txt\"\n</code></pre>"},{"location":"reference/careamics_portfolio/utils/pale_blue_dot/","title":"pale_blue_dot","text":""},{"location":"reference/careamics_portfolio/utils/pale_blue_dot/#careamics_portfolio.utils.pale_blue_dot.PaleBlueDot","title":"<code>PaleBlueDot</code>","text":"<p>               Bases: <code>PortfolioEntry</code></p> <p>The original Pale Blue Dot image.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/utils/pale_blue_dot.py</code> <pre><code>class PaleBlueDot(PortfolioEntry):\n    \"\"\"The original Pale Blue Dot image.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=\"test\",\n            name=\"PaleBlueDot\",\n            url=\"https://download.fht.org/jug/careamics/P36254.jpg\",\n            file_name=\"P36254.jpg\",\n            sha256=\"68d0f037a448dc099e893b8cbf4d303ffa4b4289903c764f737101d6ad7555dd\",\n            description=\"Pale Blue Dot, credit NASA/JPL-Caltech.\"\n            \"Original caption: This narrow-angle color image of the\"\n            \" Earth, dubbed 'Pale Blue Dot', is a part of the first\"\n            \" ever 'portrait' of the solar system taken by Voyager \"\n            \"1. The spacecraft acquired a total of 60 frames for a \"\n            \"mosaic of the solar system from a distance of more \"\n            \"than 4 billion miles from Earth and about 32 degrees \"\n            \"above the ecliptic. From Voyager's great distance \"\n            \"Earth is a mere point of light, less than the size of \"\n            \"a picture element even in the narrow-angle camera. \"\n            \"Earth was a crescent only 0.12 pixel in size. \"\n            \"Coincidentally, Earth lies right in the center of one \"\n            \"of the scattered light rays resulting from taking the \"\n            \"image so close to the sun. This blown-up image of the \"\n            \"Earth was taken through three color filters - violet, \"\n            \"blue and green - and recombined to produce the color \"\n            \"image. The background features in the image are \"\n            \"artifacts resulting from the magnification.\",\n            citation=\"NASA/JPL-Caltech\",\n            license=\"Public domain\",\n            size=0.4,\n            tags=[\"pale blue dot\", \"voyager\", \"nasa\", \"jpl\"],\n            is_zip=False,\n        )\n</code></pre>"},{"location":"reference/careamics_portfolio/utils/pale_blue_dot_zip/","title":"pale_blue_dot_zip","text":""},{"location":"reference/careamics_portfolio/utils/pale_blue_dot_zip/#careamics_portfolio.utils.pale_blue_dot_zip.PaleBlueDotZip","title":"<code>PaleBlueDotZip</code>","text":"<p>               Bases: <code>PortfolioEntry</code></p> <p>The original Pale Blue Dot image.</p> <p>Attributes:</p> Name Type Description <code>portfolio (str)</code> <code>Name of the portfolio to which the dataset belong.</code> <p>name (str): Name of the dataset. url (str): URL of the dataset. description (str): Description of the dataset. license (str): License of the dataset. citation (str): Citation to use when referring to the dataset. file_name (str): Name of the downloaded file. hash (str): SHA256 hash of the downloaded file. size (int): Size of the dataset in MB. tags (list[str]): List of tags associated to the dataset. is_zip (bool): Whether the dataset is a zip file.</p> Source code in <code>src/careamics_portfolio/utils/pale_blue_dot_zip.py</code> <pre><code>class PaleBlueDotZip(PortfolioEntry):\n    \"\"\"The original Pale Blue Dot image.\n\n    Attributes\n    ----------\n        portfolio (str): Name of the portfolio to which the dataset belong.\n        name (str): Name of the dataset.\n        url (str): URL of the dataset.\n        description (str): Description of the dataset.\n        license (str): License of the dataset.\n        citation (str): Citation to use when referring to the dataset.\n        file_name (str): Name of the downloaded file.\n        hash (str): SHA256 hash of the downloaded file.\n        size (int): Size of the dataset in MB.\n        tags (list[str]): List of tags associated to the dataset.\n        is_zip (bool): Whether the dataset is a zip file.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        super().__init__(\n            portfolio=\"test\",\n            name=\"PaleBlueDotZip\",\n            url=\"https://download.fht.org/jug/careamics/pale_blue_dot.zip\",\n            file_name=\"pale_blue_dot.zip\",\n            sha256=\"90b03ec7a9e1980fd112a40c2c935015bb349cdf89fbf3db78c715dd2a49db47\",\n            description=\"Pale Blue Dot, credit NASA/JPL-Caltech.\"\n            \"Original caption: This narrow-angle color image of the\"\n            \" Earth, dubbed 'Pale Blue Dot', is a part of the first\"\n            \" ever 'portrait' of the solar system taken by Voyager \"\n            \"1. The spacecraft acquired a total of 60 frames for a \"\n            \"mosaic of the solar system from a distance of more \"\n            \"than 4 billion miles from Earth and about 32 degrees \"\n            \"above the ecliptic. From Voyager's great distance \"\n            \"Earth is a mere point of light, less than the size of \"\n            \"a picture element even in the narrow-angle camera. \"\n            \"Earth was a crescent only 0.12 pixel in size. \"\n            \"Coincidentally, Earth lies right in the center of one \"\n            \"of the scattered light rays resulting from taking the \"\n            \"image so close to the sun. This blown-up image of the \"\n            \"Earth was taken through three color filters - violet, \"\n            \"blue and green - and recombined to produce the color \"\n            \"image. The background features in the image are \"\n            \"artifacts resulting from the magnification.\",\n            citation=\"NASA/JPL-Caltech\",\n            license=\"Public domain\",\n            size=0.4,\n            tags=[\"pale blue dot\", \"voyager\", \"nasa\", \"jpl\"],\n            is_zip=True,\n        )\n</code></pre>"}]}